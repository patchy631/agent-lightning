{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Agent Lightning","text":"<p>Agent Lightning is the absolute trainer to light up AI agents.</p>"},{"location":"#features","title":"Features","text":"<ul> <li>Turn your agent into an optimizable beast with ZERO CODE CHANGE (almost)! \ud83d\udca4</li> <li>Build with ANY agent framework (LangChain, OpenAI Agent SDK, AutoGen, CrewAI, ...); or even WITHOUT agent framework (Python OpenAI). You name it! \ud83e\udd16</li> <li>Selectively optimize one or more agents in a multi-agent system. \ud83c\udfaf</li> <li>Embraces Reinforcement Learning, Automatic Prompt Optimization and more algorithms. \ud83e\udd17</li> </ul>"},{"location":"#quick-links","title":"Quick Links","text":"<ul> <li>Installation - Get started with Agent Lightning</li> <li>Train First Agent with APO - Learn the fundamentals of Agent Lightning</li> <li>Train SQL Agent with RL - A practical example of training a SQL agent</li> <li>Join our Discord community - Connect with other users and contributors</li> </ul>"},{"location":"#resources","title":"Resources","text":"<ul> <li>8/11/2025 Training AI Agents to Write and Self-correct SQL with Reinforcement Learning Medium.</li> <li>8/5/2025 Agent Lightning: Train ANY AI Agents with Reinforcement Learning arXiv paper.</li> <li>7/26/2025 We discovered an approach to train any AI agent with RL, with (almost) zero code changes. Reddit.</li> <li>6/6/2025 Agent Lightning - Microsoft Research Project page.</li> </ul>"},{"location":"#community-projects","title":"Community Projects","text":"<ul> <li>DeepWerewolf \u2014 A case study of agent RL training for the Chinese Werewolf game built with AgentScope and Agent Lightning.</li> <li>AgentFlow \u2014 A modular multi-agent framework that combines planner, executor, verifier, and generator agents with the Flow-GRPO algorithm to tackle long-horizon, sparse-reward tasks.</li> </ul>"},{"location":"#citation","title":"Citation","text":"<p>If you find Agent Lightning useful in your research or projects, please cite our paper:</p> <pre><code>@misc{luo2025agentlightningtrainai,\n      title={Agent Lightning: Train ANY AI Agents with Reinforcement Learning},\n      author={Xufang Luo and Yuge Zhang and Zhiyuan He and Zilong Wang and Siyun Zhao and Dongsheng Li and Luna K. Qiu and Yuqing Yang},\n      year={2025},\n      eprint={2508.03680},\n      archivePrefix={arXiv},\n      primaryClass={cs.AI},\n      url={https://arxiv.org/abs/2508.03680},\n}\n</code></pre>"},{"location":"#license","title":"License","text":"<p>See the LICENSE file for details.</p>"},{"location":"algorithm-zoo/","title":"Algorithm Zoo","text":"<p>AgentLightning includes several popular and frequently requested algorithms in its built-in library, allowing agent developers to use them directly. These algorithms are designed to be compatible with most agent scenarios.</p> <p>For customizing algorithms, see Algorithm-side References.</p> Algorithm Optimizing Resources Description APO <code>{&lt;initial_prompt_key&gt;: [PromptTemplate][agentlightning.PromptTemplate]}</code> Automatic Prompt Optimization (APO) algorithm using textual gradients and beam search. VERL <code>{\"main_llm\": [LLM][agentlightning.LLM]}</code> Reinforcement Learning with VERL framework."},{"location":"algorithm-zoo/apo/","title":"APO","text":"<p>Shortcut</p> <p>You can use the shortcut <code>agl.APO(...)</code> to create an APO instance.</p> <pre><code>import agentlightning as agl\n\nagl.APO(...)\n</code></pre>"},{"location":"algorithm-zoo/apo/#installation","title":"Installation","text":"<pre><code>pip install agentlightning[apo]\n</code></pre>"},{"location":"algorithm-zoo/apo/#scope-of-current-implementation","title":"Scope of Current Implementation","text":"<p>APO is currently scoped to optimize a single prompt template. Optimizing multiple prompt templates is not supported yet.</p> <p>There is however no restriction on the number of variable placeholders in the prompt template (can range from zero to many). It's possible that invalid prompts are created during the optimization process. It is up to the agent developer to ensure that the prompt template is valid for the agent's task.</p>"},{"location":"algorithm-zoo/apo/#initial-prompt","title":"Initial Prompt","text":"<p>APO expects the initial prompt to be provided in the <code>initial_resources</code> dictionary. This can be done in two approaches:</p> <ol> <li>Pass to the Trainer constructor:</li> </ol> <pre><code>trainer = agl.Trainer(\n    algorithm=agl.APO(...),\n    initial_resources={\"main_prompt\": agl.PromptTemplate(template=\"You are a helpful assistant.\", engine=\"f-string\")},\n)\n</code></pre> <ol> <li>Pass to the <code>[APO][agentlightning.algorithm.apo.APO].set_initial_resources()</code> method:</li> </ol> <pre><code>algo = agl.APO(...)\nalgo.set_initial_resources(\n    {\"this_is_also_valid_key\": agl.PromptTemplate(template=\"You are a helpful assistant.\", engine=\"f-string\")}\n)\n</code></pre> <p>The resource key can be arbitrary, which is used to identify the prompt template in class-based implementations when you have multiple resources. When the key changes, the agent developer needs to update the key in the <code>rollout</code> method.</p>"},{"location":"algorithm-zoo/apo/#tutorials-using-apo","title":"Tutorials Using APO","text":"<ul> <li>Train the First Agent with APO - A step-by-step guide to training your first agent using APO.</li> </ul>"},{"location":"algorithm-zoo/apo/#references","title":"References","text":""},{"location":"algorithm-zoo/apo/#agentlightning.algorithm.apo","title":"<code>agentlightning.algorithm.apo</code>","text":""},{"location":"algorithm-zoo/apo/#agentlightning.algorithm.apo.APO","title":"<code>APO</code>","text":"<p>               Bases: <code>Algorithm</code>, <code>Generic[T_task]</code></p> <p>Automatic Prompt Optimization (APO) algorithm using textual gradients and beam search.</p> <p>APO is an iterative prompt optimization algorithm that uses LLM-generated textual gradients to improve prompts through a beam search process. It evaluates prompts on rollouts, computes critiques based on the results, and applies edits to generate improved prompts.</p> <p>The algorithm operates in rounds, where each round: 1. Samples parent prompts from the current beam 2. Generates new prompts by computing textual gradients and applying edits 3. Evaluates all candidates on a validation set 4. Selects the top-k prompts for the next round</p> <p>Based on the ideas from: - ProTeGi: https://aclanthology.org/2023.emnlp-main.494.pdf - TextGrad: https://github.com/zou-group/textgrad</p> Source code in <code>agentlightning/algorithm/apo/apo.py</code> <pre><code>class APO(Algorithm, Generic[T_task]):\n    \"\"\"Automatic Prompt Optimization (APO) algorithm using textual gradients and beam search.\n\n    APO is an iterative prompt optimization algorithm that uses LLM-generated textual gradients\n    to improve prompts through a beam search process. It evaluates prompts on rollouts,\n    computes critiques based on the results, and applies edits to generate improved prompts.\n\n    The algorithm operates in rounds, where each round:\n    1. Samples parent prompts from the current beam\n    2. Generates new prompts by computing textual gradients and applying edits\n    3. Evaluates all candidates on a validation set\n    4. Selects the top-k prompts for the next round\n\n    Based on the ideas from:\n    - ProTeGi: https://aclanthology.org/2023.emnlp-main.494.pdf\n    - TextGrad: https://github.com/zou-group/textgrad\n    \"\"\"\n\n    def __init__(\n        self,\n        async_openai_client: AsyncOpenAI,\n        *,\n        gradient_model: str = \"gpt-5-mini\",\n        apply_edit_model: str = \"gpt-4.1-mini\",\n        diversity_temperature: float = 1.0,\n        gradient_batch_size: int = 4,\n        val_batch_size: int = 16,\n        beam_width: int = 4,\n        branch_factor: int = 4,\n        beam_rounds: int = 3,\n        rollout_batch_timeout: float = 3600.0,\n        run_initial_validation: bool = True,\n        # Internal flags for debugging\n        _poml_trace: bool = False,\n    ):\n        \"\"\"\n        Initialize the APO algorithm with configuration parameters.\n\n        Args:\n            async_openai_client: AsyncOpenAI client for making LLM API calls.\n            gradient_model: Model name for computing textual gradients (critiques).\n            apply_edit_model: Model name for applying edits based on critiques.\n            diversity_temperature: Temperature parameter for LLM calls to control diversity.\n            gradient_batch_size: Number of rollout results to sample for gradient computation.\n            val_batch_size: Number of validation examples to use for evaluation.\n            beam_width: Number of top-scoring prompts to keep in the beam at each round.\n            branch_factor: Number of new prompt candidates to generate from each parent prompt\n                by applying textual gradient edits. This controls the expansion of the search tree.\n            beam_rounds: Number of beam search rounds to perform.\n            rollout_batch_timeout: Maximum time in seconds to wait for rollout batch completion.\n            run_initial_validation: If True, runs validation on the seed prompt before starting\n                optimization to establish a baseline score. Defaults to True.\n        \"\"\"\n        self.async_openai_client = async_openai_client\n        self.gradient_model = gradient_model\n        self.apply_edit_model = apply_edit_model\n        self.diversity_temperature = diversity_temperature\n        self.gradient_batch_size = gradient_batch_size\n        self.val_batch_size = val_batch_size\n        self.beam_width = beam_width\n        self.branch_factor = branch_factor\n        self.beam_rounds = beam_rounds\n        self.rollout_batch_timeout = rollout_batch_timeout\n        self.run_initial_validation = run_initial_validation\n\n        self._history_best_prompt: Optional[PromptTemplate] = None\n        self._history_best_score: float = float(\"-inf\")\n        self._history_best_version: Optional[str] = None\n\n        self._version_counter: int = 0\n\n        self._poml_trace = _poml_trace\n\n    def _create_versioned_prompt(\n        self,\n        prompt_template: PromptTemplate,\n        *,\n        score: Optional[float] = None,\n    ) -&gt; VersionedPromptTemplate:\n        \"\"\"\n        Wrap a prompt template with a new monotonically increasing version identifier.\n        \"\"\"\n        version = f\"v{self._version_counter}\"\n        self._version_counter += 1\n        return VersionedPromptTemplate(version=version, prompt_template=prompt_template, score=score)\n\n    def _format_log_prefix(\n        self,\n        *,\n        round_num: Optional[int] = None,\n        beam_idx: Optional[int] = None,\n        branch_idx: Optional[int] = None,\n        prompt_version: Optional[str] = None,\n    ) -&gt; str:\n        \"\"\"\n        Construct the standardized log prefix.\n        \"\"\"\n        parts: List[str] = []\n        if round_num is not None:\n            parts.append(f\"Round {round_num:02d}\")\n        if beam_idx is not None:\n            parts.append(f\"Beam {beam_idx:02d}\")\n        if branch_idx is not None:\n            parts.append(f\"Branch {branch_idx:02d}\")\n        if prompt_version is not None:\n            parts.append(f\"Prompt {prompt_version}\")\n        if not parts:\n            return \"\"\n        return f\"[{' | '.join(parts)}]\"\n\n    def _log(self, level: int, message: str, *, prefix: Optional[str] = None) -&gt; None:\n        \"\"\"\n        Log a message with an optional standardized prefix.\n        \"\"\"\n        effective_prefix = prefix\n        if effective_prefix:\n            logger.log(level, f\"{effective_prefix} {message}\")\n        else:\n            logger.log(level, message)\n\n    def get_seed_prompt_template(self) -&gt; Tuple[str, PromptTemplate]:\n        \"\"\"\n        Extract the initial prompt template from the algorithm's resources.\n\n        Returns:\n            A tuple of (resource_name, prompt_template) representing the seed prompt.\n\n        Raises:\n            ValueError: If initial_resources is not set or no PromptTemplate is found.\n        \"\"\"\n        initial_resources = self.get_initial_resources()\n        if initial_resources is None:\n            raise ValueError(\n                \"initial_resources are not set for APO algorithm. \"\n                \"Use algorithm.set_initial_resources() to set initial resources or set it in Trainer()\"\n            )\n        for name, resource in initial_resources.items():\n            if isinstance(resource, PromptTemplate):\n                return name, resource\n        raise ValueError(\"No prompt template resource found in initial_resources\")\n\n    def get_adapter(self) -&gt; TraceToMessages:\n        \"\"\"\n        Get the adapter for converting spans to messages.\n\n        Returns:\n            The TraceToMessages instance for this algorithm.\n\n        Raises:\n            ValueError: If the adapter is not a TraceToMessages.\n        \"\"\"\n        adapter = super().get_adapter()\n        if not isinstance(adapter, TraceToMessages):\n            raise ValueError(\"Adapter must be a TraceToMessages for APO algorithm\")\n        return adapter\n\n    def get_best_prompt(self) -&gt; PromptTemplate:\n        \"\"\"\n        Retrieve the best prompt discovered during optimization.\n\n        Returns:\n            The prompt template with the highest validation score found so far.\n\n        Raises:\n            ValueError: If no best prompt has been found yet (run() not called).\n        \"\"\"\n        if self._history_best_prompt is None:\n            raise ValueError(\"No best prompt found\")\n        return self._history_best_prompt\n\n    async def compute_textual_gradient(\n        self,\n        current_prompt: VersionedPromptTemplate,\n        rollout_results: List[RolloutResultForAPO],\n        *,\n        prefix: Optional[str] = None,\n    ) -&gt; Optional[str]:\n        \"\"\"\n        Compute a textual gradient (critique) for the current prompt based on rollout results.\n\n        This method samples rollout results, sends them to an LLM along with the current prompt,\n        and generates a critique describing how the prompt could be improved.\n\n        Args:\n            current_prompt: The prompt template to critique.\n            rollout_results: List of rollout results containing spans, messages, and rewards.\n\n        Returns:\n            A textual critique generated by the LLM, or None if generation fails.\n        \"\"\"\n        tg_template = random.choice(GRADIENT_PROMPT_FILES)\n\n        if len(rollout_results) &lt; self.gradient_batch_size:\n            self._log(\n                logging.WARNING,\n                f\"Only {len(rollout_results)} rollouts available, but {self.gradient_batch_size} are needed. Using all rollouts.\",\n                prefix=prefix,\n            )\n            sampled_rollout_results = rollout_results\n        else:\n            sampled_rollout_results = random.sample(rollout_results, self.gradient_batch_size)\n\n        self._log(\n            logging.INFO,\n            f\"Gradient will be computed with {self.gradient_model} for {len(sampled_rollout_results)} rollouts with template: {tg_template.name}\",\n            prefix=prefix,\n        )\n\n        tg_msg = poml.poml(  # type: ignore\n            tg_template,\n            context={\n                \"experiments\": sampled_rollout_results,\n                \"prompt_template\": current_prompt.prompt_template.template,\n            },\n            format=\"openai_chat\",\n        )\n        self._log(\n            logging.DEBUG,\n            f\"Gradient computed with {self.gradient_model} prompt: {tg_msg}\",\n            prefix=prefix,\n        )\n        critique_response = await self.async_openai_client.chat.completions.create(\n            model=self.gradient_model,\n            messages=tg_msg[\"messages\"],  # type: ignore\n            temperature=self.diversity_temperature,\n        )\n        critique_text = critique_response.choices[0].message.content\n        self._log(\n            logging.INFO,\n            f\"Gradient computed with {self.gradient_model} has result: {critique_text}\",\n            prefix=prefix,\n        )\n\n        return critique_text\n\n    async def textual_gradient_and_apply_edit(\n        self,\n        current_prompt: VersionedPromptTemplate,\n        rollout: List[RolloutResultForAPO],\n        *,\n        prefix: Optional[str] = None,\n    ) -&gt; Optional[str]:\n        \"\"\"\n        Generate an improved prompt by computing a textual gradient and applying an edit.\n\n        This is the main optimization step that:\n        1. Computes a critique (textual gradient) based on rollout performance\n        2. Uses another LLM to apply the critique and generate an improved prompt\n\n        Args:\n            current_prompt: The current prompt template to improve.\n            rollout: List of rollout results to base the critique on.\n\n        Returns:\n            The improved prompt text, or the original prompt if gradient computation fails.\n        \"\"\"\n        # 1) Critique\n        critique_text = await self.compute_textual_gradient(\n            current_prompt,\n            rollout,\n            prefix=prefix,\n        )\n        if not critique_text:\n            self._log(\n                logging.ERROR,\n                \"Failed to compute critique for prompt.\",\n                prefix=prefix,\n            )\n            return current_prompt.prompt_template.template\n\n        # 2) Apply edit\n        ae_template = random.choice(APPLY_EDIT_PROMPT_FILES)\n        self._log(\n            logging.INFO,\n            f\"Edit will be generated by {self.apply_edit_model} with template: {ae_template.name}\",\n            prefix=prefix,\n        )\n        ae_msg = poml.poml(  # type: ignore\n            ae_template,\n            context={\n                \"prompt_template\": current_prompt.prompt_template.template,\n                \"critique\": critique_text,\n            },\n            format=\"openai_chat\",\n        )\n\n        ae_response = await self.async_openai_client.chat.completions.create(\n            model=self.apply_edit_model,\n            messages=ae_msg[\"messages\"],  # type: ignore\n            temperature=self.diversity_temperature,\n        )\n        new_prompt = ae_response.choices[0].message.content\n        if new_prompt:\n            self._log(\n                logging.INFO,\n                f\"Edit generated by {self.apply_edit_model}: {new_prompt[:50]}...\",\n                prefix=prefix,\n            )\n        return new_prompt\n\n    async def get_rollout_results(\n        self,\n        rollout: List[Rollout],\n        *,\n        prefix: Optional[str] = None,\n    ) -&gt; List[RolloutResultForAPO]:\n        \"\"\"\n        Convert completed rollouts to APO-compatible result format.\n\n        Fetches spans for each rollout, adapts them to messages, and packages them\n        with rewards and status information for gradient computation.\n\n        Args:\n            rollout: List of completed rollout metadata.\n\n        Returns:\n            List of rollout results formatted for APO processing.\n        \"\"\"\n        rollout_results: List[RolloutResultForAPO] = []\n        store = self.get_store()\n        adapter = self.get_adapter()\n        for r in rollout:\n            spans = await store.query_spans(r.rollout_id)\n            messages = adapter.adapt(spans)\n            rollout_result = RolloutResultForAPO(\n                status=r.status,\n                final_reward=find_final_reward(spans),\n                spans=[span.model_dump() for span in spans],\n                messages=messages,\n            )\n            self._log(\n                logging.DEBUG,\n                f\"Rollout result for {r.rollout_id}: status {rollout_result['status']} with final reward {rollout_result['final_reward']}. \"\n                f\"{len(rollout_result['spans'])} spans and {len(rollout_result['messages'])} messages.\",\n                prefix=prefix,\n            )\n            rollout_results.append(rollout_result)\n        return rollout_results\n\n    async def evaluate_prompt_on_batch(\n        self,\n        prompt: VersionedPromptTemplate,\n        resource_name: str,\n        dataset: Sequence[T_task],\n        mode: RolloutMode,\n        *,\n        prefix: Optional[str] = None,\n    ) -&gt; Tuple[List[RolloutResultForAPO], float]:\n        \"\"\"\n        Evaluate a prompt on a batch of tasks by running rollouts and computing average reward.\n\n        This method:\n        1. Adds the prompt as a named resource to the store\n        2. Enqueues rollouts for each task in the dataset\n        3. Waits for rollouts to complete (with timeout)\n        4. Computes and returns the average reward\n\n        Args:\n            prompt: The prompt template string to evaluate.\n            resource_name: The name to register the prompt under in the store.\n            dataset: Sequence of tasks to evaluate the prompt on.\n            mode: Rollout mode (\"train\" or \"val\") for logging/tracking.\n\n        Returns:\n            A tuple of (rollout_results, average_reward) where rollout_results contains\n            detailed information for each rollout and average_reward is the mean final reward.\n        \"\"\"\n        store = self.get_store()\n        preview = prompt.prompt_template.template[:50]\n        self._log(\n            logging.INFO,\n            f'Evaluating prompt \"{preview}...\" on {len(dataset)} tasks in {mode} mode',\n            prefix=prefix,\n        )\n\n        # Install prompt as named resource\n        resources: NamedResources = {resource_name: prompt.prompt_template}\n        resource_update = await store.update_resources(prompt.version, resources)\n\n        rollout_ids: List[str] = []\n        for t in dataset:\n            r = await store.enqueue_rollout(input=t, mode=mode, resources_id=resource_update.resources_id)\n            rollout_ids.append(r.rollout_id)\n\n        deadline = time.time() + self.rollout_batch_timeout\n        finished: List[Rollout] = []\n        while time.time() &lt; deadline:\n            finished = await store.wait_for_rollouts(rollout_ids=rollout_ids, timeout=0.0)\n            if len(finished) &gt;= len(rollout_ids):\n                self._log(\n                    logging.INFO,\n                    f\"All {len(rollout_ids)} rollouts finished within timeout.\",\n                    prefix=prefix,\n                )\n                break\n            else:\n                self._log(\n                    logging.DEBUG,\n                    f\"Only {len(finished)} rollouts finished within timeout. Waiting for remaining {len(rollout_ids) - len(finished)} rollouts.\",\n                    prefix=prefix,\n                )\n                # Sleep to avoid busy-waiting\n                await asyncio.sleep(2.0)\n\n        rollout_results = await self.get_rollout_results(\n            finished,\n            prefix=prefix,\n        )\n        final_rewards = [rr[\"final_reward\"] for rr in rollout_results]\n\n        avg = float(sum([r or 0.0 for r in final_rewards]) / max(1, len(final_rewards)))\n        status_counter = Counter([rr[\"status\"] for rr in rollout_results])\n\n        self._log(\n            logging.INFO,\n            f\"Evaluated {len(rollout_results)} rollouts. Statuses: {status_counter}. Rewards: {final_rewards}, average is {avg}\",\n            prefix=prefix,\n        )\n        return rollout_results, avg\n\n    def _initialize_beam(\n        self,\n        train_dataset: Optional[Dataset[T_task]],\n        val_dataset: Optional[Dataset[T_task]],\n    ) -&gt; Tuple[str, PromptTemplate, Iterator[Sequence[T_task]], Iterator[Sequence[T_task]]]:\n        \"\"\"\n        Initialize the beam search with seed prompt and dataset iterators.\n\n        Args:\n            train_dataset: Dataset for computing gradients.\n            val_dataset: Dataset for evaluating prompts.\n\n        Returns:\n            Tuple of (resource_name, seed_prompt, grad_iterator, val_iterator).\n\n        Raises:\n            ValueError: If either dataset is None.\n        \"\"\"\n        resource_name, seed_prompt = self.get_seed_prompt_template()\n\n        if train_dataset is None:\n            raise ValueError(\"train_dataset is required for APO algorithm\")\n        if val_dataset is None:\n            raise ValueError(\"val_dataset is required for APO algorithm\")\n\n        grad_dataset_iterator = batch_iter_over_dataset(train_dataset, self.gradient_batch_size)\n        val_dataset_iterator = batch_iter_over_dataset(val_dataset, self.val_batch_size)\n\n        # Initialize history tracking\n        self._history_best_prompt = seed_prompt\n        self._history_best_score = float(\"-inf\")\n\n        return resource_name, seed_prompt, grad_dataset_iterator, val_dataset_iterator\n\n    def _sample_parent_prompts(\n        self,\n        beam: List[VersionedPromptTemplate],\n        round_num: int,\n    ) -&gt; List[Tuple[int, VersionedPromptTemplate]]:\n        \"\"\"\n        Sample parent prompts from the current beam for generating new candidates.\n\n        If the beam has fewer prompts than beam_width, replicates existing prompts.\n        Otherwise, randomly samples beam_width prompts.\n\n        Args:\n            beam: Current list of prompt templates in the beam.\n            round_num: Current round number (for logging, 0-indexed).\n\n        Returns:\n            List of parent prompts to generate children from.\n        \"\"\"\n        display_round = round_num + 1\n        if len(beam) &lt; self.beam_width:\n            prefix = self._format_log_prefix(round_num=display_round)\n            self._log(\n                logging.WARNING,\n                f\"Beam width is currently {self.beam_width}, but only {len(beam)} prompts in beam. Replicating all prompts.\",\n                prefix=prefix,\n            )\n            return [(i % len(beam), beam[i % len(beam)]) for i in range(self.beam_width)]\n\n        selected_indices = random.sample(range(len(beam)), self.beam_width)\n        return [(idx, beam[idx]) for idx in selected_indices]\n\n    async def _generate_candidate_prompts(\n        self,\n        parent_prompts: List[Tuple[int, VersionedPromptTemplate]],\n        resource_name: str,\n        grad_dataset_iterator: Iterator[Sequence[T_task]],\n        round_num: int,\n    ) -&gt; List[VersionedPromptTemplate]:\n        \"\"\"\n        Generate new candidate prompts from parents using textual gradients.\n\n        For each parent prompt, generates branch_factor new candidates by:\n        1. Evaluating the parent on a training batch\n        2. Computing textual gradient\n        3. Applying edit to generate improved prompt\n\n        Args:\n            parent_prompts: List of parent prompts to generate children from.\n            resource_name: Name to register prompts under in the store.\n            grad_dataset_iterator: Iterator over training data batches.\n            round_num: Current round number (for logging, 0-indexed).\n\n        Returns:\n            List of newly generated prompt templates.\n        \"\"\"\n        display_round = round_num + 1\n        round_prefix = self._format_log_prefix(round_num=display_round)\n        self._log(\n            logging.INFO,\n            f\"Applying {self.branch_factor} edits to each of the {len(parent_prompts)} parents based on \"\n            \"gradients computed on training dataset\",\n            prefix=round_prefix,\n        )\n\n        parent_prompts_str = [\n            f\"{p.version}:{p.score:.3f}\" if p.score is not None else p.version for _, p in parent_prompts\n        ]\n        self._log(\n            logging.INFO,\n            f\"Parent prompts: {', '.join(parent_prompts_str)}\",\n            prefix=round_prefix,\n        )\n\n        candidates: List[VersionedPromptTemplate] = []\n        used_beam_indices: Set[int] = set()\n        for real_beam_idx, (beam_idx, prompt) in enumerate(parent_prompts):\n            if beam_idx in used_beam_indices:\n                beam_prefix = self._format_log_prefix(\n                    round_num=display_round,\n                    beam_idx=beam_idx + 1,\n                    prompt_version=prompt.version,\n                )\n                self._log(\n                    logging.WARNING,\n                    \"Duplicated beam index found. Might be caused by beam_width too high. \"\n                    + f\"The real index of this beam is {real_beam_idx + 1}.\",\n                    prefix=beam_prefix,\n                )\n            else:\n                used_beam_indices.add(beam_idx)\n            for branch_idx in range(self.branch_factor):\n                parent_prefix = self._format_log_prefix(\n                    round_num=display_round,\n                    beam_idx=beam_idx + 1,\n                    branch_idx=branch_idx + 1,\n                    prompt_version=prompt.version,\n                )\n                baseline_score = f\"{prompt.score:.3f}\" if prompt.score is not None else \"N/A\"\n                self._log(\n                    logging.INFO,\n                    f\"Use parent prompt {prompt.version} as a baseline to generate a new prompt. Baseline score: {baseline_score}\",\n                    prefix=parent_prefix,\n                )\n                grad_samples = next(grad_dataset_iterator)\n                rollout_results, _ = await self.evaluate_prompt_on_batch(\n                    prompt,\n                    resource_name,\n                    grad_samples,\n                    mode=\"train\",\n                    prefix=parent_prefix,\n                )\n                new_prompt = await self.textual_gradient_and_apply_edit(\n                    prompt,\n                    rollout_results,\n                    prefix=parent_prefix,\n                )\n                if not new_prompt:\n                    self._log(\n                        logging.ERROR,\n                        f\"Failed to compute edit for prompt: {prompt.prompt_template.template}\",\n                        prefix=parent_prefix,\n                    )\n                    continue\n                new_prompt_template = PromptTemplate(template=new_prompt, engine=\"f-string\")\n                versioned_candidate = self._create_versioned_prompt(new_prompt_template)\n                self._log(\n                    logging.INFO,\n                    f\"New prompt template created from parent {prompt.version}: {versioned_candidate.version}\",\n                    prefix=parent_prefix,\n                )\n                candidate_prefix = self._format_log_prefix(\n                    round_num=display_round, prompt_version=versioned_candidate.version\n                )\n                self._log(\n                    logging.INFO,\n                    f\"New prompt template created from parent {prompt.version}:\\n```\\n{new_prompt}\\n```\",\n                    prefix=candidate_prefix,\n                )\n                candidates.append(versioned_candidate)\n\n        return candidates\n\n    async def _evaluate_and_select_beam(\n        self,\n        candidates: List[VersionedPromptTemplate],\n        resource_name: str,\n        val_dataset_iterator: Iterator[Sequence[T_task]],\n        round_num: int,\n    ) -&gt; List[VersionedPromptTemplate]:\n        \"\"\"\n        Evaluate all candidate prompts on validation data and select top-k for the beam.\n\n        Args:\n            candidates: List of candidate prompts to evaluate.\n            resource_name: Name to register prompts under in the store.\n            val_dataset_iterator: Iterator over validation data batches.\n            round_num: Current round number (for logging, 0-indexed).\n\n        Returns:\n            List of top beam_width prompts sorted by validation score (best first).\n\n        Raises:\n            ValueError: If no candidates remain after evaluation.\n        \"\"\"\n        display_round = round_num + 1\n        round_prefix = self._format_log_prefix(round_num=display_round)\n        self._log(\n            logging.INFO,\n            f\"Evaluating {len(candidates)} candidates on validation dataset\",\n            prefix=round_prefix,\n        )\n\n        val_batch = next(val_dataset_iterator)\n\n        for prompt in candidates:\n            candidate_prefix = self._format_log_prefix(\n                round_num=display_round,\n                prompt_version=prompt.version,\n            )\n            _, score = await self.evaluate_prompt_on_batch(\n                prompt,\n                resource_name,\n                val_batch,\n                mode=\"val\",\n                prefix=candidate_prefix,\n            )\n            prompt.score = score\n            self._log(\n                logging.INFO,\n                f\"Candidate score: {score:.3f}\",\n                prefix=candidate_prefix,\n            )\n\n        # Sort by score (descending) and select top beam_width\n        sorted_prompts = [p for p in sorted(candidates, key=lambda x: cast(float, x.score), reverse=True)]\n        selected_prompts = sorted_prompts[: self.beam_width]\n        selected_versions = [\n            f\"{prompt.version}:{prompt.score:.3f}\" if prompt.score is not None else prompt.version\n            for prompt in selected_prompts\n        ]\n        self._log(\n            logging.INFO,\n            f\"Top {len(selected_prompts)} candidates on validation dataset: {selected_versions}\",\n            prefix=round_prefix,\n        )\n\n        if len(selected_prompts) == 0:\n            raise ValueError(\"No beam candidates any more\")\n\n        return selected_prompts\n\n    async def _update_best_prompt(\n        self,\n        beam: List[VersionedPromptTemplate],\n        resource_name: str,\n        val_dataset: Dataset[T_task],\n        round_num: int,\n    ) -&gt; None:\n        \"\"\"\n        Evaluate the best prompt in the beam on the full validation set and update history.\n\n        Args:\n            beam: Current beam of prompts (sorted, best first).\n            resource_name: Name to register prompts under in the store.\n            val_dataset: Full validation dataset.\n            round_num: Current round number (for logging, 0-indexed).\n        \"\"\"\n        display_round = round_num + 1\n        best_prompt = beam[0]\n        prefix = self._format_log_prefix(round_num=display_round, prompt_version=best_prompt.version)\n        _, best_score = await self.evaluate_prompt_on_batch(\n            best_prompt,\n            resource_name,\n            cast(Sequence[T_task], val_dataset),\n            mode=\"val\",\n            prefix=prefix,\n        )\n        self._log(\n            logging.INFO,\n            f\"Beam leader score: {best_score:.3f}\",\n            prefix=prefix,\n        )\n\n        if best_score &gt; self._history_best_score:\n            prev = self._history_best_score\n            self._log(\n                logging.INFO,\n                f\"Best prompt updated. New best score: {best_score:.3f} (prev: {prev:.3f})\",\n                prefix=prefix,\n            )\n            self._history_best_prompt = best_prompt.prompt_template\n            self._history_best_score = best_score\n            self._history_best_version = best_prompt.version\n        else:\n            self._log(\n                logging.WARNING,\n                f\"Best prompt not updated. Current score: {best_score:.3f} vs. history best: {self._history_best_score:.3f})\",\n                prefix=prefix,\n            )\n\n    async def run(\n        self,\n        train_dataset: Optional[Dataset[T_task]] = None,\n        val_dataset: Optional[Dataset[T_task]] = None,\n    ) -&gt; None:\n        \"\"\"\n        Execute the APO algorithm to optimize prompts through beam search with textual gradients.\n\n        The algorithm performs iterative prompt optimization over multiple rounds:\n        - Each round: samples parent prompts, generates new candidates via textual gradients,\n          evaluates all candidates on validation data, and keeps the top performers\n        - Tracks the historically best prompt across all rounds\n        - Uses different training data samples for each gradient computation to ensure diversity\n\n        Args:\n            train_dataset: Dataset of tasks for computing textual gradients. Required.\n            val_dataset: Dataset of tasks for evaluating and selecting prompts. Required.\n\n        Raises:\n            ValueError: If train_dataset or val_dataset is None, or if resources are not set.\n        \"\"\"\n        # Initialize beam search\n        resource_name, seed_prompt, grad_iterator, val_iterator = self._initialize_beam(train_dataset, val_dataset)\n\n        if self._poml_trace:\n            poml.set_trace(trace_dir=\"pomltrace\")\n\n        # Validation datasets are guaranteed to be non-None after initialization\n        assert val_dataset is not None\n\n        # Start with seed prompt in the beam\n        seed_versioned = self._create_versioned_prompt(seed_prompt)\n        beam: List[VersionedPromptTemplate] = [seed_versioned]\n        self._history_best_prompt = seed_prompt\n        self._history_best_version = seed_versioned.version\n\n        # Optionally evaluate seed prompt on validation set to establish baseline\n        if self.run_initial_validation:\n            seed_prefix = self._format_log_prefix(round_num=0, prompt_version=seed_versioned.version)\n            self._log(\n                logging.INFO,\n                \"Evaluating seed prompt on validation dataset before optimization...\",\n                prefix=seed_prefix,\n            )\n            _, seed_score = await self.evaluate_prompt_on_batch(\n                seed_versioned,\n                resource_name,\n                cast(Sequence[T_task], val_dataset),\n                mode=\"val\",\n                prefix=seed_prefix,\n            )\n            self._log(\n                logging.INFO,\n                f\"Seed prompt baseline score: {seed_score:.3f}\",\n                prefix=seed_prefix,\n            )\n            self._history_best_prompt = seed_prompt\n            self._history_best_score = seed_score\n            self._history_best_version = seed_versioned.version\n\n        # Run beam search for specified number of rounds\n        for rnd in range(self.beam_rounds):\n            display_round = rnd + 1\n            round_prefix = self._format_log_prefix(round_num=display_round)\n            self._log(\n                logging.INFO,\n                f\"Round {display_round}/{self.beam_rounds}...\",\n                prefix=round_prefix,\n            )\n\n            # Sample parent prompts from current beam\n            parent_prompts = self._sample_parent_prompts(beam, rnd)\n\n            # Generate new candidate prompts from parents\n            new_candidates = await self._generate_candidate_prompts(parent_prompts, resource_name, grad_iterator, rnd)\n\n            # Combine existing beam with new candidates\n            all_candidates = [*beam, *new_candidates]\n\n            # Evaluate and select top-k prompts for next beam\n            beam = await self._evaluate_and_select_beam(all_candidates, resource_name, val_iterator, rnd)\n\n            # Update historically best prompt if improved\n            await self._update_best_prompt(beam, resource_name, val_dataset, rnd)\n</code></pre>"},{"location":"algorithm-zoo/apo/#agentlightning.algorithm.apo.APO.__init__","title":"<code>__init__(async_openai_client, *, gradient_model='gpt-5-mini', apply_edit_model='gpt-4.1-mini', diversity_temperature=1.0, gradient_batch_size=4, val_batch_size=16, beam_width=4, branch_factor=4, beam_rounds=3, rollout_batch_timeout=3600.0, run_initial_validation=True, _poml_trace=False)</code>","text":"<p>Initialize the APO algorithm with configuration parameters.</p> <p>Parameters:</p> Name Type Description Default <code>async_openai_client</code> <code>AsyncOpenAI</code> <p>AsyncOpenAI client for making LLM API calls.</p> required <code>gradient_model</code> <code>str</code> <p>Model name for computing textual gradients (critiques).</p> <code>'gpt-5-mini'</code> <code>apply_edit_model</code> <code>str</code> <p>Model name for applying edits based on critiques.</p> <code>'gpt-4.1-mini'</code> <code>diversity_temperature</code> <code>float</code> <p>Temperature parameter for LLM calls to control diversity.</p> <code>1.0</code> <code>gradient_batch_size</code> <code>int</code> <p>Number of rollout results to sample for gradient computation.</p> <code>4</code> <code>val_batch_size</code> <code>int</code> <p>Number of validation examples to use for evaluation.</p> <code>16</code> <code>beam_width</code> <code>int</code> <p>Number of top-scoring prompts to keep in the beam at each round.</p> <code>4</code> <code>branch_factor</code> <code>int</code> <p>Number of new prompt candidates to generate from each parent prompt by applying textual gradient edits. This controls the expansion of the search tree.</p> <code>4</code> <code>beam_rounds</code> <code>int</code> <p>Number of beam search rounds to perform.</p> <code>3</code> <code>rollout_batch_timeout</code> <code>float</code> <p>Maximum time in seconds to wait for rollout batch completion.</p> <code>3600.0</code> <code>run_initial_validation</code> <code>bool</code> <p>If True, runs validation on the seed prompt before starting optimization to establish a baseline score. Defaults to True.</p> <code>True</code> Source code in <code>agentlightning/algorithm/apo/apo.py</code> <pre><code>def __init__(\n    self,\n    async_openai_client: AsyncOpenAI,\n    *,\n    gradient_model: str = \"gpt-5-mini\",\n    apply_edit_model: str = \"gpt-4.1-mini\",\n    diversity_temperature: float = 1.0,\n    gradient_batch_size: int = 4,\n    val_batch_size: int = 16,\n    beam_width: int = 4,\n    branch_factor: int = 4,\n    beam_rounds: int = 3,\n    rollout_batch_timeout: float = 3600.0,\n    run_initial_validation: bool = True,\n    # Internal flags for debugging\n    _poml_trace: bool = False,\n):\n    \"\"\"\n    Initialize the APO algorithm with configuration parameters.\n\n    Args:\n        async_openai_client: AsyncOpenAI client for making LLM API calls.\n        gradient_model: Model name for computing textual gradients (critiques).\n        apply_edit_model: Model name for applying edits based on critiques.\n        diversity_temperature: Temperature parameter for LLM calls to control diversity.\n        gradient_batch_size: Number of rollout results to sample for gradient computation.\n        val_batch_size: Number of validation examples to use for evaluation.\n        beam_width: Number of top-scoring prompts to keep in the beam at each round.\n        branch_factor: Number of new prompt candidates to generate from each parent prompt\n            by applying textual gradient edits. This controls the expansion of the search tree.\n        beam_rounds: Number of beam search rounds to perform.\n        rollout_batch_timeout: Maximum time in seconds to wait for rollout batch completion.\n        run_initial_validation: If True, runs validation on the seed prompt before starting\n            optimization to establish a baseline score. Defaults to True.\n    \"\"\"\n    self.async_openai_client = async_openai_client\n    self.gradient_model = gradient_model\n    self.apply_edit_model = apply_edit_model\n    self.diversity_temperature = diversity_temperature\n    self.gradient_batch_size = gradient_batch_size\n    self.val_batch_size = val_batch_size\n    self.beam_width = beam_width\n    self.branch_factor = branch_factor\n    self.beam_rounds = beam_rounds\n    self.rollout_batch_timeout = rollout_batch_timeout\n    self.run_initial_validation = run_initial_validation\n\n    self._history_best_prompt: Optional[PromptTemplate] = None\n    self._history_best_score: float = float(\"-inf\")\n    self._history_best_version: Optional[str] = None\n\n    self._version_counter: int = 0\n\n    self._poml_trace = _poml_trace\n</code></pre>"},{"location":"algorithm-zoo/apo/#agentlightning.algorithm.apo.APO.compute_textual_gradient","title":"<code>compute_textual_gradient(current_prompt, rollout_results, *, prefix=None)</code>  <code>async</code>","text":"<p>Compute a textual gradient (critique) for the current prompt based on rollout results.</p> <p>This method samples rollout results, sends them to an LLM along with the current prompt, and generates a critique describing how the prompt could be improved.</p> <p>Parameters:</p> Name Type Description Default <code>current_prompt</code> <code>VersionedPromptTemplate</code> <p>The prompt template to critique.</p> required <code>rollout_results</code> <code>List[RolloutResultForAPO]</code> <p>List of rollout results containing spans, messages, and rewards.</p> required <p>Returns:</p> Type Description <code>Optional[str]</code> <p>A textual critique generated by the LLM, or None if generation fails.</p> Source code in <code>agentlightning/algorithm/apo/apo.py</code> <pre><code>async def compute_textual_gradient(\n    self,\n    current_prompt: VersionedPromptTemplate,\n    rollout_results: List[RolloutResultForAPO],\n    *,\n    prefix: Optional[str] = None,\n) -&gt; Optional[str]:\n    \"\"\"\n    Compute a textual gradient (critique) for the current prompt based on rollout results.\n\n    This method samples rollout results, sends them to an LLM along with the current prompt,\n    and generates a critique describing how the prompt could be improved.\n\n    Args:\n        current_prompt: The prompt template to critique.\n        rollout_results: List of rollout results containing spans, messages, and rewards.\n\n    Returns:\n        A textual critique generated by the LLM, or None if generation fails.\n    \"\"\"\n    tg_template = random.choice(GRADIENT_PROMPT_FILES)\n\n    if len(rollout_results) &lt; self.gradient_batch_size:\n        self._log(\n            logging.WARNING,\n            f\"Only {len(rollout_results)} rollouts available, but {self.gradient_batch_size} are needed. Using all rollouts.\",\n            prefix=prefix,\n        )\n        sampled_rollout_results = rollout_results\n    else:\n        sampled_rollout_results = random.sample(rollout_results, self.gradient_batch_size)\n\n    self._log(\n        logging.INFO,\n        f\"Gradient will be computed with {self.gradient_model} for {len(sampled_rollout_results)} rollouts with template: {tg_template.name}\",\n        prefix=prefix,\n    )\n\n    tg_msg = poml.poml(  # type: ignore\n        tg_template,\n        context={\n            \"experiments\": sampled_rollout_results,\n            \"prompt_template\": current_prompt.prompt_template.template,\n        },\n        format=\"openai_chat\",\n    )\n    self._log(\n        logging.DEBUG,\n        f\"Gradient computed with {self.gradient_model} prompt: {tg_msg}\",\n        prefix=prefix,\n    )\n    critique_response = await self.async_openai_client.chat.completions.create(\n        model=self.gradient_model,\n        messages=tg_msg[\"messages\"],  # type: ignore\n        temperature=self.diversity_temperature,\n    )\n    critique_text = critique_response.choices[0].message.content\n    self._log(\n        logging.INFO,\n        f\"Gradient computed with {self.gradient_model} has result: {critique_text}\",\n        prefix=prefix,\n    )\n\n    return critique_text\n</code></pre>"},{"location":"algorithm-zoo/apo/#agentlightning.algorithm.apo.APO.evaluate_prompt_on_batch","title":"<code>evaluate_prompt_on_batch(prompt, resource_name, dataset, mode, *, prefix=None)</code>  <code>async</code>","text":"<p>Evaluate a prompt on a batch of tasks by running rollouts and computing average reward.</p> <p>This method: 1. Adds the prompt as a named resource to the store 2. Enqueues rollouts for each task in the dataset 3. Waits for rollouts to complete (with timeout) 4. Computes and returns the average reward</p> <p>Parameters:</p> Name Type Description Default <code>prompt</code> <code>VersionedPromptTemplate</code> <p>The prompt template string to evaluate.</p> required <code>resource_name</code> <code>str</code> <p>The name to register the prompt under in the store.</p> required <code>dataset</code> <code>Sequence[T_task]</code> <p>Sequence of tasks to evaluate the prompt on.</p> required <code>mode</code> <code>RolloutMode</code> <p>Rollout mode (\"train\" or \"val\") for logging/tracking.</p> required <p>Returns:</p> Type Description <code>List[RolloutResultForAPO]</code> <p>A tuple of (rollout_results, average_reward) where rollout_results contains</p> <code>float</code> <p>detailed information for each rollout and average_reward is the mean final reward.</p> Source code in <code>agentlightning/algorithm/apo/apo.py</code> <pre><code>async def evaluate_prompt_on_batch(\n    self,\n    prompt: VersionedPromptTemplate,\n    resource_name: str,\n    dataset: Sequence[T_task],\n    mode: RolloutMode,\n    *,\n    prefix: Optional[str] = None,\n) -&gt; Tuple[List[RolloutResultForAPO], float]:\n    \"\"\"\n    Evaluate a prompt on a batch of tasks by running rollouts and computing average reward.\n\n    This method:\n    1. Adds the prompt as a named resource to the store\n    2. Enqueues rollouts for each task in the dataset\n    3. Waits for rollouts to complete (with timeout)\n    4. Computes and returns the average reward\n\n    Args:\n        prompt: The prompt template string to evaluate.\n        resource_name: The name to register the prompt under in the store.\n        dataset: Sequence of tasks to evaluate the prompt on.\n        mode: Rollout mode (\"train\" or \"val\") for logging/tracking.\n\n    Returns:\n        A tuple of (rollout_results, average_reward) where rollout_results contains\n        detailed information for each rollout and average_reward is the mean final reward.\n    \"\"\"\n    store = self.get_store()\n    preview = prompt.prompt_template.template[:50]\n    self._log(\n        logging.INFO,\n        f'Evaluating prompt \"{preview}...\" on {len(dataset)} tasks in {mode} mode',\n        prefix=prefix,\n    )\n\n    # Install prompt as named resource\n    resources: NamedResources = {resource_name: prompt.prompt_template}\n    resource_update = await store.update_resources(prompt.version, resources)\n\n    rollout_ids: List[str] = []\n    for t in dataset:\n        r = await store.enqueue_rollout(input=t, mode=mode, resources_id=resource_update.resources_id)\n        rollout_ids.append(r.rollout_id)\n\n    deadline = time.time() + self.rollout_batch_timeout\n    finished: List[Rollout] = []\n    while time.time() &lt; deadline:\n        finished = await store.wait_for_rollouts(rollout_ids=rollout_ids, timeout=0.0)\n        if len(finished) &gt;= len(rollout_ids):\n            self._log(\n                logging.INFO,\n                f\"All {len(rollout_ids)} rollouts finished within timeout.\",\n                prefix=prefix,\n            )\n            break\n        else:\n            self._log(\n                logging.DEBUG,\n                f\"Only {len(finished)} rollouts finished within timeout. Waiting for remaining {len(rollout_ids) - len(finished)} rollouts.\",\n                prefix=prefix,\n            )\n            # Sleep to avoid busy-waiting\n            await asyncio.sleep(2.0)\n\n    rollout_results = await self.get_rollout_results(\n        finished,\n        prefix=prefix,\n    )\n    final_rewards = [rr[\"final_reward\"] for rr in rollout_results]\n\n    avg = float(sum([r or 0.0 for r in final_rewards]) / max(1, len(final_rewards)))\n    status_counter = Counter([rr[\"status\"] for rr in rollout_results])\n\n    self._log(\n        logging.INFO,\n        f\"Evaluated {len(rollout_results)} rollouts. Statuses: {status_counter}. Rewards: {final_rewards}, average is {avg}\",\n        prefix=prefix,\n    )\n    return rollout_results, avg\n</code></pre>"},{"location":"algorithm-zoo/apo/#agentlightning.algorithm.apo.APO.get_adapter","title":"<code>get_adapter()</code>","text":"<p>Get the adapter for converting spans to messages.</p> <p>Returns:</p> Type Description <code>TraceToMessages</code> <p>The TraceToMessages instance for this algorithm.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the adapter is not a TraceToMessages.</p> Source code in <code>agentlightning/algorithm/apo/apo.py</code> <pre><code>def get_adapter(self) -&gt; TraceToMessages:\n    \"\"\"\n    Get the adapter for converting spans to messages.\n\n    Returns:\n        The TraceToMessages instance for this algorithm.\n\n    Raises:\n        ValueError: If the adapter is not a TraceToMessages.\n    \"\"\"\n    adapter = super().get_adapter()\n    if not isinstance(adapter, TraceToMessages):\n        raise ValueError(\"Adapter must be a TraceToMessages for APO algorithm\")\n    return adapter\n</code></pre>"},{"location":"algorithm-zoo/apo/#agentlightning.algorithm.apo.APO.get_best_prompt","title":"<code>get_best_prompt()</code>","text":"<p>Retrieve the best prompt discovered during optimization.</p> <p>Returns:</p> Type Description <code>PromptTemplate</code> <p>The prompt template with the highest validation score found so far.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If no best prompt has been found yet (run() not called).</p> Source code in <code>agentlightning/algorithm/apo/apo.py</code> <pre><code>def get_best_prompt(self) -&gt; PromptTemplate:\n    \"\"\"\n    Retrieve the best prompt discovered during optimization.\n\n    Returns:\n        The prompt template with the highest validation score found so far.\n\n    Raises:\n        ValueError: If no best prompt has been found yet (run() not called).\n    \"\"\"\n    if self._history_best_prompt is None:\n        raise ValueError(\"No best prompt found\")\n    return self._history_best_prompt\n</code></pre>"},{"location":"algorithm-zoo/apo/#agentlightning.algorithm.apo.APO.get_rollout_results","title":"<code>get_rollout_results(rollout, *, prefix=None)</code>  <code>async</code>","text":"<p>Convert completed rollouts to APO-compatible result format.</p> <p>Fetches spans for each rollout, adapts them to messages, and packages them with rewards and status information for gradient computation.</p> <p>Parameters:</p> Name Type Description Default <code>rollout</code> <code>List[Rollout]</code> <p>List of completed rollout metadata.</p> required <p>Returns:</p> Type Description <code>List[RolloutResultForAPO]</code> <p>List of rollout results formatted for APO processing.</p> Source code in <code>agentlightning/algorithm/apo/apo.py</code> <pre><code>async def get_rollout_results(\n    self,\n    rollout: List[Rollout],\n    *,\n    prefix: Optional[str] = None,\n) -&gt; List[RolloutResultForAPO]:\n    \"\"\"\n    Convert completed rollouts to APO-compatible result format.\n\n    Fetches spans for each rollout, adapts them to messages, and packages them\n    with rewards and status information for gradient computation.\n\n    Args:\n        rollout: List of completed rollout metadata.\n\n    Returns:\n        List of rollout results formatted for APO processing.\n    \"\"\"\n    rollout_results: List[RolloutResultForAPO] = []\n    store = self.get_store()\n    adapter = self.get_adapter()\n    for r in rollout:\n        spans = await store.query_spans(r.rollout_id)\n        messages = adapter.adapt(spans)\n        rollout_result = RolloutResultForAPO(\n            status=r.status,\n            final_reward=find_final_reward(spans),\n            spans=[span.model_dump() for span in spans],\n            messages=messages,\n        )\n        self._log(\n            logging.DEBUG,\n            f\"Rollout result for {r.rollout_id}: status {rollout_result['status']} with final reward {rollout_result['final_reward']}. \"\n            f\"{len(rollout_result['spans'])} spans and {len(rollout_result['messages'])} messages.\",\n            prefix=prefix,\n        )\n        rollout_results.append(rollout_result)\n    return rollout_results\n</code></pre>"},{"location":"algorithm-zoo/apo/#agentlightning.algorithm.apo.APO.get_seed_prompt_template","title":"<code>get_seed_prompt_template()</code>","text":"<p>Extract the initial prompt template from the algorithm's resources.</p> <p>Returns:</p> Type Description <code>Tuple[str, PromptTemplate]</code> <p>A tuple of (resource_name, prompt_template) representing the seed prompt.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If initial_resources is not set or no PromptTemplate is found.</p> Source code in <code>agentlightning/algorithm/apo/apo.py</code> <pre><code>def get_seed_prompt_template(self) -&gt; Tuple[str, PromptTemplate]:\n    \"\"\"\n    Extract the initial prompt template from the algorithm's resources.\n\n    Returns:\n        A tuple of (resource_name, prompt_template) representing the seed prompt.\n\n    Raises:\n        ValueError: If initial_resources is not set or no PromptTemplate is found.\n    \"\"\"\n    initial_resources = self.get_initial_resources()\n    if initial_resources is None:\n        raise ValueError(\n            \"initial_resources are not set for APO algorithm. \"\n            \"Use algorithm.set_initial_resources() to set initial resources or set it in Trainer()\"\n        )\n    for name, resource in initial_resources.items():\n        if isinstance(resource, PromptTemplate):\n            return name, resource\n    raise ValueError(\"No prompt template resource found in initial_resources\")\n</code></pre>"},{"location":"algorithm-zoo/apo/#agentlightning.algorithm.apo.APO.run","title":"<code>run(train_dataset=None, val_dataset=None)</code>  <code>async</code>","text":"<p>Execute the APO algorithm to optimize prompts through beam search with textual gradients.</p> <p>The algorithm performs iterative prompt optimization over multiple rounds: - Each round: samples parent prompts, generates new candidates via textual gradients,   evaluates all candidates on validation data, and keeps the top performers - Tracks the historically best prompt across all rounds - Uses different training data samples for each gradient computation to ensure diversity</p> <p>Parameters:</p> Name Type Description Default <code>train_dataset</code> <code>Optional[Dataset[T_task]]</code> <p>Dataset of tasks for computing textual gradients. Required.</p> <code>None</code> <code>val_dataset</code> <code>Optional[Dataset[T_task]]</code> <p>Dataset of tasks for evaluating and selecting prompts. Required.</p> <code>None</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If train_dataset or val_dataset is None, or if resources are not set.</p> Source code in <code>agentlightning/algorithm/apo/apo.py</code> <pre><code>async def run(\n    self,\n    train_dataset: Optional[Dataset[T_task]] = None,\n    val_dataset: Optional[Dataset[T_task]] = None,\n) -&gt; None:\n    \"\"\"\n    Execute the APO algorithm to optimize prompts through beam search with textual gradients.\n\n    The algorithm performs iterative prompt optimization over multiple rounds:\n    - Each round: samples parent prompts, generates new candidates via textual gradients,\n      evaluates all candidates on validation data, and keeps the top performers\n    - Tracks the historically best prompt across all rounds\n    - Uses different training data samples for each gradient computation to ensure diversity\n\n    Args:\n        train_dataset: Dataset of tasks for computing textual gradients. Required.\n        val_dataset: Dataset of tasks for evaluating and selecting prompts. Required.\n\n    Raises:\n        ValueError: If train_dataset or val_dataset is None, or if resources are not set.\n    \"\"\"\n    # Initialize beam search\n    resource_name, seed_prompt, grad_iterator, val_iterator = self._initialize_beam(train_dataset, val_dataset)\n\n    if self._poml_trace:\n        poml.set_trace(trace_dir=\"pomltrace\")\n\n    # Validation datasets are guaranteed to be non-None after initialization\n    assert val_dataset is not None\n\n    # Start with seed prompt in the beam\n    seed_versioned = self._create_versioned_prompt(seed_prompt)\n    beam: List[VersionedPromptTemplate] = [seed_versioned]\n    self._history_best_prompt = seed_prompt\n    self._history_best_version = seed_versioned.version\n\n    # Optionally evaluate seed prompt on validation set to establish baseline\n    if self.run_initial_validation:\n        seed_prefix = self._format_log_prefix(round_num=0, prompt_version=seed_versioned.version)\n        self._log(\n            logging.INFO,\n            \"Evaluating seed prompt on validation dataset before optimization...\",\n            prefix=seed_prefix,\n        )\n        _, seed_score = await self.evaluate_prompt_on_batch(\n            seed_versioned,\n            resource_name,\n            cast(Sequence[T_task], val_dataset),\n            mode=\"val\",\n            prefix=seed_prefix,\n        )\n        self._log(\n            logging.INFO,\n            f\"Seed prompt baseline score: {seed_score:.3f}\",\n            prefix=seed_prefix,\n        )\n        self._history_best_prompt = seed_prompt\n        self._history_best_score = seed_score\n        self._history_best_version = seed_versioned.version\n\n    # Run beam search for specified number of rounds\n    for rnd in range(self.beam_rounds):\n        display_round = rnd + 1\n        round_prefix = self._format_log_prefix(round_num=display_round)\n        self._log(\n            logging.INFO,\n            f\"Round {display_round}/{self.beam_rounds}...\",\n            prefix=round_prefix,\n        )\n\n        # Sample parent prompts from current beam\n        parent_prompts = self._sample_parent_prompts(beam, rnd)\n\n        # Generate new candidate prompts from parents\n        new_candidates = await self._generate_candidate_prompts(parent_prompts, resource_name, grad_iterator, rnd)\n\n        # Combine existing beam with new candidates\n        all_candidates = [*beam, *new_candidates]\n\n        # Evaluate and select top-k prompts for next beam\n        beam = await self._evaluate_and_select_beam(all_candidates, resource_name, val_iterator, rnd)\n\n        # Update historically best prompt if improved\n        await self._update_best_prompt(beam, resource_name, val_dataset, rnd)\n</code></pre>"},{"location":"algorithm-zoo/apo/#agentlightning.algorithm.apo.APO.textual_gradient_and_apply_edit","title":"<code>textual_gradient_and_apply_edit(current_prompt, rollout, *, prefix=None)</code>  <code>async</code>","text":"<p>Generate an improved prompt by computing a textual gradient and applying an edit.</p> <p>This is the main optimization step that: 1. Computes a critique (textual gradient) based on rollout performance 2. Uses another LLM to apply the critique and generate an improved prompt</p> <p>Parameters:</p> Name Type Description Default <code>current_prompt</code> <code>VersionedPromptTemplate</code> <p>The current prompt template to improve.</p> required <code>rollout</code> <code>List[RolloutResultForAPO]</code> <p>List of rollout results to base the critique on.</p> required <p>Returns:</p> Type Description <code>Optional[str]</code> <p>The improved prompt text, or the original prompt if gradient computation fails.</p> Source code in <code>agentlightning/algorithm/apo/apo.py</code> <pre><code>async def textual_gradient_and_apply_edit(\n    self,\n    current_prompt: VersionedPromptTemplate,\n    rollout: List[RolloutResultForAPO],\n    *,\n    prefix: Optional[str] = None,\n) -&gt; Optional[str]:\n    \"\"\"\n    Generate an improved prompt by computing a textual gradient and applying an edit.\n\n    This is the main optimization step that:\n    1. Computes a critique (textual gradient) based on rollout performance\n    2. Uses another LLM to apply the critique and generate an improved prompt\n\n    Args:\n        current_prompt: The current prompt template to improve.\n        rollout: List of rollout results to base the critique on.\n\n    Returns:\n        The improved prompt text, or the original prompt if gradient computation fails.\n    \"\"\"\n    # 1) Critique\n    critique_text = await self.compute_textual_gradient(\n        current_prompt,\n        rollout,\n        prefix=prefix,\n    )\n    if not critique_text:\n        self._log(\n            logging.ERROR,\n            \"Failed to compute critique for prompt.\",\n            prefix=prefix,\n        )\n        return current_prompt.prompt_template.template\n\n    # 2) Apply edit\n    ae_template = random.choice(APPLY_EDIT_PROMPT_FILES)\n    self._log(\n        logging.INFO,\n        f\"Edit will be generated by {self.apply_edit_model} with template: {ae_template.name}\",\n        prefix=prefix,\n    )\n    ae_msg = poml.poml(  # type: ignore\n        ae_template,\n        context={\n            \"prompt_template\": current_prompt.prompt_template.template,\n            \"critique\": critique_text,\n        },\n        format=\"openai_chat\",\n    )\n\n    ae_response = await self.async_openai_client.chat.completions.create(\n        model=self.apply_edit_model,\n        messages=ae_msg[\"messages\"],  # type: ignore\n        temperature=self.diversity_temperature,\n    )\n    new_prompt = ae_response.choices[0].message.content\n    if new_prompt:\n        self._log(\n            logging.INFO,\n            f\"Edit generated by {self.apply_edit_model}: {new_prompt[:50]}...\",\n            prefix=prefix,\n        )\n    return new_prompt\n</code></pre>"},{"location":"algorithm-zoo/verl/","title":"VERL","text":"<p>Shortcut</p> <p>You can use the shortcut <code>agl.VERL(...)</code> to create a VERL instance.</p> <pre><code>import agentlightning as agl\n\nagl.VERL(...)\n</code></pre>"},{"location":"algorithm-zoo/verl/#installation","title":"Installation","text":"<pre><code>pip install agentlightning[verl]\n</code></pre> <p>Warning</p> <p>To avoid various compatibility issues, follow the steps in the installation guide to set up VERL and its dependencies. Installing VERL directly with <code>pip install agentlightning[verl]</code> can cause issues unless you already have a compatible version of PyTorch installed.</p> <p>Notes for Readers</p> <p>VERL in this article refers to a wrapper, provided by Agent-lightning, of the VERL framework. It's a subclass of agentlightning.Algorithm. To differentiate it from the VERL framework, all references to the VERL framework shall use the term \"VERL framework\", and all references to the Agent-lightning wrapper shall be highlighted with a link.</p>"},{"location":"algorithm-zoo/verl/#resources","title":"Resources","text":"<p>VERL expects no initial resources. The first LLM endpoint is directly deployed from the VERL configuration (<code>.actor_rollout_ref.model.path</code>). The resource key is always <code>main_llm</code>.</p> <p>VERL currently does not support optimizing multiple LLMs together.</p> <p>Note</p> <p>The resource type created by VERL is actually a ProxyLLM, a subclass of the LLM type. This object contains a URL template provided by VERL, with placeholders for rollout and attempt IDs. When a rollout begins on the agent side, the framework uses the current <code>rollout_id</code> and <code>attempt_id</code> to format this template, generating a final, unique endpoint URL. This URL points to VERL's internal proxy, allowing it to intercept and log all traffic for that specific attempt, for tracing and load balancing purposes. For agents created with the <code>@rollout</code> decorator, this resolution of the template is handled automatically (\"auto-stripped\"). Class-based agents will need to manually resolve the <code>ProxyLLM</code> using the rollout context.</p> <pre><code>proxy_llm = resources[\"main_llm\"]\nproxy_llm.get_base_url(rollout.rollout_id, rollout.attempt.attempt_id)\n</code></pre>"},{"location":"algorithm-zoo/verl/#customization","title":"Customization","text":"<p>Internally, VERL decomposes each agent execution into prompt\u2013response pairs via the Adapter and associates them with their corresponding reward signals as Triplet objects. The final scalar reward, derived from the last triplet in the trajectory, is propagated to all preceding triplets following the identical assignment strategy. This ensures that each triplet receives an identical reward signal and can be independently optimized as a valid RLHF trajectory within the VERL framework.</p> <p>At present, VERL does not expose fine-grained control over its reward propagation or credit assignment mechanisms. Users requiring customized reward shaping or trajectory decomposition are advised to clone and modify the VERL source implementation directly.</p>"},{"location":"algorithm-zoo/verl/#tutorials-using-verl","title":"Tutorials Using VERL","text":"<ul> <li>Train SQL Agent with RL - A practical example of training a SQL agent using VERL.</li> </ul>"},{"location":"algorithm-zoo/verl/#references-entrypoint","title":"References - Entrypoint","text":""},{"location":"algorithm-zoo/verl/#agentlightning.algorithm.verl","title":"<code>agentlightning.algorithm.verl</code>","text":""},{"location":"algorithm-zoo/verl/#agentlightning.algorithm.verl.VERL","title":"<code>VERL</code>","text":"<p>               Bases: <code>Algorithm</code></p> <p>Algorithm leveraging VERL as the backend framework.</p> <p>Note on Customization:</p> <p>At present, we recommend copying the source code from VERL and modifying it as needed to suit your requirements. Native support for customizing training logic will be provided in future releases.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>dict[str, Any]</code> <p>The VERL configuration, matching what is typically provided when running VERL via the command line. This config will be merged with VERL's base configuration and processed by Hydra.</p> required Source code in <code>agentlightning/algorithm/verl/interface.py</code> <pre><code>class VERL(Algorithm):\n    \"\"\"Algorithm leveraging VERL as the backend framework.\n\n    **Note on Customization:**\n\n    At present, we recommend copying the source code from VERL and modifying it as needed to suit your requirements.\n    Native support for customizing training logic will be provided in future releases.\n\n    Args:\n        config: The VERL configuration, matching what is typically provided when running VERL via the command line.\n            This config will be merged with VERL's base configuration and processed by Hydra.\n    \"\"\"\n\n    def __init__(self, config: dict[str, Any]):\n        super().__init__()\n\n        # Compose the base config exactly like your decorator:\n        with initialize(version_base=None, config_path=\"pkg://agentlightning/verl\"):\n            base_cfg = compose(config_name=\"config\")\n\n        # Merge your dict overrides\n        override_conf = OmegaConf.create(config)\n        self.config = OmegaConf.merge(base_cfg, override_conf)\n\n    def run(\n        self,\n        train_dataset: Optional[Dataset[Any]] = None,\n        val_dataset: Optional[Dataset[Any]] = None,\n    ) -&gt; None:\n        try:\n            store = self.get_store()\n        except Exception:\n            print(\"Store is not set. Assuming v0 execution mode.\")\n            run_ppo(\n                self.config,\n                train_dataset=train_dataset,\n                val_dataset=val_dataset,\n                store=None,\n                llm_proxy=None,\n                adapter=None,\n            )\n        else:\n            print(\"Store is set. Assuming v1 execution mode.\")\n            llm_proxy = self.get_llm_proxy()\n            adapter = self.get_adapter()\n            run_ppo(\n                self.config,\n                train_dataset=train_dataset,\n                val_dataset=val_dataset,\n                store=store,\n                llm_proxy=llm_proxy,\n                adapter=adapter,\n            )\n\n    def get_client(self) -&gt; AgentLightningClient:\n        port = self.config.agentlightning.port\n        return AgentLightningClient(endpoint=f\"http://localhost:{port}\")\n</code></pre>"},{"location":"algorithm-zoo/verl/#references-implementation","title":"References - Implementation","text":""},{"location":"algorithm-zoo/verl/#agentlightning.verl","title":"<code>agentlightning.verl</code>","text":"<p>This package contains a hacky integration of VERL with Agent Lightning.</p>"},{"location":"algorithm-zoo/verl/#agentlightning.verl.AgentLightningTrainer","title":"<code>AgentLightningTrainer</code>","text":"<p>               Bases: <code>RayPPOTrainer</code></p> <p>Specialized PPO trainer for agent-based reinforcement learning.</p> <p>This trainer is designed specifically for scenarios where the model interacts with external environments, tools, or APIs through an AgentLightningServer. It simplifies the training loop by removing the complex conditional logic present in the original RayPPOTrainer and focusing on the agent mode workflow.</p> <p>Key differences from RayPPOTrainer: 1. Uses AgentModeDaemon for server communication 2. Simplified data flow without pop/union operations 3. Direct batch processing through agent daemon 4. Streamlined validation using agent_mode validation</p> Source code in <code>agentlightning/verl/trainer.py</code> <pre><code>class AgentLightningTrainer(RayPPOTrainer):\n    \"\"\"\n    Specialized PPO trainer for agent-based reinforcement learning.\n\n    This trainer is designed specifically for scenarios where the model interacts with\n    external environments, tools, or APIs through an AgentLightningServer. It simplifies\n    the training loop by removing the complex conditional logic present in the original\n    RayPPOTrainer and focusing on the agent mode workflow.\n\n    Key differences from RayPPOTrainer:\n    1. Uses AgentModeDaemon for server communication\n    2. Simplified data flow without pop/union operations\n    3. Direct batch processing through agent daemon\n    4. Streamlined validation using agent_mode validation\n    \"\"\"\n\n    def __init__(\n        self, store: LightningStore | None, llm_proxy: LLMProxy | None, adapter: TraceAdapter | None, **kwargs\n    ):\n        super().__init__(**kwargs)\n        self.store = store\n        self.llm_proxy = llm_proxy\n        self.adapter = adapter\n\n    def _validate(self):\n        assert len(self.val_dataloader) == 1, \"Please set val_batch_size to None for better throughput.\"\n\n        test_data = next(iter(self.val_dataloader))\n        test_batch = DataProto.from_single_dict(test_data)\n\n        self.async_rollout_manager.wake_up()\n        self.agent_mode_daemon.set_up_data_and_server(\n            test_batch.non_tensor_batch,\n            self.async_rollout_manager.server_addresses,\n            is_train=False,\n        )\n        self.agent_mode_daemon.run_until_all_finished()\n        test_metrics = self.agent_mode_daemon.get_test_metrics()\n        self.agent_mode_daemon.clear_data_and_server()\n        self.async_rollout_manager.sleep()\n        return test_metrics\n\n    def _train_step(self, batch_dict: dict) -&gt; dict:\n        # Isolate in a separate method to automatically recycle the variables before validation.\n        batch: DataProto = DataProto.from_single_dict(batch_dict)\n        metrics = {}\n        timing_raw = {}\n\n        with _timer(\"step\", timing_raw):\n\n            # When agent mode is enabled, we read the batch as it is.\n            gen_batch = batch\n\n            # generate a batch\n            with _timer(\"gen\", timing_raw):\n                self.async_rollout_manager.wake_up()\n                self.agent_mode_daemon.set_up_data_and_server(\n                    gen_batch.non_tensor_batch, self.async_rollout_manager.server_addresses\n                )\n                self.agent_mode_daemon.run_until_all_finished()\n                batch, agent_metrics = self.agent_mode_daemon.get_train_data_batch(\n                    max_prompt_length=self.config.data.max_prompt_length,\n                    max_response_length=self.config.data.max_response_length,\n                    device=gen_batch.batch[\"fake_ids\"].device,\n                )\n                metrics.update(agent_metrics)\n                self.agent_mode_daemon.clear_data_and_server()\n                self.async_rollout_manager.sleep()\n\n            if self.config.algorithm.adv_estimator == AdvantageEstimator.REMAX:\n                with _timer(\"gen_max\", timing_raw):\n                    gen_baseline_batch = deepcopy(gen_batch)\n                    gen_baseline_batch.meta_info[\"do_sample\"] = False\n                    gen_baseline_output = self.async_rollout_manager.generate_sequences(gen_baseline_batch)\n\n                    batch = batch.union(gen_baseline_output)\n                    reward_baseline_tensor = self.reward_fn(batch)\n                    reward_baseline_tensor = reward_baseline_tensor.sum(dim=-1)\n\n                    batch.pop(batch_keys=list(gen_baseline_output.batch.keys()))\n\n                    batch.batch[\"reward_baselines\"] = reward_baseline_tensor\n\n                    del gen_baseline_batch, gen_baseline_output\n\n            # uid is used for algorithm like GRPO, should be aligned to data id\n            batch.non_tensor_batch[\"uid\"] = batch.non_tensor_batch[\"data_id_list\"]\n\n            batch.batch[\"response_mask\"] = compute_response_mask(batch)\n\n            # compute global_valid tokens\n            batch.meta_info[\"global_token_num\"] = torch.sum(batch.batch[\"attention_mask\"], dim=-1).tolist()\n\n            with _timer(\"reward\", timing_raw):\n                # compute reward model score\n                if self.use_rm:\n                    reward_tensor = self.rm_wg.compute_rm_score(batch)\n                    batch = batch.union(reward_tensor)\n\n                reward_extra_infos_dict = {}\n\n            # for agent mode, pad the lengths to calculate old log prob, ref, and values\n            batch, pad_size = pad_dataproto_to_divisor(batch, self.actor_rollout_wg.world_size)\n\n            # recompute old_log_probs\n            with _timer(\"old_log_prob\", timing_raw):\n                old_log_prob = self.actor_rollout_wg.compute_log_prob(batch)\n                entropys = old_log_prob.batch[\"entropys\"]\n                response_masks = batch.batch[\"response_mask\"]\n                loss_agg_mode = self.config.actor_rollout_ref.actor.loss_agg_mode\n                entropy_loss = agg_loss(loss_mat=entropys, loss_mask=response_masks, loss_agg_mode=loss_agg_mode)\n                old_log_prob_metrics = {\"actor/entropy_loss\": entropy_loss.detach().item()}\n                metrics.update(old_log_prob_metrics)\n                old_log_prob.batch.pop(\"entropys\")\n                batch = batch.union(old_log_prob)\n\n            if self.use_reference_policy:\n                # compute reference log_prob\n                with _timer(\"ref\", timing_raw):\n                    ref_log_prob = self.ref_policy_wg.compute_ref_log_prob(batch)\n                    batch = batch.union(ref_log_prob)\n\n            # compute values\n            if self.use_critic:\n                with _timer(\"values\", timing_raw):\n                    values = self.critic_wg.compute_values(batch)\n                    batch = batch.union(values)\n\n            # for agent mode, unpad to calculate adv\n            # it is important, as adv should be based on the raw traces\n            batch = unpad_dataproto(batch, pad_size=pad_size)\n\n            with _timer(\"adv\", timing_raw):\n                # if agent_mode is enabled, there is already token_level_scores\n                # token_level_scores is not needed to compute here\n\n                # compute rewards. apply_kl_penalty if available\n                if self.config.algorithm.use_kl_in_reward:\n                    batch, kl_metrics = apply_kl_penalty(\n                        batch, kl_ctrl=self.kl_ctrl_in_reward, kl_penalty=self.config.algorithm.kl_penalty\n                    )\n                    metrics.update(kl_metrics)\n                else:\n                    batch.batch[\"token_level_rewards\"] = batch.batch[\"token_level_scores\"]\n\n                # compute advantages, executed on the driver process\n\n                norm_adv_by_std_in_grpo = self.config.algorithm.get(\n                    \"norm_adv_by_std_in_grpo\", True\n                )  # GRPO adv normalization factor\n\n                batch = compute_advantage(\n                    batch,\n                    adv_estimator=self.config.algorithm.adv_estimator,\n                    gamma=self.config.algorithm.gamma,\n                    lam=self.config.algorithm.lam,\n                    num_repeat=self.config.actor_rollout_ref.rollout.n,\n                    norm_adv_by_std_in_grpo=norm_adv_by_std_in_grpo,\n                    config=self.config.algorithm,\n                )\n\n            # after advantages are assinged, we begin to drop (1) long prompt (2) floor to ppo minisize\n            keep_indices = (~batch.batch[\"is_drop_mask\"]).nonzero(as_tuple=True)[0]\n            metrics[\"training/n_triplets_prompt_too_long\"] = (\n                batch.batch[\"is_drop_mask\"].shape[0] - keep_indices.shape[0]\n            )\n            batch = batch[keep_indices]\n            # next, round to minibatch size\n            mini_batch_size = self.config.actor_rollout_ref.actor.ppo_mini_batch_size\n            n_transition = len(batch)\n            random_indices = list(range(n_transition))\n            random.shuffle(random_indices)\n            batch.reorder(torch.tensor(random_indices).type(torch.int32))\n            n_remained_transition = n_transition // mini_batch_size * mini_batch_size\n            batch = batch[list(range(n_remained_transition))]\n            metrics[\"training/n_triplets_dropped_remainder\"] = n_transition - n_remained_transition\n\n            # Agent mode note: Change the order of balance batch;\n            #     1. first calculate advantage\n            #     2. then drop the samples (too long prompt &amp; floor to ppo minisize)\n            #     3. balance\n            # balance the number of valid tokens on each dp rank.\n            # Note that this breaks the order of data inside the batch.\n            # Please take care when you implement group based adv computation such as GRPO and rloo\n            if self.config.trainer.balance_batch:\n                self._balance_batch(batch, metrics=metrics)\n\n            # update critic\n            if self.use_critic:\n                with _timer(\"update_critic\", timing_raw):\n                    critic_output = self.critic_wg.update_critic(batch)\n                critic_output_metrics = reduce_metrics(critic_output.meta_info[\"metrics\"])\n                metrics.update(critic_output_metrics)\n\n            # implement critic warmup\n            if self.config.trainer.critic_warmup &lt;= self.global_steps:\n                # update actor\n                with _timer(\"update_actor\", timing_raw):\n                    batch.meta_info[\"multi_turn\"] = self.config.actor_rollout_ref.rollout.multi_turn.enable\n                    actor_output = self.actor_rollout_wg.update_actor(batch)\n                actor_output_metrics = reduce_metrics(actor_output.meta_info[\"metrics\"])\n                metrics.update(actor_output_metrics)\n\n            # Log rollout generations if enabled\n            rollout_data_dir = self.config.trainer.get(\"rollout_data_dir\", None)\n            if rollout_data_dir:\n                with _timer(\"dump_rollout_generations\", timing_raw):\n                    print(batch.batch.keys())\n                    inputs = self.tokenizer.batch_decode(batch.batch[\"prompts\"], skip_special_tokens=True)\n                    outputs = self.tokenizer.batch_decode(batch.batch[\"responses\"], skip_special_tokens=True)\n                    scores = batch.batch[\"token_level_scores\"].sum(-1).cpu().tolist()\n                    self._dump_generations(\n                        inputs=inputs,\n                        outputs=outputs,\n                        scores=scores,\n                        reward_extra_infos_dict=reward_extra_infos_dict,\n                        dump_path=rollout_data_dir,\n                    )\n\n        # compute training metrics\n        metrics.update(compute_data_metrics(batch=batch, use_critic=self.use_critic))\n        metrics.update(compute_timing_metrics(batch=batch, timing_raw=timing_raw))\n        # TODO: implement actual tflpo and theoretical tflpo\n        n_gpus = self.resource_pool_manager.get_n_gpus()\n        metrics.update(compute_throughout_metrics(batch=batch, timing_raw=timing_raw, n_gpus=n_gpus))\n\n        return metrics\n\n    def fit(self):\n        logger = Tracking(\n            project_name=self.config.trainer.project_name,\n            experiment_name=self.config.trainer.experiment_name,\n            default_backend=self.config.trainer.logger,\n            config=OmegaConf.to_container(self.config, resolve=True),\n        )\n\n        self.global_steps = 0\n\n        # load checkpoint before doing anything\n        self._load_checkpoint()\n\n        assert self.async_rollout_mode, \"If agent mode is enabled, async server must be enabled\"\n        if self.adapter is not None and not isinstance(self.adapter, TraceToTripletBase):\n            raise ValueError(\"Adapter must be a TraceToTripletBase for currently VERL implementation.\")\n        self.agent_mode_daemon = AgentModeDaemon(\n            self.config.agentlightning.port,\n            self.config.actor_rollout_ref.rollout.n,\n            train_information={\n                # Note (Zhiyuan): To avoid further patch into vllm async server, using the same sentence to get the naming here.\n                # However, it is possible that verl updates the naming and causes incompatibility.\n                # Reference: https://github.com/volcengine/verl/blob/5b5e09d9cc20625e436d01f69d9cc739ff681c54/verl/workers/rollout/vllm_rollout/vllm_async_server.py#L217\n                \"model\": \"/\".join(self.config.actor_rollout_ref.model.path.split(\"/\")[-2:]),\n                \"temperature\": self.config.actor_rollout_ref.rollout.temperature,\n            },\n            tokenizer=self.tokenizer,\n            mini_batch_size=self.config.actor_rollout_ref.actor.ppo_mini_batch_size,\n            pad_token_id=self.tokenizer.pad_token_id,\n            mode=\"v1\" if self.store is not None else \"v0\",\n            store=self.store,\n            llm_proxy=self.llm_proxy,\n            adapter=self.adapter,\n        )\n        self.agent_mode_daemon.start()\n\n        # perform validation before training\n        # currently, we only support validation using the reward_function.\n        if self.val_reward_fn is not None and self.config.trainer.get(\"val_before_train\", True):\n            val_metrics = self._validate()\n            assert val_metrics, f\"{val_metrics=}\"\n            pprint(f\"Initial validation metrics: {val_metrics}\")\n            logger.log(data=val_metrics, step=self.global_steps)\n            if self.config.trainer.get(\"val_only\", False):\n                return\n\n        # add tqdm\n        progress_bar = tqdm(total=self.total_training_steps, initial=self.global_steps, desc=\"Training Progress\")\n\n        # we start from step 1\n        self.global_steps += 1\n        last_val_metrics = None\n\n        for epoch in range(self.config.trainer.total_epochs):\n            for batch_dict in self.train_dataloader:\n                metrics = {}\n                timing_raw = {}\n                is_last_step = self.global_steps &gt;= self.total_training_steps\n\n                # train step\n                metrics = self._train_step(batch_dict)\n\n                # validate\n                if (\n                    self.val_reward_fn is not None\n                    and self.config.trainer.test_freq &gt; 0\n                    and (is_last_step or self.global_steps % self.config.trainer.test_freq == 0)\n                ):\n                    with _timer(\"validate\", timing_raw):\n                        val_metrics: dict = self._validate()\n                        if is_last_step:\n                            last_val_metrics = val_metrics\n                    metrics.update(val_metrics)\n\n                if self.config.trainer.save_freq &gt; 0 and (\n                    is_last_step or self.global_steps % self.config.trainer.save_freq == 0\n                ):\n                    with _timer(\"save_checkpoint\", timing_raw):\n                        self._save_checkpoint()\n\n                # step metrics\n                metrics.update(\n                    {\n                        \"training/global_step\": self.global_steps,\n                        \"training/epoch\": epoch,\n                    }\n                )\n\n                # TODO: make a canonical logger that supports various backend\n                logger.log(data=metrics, step=self.global_steps)\n\n                if is_last_step:\n                    pprint(f\"Final validation metrics: {last_val_metrics}\")\n                    progress_bar.close()\n\n                    # This exit logic is to ensure a robust CI.\n                    pprint(f\"Flush the logger...\")\n                    del logger  # Make sure the loggers are flushed and closed properly\n                    pprint(f\"Training finished at step {self.global_steps}.\")\n                    return\n\n                progress_bar.update(1)\n                self.global_steps += 1\n</code></pre>"},{"location":"algorithm-zoo/verl/#agentlightning.verl.AgentModeDaemon","title":"<code>AgentModeDaemon</code>","text":"<p>AgentModeDaemon using the AgentLightningServer SDK.</p> <p>This class manages the server lifecycle, task queueing, and results retrieval, while also running a proxy server for LLM requests. It maintains the original interface for compatibility with the RayPPOTrainer.</p> Source code in <code>agentlightning/verl/daemon.py</code> <pre><code>class AgentModeDaemon:\n    \"\"\"\n    AgentModeDaemon using the AgentLightningServer SDK.\n\n    This class manages the server lifecycle, task queueing, and results\n    retrieval, while also running a proxy server for LLM requests. It maintains\n    the original interface for compatibility with the RayPPOTrainer.\n    \"\"\"\n\n    def __init__(\n        self,\n        port: Optional[int],\n        train_rollout_n: int,\n        train_information: Dict[str, Any],\n        tokenizer: Any,\n        mini_batch_size: int,\n        pad_token_id: int,\n        reward_fillna_value: float = 0.0,\n        llm_timeout_seconds: float = 1200.0,\n        mode: Literal[\"v0\", \"v1\"] = \"v1\",\n        llm_proxy: LLMProxy | None = None,\n        store: LightningStore | None = None,\n        adapter: TraceToTripletBase | None = None,\n    ):\n        self.mode = mode\n        self.llm_timeout_seconds = llm_timeout_seconds\n\n        # Server and Task Configuration\n        if mode == \"v0\":\n            assert port is not None\n            self.server_port = port\n            self.server = AgentLightningServer(\n                host=\"0.0.0.0\", port=self.server_port, task_timeout_seconds=self.llm_timeout_seconds\n            )\n            self.proxy_port = _find_available_port()  # Run proxy on a different port\n        else:\n            assert store is not None\n            self.store = store\n            if llm_proxy is None:\n                self.llm_proxy = LLMProxy(\n                    port=_find_available_port(),\n                    model_list=[],\n                    store=store,\n                )\n            else:\n                # Reuse the existing LLM proxy (probably configured by user)\n                self.llm_proxy = llm_proxy\n            if adapter is None:\n                self.adapter = TracerTraceToTriplet()\n            else:\n                # Reuse the one from trainer\n                self.adapter = adapter\n            self._internal_loop: Optional[asyncio.AbstractEventLoop] = None\n            self._internal_loop_thread = threading.Thread(target=self._internal_loop_runner, daemon=True)\n            self._internal_loop_thread.start()\n\n        # Training and Data Configuration\n        self.train_rollout_n = train_rollout_n\n        self.train_information = train_information\n        self.mini_batch_size = mini_batch_size\n        self.pad_token_id = pad_token_id\n        self.tokenizer = tokenizer\n        self.reward_fillna_value = reward_fillna_value\n\n        # Internal State\n        self.backend_llm_server_addresses: List[str] = []\n        self._total_tasks_queued = 0\n        self._completed_rollouts_v0: Dict[str, RolloutLegacy] = {}\n        self._task_id_to_original_sample: Dict[str, Dict[str, Any]] = {}\n        self._server_thread: Optional[threading.Thread] = None\n        self._proxy_thread: Optional[threading.Thread] = None\n        self.is_train = True\n\n    def _internal_loop_runner(self):\n        \"\"\"Run the internal loop.\"\"\"\n        loop = asyncio.new_event_loop()\n        asyncio.set_event_loop(loop)\n        self._internal_loop = loop\n        loop.run_forever()\n        loop.close()\n\n    def _start_proxy_server_v0(self):\n        \"\"\"\n        Initializes and runs a Flask-based proxy server in a separate thread.\n        This proxy load-balances requests to the actual backend LLM servers.\n        \"\"\"\n        app = Flask(__name__)\n\n        num_requests = 0\n        last_request_time = 0\n\n        @app.route(\"/v1/&lt;path:path&gt;\", methods=[\"GET\", \"POST\", \"PUT\", \"DELETE\", \"PATCH\", \"OPTIONS\", \"HEAD\"])\n        def proxy(path: str):  # type: ignore\n            if not self.backend_llm_server_addresses:\n                abort(503, description=\"No backend LLM servers available.\")\n\n            # Randomly choose a backend server for load balancing\n            target_server = random.choice(self.backend_llm_server_addresses)\n            target_url = f\"http://{target_server}/v1/{path}\"\n\n            # Copy client request headers, removing the Host header\n            headers = {key: value for key, value in request.headers if key.lower() != \"host\"}\n\n            # Log the request for debugging\n            nonlocal num_requests, last_request_time\n            current_time = time.time()\n            num_requests += 1\n            if current_time - last_request_time &gt; 60 or num_requests == 1 or num_requests % 100 == 0:\n                print(f\"Proxying {request.method} request to {target_server}. Request data: {request.get_data()}\")\n            last_request_time = current_time\n\n            try:\n                # Forward the request to the target backend\n                resp = requests.request(\n                    method=request.method,\n                    url=target_url,\n                    headers=headers,\n                    params=request.args,  # type: ignore\n                    data=request.get_data(),\n                    cookies=request.cookies,\n                    allow_redirects=False,\n                    timeout=self.llm_timeout_seconds,\n                )\n                # Filter out hop-by-hop headers before returning the response\n                excluded_headers = [\n                    \"content-encoding\",\n                    \"content-length\",\n                    \"transfer-encoding\",\n                    \"connection\",\n                    \"keep-alive\",\n                    \"proxy-authenticate\",\n                    \"proxy-authorization\",\n                    \"te\",\n                    \"trailers\",\n                    \"upgrade\",\n                ]\n                response_headers = [\n                    (name, value) for name, value in resp.raw.headers.items() if name.lower() not in excluded_headers\n                ]\n                if resp.status_code == 200:\n                    # NOTE: from Zhiyuan's code.\n                    # https://github.com/hzy46/verl_agent_mode/blob/2db65ea9858f645a914120357412a7540f8bd82d/verl/trainer/ppo/ray_trainer.py#L692-L711\n                    # request_json = json.loads(request.get_data().decode(\"utf-8\"))\n                    response_json = json.loads(resp.content.decode(\"utf-8\"))\n                    # response_message = ChatCompletion(**response_json).choices[0].message.model_dump(exclude_unset=True, exclude_none=True)\n                    # tool_schemas = request_json.get(\"tools\", None)\n                    # prompt_ids = self.tokenizer.apply_chat_template(request_json[\"messages\"], tools=tool_schemas, add_generation_prompt=True, tokenize=True)\n                    # full_ids = self.tokenizer.apply_chat_template(request_json[\"messages\"] + [response_message], tools=tool_schemas, add_generation_prompt=False, tokenize=True)\n                    # TBD: response_ids sometimes ends with \"&lt;eos_id&gt;\\n\", shall we keep the extra \"\\n\"?\n                    # sometimes it has some differences with the hacky method in the end, but this should align with ToolCompletionCallback\n                    # response_ids = full_ids[len(prompt_ids):]\n\n                    # NOTE (yuge): They are different. Don't know why.\n                    # assert response_json['prompt_token_ids'] == prompt_ids\n                    # patched_response_ids = response_json['response_token_ids'][0]\n                    # assert patched_response_ids == response_ids[:len(patched_response_ids)], f\"{patched_response_ids} != {response_ids[:len(patched_response_ids)]}\"\n                    # response_json['prompt_token_ids'] = prompt_ids\n                    # response_json['response_token_ids'] = [response_ids]\n                    replaced_return_content = json.dumps(response_json).encode(\"utf-8\")\n                    return Response(replaced_return_content, status=resp.status_code, headers=response_headers)\n                return Response(resp.content, resp.status_code, response_headers)\n            except requests.exceptions.RequestException as e:\n                abort(500, description=f\"Error proxying request: {e}\")\n\n        def run_app():\n            app.run(host=\"0.0.0.0\", port=self.proxy_port, threaded=True, debug=False)\n\n        self._proxy_thread = threading.Thread(target=run_app, daemon=True)\n        self._proxy_thread.start()\n        print(f\"Proxy server running on port {self.proxy_port}\")\n\n    def _update_proxy_server_v1(self):\n        model_name = self.train_information.get(\"model\")\n        if not model_name:\n            raise ValueError(\"Model name is not set.\")\n        self.llm_proxy.update_model_list(\n            [\n                ModelConfig(\n                    {\n                        \"model_name\": model_name,\n                        \"litellm_params\": {\n                            \"model\": \"hosted_vllm/\" + model_name,\n                            \"api_base\": f\"http://{address}/v1/\",\n                        },\n                    }\n                )\n                for address in self.backend_llm_server_addresses\n            ],\n        )\n\n        if self.llm_proxy.is_running():\n            # FIXME: Need to switch to a different port right now\n            # because the forked processes carried the old fd\n            self.llm_proxy.restart(_port=_find_available_port())\n        else:\n            self.llm_proxy.start()\n\n    def start(self):\n        \"\"\"Starts the main AgentLightningServer and the proxy server.\"\"\"\n\n        if self.mode == \"v0\":\n\n            def run_server():\n                \"\"\"Run the AgentLightningServer in a separate thread.\"\"\"\n                asyncio.run(self.server.run_forever())\n\n            self._server_thread = threading.Thread(target=run_server, daemon=True)\n            self._server_thread.start()\n\n            # Wait for the server's internal startup event to be set.\n            print(\"Waiting for AgentLightningServer to start...\")\n            is_ready = self.server.startup_event.wait(timeout=20.0)  # Wait up to 20s\n            if not is_ready:\n                raise RuntimeError(\"AgentLightningServer failed to start within the timeout period.\")\n\n            print(f\"AgentLightningServer control plane running on port {self.server_port}\")\n\n            self._start_proxy_server_v0()\n        else:\n            # Agent lightning server is no longer needed;\n            # Start proxy server in _async_set_up\n            pass\n\n    async def _async_set_up(self, data: Dict[str, Any], server_addresses: List[str], is_train: bool = True):\n        \"\"\"Async helper to set up data and resources on the server.\"\"\"\n        self.clear_data_and_server()\n        if server_addresses != self.backend_llm_server_addresses:\n            self.backend_llm_server_addresses = server_addresses\n            if self.mode == \"v1\" and not self.llm_proxy.is_running():\n                self._update_proxy_server_v1()\n        self.is_train = is_train\n\n        # 1. Update resources on the server for clients to use\n        if self.mode == \"v0\":\n            llm_resource = LLM(\n                endpoint=f\"http://127.0.0.1:{self.proxy_port}/v1\",\n                model=self.train_information.get(\"model\", \"default-model\"),\n                sampling_parameters={\n                    \"temperature\": self.train_information.get(\"temperature\", 0.7 if is_train else 0.0)\n                },\n            )\n        else:\n            llm_resource = self.llm_proxy.as_resource(\n                sampling_parameters={\n                    \"temperature\": self.train_information.get(\"temperature\", 0.7 if is_train else 0.0)\n                },\n            )\n\n        resources: NamedResources = {\"main_llm\": llm_resource}\n\n        if self.mode == \"v0\":\n            resources_id = await self.server.update_resources(resources)\n        else:\n            resources_update = await self.store.add_resources(resources)\n            resources_id = resources_update.resources_id\n\n        # 2. Queue tasks for agents to process\n        keys = list(data.keys())\n        num_samples = len(data[keys[0]])\n        rollouts_per_sample = self.train_rollout_n if is_train else 1\n\n        for i in range(num_samples):\n            data_id = str(uuid.uuid4())\n            original_sample = {key: data[key][i] for key in keys}\n            original_sample[\"data_id\"] = data_id\n\n            # For training, each sample is rolled out multiple times\n            for _ in range(rollouts_per_sample):\n                task_metadata = {\"data_id\": data_id, \"is_train\": is_train}\n\n                # Data ID is different from Rollout ID, as one data can have multiple rollouts.\n                if self.mode == \"v0\":\n                    rollout_id = await self.server.queue_task(\n                        sample=_to_native(original_sample),\n                        mode=\"train\" if is_train else \"val\",\n                        resources_id=resources_id,\n                        metadata=task_metadata,\n                    )\n                else:\n                    rollout = await self.store.enqueue_rollout(\n                        input=_to_native(original_sample),\n                        mode=\"train\" if is_train else \"val\",\n                        resources_id=resources_id,\n                        metadata=task_metadata,\n                    )\n                    await self.store.update_rollout(\n                        rollout_id=rollout.rollout_id,\n                        config=RolloutConfig(\n                            unresponsive_seconds=self.llm_timeout_seconds,\n                            timeout_seconds=self.llm_timeout_seconds,\n                        ),\n                    )\n                    rollout_id = rollout.rollout_id\n\n                # Store original sample data to reconstruct batch information later\n                self._task_id_to_original_sample[rollout_id] = original_sample\n                self._total_tasks_queued += 1\n\n    def set_up_data_and_server(self, data: Dict[str, Any], server_addresses: List[str], is_train: bool = True):\n        \"\"\"Synchronous wrapper for setting up data and server resources.\"\"\"\n        coro = self._async_set_up(data, server_addresses, is_train)\n\n        if self.mode == \"v0\":\n            if not self.server.loop or not self.server.startup_event.is_set():\n                raise RuntimeError(\"Server is not running or ready.\")\n\n            future = asyncio.run_coroutine_threadsafe(coro, self.server.loop)\n\n        else:\n            if self._internal_loop is None:\n                raise RuntimeError(\"Internal loop is not running.\")\n            future = asyncio.run_coroutine_threadsafe(coro, self._internal_loop)\n        try:\n            future.result(timeout=60)  # Wait for completion with a timeout\n        except Exception as e:\n            print(f\"Failed to set up data on server: {e}\")\n            raise\n\n    def _validate_data(self, rollout: RolloutLegacy):\n        if rollout.final_reward is None:\n            print(\n                f\"Warning: Reward is None for rollout {rollout.rollout_id}, will be auto-set to {self.reward_fillna_value}.\"\n            )\n        if rollout.triplets is None:\n            print(f\"Warning: Triplet is None for rollout {rollout.rollout_id}.\")\n        elif len(rollout.triplets) == 0:\n            print(f\"Warning: Length of triplets is 0 for rollout {rollout.rollout_id}.\")\n        elif any(not r.response.get(\"token_ids\", []) for r in rollout.triplets):\n            print(f\"Warning: Rollout {rollout.rollout_id} contains empty response: {rollout.triplets}\")\n        elif any(not r.prompt.get(\"token_ids\", []) for r in rollout.triplets):\n            print(f\"Warning: Rollout {rollout.rollout_id} contains empty prompt: {rollout.triplets}\")\n\n    async def _validate_data_v1(self, rollout: Rollout) -&gt; RolloutLegacy:\n        \"\"\"Convert Rollout to RolloutLegacy and validate.\n\n        1. Task: construct from Rollout\n        2. Triplets: obtained by querying spans and feeding into the adapter\n        3. Final reward: extracted from last triplet's reward, searching backwards if not found\n        \"\"\"\n        # Query spans for this rollout (latest attempt)\n        spans = await self.store.query_spans(rollout.rollout_id, attempt_id=\"latest\")\n\n        # Convert spans to triplets using the adapter\n        if not spans:\n            # No triplets found, will emit a warning later.\n            triplets = []\n        else:\n            triplets = self.adapter.adapt(spans)\n\n        # Extract final reward from triplets\n        final_reward: Optional[float] = None\n        if triplets:\n            # Search backwards through triplets for the first non-None reward\n            for triplet in reversed(triplets):\n                if triplet.reward is not None:\n                    final_reward = triplet.reward\n                    break\n\n        # Construct the Task object from Rollout\n        task = Task(\n            rollout_id=rollout.rollout_id,\n            input=rollout.input,\n            mode=rollout.mode,\n            resources_id=rollout.resources_id,\n            metadata=rollout.metadata or {},\n        )\n\n        # Create the Rollout object (without trace and logs as per user's note)\n        result_rollout = RolloutLegacy(\n            rollout_id=rollout.rollout_id,\n            task=task,\n            final_reward=final_reward,\n            triplets=triplets,\n            metadata=rollout.metadata or {},\n        )\n\n        # Run the same validation as v0\n        self._validate_data(result_rollout)\n\n        return result_rollout\n\n    async def _async_run_until_finished(self, verbose: bool = True):\n        \"\"\"Async helper to wait for all tasks to complete.\"\"\"\n        while len(self._completed_rollouts_v0) &lt; self._total_tasks_queued:\n            if self.mode == \"v0\":\n                completed_batch = await self.server.retrieve_completed_rollouts()\n            else:\n                completed_batch = await self.store.wait_for_rollouts(\n                    rollout_ids=list(self._task_id_to_original_sample.keys()), timeout=0\n                )\n            for rollout in completed_batch:\n                if rollout.rollout_id in self._completed_rollouts_v0:\n                    # Already processed, skip\n                    continue\n                if isinstance(rollout, Rollout):\n                    rollout = await self._validate_data_v1(rollout)\n                else:\n                    self._validate_data(rollout)\n                if rollout.rollout_id not in self._task_id_to_original_sample:\n                    print(f\"Warning: Received unknown rollout ID {rollout.rollout_id}, skipping.\")\n                else:\n                    self._completed_rollouts_v0[rollout.rollout_id] = rollout\n            if verbose:\n                print(f\"Completed {len(self._completed_rollouts_v0)}/{self._total_tasks_queued} tasks...\")\n            await asyncio.sleep(5)\n\n        print(\"All tasks finished.\")\n\n    def run_until_all_finished(self, verbose: bool = True):\n        \"\"\"Synchronously waits for all queued tasks to be completed and reported.\"\"\"\n        if self._total_tasks_queued == 0:\n            print(\"Warning: No tasks were queued.\")\n            return\n\n        if self.mode == \"v0\":\n            if not self.server.loop or not self.server.startup_event.is_set():\n                raise RuntimeError(\"Server is not running or ready.\")\n            loop = self.server.loop\n        else:\n            loop = self._internal_loop\n            assert loop is not None\n\n        coro = self._async_run_until_finished(verbose)\n        future = asyncio.run_coroutine_threadsafe(coro, loop)\n        try:\n            future.result()  # Wait indefinitely for all tasks to complete\n        except Exception as e:\n            print(f\"Error while waiting for tasks to finish: {e}\")\n            raise\n\n    def get_test_metrics(self):\n        \"\"\"Calculates and returns metrics for a validation run.\"\"\"\n        assert not self.is_train, \"This method should only be called during validation.\"\n        assert len(self._completed_rollouts_v0) == self._total_tasks_queued\n\n        sample_stat_list: List[Dict[str, Any]] = []\n        sample_stat_list_by_source: Dict[str, List[Dict[str, Any]]] = defaultdict(\n            list\n        )  # FIXME: Evaluate whether grouping stats by source is actually needed.\n\n        for rollout_id, rollout in self._completed_rollouts_v0.items():\n            final_reward = self._fillna_reward(rollout)\n            if not rollout.triplets:\n                print(f\"Warning: No triplets found for test rollout {rollout.rollout_id}.\")\n                sample_stat_list.append({\"reward\": final_reward})\n                continue\n            response_length_list = [len(triplet.response.get(\"token_ids\", [])) for triplet in rollout.triplets]\n            if \"data_source\" in self._task_id_to_original_sample[rollout_id]:\n                # When a test sample includes a 'data_source' field, record per-source statistics for test results.\n                data_source = self._task_id_to_original_sample[rollout_id][\"data_source\"]\n                sample_stat_list_by_source[data_source].append(\n                    {\n                        \"sum_response_length\": np.sum(response_length_list),\n                        \"mean_response_length\": np.mean(response_length_list) if response_length_list else 0,\n                        \"turn_count\": len(rollout.triplets),\n                        \"reward\": final_reward,\n                    }\n                )\n            sample_stat_list.append(\n                {\n                    \"sum_response_length\": np.sum(response_length_list),\n                    \"mean_response_length\": np.mean(response_length_list) if response_length_list else 0,\n                    \"turn_count\": len(rollout.triplets),\n                    \"reward\": final_reward,\n                }\n            )\n        metric_dict: Dict[str, Any] = {}\n\n        stats_w_trace = [stat for stat in sample_stat_list if \"sum_response_length\" in stat]\n        stats_w_trace_by_source = {\n            data_source: [stat for stat in sample_stats if \"sum_response_length\" in stat]\n            for data_source, sample_stats in sample_stat_list_by_source.items()\n        }\n        for data_source, sample_stats in sample_stat_list_by_source.items():\n            metric_dict.update(\n                {\n                    f\"val/{data_source}/n_rollouts\": len(sample_stats),\n                    f\"val/{data_source}/n_rollouts_w_trace\": len(stats_w_trace_by_source[data_source]),\n                    f\"val/{data_source}/reward\": np.mean(\n                        [stat[\"reward\"] for stat in sample_stats]\n                    ),  # each rollout must have a reward (fillna if missing)\n                    f\"val/{data_source}/mean_response_length\": np.mean(\n                        [stat[\"mean_response_length\"] for stat in stats_w_trace_by_source[data_source]]\n                    ),\n                    f\"val/{data_source}/sum_response_length\": np.mean(\n                        [stat[\"sum_response_length\"] for stat in stats_w_trace_by_source[data_source]]\n                    ),\n                    f\"val/{data_source}/turn_count\": np.mean(\n                        [stat[\"turn_count\"] for stat in stats_w_trace_by_source[data_source]]\n                    ),\n                }\n            )\n        metric_dict.update(\n            {\n                \"val/n_rollouts\": len(sample_stat_list),\n                \"val/n_rollouts_w_trace\": len(stats_w_trace),\n                \"val/reward\": np.mean(\n                    [stat[\"reward\"] for stat in sample_stat_list]\n                ),  # each rollout must have a reward (fillna if missing)\n                \"val/mean_response_length\": np.mean([stat[\"mean_response_length\"] for stat in stats_w_trace]),\n                \"val/sum_response_length\": np.mean([stat[\"sum_response_length\"] for stat in stats_w_trace]),\n                \"val/turn_count\": np.mean([stat[\"turn_count\"] for stat in stats_w_trace]),\n            }\n        )\n        return metric_dict\n\n    def get_train_data_batch(self, max_prompt_length: int, max_response_length: int, device: torch.device):\n        \"\"\"\n        Processes completed rollouts to generate a training data batch.\n\n        This function reconstructs the logic from the original AgentModeDaemon,\n        using data retrieved from the new server architecture. It handles padding,\n        truncation, and tensor creation for the PPO training loop.\n        \"\"\"\n        assert self.is_train, \"This method should only be called during training.\"\n        assert len(self._completed_rollouts_v0) == self._total_tasks_queued\n\n        # 1. Reconstruct the `finished_id_to_sample_info` structure from completed rollouts\n        finished_id_to_sample_info: Dict[str, Dict[str, Any]] = {}\n        finished_id_to_final_reward: Dict[str, float] = {}\n        for rollout_id, rollout in self._completed_rollouts_v0.items():\n            original_sample = self._task_id_to_original_sample[rollout_id]\n\n            final_reward = self._fillna_reward(rollout)\n\n            if not rollout.triplets:\n                finished_id_to_final_reward[rollout_id] = final_reward\n                print(f\"Warning: No triplets found for training rollout {rollout.rollout_id}, skipping.\")\n                continue\n\n            # The client should report triplets that contain prompt_ids and response_ids.\n            # Example triplet.prompt: {\"token_ids\": [...]}\n            # Example triplet.response: {\"token_ids\": [...]}\n            trace_list = [\n                {\"prompt_ids\": t.prompt.get(\"token_ids\", []), \"response_ids\": t.response.get(\"token_ids\", [])}\n                for t in rollout.triplets\n            ]\n            info = {\n                \"reward\": final_reward,\n                \"trace_list\": trace_list,\n                \"data_id\": original_sample[\"data_id\"],\n            }\n            finished_id_to_sample_info[rollout_id] = info\n            finished_id_to_final_reward[rollout_id] = final_reward\n        #\n        # --- Data processing and tensor creation logic ---\n        # Get all the reported data.\n        # prompt_ids are left-padded.\n        # response_ids are right-padded.\n        # They are concatenated in the middle.\n        # Discard handling:\n        #   - Those exceeding max_prompt_length will be marked for discard, but not\n        #     discarded here. They are only truncated and marked, to be discarded later.\n        #     This is for the correctness of the advantage calculation.\n        #   - The discard for the PPO mini-batch should also be handled this way.\n        input_ids_list: List[List[int]] = []\n        input_attention_mask_list: List[List[int]] = []\n        response_ids_list: List[List[int]] = []\n        response_attention_mask_list: List[List[int]] = []\n        reward_list: List[float] = []\n        data_id_list: List[str] = []\n        rollout_id_list: List[str] = []\n        turn_index_list: List[int] = []\n        is_drop_list: List[bool] = []\n        n_trunc_sample_because_of_response = 0\n\n        for rollout_id, sample_info in finished_id_to_sample_info.items():\n            for turn_index, trace in enumerate(sample_info[\"trace_list\"]):\n\n                reward_list.append(sample_info[\"reward\"])\n                prompt_ids, response_ids = trace[\"prompt_ids\"], trace[\"response_ids\"]\n\n                # Mark samples with prompts exceeding max_prompt_length to be dropped later\n                if len(prompt_ids) &gt; max_prompt_length:\n                    prompt_ids = prompt_ids[:max_prompt_length]\n                    is_drop_list.append(True)\n                else:\n                    is_drop_list.append(False)\n\n                # Truncate responses that exceed max_response_length\n                if len(response_ids) &gt; max_response_length:\n                    response_ids = response_ids[:max_response_length]\n                    n_trunc_sample_because_of_response += 1\n\n                # Pad prompts to the left and responses to the right\n                one_input_ids, one_input_attention_mask = get_left_padded_ids_and_attention_mask(\n                    prompt_ids, max_prompt_length, self.pad_token_id\n                )\n                one_response_ids, one_response_attention_mask = get_right_padded_ids_and_attention_mask(\n                    response_ids, max_response_length, self.pad_token_id\n                )\n\n                input_ids_list.append(one_input_ids)\n                input_attention_mask_list.append(one_input_attention_mask)\n                response_ids_list.append(one_response_ids)\n                response_attention_mask_list.append(one_response_attention_mask)\n                data_id_list.append(sample_info[\"data_id\"])\n                rollout_id_list.append(rollout_id)\n                turn_index_list.append(turn_index)\n\n        n_transition = len(input_ids_list)\n        batch_input_ids = torch.LongTensor(input_ids_list).to(device)\n        input_attention_mask = torch.LongTensor(input_attention_mask_list).to(device)\n        batch_response_ids = torch.LongTensor(response_ids_list).to(device)\n        response_attention_mask = torch.LongTensor(response_attention_mask_list).to(device)\n\n        # Concatenate prompts and responses to form the full sequence\n        batch_seq = torch.cat([batch_input_ids, batch_response_ids], dim=-1)\n        attention_mask = torch.cat([input_attention_mask, response_attention_mask], dim=-1)\n        position_ids = torch.clamp(torch.cumsum(attention_mask, dim=-1) - 1, min=0)\n        is_drop_mask = torch.BoolTensor(is_drop_list).to(device)\n        scores = torch.tensor(reward_list, dtype=torch.bfloat16).to(device)\n\n        # Create token-level scores by placing the final reward at the last token position\n        token_level_scores = torch.zeros_like(attention_mask, dtype=scores.dtype)\n        # At the eos_mask_idx position of each sample, fill in the corresponding scores.\n        # torch.arange(n_transition) generates [0,1,2,...,bsz-1] as indices for the batch dimension.\n        eos_mask_idx = torch.argmax(position_ids * attention_mask, dim=-1)  # (bsz,)\n        token_level_scores[torch.arange(n_transition), eos_mask_idx] = scores\n        # Only take the last response_length part of the sequence to get the token-level scores for the model's response part.\n        token_level_scores = token_level_scores[:, -max_response_length:]\n\n        # Form the final batch using TensorDict\n        batch = TensorDict(\n            {\n                \"prompts\": batch_input_ids,\n                \"responses\": batch_response_ids,\n                \"input_ids\": batch_seq,  # here input_ids become the whole sentences\n                \"attention_mask\": attention_mask,\n                \"position_ids\": position_ids,\n                \"is_drop_mask\": is_drop_mask,\n                \"token_level_scores\": token_level_scores.contiguous(),\n            },\n            batch_size=n_transition,\n        )\n        data_proto = DataProto(batch=batch)\n\n        data_metrics = {\n            \"training/reward\": np.mean(list(finished_id_to_final_reward.values())),\n            \"training/n_rollouts\": len(finished_id_to_final_reward),\n            \"training/n_rollouts_w_trace\": len(finished_id_to_sample_info),\n            \"training/n_truncated_triplets\": n_trunc_sample_because_of_response,\n            \"training/n_triplets\": n_transition,\n        }\n\n        # Add non-tensor data for advantage calculation and logging\n        data_proto.non_tensor_batch[\"data_id_list\"] = np.array(data_id_list)  # type: ignore\n        data_proto.non_tensor_batch[\"rollout_id_list\"] = np.array(rollout_id_list)  # type: ignore\n        data_proto.non_tensor_batch[\"turn_index_list\"] = np.array(turn_index_list)  # type: ignore\n\n        return data_proto, data_metrics\n\n    def clear_data_and_server(self):\n        \"\"\"Resets the internal state of the daemon for the next run.\"\"\"\n        self.backend_llm_server_addresses = []\n        self._completed_rollouts_v0.clear()\n        self._task_id_to_original_sample.clear()\n        self._total_tasks_queued = 0\n        # For a true reset, the server's internal queues would also need clearing.\n        # This implementation assumes that `set_up_data_and_server` is called\n        # for each new run, effectively starting a fresh batch.\n\n    def _fillna_reward(self, rollout: RolloutLegacy):\n        if rollout.final_reward is None:\n            if self.reward_fillna_value is not None:  # type: ignore\n                final_reward = self.reward_fillna_value\n            else:\n                raise ValueError(f\"Reward is None for rollout {rollout.rollout_id}, please check the reward function.\")\n        else:\n            final_reward = rollout.final_reward\n        return final_reward\n</code></pre>"},{"location":"algorithm-zoo/verl/#agentlightning.verl.AgentModeDaemon.clear_data_and_server","title":"<code>clear_data_and_server()</code>","text":"<p>Resets the internal state of the daemon for the next run.</p> Source code in <code>agentlightning/verl/daemon.py</code> <pre><code>def clear_data_and_server(self):\n    \"\"\"Resets the internal state of the daemon for the next run.\"\"\"\n    self.backend_llm_server_addresses = []\n    self._completed_rollouts_v0.clear()\n    self._task_id_to_original_sample.clear()\n    self._total_tasks_queued = 0\n</code></pre>"},{"location":"algorithm-zoo/verl/#agentlightning.verl.AgentModeDaemon.get_test_metrics","title":"<code>get_test_metrics()</code>","text":"<p>Calculates and returns metrics for a validation run.</p> Source code in <code>agentlightning/verl/daemon.py</code> <pre><code>def get_test_metrics(self):\n    \"\"\"Calculates and returns metrics for a validation run.\"\"\"\n    assert not self.is_train, \"This method should only be called during validation.\"\n    assert len(self._completed_rollouts_v0) == self._total_tasks_queued\n\n    sample_stat_list: List[Dict[str, Any]] = []\n    sample_stat_list_by_source: Dict[str, List[Dict[str, Any]]] = defaultdict(\n        list\n    )  # FIXME: Evaluate whether grouping stats by source is actually needed.\n\n    for rollout_id, rollout in self._completed_rollouts_v0.items():\n        final_reward = self._fillna_reward(rollout)\n        if not rollout.triplets:\n            print(f\"Warning: No triplets found for test rollout {rollout.rollout_id}.\")\n            sample_stat_list.append({\"reward\": final_reward})\n            continue\n        response_length_list = [len(triplet.response.get(\"token_ids\", [])) for triplet in rollout.triplets]\n        if \"data_source\" in self._task_id_to_original_sample[rollout_id]:\n            # When a test sample includes a 'data_source' field, record per-source statistics for test results.\n            data_source = self._task_id_to_original_sample[rollout_id][\"data_source\"]\n            sample_stat_list_by_source[data_source].append(\n                {\n                    \"sum_response_length\": np.sum(response_length_list),\n                    \"mean_response_length\": np.mean(response_length_list) if response_length_list else 0,\n                    \"turn_count\": len(rollout.triplets),\n                    \"reward\": final_reward,\n                }\n            )\n        sample_stat_list.append(\n            {\n                \"sum_response_length\": np.sum(response_length_list),\n                \"mean_response_length\": np.mean(response_length_list) if response_length_list else 0,\n                \"turn_count\": len(rollout.triplets),\n                \"reward\": final_reward,\n            }\n        )\n    metric_dict: Dict[str, Any] = {}\n\n    stats_w_trace = [stat for stat in sample_stat_list if \"sum_response_length\" in stat]\n    stats_w_trace_by_source = {\n        data_source: [stat for stat in sample_stats if \"sum_response_length\" in stat]\n        for data_source, sample_stats in sample_stat_list_by_source.items()\n    }\n    for data_source, sample_stats in sample_stat_list_by_source.items():\n        metric_dict.update(\n            {\n                f\"val/{data_source}/n_rollouts\": len(sample_stats),\n                f\"val/{data_source}/n_rollouts_w_trace\": len(stats_w_trace_by_source[data_source]),\n                f\"val/{data_source}/reward\": np.mean(\n                    [stat[\"reward\"] for stat in sample_stats]\n                ),  # each rollout must have a reward (fillna if missing)\n                f\"val/{data_source}/mean_response_length\": np.mean(\n                    [stat[\"mean_response_length\"] for stat in stats_w_trace_by_source[data_source]]\n                ),\n                f\"val/{data_source}/sum_response_length\": np.mean(\n                    [stat[\"sum_response_length\"] for stat in stats_w_trace_by_source[data_source]]\n                ),\n                f\"val/{data_source}/turn_count\": np.mean(\n                    [stat[\"turn_count\"] for stat in stats_w_trace_by_source[data_source]]\n                ),\n            }\n        )\n    metric_dict.update(\n        {\n            \"val/n_rollouts\": len(sample_stat_list),\n            \"val/n_rollouts_w_trace\": len(stats_w_trace),\n            \"val/reward\": np.mean(\n                [stat[\"reward\"] for stat in sample_stat_list]\n            ),  # each rollout must have a reward (fillna if missing)\n            \"val/mean_response_length\": np.mean([stat[\"mean_response_length\"] for stat in stats_w_trace]),\n            \"val/sum_response_length\": np.mean([stat[\"sum_response_length\"] for stat in stats_w_trace]),\n            \"val/turn_count\": np.mean([stat[\"turn_count\"] for stat in stats_w_trace]),\n        }\n    )\n    return metric_dict\n</code></pre>"},{"location":"algorithm-zoo/verl/#agentlightning.verl.AgentModeDaemon.get_train_data_batch","title":"<code>get_train_data_batch(max_prompt_length, max_response_length, device)</code>","text":"<p>Processes completed rollouts to generate a training data batch.</p> <p>This function reconstructs the logic from the original AgentModeDaemon, using data retrieved from the new server architecture. It handles padding, truncation, and tensor creation for the PPO training loop.</p> Source code in <code>agentlightning/verl/daemon.py</code> <pre><code>def get_train_data_batch(self, max_prompt_length: int, max_response_length: int, device: torch.device):\n    \"\"\"\n    Processes completed rollouts to generate a training data batch.\n\n    This function reconstructs the logic from the original AgentModeDaemon,\n    using data retrieved from the new server architecture. It handles padding,\n    truncation, and tensor creation for the PPO training loop.\n    \"\"\"\n    assert self.is_train, \"This method should only be called during training.\"\n    assert len(self._completed_rollouts_v0) == self._total_tasks_queued\n\n    # 1. Reconstruct the `finished_id_to_sample_info` structure from completed rollouts\n    finished_id_to_sample_info: Dict[str, Dict[str, Any]] = {}\n    finished_id_to_final_reward: Dict[str, float] = {}\n    for rollout_id, rollout in self._completed_rollouts_v0.items():\n        original_sample = self._task_id_to_original_sample[rollout_id]\n\n        final_reward = self._fillna_reward(rollout)\n\n        if not rollout.triplets:\n            finished_id_to_final_reward[rollout_id] = final_reward\n            print(f\"Warning: No triplets found for training rollout {rollout.rollout_id}, skipping.\")\n            continue\n\n        # The client should report triplets that contain prompt_ids and response_ids.\n        # Example triplet.prompt: {\"token_ids\": [...]}\n        # Example triplet.response: {\"token_ids\": [...]}\n        trace_list = [\n            {\"prompt_ids\": t.prompt.get(\"token_ids\", []), \"response_ids\": t.response.get(\"token_ids\", [])}\n            for t in rollout.triplets\n        ]\n        info = {\n            \"reward\": final_reward,\n            \"trace_list\": trace_list,\n            \"data_id\": original_sample[\"data_id\"],\n        }\n        finished_id_to_sample_info[rollout_id] = info\n        finished_id_to_final_reward[rollout_id] = final_reward\n    #\n    # --- Data processing and tensor creation logic ---\n    # Get all the reported data.\n    # prompt_ids are left-padded.\n    # response_ids are right-padded.\n    # They are concatenated in the middle.\n    # Discard handling:\n    #   - Those exceeding max_prompt_length will be marked for discard, but not\n    #     discarded here. They are only truncated and marked, to be discarded later.\n    #     This is for the correctness of the advantage calculation.\n    #   - The discard for the PPO mini-batch should also be handled this way.\n    input_ids_list: List[List[int]] = []\n    input_attention_mask_list: List[List[int]] = []\n    response_ids_list: List[List[int]] = []\n    response_attention_mask_list: List[List[int]] = []\n    reward_list: List[float] = []\n    data_id_list: List[str] = []\n    rollout_id_list: List[str] = []\n    turn_index_list: List[int] = []\n    is_drop_list: List[bool] = []\n    n_trunc_sample_because_of_response = 0\n\n    for rollout_id, sample_info in finished_id_to_sample_info.items():\n        for turn_index, trace in enumerate(sample_info[\"trace_list\"]):\n\n            reward_list.append(sample_info[\"reward\"])\n            prompt_ids, response_ids = trace[\"prompt_ids\"], trace[\"response_ids\"]\n\n            # Mark samples with prompts exceeding max_prompt_length to be dropped later\n            if len(prompt_ids) &gt; max_prompt_length:\n                prompt_ids = prompt_ids[:max_prompt_length]\n                is_drop_list.append(True)\n            else:\n                is_drop_list.append(False)\n\n            # Truncate responses that exceed max_response_length\n            if len(response_ids) &gt; max_response_length:\n                response_ids = response_ids[:max_response_length]\n                n_trunc_sample_because_of_response += 1\n\n            # Pad prompts to the left and responses to the right\n            one_input_ids, one_input_attention_mask = get_left_padded_ids_and_attention_mask(\n                prompt_ids, max_prompt_length, self.pad_token_id\n            )\n            one_response_ids, one_response_attention_mask = get_right_padded_ids_and_attention_mask(\n                response_ids, max_response_length, self.pad_token_id\n            )\n\n            input_ids_list.append(one_input_ids)\n            input_attention_mask_list.append(one_input_attention_mask)\n            response_ids_list.append(one_response_ids)\n            response_attention_mask_list.append(one_response_attention_mask)\n            data_id_list.append(sample_info[\"data_id\"])\n            rollout_id_list.append(rollout_id)\n            turn_index_list.append(turn_index)\n\n    n_transition = len(input_ids_list)\n    batch_input_ids = torch.LongTensor(input_ids_list).to(device)\n    input_attention_mask = torch.LongTensor(input_attention_mask_list).to(device)\n    batch_response_ids = torch.LongTensor(response_ids_list).to(device)\n    response_attention_mask = torch.LongTensor(response_attention_mask_list).to(device)\n\n    # Concatenate prompts and responses to form the full sequence\n    batch_seq = torch.cat([batch_input_ids, batch_response_ids], dim=-1)\n    attention_mask = torch.cat([input_attention_mask, response_attention_mask], dim=-1)\n    position_ids = torch.clamp(torch.cumsum(attention_mask, dim=-1) - 1, min=0)\n    is_drop_mask = torch.BoolTensor(is_drop_list).to(device)\n    scores = torch.tensor(reward_list, dtype=torch.bfloat16).to(device)\n\n    # Create token-level scores by placing the final reward at the last token position\n    token_level_scores = torch.zeros_like(attention_mask, dtype=scores.dtype)\n    # At the eos_mask_idx position of each sample, fill in the corresponding scores.\n    # torch.arange(n_transition) generates [0,1,2,...,bsz-1] as indices for the batch dimension.\n    eos_mask_idx = torch.argmax(position_ids * attention_mask, dim=-1)  # (bsz,)\n    token_level_scores[torch.arange(n_transition), eos_mask_idx] = scores\n    # Only take the last response_length part of the sequence to get the token-level scores for the model's response part.\n    token_level_scores = token_level_scores[:, -max_response_length:]\n\n    # Form the final batch using TensorDict\n    batch = TensorDict(\n        {\n            \"prompts\": batch_input_ids,\n            \"responses\": batch_response_ids,\n            \"input_ids\": batch_seq,  # here input_ids become the whole sentences\n            \"attention_mask\": attention_mask,\n            \"position_ids\": position_ids,\n            \"is_drop_mask\": is_drop_mask,\n            \"token_level_scores\": token_level_scores.contiguous(),\n        },\n        batch_size=n_transition,\n    )\n    data_proto = DataProto(batch=batch)\n\n    data_metrics = {\n        \"training/reward\": np.mean(list(finished_id_to_final_reward.values())),\n        \"training/n_rollouts\": len(finished_id_to_final_reward),\n        \"training/n_rollouts_w_trace\": len(finished_id_to_sample_info),\n        \"training/n_truncated_triplets\": n_trunc_sample_because_of_response,\n        \"training/n_triplets\": n_transition,\n    }\n\n    # Add non-tensor data for advantage calculation and logging\n    data_proto.non_tensor_batch[\"data_id_list\"] = np.array(data_id_list)  # type: ignore\n    data_proto.non_tensor_batch[\"rollout_id_list\"] = np.array(rollout_id_list)  # type: ignore\n    data_proto.non_tensor_batch[\"turn_index_list\"] = np.array(turn_index_list)  # type: ignore\n\n    return data_proto, data_metrics\n</code></pre>"},{"location":"algorithm-zoo/verl/#agentlightning.verl.AgentModeDaemon.run_until_all_finished","title":"<code>run_until_all_finished(verbose=True)</code>","text":"<p>Synchronously waits for all queued tasks to be completed and reported.</p> Source code in <code>agentlightning/verl/daemon.py</code> <pre><code>def run_until_all_finished(self, verbose: bool = True):\n    \"\"\"Synchronously waits for all queued tasks to be completed and reported.\"\"\"\n    if self._total_tasks_queued == 0:\n        print(\"Warning: No tasks were queued.\")\n        return\n\n    if self.mode == \"v0\":\n        if not self.server.loop or not self.server.startup_event.is_set():\n            raise RuntimeError(\"Server is not running or ready.\")\n        loop = self.server.loop\n    else:\n        loop = self._internal_loop\n        assert loop is not None\n\n    coro = self._async_run_until_finished(verbose)\n    future = asyncio.run_coroutine_threadsafe(coro, loop)\n    try:\n        future.result()  # Wait indefinitely for all tasks to complete\n    except Exception as e:\n        print(f\"Error while waiting for tasks to finish: {e}\")\n        raise\n</code></pre>"},{"location":"algorithm-zoo/verl/#agentlightning.verl.AgentModeDaemon.set_up_data_and_server","title":"<code>set_up_data_and_server(data, server_addresses, is_train=True)</code>","text":"<p>Synchronous wrapper for setting up data and server resources.</p> Source code in <code>agentlightning/verl/daemon.py</code> <pre><code>def set_up_data_and_server(self, data: Dict[str, Any], server_addresses: List[str], is_train: bool = True):\n    \"\"\"Synchronous wrapper for setting up data and server resources.\"\"\"\n    coro = self._async_set_up(data, server_addresses, is_train)\n\n    if self.mode == \"v0\":\n        if not self.server.loop or not self.server.startup_event.is_set():\n            raise RuntimeError(\"Server is not running or ready.\")\n\n        future = asyncio.run_coroutine_threadsafe(coro, self.server.loop)\n\n    else:\n        if self._internal_loop is None:\n            raise RuntimeError(\"Internal loop is not running.\")\n        future = asyncio.run_coroutine_threadsafe(coro, self._internal_loop)\n    try:\n        future.result(timeout=60)  # Wait for completion with a timeout\n    except Exception as e:\n        print(f\"Failed to set up data on server: {e}\")\n        raise\n</code></pre>"},{"location":"algorithm-zoo/verl/#agentlightning.verl.AgentModeDaemon.start","title":"<code>start()</code>","text":"<p>Starts the main AgentLightningServer and the proxy server.</p> Source code in <code>agentlightning/verl/daemon.py</code> <pre><code>def start(self):\n    \"\"\"Starts the main AgentLightningServer and the proxy server.\"\"\"\n\n    if self.mode == \"v0\":\n\n        def run_server():\n            \"\"\"Run the AgentLightningServer in a separate thread.\"\"\"\n            asyncio.run(self.server.run_forever())\n\n        self._server_thread = threading.Thread(target=run_server, daemon=True)\n        self._server_thread.start()\n\n        # Wait for the server's internal startup event to be set.\n        print(\"Waiting for AgentLightningServer to start...\")\n        is_ready = self.server.startup_event.wait(timeout=20.0)  # Wait up to 20s\n        if not is_ready:\n            raise RuntimeError(\"AgentLightningServer failed to start within the timeout period.\")\n\n        print(f\"AgentLightningServer control plane running on port {self.server_port}\")\n\n        self._start_proxy_server_v0()\n    else:\n        # Agent lightning server is no longer needed;\n        # Start proxy server in _async_set_up\n        pass\n</code></pre>"},{"location":"algorithm-zoo/verl/#agentlightning.verl.get_left_padded_ids_and_attention_mask","title":"<code>get_left_padded_ids_and_attention_mask(ids, max_length, pad_token_id)</code>","text":"<p>Left-pad (or truncate) a sequence of token IDs to a fixed length, and build the corresponding attention mask.</p> <p>Parameters:</p> Name Type Description Default <code>ids</code> <code>List[int]</code> <p>the original list of token IDs.</p> required <code>max_length</code> <code>int</code> <p>desired total length after padding/truncation.</p> required <code>pad_token_id</code> <code>int</code> <p>ID to use for padding.</p> required <p>Returns:</p> Name Type Description <code>padded_ids</code> <code>any</code> <p>list of length == max_length.</p> <code>attention_mask</code> <code>any</code> <p>list of same length: 1 for non-pad tokens, 0 for pads.</p> Source code in <code>agentlightning/verl/daemon.py</code> <pre><code>def get_left_padded_ids_and_attention_mask(\n    ids: List[int], max_length: int, pad_token_id: int\n) -&gt; Tuple[List[int], List[int]]:\n    \"\"\"\n    Left-pad (or truncate) a sequence of token IDs to a fixed length,\n    and build the corresponding attention mask.\n\n    Args:\n        ids:             the original list of token IDs.\n        max_length:      desired total length after padding/truncation.\n        pad_token_id:    ID to use for padding.\n\n    Returns:\n        padded_ids (any):      list of length == max_length.\n        attention_mask (any):  list of same length: 1 for non-pad tokens, 0 for pads.\n    \"\"\"\n    seq_len = len(ids)\n\n    if seq_len &gt;= max_length:\n        # too long \u2192 truncate from the left, keep the last max_length tokens\n        trimmed = ids[-max_length:]\n        attention_mask = [1] * max_length\n        return trimmed, attention_mask\n\n    # too short \u2192 pad on the left\n    pad_len = max_length - seq_len\n    padded_ids = [pad_token_id] * pad_len + ids\n    attention_mask = [0] * pad_len + [1] * seq_len\n    return padded_ids, attention_mask\n</code></pre>"},{"location":"algorithm-zoo/verl/#agentlightning.verl.get_right_padded_ids_and_attention_mask","title":"<code>get_right_padded_ids_and_attention_mask(ids, max_length, pad_token_id)</code>","text":"<p>Right-pad (or truncate) a sequence of token IDs to a fixed length, and build the corresponding attention mask.</p> <p>Parameters:</p> Name Type Description Default <code>ids</code> <code>List[int]</code> <p>the original list of token IDs.</p> required <code>max_length</code> <code>int</code> <p>desired total length after padding/truncation.</p> required <code>pad_token_id</code> <code>int</code> <p>ID to use for padding.</p> required <p>Returns:</p> Name Type Description <code>padded_ids</code> <code>any</code> <p>list of length == max_length.</p> <code>attention_mask</code> <code>any</code> <p>list of same length: 1 for non-pad tokens, 0 for pads.</p> Source code in <code>agentlightning/verl/daemon.py</code> <pre><code>def get_right_padded_ids_and_attention_mask(\n    ids: List[int], max_length: int, pad_token_id: int\n) -&gt; Tuple[List[int], List[int]]:\n    \"\"\"\n    Right-pad (or truncate) a sequence of token IDs to a fixed length,\n    and build the corresponding attention mask.\n\n    Args:\n        ids:            the original list of token IDs.\n        max_length:     desired total length after padding/truncation.\n        pad_token_id:   ID to use for padding.\n\n    Returns:\n        padded_ids (any):     list of length == max_length.\n        attention_mask (any): list of same length: 1 for non-pad tokens, 0 for pads.\n    \"\"\"\n    seq_len = len(ids)\n\n    if seq_len &gt;= max_length:\n        # too long \u2192 truncate to the first max_length tokens\n        trimmed = ids[:max_length]\n        attention_mask = [1] * max_length\n        return trimmed, attention_mask\n\n    # too short \u2192 pad on the right\n    pad_len = max_length - seq_len\n    padded_ids = ids + [pad_token_id] * pad_len\n    attention_mask = [1] * seq_len + [0] * pad_len\n    return padded_ids, attention_mask\n</code></pre>"},{"location":"deep-dive/birds-eye-view/","title":"The Bird's Eye View of Agent-lightning","text":"<p>This article summarizes how Agent-lightning (as of v0.2) wires algorithms, runners, and stores together and shows where auxiliary components (tracer, adapters, proxies) plug into the loop. Each section provides a diagram for a different perspective of the system.</p>"},{"location":"deep-dive/birds-eye-view/#algorithm-runner-store-data-flow","title":"Algorithm \u2194 Runner \u2194 Store data flow","text":"<p>At its heart, Agent-lightning is built on three main components that work in a coordinated loop:</p> <ul> <li>Algorithm: The \"brain\" of the system. It decides what tasks to run, learns from the results, and updates resources (like AI models or prompts).</li> <li>Runner: The \"worker\" of the system. It executes tasks assigned by the algorithm, runs the agent, and records the results.</li> <li>LightningStore: The central \"database\" and message queue. It acts as the single source of truth, storing tasks, results, and resources, and enabling communication between the Algorithm and Runner.</li> </ul> <p>The typical data flow in a training loop is as follows: The Algorithm enqueues tasks (called Rollouts) into the Store. A Runner then dequeues a task, executes it, and streams the results (called Spans) back to the Store. Once the task is complete, the Algorithm can query the new data from the Store to learn and update its resources.</p> <p>The diagram below shows this fundamental interaction in a simple, non-parallel setup.</p> <pre><code>sequenceDiagram\n    autonumber\n    participant Algo as Algorithm\n    participant Store as LightningStore\n    participant Runner\n    participant Agent\n\n    loop Over the dataset\n        Algo--&gt;&gt;Store: add_resources + enqueue_rollout\n        Store--&gt;&gt;Runner: dequeue_rollout \u2192 AttemptedRollout\n        Store--&gt;&gt;Runner: get_latest_resources\n        Runner--&gt;&gt;Store: update_attempt(\"running\", worker_id)\n        Runner-&gt;&gt;Agent: rollout + resources\n        Agent-&gt;&gt;Runner: reward / spans\n        Runner--&gt;&gt;Store: add_span or add_otel_span\n        Runner--&gt;&gt;Store: update_attempt(\"finished\", status)\n        Store--&gt;&gt;Algo: query_rollouts + spans\n        Algo--&gt;&gt;Algo: Update resources (optional)\n    end</code></pre> <p>Solid lines represent direct calls, while dashed lines are asynchronous or long-running operations.</p>"},{"location":"deep-dive/birds-eye-view/#key-terminology","title":"Key Terminology","text":"<p>We define the following terms, which may be helpful for understanding the diagram above.</p> <ul> <li>Resources: A collection of assets to be tuned or trained. Agents perform rollouts against resources and collect span data. Algorithms use those data to update the resources. In RL training, the resources are a tunable model. In prompt tuning, the resources are prompt templates.</li> <li>Rollout: A unit of work that an agent performs against a resource. A rollout (noun) can be incomplete, in which case it is also known as a task, sample, or job (these terms are used interchangeably). The agent executes its own defined workflow against the rollout \u2014 the process is also called \"to rollout\" (verb). After execution, the rollout (noun) is considered complete.</li> <li>Attempt: A single execution of a rollout. One rollout can have multiple attempts in case of failures or timeouts.</li> <li>Span: During the rollout, the agent can generate multiple spans (also known as \"traces\" or \"events\"). The recorded spans are collected in the store, which is crucial for understanding agent behavior and optimizing agents.</li> <li>Reward: A special span that is defined as a number judging the quality of the rollout during some period of the rollout.</li> <li>Dataset: A collection of incomplete rollouts (i.e., tasks) for the agent to process. The dual datasets (train, val) serve as the initial input for the algorithm to enqueue the first batch of rollouts.</li> </ul>"},{"location":"deep-dive/birds-eye-view/#store","title":"Store","text":"<p>As discussed previously, the store is the central hub for all data in Agent-lightning. The store exposes a set of APIs for algorithms and runners to interact with the data; the most important ones are:</p> <pre><code>from agentlightning.types import AttemptedRollout, ResourcesUpdate, Span, TaskInput\n\nclass LightningStore:\n\n    async def enqueue_rollout(self, input: TaskInput, ...) -&gt; Rollout: ...\n\n    async def dequeue_rollout(self) -&gt; AttemptedRollout | None: ...\n\n    async def add_span(self, span: Span) -&gt; Span: ...\n\n    async def get_latest_resources(self) -&gt; Optional[ResourcesUpdate]: ...\n\n    async def wait_for_rollouts(self, rollout_ids: List[str], ...): ...\n\n    async def query_spans(self, rollout_id: str, ...): ...\n\n    async def update_attempt(self, rollout_id: str, attempt_id: str, status: str, ...): ...\n\n    ...\n</code></pre> <p>As the APIs show, the store essentially provides a queue for rollouts and storage for resources, spans, and attempts. Developers should implement the store carefully to ensure data integrity and consistency, especially when multiple runners work in parallel across multiple attempts.</p> <p>The store is designed to be extensible. Users can implement their own store by inheriting from <code>LightningStore</code> and overriding methods. Agent-lightning provides a few reference implementations, such as <code>InMemoryLightningStore</code> (default) and <code>SqliteLightningStore</code> (under construction). When parallelized, the store may need special wrappers to ensure thread/process safety or delegate computation to a store in another process or machine.</p>"},{"location":"deep-dive/birds-eye-view/#supporting-components-in-the-loop","title":"Supporting Components in the Loop","text":"<p>While the core loop is simple, Agent-lightning provides several components to make development easier and more powerful.</p>"},{"location":"deep-dive/birds-eye-view/#tracer","title":"Tracer","text":"<p>The tracer is a component within the Runner that records detailed spans (events) during an agent's execution and sends them to the Store. Instead of requiring the agent to manually log every span, the tracer automatically instruments key methods (e.g., LLM calls) and captures their inputs, outputs, and metadata. This provides a detailed log of the agent's behavior with minimal effort.</p> <pre><code>sequenceDiagram\n    autonumber\n    participant Store\n    participant Runner\n    participant Tracer\n    participant Agent\n\n    Note over Runner,Tracer: Runner manages tracer as member\n\n    Tracer-&gt;&gt;Agent: Apply instrumentation\n    loop Until no more rollouts\n        Store--&gt;&gt;Runner: dequeue_rollout \u2192 AttemptedRollout\n        Store--&gt;&gt;Runner: get_latest_resources\n        Runner-&gt;&gt;Agent: training_rollout / validation_rollout\n        loop For each finished span\n            Agent--&gt;&gt;Tracer: openai.chat.completion invoked&lt;br&gt;agent.execute invoked&lt;br&gt;...\n            Agent-&gt;&gt;Tracer: emit intermediate reward\n            Tracer--&gt;&gt;Store: add_otel_span(rollout_id, attempt_id, span)\n        end\n        Agent-&gt;&gt;Runner: final reward + extra spans (if any)\n        Runner--&gt;&gt;Store: add_span(rollout_id, attempt_id, span)\n        Runner--&gt;&gt;Store: update_attempt(status)\n    end\n    Tracer-&gt;&gt;Agent: Unapply instrumentation</code></pre> <p>The above diagram shows the overall data flow between store, tracer and agent. In realistic, it's a bit more complicated than that. Spans are not emitted actively by the agent; they are intercepted by the tracer by hooking and instrumenting key methods used in the agents.  The tracer uses a callback (called exporter) to monitor events and log to the store. Before a rollout starts, the runner enters a <code>trace_context</code> before invoking the agent, wiring store identifiers into the tracer. Each span completion streams back to the store through <code>LightningSpanProcessor.on_end</code>, so the agent\u2019s instrumentation lands in <code>add_otel_span</code>. If the agent\u2019s rollout method returns a numeric reward, the runner emits one more OpenTelemetry span before finalizing the attempt.</p>"},{"location":"deep-dive/birds-eye-view/#hooks","title":"Hooks","text":"<p>Hooks are user-defined callback functions that allow you to augment a Runner's behavior at specific points in its lifecycle. You can use hooks to add custom logging, set up resources before a rollout begins, or tear them down after it ends. Hooks can be triggered at four key moments: <code>on_rollout_start</code>, <code>on_trace_start</code>, <code>on_trace_end</code>, and <code>on_rollout_end</code>.</p> <p>Users should pay special attention to the difference between <code>on_trace_end</code> and <code>on_rollout_end</code>. The former is called right before the tracer exits the trace context, while the latter is called after the runner processes the final leftover rewards and spans, and finalizes the attempt in the store.</p> <pre><code>sequenceDiagram\n    autonumber\n    participant Store\n    participant Hooks\n    participant Runner\n    participant Tracer\n    participant Agent\n\n    Note over Runner,Hooks: Runner manages hooks as member\n\n    loop Until no more rollouts\n        Store--&gt;&gt;Runner: dequeue_rollout \u2192 AttemptedRollout\n        Store--&gt;&gt;Runner: get_latest_resources\n\n        Runner-&gt;&gt;Hooks: on_rollout_start(agent, runner, rollout)\n        Runner-&gt;&gt;Agent: training_rollout / validation_rollout\n        Tracer-&gt;&gt;Agent: enter_trace_context\n        activate Tracer\n        Runner-&gt;&gt;Hooks: on_trace_start(agent, runner, tracer, rollout)\n        Note over Runner,Agent: Agent rollout omitted\n        Runner-&gt;&gt;Hooks: on_trace_end(agent, runner, tracer, rollout)\n        Tracer-&gt;&gt;Agent: exit_trace_context\n        deactivate Tracer\n        Agent-&gt;&gt;Runner: final reward + extra spans (if any)\n        Runner--&gt;&gt;Store: add_span(rollout_id, attempt_id, span)\n        Runner-&gt;&gt;Hooks: on_rollout_end(agent, runner, rollout, status)\n    end</code></pre>"},{"location":"deep-dive/birds-eye-view/#adapter","title":"Adapter","text":"<p>The Adapter is a component used by the Algorithm to transform raw data from the Store into a format suitable for learning. Runners stream raw spans into the Store during execution. Later, the Algorithm queries these spans and uses an Adapter to convert them into structured data, like training examples for a reinforcement learning model.</p> <p>For instance, the <code>TracerTraceToTriplet</code> processes OpenTelemetry spans to create <code>(prompt, response, reward)</code> triplets, which are the fundamental data structure for many RL fine-tuning algorithms.</p> <pre><code>flowchart LR\n    Runner -- (1) add_otel_span --&gt; Store\n    Store -- (2) query_spans --&gt; Algorithm\n    Algorithm -- (3) spans --&gt; Adapter\n    Adapter -- (4) transformed data --&gt; Algorithm</code></pre>"},{"location":"deep-dive/birds-eye-view/#llm-proxy","title":"LLM Proxy","text":"<p>The LLM Proxy is an optional bridge component that sits between an agent and the algorithms' resources. It acts as a centralized endpoint for all LLM calls. Usually the proxy URL is added to the store as a special resource, so that the runner can fetch it along with other resources when dequeuing a rollout. During rollouts, the runner invokes the proxy's HTTP endpoint instead of calling a model backend directly.</p> <p>This design offers several benefits:</p> <ol> <li>Instrumentation: It automatically captures detailed traces of LLM interactions (prompts, responses, metadata) and sends them to the Store, complementing the Tracer, especially when the agent's code is hard to instrument directly.</li> <li>Backend Abstraction: It provides a unified interface for various LLM backends (OpenAI, Anthropic, local models) and can add features like retry logic, rate limiting, and caching.</li> <li>Resource Management: The Algorithm can dynamically update which LLM the agent uses (e.g., swapping to a newly fine-tuned model) by simply swapping the backend model the proxy is using, without interrupting the agent's code.</li> </ol> <p>The benefits above seem to be all discussed within the context of model fine-tuning. As a matter of fact, the proxy can be useful for prompt tuning as well. The algorithm can register one of the following two types of endpoints into the proxy:</p> <ol> <li>Endpoint served by the algorithm: If the algorithm is internally updating the LLM weights (e.g., RL), it can launch an LLM inference engine (i.e., a model server) and register the endpoint URL with the proxy. The proxy then forwards all LLM calls to that endpoint.</li> <li>Third-party LLM endpoint: If the algorithm is not updating the LLM weights (e.g., prompt tuning), it can register a third-party LLM endpoint into the proxy.</li> </ol> <p>We show a diagram below that illustrates how the proxy fits into the overall data flow.</p> <pre><code>sequenceDiagram\n    autonumber\n    participant Algo as Algorithm\n    participant LLMProxy as LLM Proxy\n    participant Store\n    participant Runner\n    participant Agent\n\n    Note over Algo,LLMProxy: Algorithm manages LLMProxy as member\n\n    loop Over the Dataset\n        Algo-&gt;&gt;Algo: Launch LLM Inference Engine&lt;br&gt;(optional)\n        Algo-&gt;&gt;LLMProxy: Register Inference Engine&lt;br&gt;(optional)\n        Algo--&gt;&gt;Store: enqueue_rollout\n        LLMProxy-&gt;&gt;Store: Proxy URL added as Resource\n        Store--&gt;&gt;Runner: dequeue_rollout \u2192 AttemptedRollout\n        Store--&gt;&gt;Runner: get_latest_resources\n        Runner-&gt;&gt;Agent: rollout + resources&lt;br&gt;(LLM Proxy URL as resource)\n        loop Defined by Agent\n            Agent--&gt;&gt;LLMProxy: LLM calls\n            activate LLMProxy\n            LLMProxy--&gt;&gt;Store: add_span or add_otel_span\n            LLMProxy--&gt;&gt;Agent: LLM responses\n            deactivate LLMProxy\n            Agent--&gt;&gt;Runner: rewards\n            Runner--&gt;&gt;Store: add_span or add_otel_span\n        end\n        Runner--&gt;&gt;Store: update_attempt(\"finished\", status)\n        Store--&gt;&gt;Algo: query_rollouts + spans\n        Algo--&gt;&gt;Algo: Update LLM Weights&lt;br&gt;(optional)\n    end</code></pre> <p>In this diagram, the store receives spans from both the proxy and the runner. We will see a problem later with parallelism where the proxy and runner are in different machines, and spans need to obtain a special counter from the store to ensure the ordering of spans.</p>"},{"location":"deep-dive/birds-eye-view/#trainer","title":"Trainer","text":"<p>The Trainer is the high-level orchestrator that initializes and connects all major components -- algorithm, runner, store, tracer, adapter, LLM proxy, and hooks. The components can have a lifecycle as long as the trainer. The trainer manages their lifecycles and handles dependency injection, ensuring that every part of the system operates within a consistent and shared environment.</p> <p>Below, we demonstrate how the components relate to each other and their roles. We first clarify the roles and relationships shown in the diagram:</p> <ol> <li>Owns: components that the trainer constructs and manages directly (e.g., runner, tracer).</li> <li>Injects: components passed into others as dependencies.</li> <li>References: weak links for coordination without ownership.</li> <li>Uses: components that are temporarily interacted with.</li> </ol> <p>For example, the store is injected into the algorithm and runner. The tracer and agent are injected into the runner. The adapter and LLM proxy are injected into the algorithm. The store is further injected into the tracer, adapter and LLM proxy by the runner and algorithm respectively.</p> <pre><code>flowchart TD\n    %% === Left side: Algorithm domain ===\n    subgraph L[\"Algorithm Side\"]\n        Algorithm[\"Algorithm&lt;br&gt;(no default)\"]\n        Adapter[\"Adapter&lt;br&gt;(TracerTraceToTriplet*)\"]\n        LLMProxy[\"LLM Proxy&lt;br&gt;(no default)\"]\n        Algorithm -.injects.-&gt; Adapter\n        Algorithm -.injects.-&gt; LLMProxy\n    end\n    linkStyle 0,1 stroke:#896978,stroke-width:2px;\n\n    %% === Middle: Core trainer and store ===\n    subgraph M[\"Core\"]\n        Trainer[\"Trainer\"]\n        Store[\"LightningStore&lt;br&gt;(InMemory* default)\"]\n        Trainer --has--&gt; Algorithm\n        Trainer --has--&gt; Store\n        Trainer --has--&gt; Adapter\n        Trainer --has--&gt; LLMProxy\n    end\n    linkStyle 2,3,4,5 stroke:#839791,stroke-width:2px;\n\n    %% === Right side: Runner side ===\n    subgraph R[\"Runner Side\"]\n        Runner[\"Runner&lt;br&gt;(LitAgentRunner* default)\"]\n        Tracer[\"Tracer&lt;br&gt;(AgentOpsTracer*)\"]\n        Hooks[\"Hooks (empty default)\"]\n        Agent[\"Agent&lt;br&gt;(LitAgent*)\"]\n        Runner -.injects.-&gt; Tracer\n        Runner -.injects.-&gt; Store\n        Runner -.injects.-&gt; Agent\n        Runner -.injects.-&gt; Hooks\n        Tracer -.injects.-&gt; Store\n        Hooks -.uses.-&gt; Runner\n        Hooks -.uses.-&gt; Agent\n        Hooks -.uses.-&gt; Tracer\n    end\n    linkStyle 6,7,8,9,10 stroke:#896978,stroke-width:2px;\n    linkStyle 11,12,13 stroke:#7a89c2,stroke-width:2px;\n\n    %% === Cross-section connections ===\n    Trainer --has--&gt; Runner\n    Trainer --has--&gt; Tracer\n    Trainer --has--&gt; Hooks\n    Trainer --uses--&gt; Agent\n    Algorithm -.injects.-&gt; Store\n    LLMProxy -.injects.-&gt; Store\n    Agent -.references.-&gt; Trainer\n    Runner -.references.-&gt; Trainer\n    Algorithm -.references.-&gt; Trainer\n    linkStyle 14,15,16 stroke:#839791,stroke-width:2px;\n    linkStyle 17,20,21,22 stroke:#7a89c2,stroke-width:2px;\n    linkStyle 18,19 stroke:#896978,stroke-width:2px;\n\n    style L fill:none;\n    style M fill:none;\n    style R fill:none;</code></pre>"},{"location":"deep-dive/birds-eye-view/#putting-it-all-together-a-reinforcement-learning-example-verl","title":"Putting It All Together: A Reinforcement Learning Example (VERL)","text":"<p>VERL shows how an algorithm consumes the shared infrastructure. For historical reasons, code lives in <code>agentlightning.algorithm.verl</code> and <code>agentlightning.verl</code>. The latter is legacy and reuses terms like <code>Trainer</code> in confusing ways. The former is a thin wrapper that conforms to the new algorithm interface. Future versions will merge the two.</p> <p>Reinforcement learning aims to learn a policy that takes actions in states to maximize expected reward. For agents, the policy is usually a language model. Inputs are prompts (state). Outputs are generated text (action). A numeric score judges quality (reward). The <code>(state, action, reward)</code> triplet is the basic learning unit.</p> <p>In Agent-lightning, the environment is implicit in the agent\u2019s workflow, which orchestrates one or more LLM calls and often self-judges using rules or additional model calls. During a rollout, the agent emits spans that contain everything needed for RL training, including LLM call traces and numeric judge/reward signals. The \"algorithm\", on the other hand, have more responsibilities.</p> <ol> <li>Providing a language model deployment that is currently learning and improving for the agent to interact with;</li> <li>Preparing the tasks that the agents will perform;</li> <li>Querying the spans generated, extracting triplets, and converting them into a format that the underlying RL library can consume;</li> <li>Updating the language model based on the learning signals.</li> </ol> <p>In the VERL integration, the algorithm launches a chat completion endpoint using <code>vLLM</code> and wraps training with <code>FSDP</code> for distributed optimization. It enqueues tasks from the dataset. After rollouts finish, it queries spans and converts them to triplets with <code>TracerTraceToTriplet</code>. VERL\u2019s native training loop then consumes these triplets to update model weights. The workflow can be summarized in the following diagram.</p> <pre><code>sequenceDiagram\n    autonumber\n    participant vLLM as vLLM Chat&lt;br&gt;Completion Endpoint\n    participant FSDP as FSDP / Megatron&lt;br&gt;Weights Optimizer\n    participant Algo as Algorithm&lt;br&gt;Main Controller&lt;br&gt;(Main Process)\n    participant Adapter as TracerTraceToTriplet\n    participant LLMProxy as LLM Proxy\n    participant Store as LightningStore\n    participant Runner as Runner + Agent\n\n    Note over Algo,LLMProxy: LLMProxy and Adapter are injected by Trainer as member\n    Note over vLLM,Algo: Algorithm creates and owns vLLM and FSDP\n\n    loop Over the Dataset in Batches\n        Algo-&gt;&gt;vLLM: Create Chat Completion Endpoint\n        activate vLLM\n        vLLM-&gt;&gt;LLMProxy: Registered as Backend Endpoint\n        LLMProxy-&gt;&gt;Store: Proxy URL added as Resource\n        par Over data samples in the batch\n            Algo--&gt;&gt;Store: enqueue_rollout\n            Store--&gt;&gt;Runner: Dequeue Rollout +&lt;br&gt;Resources (i.e., URL)\n            loop One Rollout Attempt\n                Runner--&gt;&gt;LLMProxy: LLM calls\n                LLMProxy--&gt;&gt;vLLM: Forwarded LLM calls\n                vLLM--&gt;&gt;LLMProxy: LLM responses\n                LLMProxy--&gt;&gt;Store: add_span / add_otel_span\n                LLMProxy--&gt;&gt;Runner: Forwarded LLM responses\n                Runner--&gt;&gt;Store: add_span / add_otel_span &lt;br&gt; (by tracer, including rewards)\n            end\n            Runner--&gt;&gt;Store: update_attempt(\"finished\", status)\n        end\n        Algo--&gt;&gt;Store: Poll for completed rollouts + spans\n        Algo-&gt;&gt;vLLM: Chat Completion Endpoint Sleeps\n        deactivate vLLM\n        Algo-&gt;&gt;Adapter: adapt(spans)\n        Adapter-&gt;&gt;FSDP: Triplets (state, action, reward)\n        activate FSDP\n        FSDP--&gt;&gt;Algo: Updated LLM weights\n        deactivate FSDP\n    end</code></pre> <p>Notes:</p> <ol> <li> <p>There are interactions between different components injected into or owned by algorithms in the diagram, such as the output of the adapter feeding into the FSDP optimizer. This is for simplicity of illustration and slightly different from the actual implementation, where it's the algorithm main controller that orchestrates the data flow between components.</p> </li> <li> <p>On mapping to VERL. VERL uses a classic RLHF setup where each action is a single token, the state is the full conversation history up to that token, and reward is given at the end. This is very different from our setup where each action is actually  a chunk of text, although they are both called RL! Therefore, after the adapter produces triplets, the algorithm converts each <code>(state, action, reward)</code> into a VERL trajectory (<code>DataProto</code>) with keys like <code>input_ids</code>, <code>position_ids</code>, <code>attention_mask</code>, and <code>token_level_scores</code>. That conversion happens after triplet generation and is not shown in the diagram.</p> </li> </ol>"},{"location":"deep-dive/birds-eye-view/#execution-strategies-and-parallelism","title":"Execution Strategies and Parallelism","text":"<p>Readers might have observed from the diagram above that there is absolutely no communication between (1) runner and agents and (2) algorithm. The only overlap of them is the trainer and store. This observation is very clear with the diagram within the trainer section. This design allows us to flexibly scale the runner and algorithm independently, which is crucial for large-scale training.</p> <p>Agent-lightning packages two executable bundles: a runner bundle (runner, tracer, hooks, agent) and an algorithm bundle (algorithm, adapter, LLM proxy). Both share the store. The trainer initializes and connects the bundles.</p> <pre><code>graph TD\n    subgraph Runner_Side[\"Runner Bundle\"]\n        direction LR\n        R[Runner] --- T[Tracer] --- H[Hooks] --- A1[Agent]\n    end\n\n    subgraph Algorithm_Side[\"Algorithm Bundle\"]\n        direction LR\n        ALG[Algorithm] --- AD[Adapter] --- LLM[LLM Proxy]\n    end\n\n    S[(Store)]\n    TR[Trainer]\n\n    Runner_Side &lt;--&gt; S\n    Algorithm_Side &lt;--&gt; S\n    TR --&gt; Runner_Side\n    TR --&gt; Algorithm_Side\n\n    linkStyle 0,1,2,3,4 opacity:0;</code></pre> <p>An execution strategy, defined and owned by the trainer, governs how algorithm and runner bundles are placed, connected, scaled, and aborted. It serves four primary purposes.</p> <p>Execution strategies first determine bundle placement \u2014 whether the two bundles run in the same thread, process, machine, or across separate machines. They also define store management, wrapping the store and specifying how data is shared between bundles.</p> <p>In terms of scalability, the strategy can replicate the runner bundle across multiple threads, processes, or machines to expand throughput on the runner side. The algorithm side remains single-process due to the complexity of parallelization. Mature frameworks such as DeepSpeed and Megatron already support distributed model training, so scaling of the algorithm bundle is delegated to those implementations.</p> <p>Abort handling is another core responsibility. Aborts may be triggered by normal exits, failures in either bundle, or user interrupts. The trainer must include cancellation interfaces for the bundles so that bundles can be cleanly aborted. When the algorithm bundle exits normally, the strategy signals the runner bundle to terminate. If the runner exits first, no signal is sent to the algorithm, as it may still be processing completed rollouts. In cases of failure or user interruption, the strategy signals both bundles to abort; if a bundle fails to respond, the strategy should attempt a forceful termination.</p> <p>Agent-lightning currently provides two execution strategies: shared-memory and client-server, described in the following sections.</p>"},{"location":"deep-dive/birds-eye-view/#shared-memory-strategy","title":"Shared-memory Strategy","text":"<p><code>SharedMemoryExecutionStrategy</code> runs algorithm and runner bundles as threads in one process. The strategy wraps the store with <code>LightningStoreThreaded</code>, which guards calls with a lock for safe concurrency.</p> <p>This is good for lightweight debugging because components share one Python heap and avoid serialization. It is not suitable for heavy RL training or compute-intensive agents.</p> <pre><code>flowchart TB\n    subgraph MainProcess\n        direction TB\n        subgraph AlgorithmThread [Thread 0]\n            Algorithm[Algorithm bundle]\n        end\n        subgraph RunnerThread1 [Thread 1]\n            Runner1[Runner bundle #1]\n        end\n        subgraph RunnerThread2 [Thread 2]\n            Runner2[Runner bundle #2]\n        end\n        subgraph RunnerThread3 [Thread 3]\n            RunnerN[Runner bundle #N]\n        end\n        LightningStoreFacade[LightningStoreThreaded]\n        BaseStore[Underlying LightningStore]\n    end\n    Algorithm -- async calls --&gt; LightningStoreFacade\n    Runner1 -- async calls --&gt; LightningStoreFacade\n    Runner2 -- async calls --&gt; LightningStoreFacade\n    RunnerN -- async calls --&gt; LightningStoreFacade\n    LightningStoreFacade --&gt;|thread-safe delegates| BaseStore</code></pre> <p>You can configure which role runs on the main thread. If the main thread runs the algorithm, it is able to spawn multiple runner threads. If it runs a runner, <code>n_runners</code> must be 1 and the runner lives on the main thread.</p>"},{"location":"deep-dive/birds-eye-view/#client-server-strategy","title":"Client-server Strategy","text":"<p><code>ClientServerExecutionStrategy</code> splits concerns across processes. The algorithm bundle starts a <code>LightningStoreServer</code> (HTTP API) that wraps the underlying store. Runners connect via <code>LightningStoreClient</code> to call the same interface over REST. The server embeds a client to support algorithm-launched subprocesses (e.g., an LLM proxy worker) that need to talk back to the algorithm\u2019s process through the same API.</p> <p>Currently this design introduces an extra wrapper in the Server side (as shown in the diagram), which helps debugging and improves fault tolerance. We might revisit this design in the future and enforce the client to be the only way to communicate with the store.</p> <pre><code>flowchart TD\n    subgraph Algorithm Process Group\n        subgraph StoreServer[LightningStoreServer]\n            StoreHttpClient[HTTP Client]\n            StoreHttpServer[HTTP Server]\n            StoreWrapper[LightningStore Wrapper]\n            StoreHttpClient -- HTTP --&gt; StoreHttpServer\n        end\n        subgraph Algorithm Bundle\n            Algorithm[Algorithm Main Process]\n            subgraph Another subprocess\n                LLMProxy[LLM Proxy]\n            end\n        end\n        LLMProxy -- async calls --&gt; StoreHttpClient\n        Algorithm -- async calls --&gt; StoreWrapper\n    end\n    subgraph RunnerSide [\"Runner Side\"]\n        subgraph Runner Process 1\n            Runner1[Runner bundle #1]\n            Runner1 -- async calls --&gt; LightningStoreClient1\n            LightningStoreClient1[LightningStoreClient]\n        end\n        subgraph Runner Process 2\n            Runner2[Runner bundle #2]\n            Runner2 -- async calls --&gt; LightningStoreClient2\n            LightningStoreClient2[LightningStoreClient]\n        end\n        subgraph Runner Process N\n            RunnerN[Runner bundle #N]\n            RunnerN -- async calls --&gt; LightningStoreClientN\n            LightningStoreClientN[LightningStoreClient]\n        end\n    end\n    LocalStore[Underlying LightningStore]\n    StoreHttpServer --&gt;|delegates| StoreWrapper\n    StoreWrapper --&gt;|delegates| LocalStore\n    LightningStoreClient1 -- HTTP --&gt; StoreHttpServer\n    LightningStoreClient2 -- HTTP --&gt; StoreHttpServer\n    LightningStoreClientN -- HTTP --&gt; StoreHttpServer\n\n    style RunnerSide fill:none;</code></pre>"},{"location":"deep-dive/birds-eye-view/#onlinecontinuous-learning","title":"Online/Continuous Learning","text":"<p>Continuous learning keeps the algorithm loop running while runners report tasks and spans opportunistically. Key differences from batch mode:</p> <ol> <li>The algorithm does not enqueue rollouts from a fixed dataset. Runners report tasks/rollouts and spans spontaneously.</li> <li>The algorithm can wait for rollouts with a expected set of rollout IDs, but more oftenly polls for new rollouts and spans or waits for a count to arrive.</li> <li>The runner processes one rollout at a time via <code>step(task)</code> instead of exhausting a task queue. It notifies the store when starting a rollout so the store records it.</li> <li>A user or higher-level loop controls which resources the next step uses and when to retry.</li> </ol> <p>Spans, adapters, and LLM proxies work the same way.</p> <pre><code>sequenceDiagram\n    autonumber\n    actor User\n    participant Runner\n    participant Agent\n    participant Store as LightningStore\n    participant Algorithm\n\n    Note over Algorithm: Algorithm is long-running and loops continuously\n\n    loop Continuous Learning Loop\n        activate User\n        opt Decide what to do next\n            User--&gt;&gt;Store: get_resources_by_id\n            Store--&gt;&gt;User: Resources\n            User--&gt;&gt;User: Prepare input for next step\n        end\n        User-&gt;&gt;Runner: step(input, resources)\n        activate Runner\n        Runner--&gt;&gt;Store: Notify: start_rollout(input)\n        Runner-&gt;&gt;Agent: rollout(input, resources)\n        Agent--&gt;&gt;Runner: add_span / reward spans\n        Runner--&gt;&gt;Store: add_span or add_otel_span\n        Runner--&gt;&gt;Store: update_attempt(status=\"finished\")\n        deactivate Runner\n        deactivate User\n        Algorithm-&gt;&gt;Store: poll for new rollouts and spans\n        opt If there is enough new data\n            Store--&gt;&gt;Algorithm: new spans\n            Algorithm-&gt;&gt;Algorithm: adapt spans \u2192 learning signal\n            Algorithm-&gt;&gt;Store: update_resources\n        end\n    end</code></pre>"},{"location":"deep-dive/serving-llm/","title":"Serving LLMs under Agent-lightning","text":"<p>Fine-tuning (the weights of) Large Language Models (LLMs) is a core functionality of Agent-lightning. Nevertheless, Agent-lightning is NEITHER a LLM inference engine NOR a model serving framework. In this deep dive, we discuss how to \"correctly\" serve a LLM under Agent-lightning and the surronding infrastructure Agent-lightning provides.</p>"},{"location":"deep-dive/serving-llm/#general-background-on-llm-serving","title":"General Background on LLM Serving","text":""},{"location":"deep-dive/serving-llm/#llm-proxy","title":"LLM Proxy","text":""},{"location":"deep-dive/serving-llm/#token-ids-and-why-it-matters","title":"Token IDs and Why it Matters","text":""},{"location":"deep-dive/store/","title":"Understanding Store","text":"<p>The <code>LightningStore</code> is the central coordination point for Agent-lightning. It holds the task queue, rollouts, attempts, spans, and versioned resources, and exposes a small API both Runners and Algorithms use to communicate. This document explains what\u2019s in the store, how statuses transition, how spans are recorded, and the concurrency model (threads &amp; processes).</p>"},{"location":"deep-dive/store/#whats-in-the-store","title":"What\u2019s in the Store?","text":"<p>At a high level:</p> <ul> <li>Task Queue \u2013 <code>enqueue_rollout</code> adds work; workers poll with <code>dequeue_rollout</code>. When a rollout is dequeued, it automatically creates a new attempt associated with itself.</li> <li>Rollouts \u2013 A rollout is one unit of work. It has input, metadata, links to resources, and a lifecycle (<code>queuing \u2192 preparing \u2192 running \u2192 ...</code>). Valid RolloutStatus are <code>queuing</code>, <code>preparing</code>, <code>running</code>, <code>succeeded</code>, <code>failed</code>, <code>requeuing</code>, <code>cancelled</code>. For algorithms and runners, the rollout can be seen as a whole, without worrying about the internal attempts.</li> <li>Attempts \u2013 Each rollout can have multiple executions (retries). Attempts track <code>status</code>, <code>start_time</code>, <code>end_time</code>, <code>last_heartbeat_time</code> and link to spans. Valid AttemptStatus are <code>preparing</code>, <code>running</code>, <code>succeeded</code>, <code>failed</code>, <code>requeuing</code>, <code>cancelled</code>.</li> <li>Spans \u2013 Structured trace events produced by the Tracer during an attempt. Spans are ordered by a monotonic sequence id per <code>(rollout_id, attempt_id)</code>.</li> <li>Resources \u2013 Versioned, named bundles (e.g., prompt templates) referenced by rollouts.</li> </ul> <p>Rollout and Task share the same surface in practice: <code>Rollout.input</code> is the task input. The queue stores rollouts that are not yet running; Runners dequeue them and update the same rollout\u2019s status as work progresses.</p> <p>All <code>LightningStore</code> implementations must inherit from <code>LightningStore</code> and override the methods to implement the storage logic.</p> <p>Before we look at status transitions, it helps to keep in mind that rollouts are the \u201coutside view,\u201d while attempts are the \u201cinside view.\u201d Attempts are what actually run; rollouts summarize the latest attempt plus a small set of control actions like queueing and cancellation.</p>"},{"location":"deep-dive/store/#attempt-status-transitions","title":"Attempt Status Transitions","text":"<p>The status model is intentionally small and operationally clear.</p> <pre><code>stateDiagram-v2\ndirection LR\n\n[*] --&gt; preparing: &lt;b&gt;Runner calls&lt;/b&gt; dequeue_rollout()&lt;br&gt;or start_rollout()&lt;br&gt;or start_attempt()\npreparing --&gt; running: &lt;b&gt;Runner calls&lt;/b&gt;&lt;br&gt;add_[otel_]span()&lt;br&gt;for the first time\n\nstate c_runner &lt;&lt;choice&gt;&gt;\nstate c_watch  &lt;&lt;choice&gt;&gt;\n\npreparing --&gt; c_runner: &lt;b&gt;Runner calls&lt;/b&gt;&lt;br&gt;update_attempt(...)&lt;/b&gt;\nrunning --&gt; c_runner: &lt;b&gt;Runner calls&lt;/b&gt;&lt;br&gt;update_attempt(...)\nrunning --&gt; c_watch: &lt;b&gt;Watchdog checks&lt;/b&gt;\npreparing --&gt; c_watch: &lt;b&gt;Watchdog checks&lt;/b&gt;\n\nstate \"Client-set outcome\" as Client {\n  direction TB\n  succeeded\n  failed\n}\nstate \"Watchdog / policy\" as Watch {\n  direction TB\n  timeout\n  unresponsive\n}\n\nc_runner --&gt; succeeded: update_attempt(status=succeeded)\nc_runner --&gt; failed: update_attempt(status=failed)\n\nc_watch --&gt; timeout: now - start_time &gt; timeout_seconds\nc_watch --&gt; unresponsive: now - last_heartbeat &gt; unresponsive_seconds\n\nunresponsive --&gt; running: &lt;b&gt;Runner calls&lt;/b&gt;&lt;br&gt;add_[otel_]span()</code></pre> <p>Each attempt begins in preparing, created either when a rollout is dequeued or explicitly started. It transitions to running the first time a span is recorded. From there, a few clear rules govern how it can change:</p> <ul> <li>When the runner explicitly marks completion, the attempt becomes succeeded or failed (when the runner catches exception thrown out by the agent).</li> <li>When the watchdog detects that the total elapsed time since start exceeds the configured limit, it marks the attempt as timeout.</li> <li>If heartbeats stop arriving for too long, the watchdog marks it unresponsive.</li> <li>A new span from the runner can immediately revive an unresponsive attempt back to running.</li> </ul> <p>What's a Watchdog?</p> <p>The watchdog enforces timing and liveness rules defined by each rollout\u2019s <code>RolloutConfig</code>. It\u2019s not a separate thread or service, but a function periodically invoked (e.g., before store mutations) to keep attempts healthy and consistent.</p> <p>This simple model allows the system to distinguish between normal termination, abnormal stalling, and recoverable interruption without additional state flags.</p>"},{"location":"deep-dive/store/#rollout-transition-map","title":"Rollout Transition Map","text":"<p>Rollout status is an aggregated view of its latest attempt\u2019s status, with additional transitions for queueing and explicit cancellation.</p> <p>A rollout\u2019s retry behavior is controlled by <code>Rollout.config</code> (a <code>RolloutConfig</code>). The key fields are:</p> <ul> <li><code>timeout_seconds</code> \u2013 maximum wall-clock time for an attempt before it is marked <code>timeout</code>.</li> <li><code>unresponsive_seconds</code> \u2013 maximum silence between heartbeats before an attempt is marked <code>unresponsive</code>.</li> <li><code>max_attempts</code> \u2013 total number of attempts allowed for the rollout (including the first).</li> <li><code>retry_condition</code> \u2013 which attempt terminal statuses should trigger a retry (e.g., <code>[\"failed\", \"timeout\", \"unresponsive\"]</code>).</li> </ul> <p>How it plays out: The runner works on attempt <code>k</code>. If the attempt ends in a status that is listed in <code>retry_condition</code>, and <code>k &lt; max_attempts</code>, the rollout moves to requeuing and the store creates attempt <code>k+1</code>. Otherwise, the rollout becomes failed (or succeeded if the runner marked it so). <code>timeout_seconds</code> and <code>unresponsive_seconds</code> are enforced by the watchdog and feed into the same decision flow.</p> <p>A minimal example of how to use <code>RolloutConfig</code>:</p> <pre><code>from agentlightning import RolloutConfig\n\n# Retry on explicit failures or timeouts, up to 3 attempts in total.\ncfg = RolloutConfig(\n    timeout_seconds=600,\n    unresponsive_seconds=120,\n    max_attempts=3,\n    retry_condition=[\"failed\", \"timeout\"]\n)\n\n# When creating/enqueuing a rollout, attach this config.\n# The store will propagate attempt outcomes according to cfg.\nrollout = await store.enqueue_rollout(input, config=cfg)\n</code></pre> Latest attempt status Rollout transition Notes / guards N/A <code>queuing</code> Created by <code>enqueue_rollout()</code>. <code>preparing</code> <code>queuing/requeuing</code> \u2192 <code>preparing</code> Typically <code>dequeue_rollout()</code> or <code>start_rollout()</code>/<code>start_attempt()</code> creates a new attempt. <code>running</code> <code>preparing/queuing/requeuing</code> \u2192 <code>running</code> First <code>add_[otel_]span()</code> flips the attempt to <code>running</code>; rollout follows via <code>propagate_status</code>. <code>succeeded</code> <code>*</code> \u2192 <code>succeeded</code> Terminal. Rollout <code>end_time</code> set. <code>failed</code> / <code>timeout</code> / <code>unresponsive</code> <code>*</code> \u2192 <code>requeuing</code> Only if <code>status \u2208 retry_condition \u2227 sequence_id &lt; max_attempts</code>. <code>failed</code> / <code>timeout</code> / <code>unresponsive</code> <code>*</code> \u2192 <code>failed</code> Otherwise (no retries left or retries disabled). <code>*</code> <code>*</code> \u2192 <code>cancelled</code> Explicitly set by <code>update_rollout(status=cancelled)</code>. <p>Why aggregation?</p> <p>In code, we use <code>propagate_status()</code> which actively updates the rollout based on the latest attempt. Reading the table above is usually easier than reverse-engineering the propagation logic in the code: think of the rollout\u2019s transitions as callbacks on attempt state changes, plus queue/cancel paths.</p>"},{"location":"deep-dive/store/#spans","title":"Spans","text":"<p>Every traceable operation in a rollout is stored as a Span. Spans not only capture fine-grained instrumentation but also act as periodic heartbeats that demonstrate liveness. The first span marks activation; each subsequent one both extends the trace and refreshes the attempt\u2019s <code>last_heartbeat_time</code>. If no span arrives within the configured <code>unresponsive_seconds</code>, the watchdog downgrades the attempt to unresponsive until activity resumes.</p> <p>Spans are indexed by <code>(rollout_id, attempt_id, sequence_id)</code> where the sequence is monotonic. Tracing analysis tools like Adapter usually rely on \"time order\" to reconstruct the trace. However, in a distributed system, the recorded start time and end time of a span are not necessarily in the right order when they aggregated into a central store. Therefore, we enforce every span creation to retrieve a monotonically increasing <code>sequence_id</code> from the store before adding the span.</p> <p>Note</p> <p>In practice, one <code>sequence_id</code> can be used to create multiple spans. In that case, the orders between the multiple spans are determined by the order of <code>start_time</code> and <code>end_time</code> of the spans.</p>"},{"location":"deep-dive/store/#opentelemetry-conversion","title":"OpenTelemetry conversion","text":"<p>Runners often produce OpenTelemetry <code>ReadableSpan</code> objects directly. The store normalizes them into <code>Span</code> as follows:</p> <ol> <li>The runner first requests <code>get_next_span_sequence_id</code> via <code>sequence_id = await store.get_next_span_sequence_id(rollout_id, attempt_id)</code>. This guarantees ordering within the attempt regardless of clock skew.</li> <li><code>trace_id</code>, <code>span_id</code>, <code>parent_id</code>, <code>name</code>, <code>status</code>, timestamps, attributes, events, links, and resource are copied from the OTEL span. Timestamps are auto-normalized to seconds (nanoseconds are converted).</li> <li>OTEL <code>SpanContext</code> and parent context are preserved so downstream tools can correlate traces across systems.</li> <li>Any additional serializable fields present on the <code>ReadableSpan</code> are retained in the stored span (after safe JSON serialization), which keeps the representation forward-compatible.</li> </ol> <p>Programmatically this is encapsulated by <code>Span.from_opentelemetry(readable_span, rollout_id, attempt_id, sequence_id)</code>; <code>store.add_otel_span(...)</code> simply wraps the fetch-then-add flow. The end result is a store span that is stable to sort, merge, and query, while still preserving the richness of the original OTEL payload.</p> <p>Tip</p> <p><code>add_span</code> or <code>add_otel_span</code> both appends a span and acts as a heartbeat that can revive <code>unresponsive</code> \u2192 <code>running</code>.</p>"},{"location":"deep-dive/store/#store-implementations","title":"Store Implementations","text":"<p>Currently, the only out-of-the-box implementation is <code>InMemoryLightningStore</code>:</p> <ul> <li>Fast startup, zero external dependencies, and ideal for local development, CI, and unit tests.</li> <li>Fully asyncio-safe for writes; most reader operations can iterate without locks, except those that need to perform multiple queries.</li> <li>Includes a best-effort span eviction policy once memory crosses a configured watermark; querying evicted spans raises a clear error so callers can fall back.</li> </ul> <p>For production you will likely want persistence. We\u2019re actively building a SQLite-backed store that keeps the same API surface while adding durability, crash recovery, and better historical span queries. If you need something sooner, implement your own store by subclassing <code>LightningStore</code> and providing concrete storage for the small set of abstract methods (<code>enqueue_rollout</code>, <code>dequeue_rollout</code>, <code>update_attempt</code>, <code>add_span</code>, etc.). This document plus the tests in <code>tests/store/</code> illustrate the expected behavior.</p>"},{"location":"deep-dive/store/#thread-safety","title":"Thread Safety","text":"<p><code>LightningStoreThreaded</code> is a subclass of <code>LightningStore</code> that wraps another underlying store to make a store instance safe for multi-threaded callers. It wraps every state-mutating call in a mutex. Specifically:</p> <ul> <li>Methods like <code>start_rollout</code>, <code>enqueue_rollout</code>, <code>update_attempt</code>, <code>add_span</code>, etc. are guarded by a lock.</li> <li>Non-mutating, potentially blocking calls remain pass-through by design (e.g., <code>wait_for_rollouts</code>), as they don\u2019t modify shared state and should not hold the lock for long periods.</li> </ul>"},{"location":"deep-dive/store/#process-safety-and-client-server-store","title":"Process Safety and Client-server Store","text":"<p><code>LightningStoreServer</code> wraps another underlying store and runs a FastAPI app to expose the store API over HTTP. <code>LightningStoreClient</code> is a small <code>LightningStore</code> implementation that talks to the HTTP API.</p> <p>Warning</p> <p>The server HTTP API is not considered a stable API at this moment. Users are encouraged to use the <code>LightningStoreClient</code> to communicate with the server as a stable interface.</p> <p>The server tracks the creator PID. In the owner process it delegates directly to the in-memory store; in other processes it lazily constructs a <code>LightningStoreClient</code> to talk to the HTTP API. This prevents accidental cross-process mutation of the wrong memory image. When the server is pickled (e.g., via <code>multiprocessing</code>), only the minimal fields are serialized, but NOT the FastAPI/uvicorn objects. Subprocesses won\u2019t accidentally carry live server state. Forked subprocess should also use <code>LightningStoreClient</code> to communicate with the server in the main process.</p> <p>On the client side, the client retries network/5xx failures using a small backoff, and probes <code>/health</code> between attempts. Application exceptions inside the server are wrapped as HTTP 400 with a traceback\u2014these are not retried. The client also maintains a per-event-loop <code>aiohttp.ClientSession</code> map so that tracer callbacks (often on separate loops/threads) don\u2019t hang by reusing a session from another loop.</p> <p>Minimal lifecycle:</p> <pre><code>import agentlightning as agl\n\n# Server (owner process)\nin_memory_store = agl.InMemoryLightningStore()\nserver = agl.LightningStoreServer(store=in_memory_store, host=\"0.0.0.0\", port=4747)\nawait server.start()      # starts uvicorn in a daemon thread and waits for /health\n# or keep your own event loop and stop via await server.stop()\n# await server.run_forever()\n\n# Client (same or different process)\nclient = agl.LightningStoreClient(\"http://localhost:4747\")\n\nprint(await client.query_rollouts(status=[\"queuing\"]))\n\nawait client.close()\nawait server.stop()\n</code></pre> <p>Another approach is to use a dedicated command line to start a long running server process, possibly sharable across multiple processes. In the main process, you can always use <code>LightningStoreClient</code> to communicate with the server.</p> <pre><code>agl store --port 4747\n</code></pre> <p>Note</p> <p><code>LightningStoreClient.wait_for_rollouts</code> intentionally enforces a tiny timeout (\u2264 0.1s) to avoid blocking event loops. Poll with short timeouts or compose with <code>asyncio.wait_for</code> at a higher layer.</p>"},{"location":"how-to/train-first-agent/","title":"Train the First Agent with Agent-lightning","text":"<p>Welcome! This tutorial is your first step into making AI agents smarter using the Agent-lightning framework. We'll show you how to take a simple agent and automatically improve its performance through a process called Automatic Prompt Optimization (APO).</p> <p>The main goal of Agent-lightning is to provide a structured way to train your agents. Just like you train a machine learning model on data, you can train an agent on a task dataset. This could involve using Reinforcement Learning (RL) to teach it new behaviors or, as we'll do today, optimizing its prompts to make it more accurate and reliable.</p>"},{"location":"how-to/train-first-agent/#our-example-the-room-selector-agent","title":"Our Example: The Room Selector Agent","text":"<p>Today, we'll work with an agent whose job is to book a meeting room. It's a common but tricky task with multiple constraints.</p> <p>Here's how the agent works:</p> <ul> <li>Input: It receives a task with specific requirements, like \"<code>Find a room for 4 people at 10:00 AM with a whiteboard.</code>\"</li> <li>Action: The agent uses a Large Language Model (LLM) to understand the request. It can also use tools, which are pre-defined functions it can call, to get more information, such as checking room availability in an external database.</li> <li>Output: Its final decision is the ID of the best room it found, like \"<code>A103</code>\".</li> <li>Reward: After the agent makes its choice, a separate \"grader\" function scores its performance on a scale of 0 to 1. This score is called its reward. A perfect choice gets a 1.0, while a wrong one gets a 0.0.</li> </ul> <p>The agent's logic is sound, but its performance heavily depends on its initial prompt. A poorly worded prompt will confuse the LLM, leading to bad decisions. Our goal is to use Agent-lightning to find the best possible prompt automatically.</p> <p>A Closer Look at the Agent's Logic</p> <p>Modern LLMs can do more than just generate text; they can decide to call functions you provide. This is often called tool use or function calling. Our agent uses this capability to make informed decisions. If you're new to this concept, you can read more about it in OpenAI's documentation.</p> <p>Here is a sketch of the agent's logic, adhering closely to the OpenAI API:</p> <pre><code># Pseudo-code for the Room Selector agent\n\nimport openai\nimport json\n\ndef room_selector_agent(task, prompt):\n    client = openai.OpenAI()\n    messages = [{\"role\": \"user\", \"content\": prompt.format(**task)}]\n    tools = [ ... ] # Tool definition for the LLM\n\n    # 1. First LLM call to decide if a tool is needed.\n    response = client.chat.completions.create(\n        model=\"gpt-5-mini\",\n        messages=messages,\n        tools=tools,\n        tool_choice=\"auto\",\n    )\n    response_message = response.choices[0].message\n    tool_calls = response_message.tool_calls\n\n    # 2. Check if the LLM wants to use a tool.\n    if tool_calls:\n        messages.append(response_message) # Append assistant's reply\n\n        # 3. Execute the tool and get the real-world data.\n        for tool_call in tool_calls:\n            function_name = tool_call.function.name\n            if function_name == \"get_rooms_and_availability\":\n                function_args = json.loads(tool_call.function.arguments)\n                # Query the local room database\n                function_response = get_rooms_and_availability(\n                    date=function_args.get(\"date\"),\n                    time_str=function_args.get(\"time\"),\n                    duration_min=function_args.get(\"duration_min\"),\n                )\n                messages.append({\n                    \"tool_call_id\": tool_call.id,\n                    \"role\": \"tool\",\n                    \"name\": function_name,\n                    \"content\": json.dumps(function_response),\n                })\n\n        # 4. Second LLM call with the tool's output to get a final choice.\n        second_response = client.chat.completions.create(\n            model=\"gpt-5-mini\",\n            messages=messages,\n        )\n        final_choice = second_response.choices[0].message.content\n    else:\n        final_choice = response_message.content\n\n    # 5. Grade the final choice to get a reward.\n    reward = grade_the_choice(final_choice, task[\"expected_choice\"])\n    return reward\n</code></pre> <p>In Agent-lightning, you wrap this logic in a Python function marked with the <code>@rollout</code> decorator, so that the agent can be managed and tuned by Agent-lightning's runner and trainer. The <code>prompt_template</code> that the APO algorithm tunes is passed in as an argument:</p> <pre><code>from agentlightning import rollout\nfrom agentlightning.types import PromptTemplate\n\n@rollout\ndef room_selector(task: RoomSelectionTask, prompt_template: PromptTemplate) -&gt; float:\n    # ... agent logic using the prompt_template ...\n\n    # The final reward is determined by a grader function\n    reward = room_selection_grader(client, final_message, task[\"expected_choice\"])\n    return reward\n</code></pre>"},{"location":"how-to/train-first-agent/#core-concepts-tasks-rollouts-spans-and-prompt-templates","title":"Core Concepts: Tasks, Rollouts, Spans, and Prompt Templates","text":"<p>To understand how Agent-lightning works, you need to know these key terms.</p>"},{"location":"how-to/train-first-agent/#task","title":"Task","text":"<p>A task is a specific input or problem statement given to the agent. It defines what the agent needs to accomplish.</p> <p>Analogy</p> <p>If the agent is a chef, a task is the recipe request: \"Bake a chocolate cake.\"</p>"},{"location":"how-to/train-first-agent/#rollout","title":"Rollout","text":"<p>A rollout is a single, complete execution of an agent attempting to solve a given task. It's the entire story from receiving the task to producing a final result and receiving a reward. A rollout captures a full trace of the agent's execution.</p> <p>Analogy</p> <p>A rollout is one full attempt by the chef to bake the chocolate cake, from gathering ingredients to the final taste test.</p>"},{"location":"how-to/train-first-agent/#span","title":"Span","text":"<p>A span represents a single unit of work or an operation within a rollout. Spans are the building blocks of a trace. They have a start and end time and contain details about the specific operation, like an LLM call, a tool execution, or a reward calculation. For a more precise definition, see the OpenTelemetry documentation.</p> <p>Analogy</p> <p>If the rollout is \"baking a cake,\" a span could be \"preheating the oven,\" \"mixing flour and sugar,\" or \"adding frosting.\" Each is a distinct step or unit of work.</p> <p>The picture below from ADK shows a typical rollout, where each rectangle in the waterfall visualizes a span. As can be seen in the visualization, spans can be sequential, parallel or nested among each other. In other frameworks, the terminilogy might be slightly different. Agent-lightning follows the terminalogies used by OpenTelemetry to avoid confusion.</p> <p></p>"},{"location":"how-to/train-first-agent/#prompt-template","title":"Prompt Template","text":"<p>A prompt template is a reusable instruction for the agent, often containing placeholders that can be filled in with specific details from a task. It is a key \"resource\" that the algorithm learns and improves over time.</p> <p>Analogy</p> <p>If the task is the recipe request, the prompt template is the master recipe card that the chef follows. The algorithm's job is to edit this recipe card to make the instructions clearer and the final dish better.</p>"},{"location":"how-to/train-first-agent/#the-training-loop-how-the-magic-happens","title":"The Training Loop: How the Magic Happens","text":"<p>Training in Agent-lightning revolves around a clear, managed loop, orchestrated by the Trainer. The diagram below illustrates this core interaction:</p> <p></p> <p>The Loop Explained:</p> <ul> <li>Algorithm to Agent (via Trainer): The Algorithm (the \"brain\") creates an improved Prompt Template and selects Tasks. The Trainer then sends both to the Trainer.</li> <li>Agent to Algorithm (via Trainer): For each task it receives, the Agent uses the provided prompt template to perform a Rollout, executing its logic and potentially using tools. During this rollout, the runner that runs the agent captures Spans that detail every step. The agent also calculates a Reward for its performance on the task. These spans and rewards are then sent back to the Algorithm via the Trainer.</li> <li>Algorithm Learning: The Algorithm then analyzes these spans and rewards to learn how to improve the agent's behavior, for example, by generating a better prompt. This improved prompt is then used in the next iteration of tasks.</li> </ul> <p>This cycle continues, allowing the agent to continuously learn and get better at solving tasks.</p> <p>Note</p> <p>In the next tutorial, we will see that the \"via Trainer\" here is not accurate. It's actually via the runner and store.</p>"},{"location":"how-to/train-first-agent/#the-algorithm","title":"The Algorithm","text":"<p>The algorithm is the smart part of the system that drives the improvement. In this tutorial, we use APO (Automatic Prompt Optimization). It works in a few steps:</p> <ol> <li>Evaluate: The algorithm first asks for rollouts to be run using the current prompt template to see how well it performs.</li> <li>Critique: It then looks at the detailed spans from those rollouts. Using a powerful LLM (<code>gpt-5-mini</code>), it generates a \"textual gradient\", which is a natural language critique of the prompt. For example: \"The prompt is ambiguous about how to handle tie-breakers for equally good rooms.\"</li> <li>Rewrite: Finally, it gives the critique and the original prompt to another LLM (<code>gpt-4.1-mini</code>) and asks it to apply the edits, generating a new, improved prompt template.</li> </ol> <p>This cycle repeats, with each round producing a slightly better prompt. To use it, you simply initialize the APO class with your desired hyperparameters.</p> <pre><code># In the main training script: run_apo.py\nfrom agentlightning.algorithm.apo import APO\nfrom openai import AsyncOpenAI\n\nopenai = AsyncOpenAI()\nalgo = APO(openai)\n</code></pre>"},{"location":"how-to/train-first-agent/#the-trainer","title":"The Trainer","text":"<p>The Trainer is the central component you'll interact with. It connects everything and manages the entire workflow by running the loop described above. You configure the Trainer, providing the algorithm, the number of parallel runners, and the initial prompt. A single call to <code>trainer.fit()</code> kicks off the entire process!</p> <pre><code># In the main training script: run_apo.py\nfrom agentlightning import Trainer\n\n# 1. Configure the Trainer with the algorithm and initial prompt\ntrainer = Trainer(\n    algorithm=algo,\n    n_runners=8, # Run 8 agents in parallel to try out the prompts\n    initial_resources={\n        # The initial prompt template to be tuned\n        \"prompt_template\": prompt_template_baseline()\n    },\n    # This is used to convert the span data into a message format consumable by APO algorithm\n    adapter=TraceMessagesAdapter(),\n)\n\n# 2. Load datasets: They can be list of task objects consumable by `room_selector`.\ndataset_train, dataset_val = ...\n\n# 3. Start the training process!\ntrainer.fit(\n    agent=room_selector,\n    train_dataset=dataset_train,\n    val_dataset=dataset_val\n)\n</code></pre>"},{"location":"how-to/train-first-agent/#training-results","title":"Training Results","text":"<p>The APO algorithm successfully improved the agent's performance. We ran the example with the following hyper-parameters:</p> <ul> <li><code>val_batch_size</code> = 10</li> <li><code>gradient_batch_size</code> = 4</li> <li><code>beam_width</code> = 2</li> <li><code>branch_factor</code> = 2</li> <li><code>beam_rounds</code> = 2</li> </ul> <p>The validation accuracy on the 29 samples of datasets steadily increase from 0.569 (baseline) to 0.721 (after round 2). The tuning takes around 10 minutes with 8 runners. We ran twice, and the results are shown in the chart below.</p> <p>This demonstrates how Agent-lightning can efficiently and automatically enhance your agent's capabilities with just a few lines of code.</p>"},{"location":"how-to/train-sql-agent/","title":"Train SQL Agent with Agent-lightning and VERL","text":"<p>This walkthrough builds upon the Agent-lightning v0.2 SQL Agent example and explains how the system components integrate: a LangGraph-based SQL agent wrapped as a <code>LitAgent</code>, the <code>VERL</code> reinforcement learning (RL) algorithm, and the <code>Trainer</code>, which coordinates both training and debugging.</p> <p>The command-line interface in <code>examples/spider/train_sql_agent.py</code> provides a complete runnable example. However, this document focuses on understanding the underlying architecture so you can effectively adapt the workflow to your own agents.</p>"},{"location":"how-to/train-sql-agent/#sql-agent-architecture","title":"SQL Agent Architecture","text":"<p>Agent-lightning integrates seamlessly with various orchestration frameworks, including Agent Framework, AutoGen, CrewAI, LangGraph, and the OpenAI Agents SDK. It can also interoperate with custom Python logic.</p> <p>In this example, LangGraph defines a cyclic workflow that mirrors an analyst\u2019s iterative SQL development process. The following graph (rendered directly from <code>sql_agent.py</code>) illustrates how the agent drafts, executes, critiques, and refines queries until a satisfactory result is achieved.</p> <pre><code>---\nconfig:\n  flowchart:\n    curve: linear\n---\ngraph LR;\n        __start__([&lt;p&gt;__start__&lt;/p&gt;]):::first\n        write_query(write_query)\n        execute_query(execute_query)\n        check_query(check_query)\n        rewrite_query(rewrite_query)\n        __end__([&lt;p&gt;__end__&lt;/p&gt;]):::last\n        __start__ --&gt; write_query;\n        check_query -.-&gt; __end__;\n        check_query -.-&gt; rewrite_query;\n        execute_query --&gt; check_query;\n        rewrite_query --&gt; execute_query;\n        write_query --&gt; execute_query;\n        classDef default fill:#f2f2f2,line-height:1.2\n        classDef first fill-opacity:0\n        classDef last fill:#cccccc</code></pre> <p>Note</p> <p>The workflow proceeds through the following stages:</p> <ol> <li>write_query \u2013 Generates an initial SQL query from the user\u2019s question and the database schema.</li> <li>execute_query \u2013 Executes the generated query against the target database.</li> <li>check_query \u2013 Evaluates the query and its results (or errors) using a specialized prompt (<code>CHECK_QUERY_PROMPT</code>) to detect issues.</li> <li>rewrite_query \u2013 If issues are identified, the agent rewrites the query using feedback from the previous step and re-enters the loop.</li> <li>END \u2013 The cycle terminates when the query is validated or the maximum iteration count (<code>max_turns</code>) is reached. Each turn consists of one full loop through the <code>write_query</code>, <code>execute_query</code>, <code>check_query</code>, and (if applicable) <code>rewrite_query</code> stages.</li> </ol> <p>In this tutorial, reinforcement learning (RL) is used to optimize the <code>write_query</code> and <code>rewrite_query</code> stages. While the <code>check_query</code> step shares the same underlying LLM weights, its trace data is not used for learning.</p> <p>To keep the design modular and maintainable, it is recommended to define the LangGraph-based SQL Agent in a separate file and expose it via a builder function such as:</p> <pre><code>def build_langgraph_sql_agent(\n    database_path: str,\n    openai_base_url: str,\n    model: str,\n    sampling_parameters: Dict[str, Any],\n    max_turns: int,\n    truncate_length: int\n):\n    builder = StateGraph(State)\n    builder.add_node(write_query)\n    ...\n\n    builder.add_edge(START, \"write_query\")\n    ...\n\n    return builder.compile().graph()\n</code></pre> <p>This approach isolates your LangGraph logic from Agent-lightning version changes, improving both readability and debuggability.</p>"},{"location":"how-to/train-sql-agent/#bridging-langgraph-and-agent-lightning","title":"Bridging LangGraph and Agent-lightning","text":"<p>Tip</p> <p>Keep <code>sql_agent.py</code> open on the side while reading this section. This will help you understand how the code snippets shown here work in practice.</p> <p>The <code>LitSQLAgent</code> class defined in <code>sql_agent.py</code> acts as the bridge. It subclasses <code>agl.LitAgent</code>, allowing the runner to provision shared resources (e.g., LLMs) for each rollout.</p> <p>Below is a simplified illustration of the key logic (note: this is conceptual pseudocode; the actual implementation includes dataset-specific details):</p> <pre><code>class LitSQLAgent(agl.LitAgent[Dict[str, Any]]):\n\n    def __init__(self, max_turns: int, truncate_length: int):\n        # Every turn here refers to a full cycle of write/exe/check/rewrite\n        self.max_turns = max_turns\n        self.truncate_length = truncate_length\n\n    def rollout(\n        self,\n        task: Dict[str, Any],\n        resources: agl.NamedResources,\n        rollout: agl.Rollout\n    ) -&gt; float | None:\n        llm: agl.LLM = resources[\"main_llm\"]\n        agent = build_langgraph_sql_agent(\n            database_path=\"sqlite:///\" + task[\"db_id\"],\n            max_turns=self.max_turns,\n            truncate_length=self.truncate_length,\n            openai_base_url=llm.get_base_url(rollout.rollout_id, rollout.attempt.attempt_id),\n            model=llm.model,\n            sampling_parameters=llm.sampling_parameters,\n        )\n        result = agent.invoke({\"question\": question}, {\n            \"callbacks\": [self.tracer.get_langchain_handler()],\n            \"recursion_limit\": 100,\n        })\n        reward = evaluate_query(result[\"query\"], ground_truth, db_path, raise_on_error=False)\n        return reward\n</code></pre> <p>The <code>LitSQLAgent</code> serves as a lightweight wrapper around the LangGraph agent, providing the correct interface for the <code>rollout</code> method. It constructs the LangGraph agent, invokes it, and returns the evaluation result as a reward signal.</p> <p>The <code>\"main_llm\"</code> resource key is a convention between the agent and VERL. It is used to inject an OpenAI-compatible endpoint from the VERL algorithm during rollout. Two approaches are supported to use this agentlightning.LLM resource:</p> <ol> <li>Direct access \u2013 Use <code>llm.endpoint</code> for a simple integration (identical to the v0.1 example).</li> <li>Context-aware access \u2013 Use <code>get_base_url</code> with <code>rollout.rollout_id</code> and <code>rollout.attempt.attempt_id</code>.    This approach enables per-caller trace attribution, improving trace collection per rollout or attempt when runner-side tracers are unavailable. For details, see Working with Traces.</li> </ol>"},{"location":"how-to/train-sql-agent/#reward-signal-and-evaluation","title":"Reward Signal and Evaluation","text":"<p>The <code>evaluate_query</code> function provides the reward mechanism for RL training. In agent training, obtaining a consistent and meaningful reward signal is often challenging. Fortunately, this is simplified when using the Spider dataset. The dataset includes ~8k samples containing natural-language questions, database schemas, and ground-truth SQL queries.</p> <p>Using the Spider evaluator, the agent's generated query is executed and compared to the ground-truth query on the target database. The two queries are considered equivalent if they produce identical execution results.</p> <p>Attention</p> <p>The ground-truth queries must never be exposed to the agent during training to prevent data leakage.</p> <p>In this setup, the reward is returned directly from the <code>rollout</code> method, enabling the runner to forward it back to the RL algorithm.</p> <p>Warning</p> <p>Avoid using <code>emit_reward</code> in conjunction with returning a reward value. Doing both will cause the algorithm to receive duplicate reward signals, leading to inconsistent training behavior.</p>"},{"location":"how-to/train-sql-agent/#configuring-verl-for-reinforcement-learning","title":"Configuring VERL for Reinforcement Learning","text":"<p>View <code>examples/spider/train_sql_agent.py</code> for a full reinforcement learning configuration, which is a plain Python dictionary. It mirrors (and actually is) the shell arguments used to launch training in the VERL framework but is easier to tweak programmatically:</p> <pre><code>verl_config: Dict[str, Any] = {\n    \"algorithm\": {\"adv_estimator\": \"grpo\", \"use_kl_in_reward\": False},\n    \"data\": {\n        # train_files and val_files are no longer needed here\n        # because data are read in agl.Trainer\n        ...,\n        # Controls how many tasks are pooled per step\n        # (multiplied by actor_rollout_ref.rollout.n)\n        \"train_batch_size\": 32,\n        # Prompt and responses larger than these lengths are truncated\n        \"max_prompt_length\": 4096,\n        \"max_response_length\": 2048,\n    },\n    \"actor_rollout_ref\": {\n        \"rollout\": {\n            # Only vLLM is supported currently\n            \"name\": \"vllm\",\n            # Equals to group size of GRPO\n            \"n\": 4,\n            # Used to enable tool call parser in vLLM\n            \"multi_turn\": {\"format\": \"hermes\"},\n            ...\n        },\n        \"actor\": {\"ppo_mini_batch_size\": 32, \"optim\": {\"lr\": 1e-6}, ...},\n        \"model\": {\n            # Config your preferred LLM here\n            \"path\": \"Qwen/Qwen2.5-Coder-1.5B-Instruct\",\n            ...\n        },\n    },\n    \"trainer\": {\n        \"n_gpus_per_node\": 1,\n        # Validation once before training starts\n        \"val_before_train\": True,\n        # Validation every N training steps\n        \"test_freq\": 32,\n        # Save checkpoints every N training steps\n        \"save_freq\": 64,\n        # Go through the train dataset this many times\n        \"total_epochs\": 2\n    },\n}\n</code></pre> <p>This is equivalent to the following CLI invocation:</p> <pre><code>python3 -m verl.trainer.main_ppo \\\n    algorithm.adv_estimator=grpo \\\n    algorithm.use_kl_in_reward=False \\\n    data.train_batch_size=32 \\\n    data.max_prompt_length=4096 \\\n    data.max_response_length=2048 \\\n    actor_rollout_ref.rollout.name=vllm \\\n    actor_rollout_ref.rollout.n=4 \\\n    actor_rollout_ref.rollout.multi_turn.format=hermes \\\n    actor_rollout_ref.actor.ppo_mini_batch_size=32 \\\n    actor_rollout_ref.actor.optim.lr=1e-6 \\\n    actor_rollout_ref.model.path=Qwen/Qwen2.5-Coder-1.5B-Instruct \\\n    trainer.n_gpus_per_node=1 \\\n    trainer.val_before_train=True \\\n    trainer.test_freq=32 \\\n    trainer.save_freq=64 \\\n    trainer.total_epochs=2\n</code></pre> <p>Warning</p> <p>We used to provide a CLI called <code>python -m agentlightning.verl</code> to launch training in v0.1. This is no longer the recommended approach. Instead, use <code>agl.Trainer</code> to run VERL and agent runners together, or follow the debugging tutorial if you want an isolated experience similar to v0.1.</p>"},{"location":"how-to/train-sql-agent/#orchestrating-training-with-trainer","title":"Orchestrating Training with <code>Trainer</code>","text":"<p><code>Trainer</code> is the high-level orchestrator that integrates the agent, algorithm, dataset, and distributed runners. The key benefits of using the <code>Trainer</code> are:</p> <ol> <li>It allows you to launch everything with a single line of code: <code>trainer.fit(...)</code>.</li> <li>It exposes configuration options such as <code>n_runners</code> to control parallelism and <code>adapter</code> to define how algorithms interpret the trace data produced by the agent.</li> </ol> <p>An example usage is shown below:</p> <pre><code>import agentlightning as agl\n\nagent = LitSQLAgent()\nalgorithm = agl.VERL(verl_config)\ntrainer = agl.Trainer(\n    n_runners=10,\n    algorithm=algorithm,\n    adapter={\"agent_match\": active_agent},\n)\ntrain_data = pd.read_parquet(\"data/train_spider.parquet\").to_dict(\"records\")\nval_data = pd.read_parquet(\"data/test_dev_500.parquet\").to_dict(\"records\")\ntrainer.fit(agent, train_dataset=train_data, val_dataset=val_data)\n</code></pre> <p>First, <code>agl.VERL(verl_config)</code> launches the <code>VERL</code> algorithm and its OpenAI-compatible proxy. The <code>train_data</code> and <code>val_data</code> are passed into <code>VERL</code>, which enqueues tasks to a centralized task queue managed by the <code>LightningStore</code>, accessible to all runners.</p> <p>When <code>Trainer.fit</code> is called, it launches 10 concurrent runners (as specified by <code>n_runners=10</code>). Each runner pulls tasks from the centralized task queue, executes the agent\u2019s <code>rollout</code> method, collects traces, and returns rewards to VERL for training.</p> <p>The <code>Adapter</code>, as discussed earlier, is used at the algorithm side, and receives the traces emitted by the agent and runners. The <code>agent_match</code> parameter ensures <code>VERL</code> only ingests spans from the specific agent you want to optimize. In the example above, there are at least three agents\u2014<code>write_query</code>, <code>rewrite_query</code>, and <code>check_query</code>. By setting <code>agent_match</code> to a regex like <code>\"write\"</code>, both <code>write_query</code> and <code>rewrite_query</code> agents are optimized simultaneously. You can also set it to <code>\"write|check\"</code> or <code>None</code> to include all agents if desired.</p>"},{"location":"how-to/train-sql-agent/#dry-run-the-pipeline-with-trainerdev","title":"Dry-Run the Pipeline with <code>Trainer.dev</code>","text":"<p>Before committing hours of GPU time, you can dry-run the agent with <code>Trainer.dev()</code>. This method swaps in the lightweight <code>Baseline</code> algorithm, enqueues up to ten tasks, and prints every span emitted by the agent. Because it uses the same runner stack as full training, it\u2019s ideal for verifying database connections and LangGraph control flow.</p> <p>To begin, the agent needs a valid OpenAI-compatible endpoint since VERL is not active in this mode. You can use OpenAI\u2019s official API or your own local LLM endpoint. Wrap it as follows:</p> <pre><code>trainer = agl.Trainer(\n    n_workers=1,\n    initial_resources={\n        \"main_llm\": agl.LLM(\n            endpoint=os.environ[\"OPENAI_API_BASE\"],\n            model=\"gpt-4.1-nano\",\n            sampling_parameters={\"temperature\": 0.7},\n        )\n    },\n)\n</code></pre> <p>Then, call <code>trainer.dev(...)</code> with a small number of tasks:</p> <pre><code>dev_data = pd.read_parquet(\"data/test_dev_500.parquet\").to_dict(\"records\")[:10]\ntrainer.dev(agent, dev_dataset=dev_data)\n</code></pre> <p>Run this in a Python session or adapt your script to include a <code>--dev</code> flag. Once the spans appear healthy and the rewards are non-zero, switch back to <code>trainer.fit(...)</code> for full RL training.</p>"},{"location":"how-to/train-sql-agent/#running-the-sample-code","title":"Running the Sample Code","text":"<p>The following tutorial explains how to run the complete example in <code>examples/spider</code>.</p>"},{"location":"how-to/train-sql-agent/#dataset","title":"Dataset","text":"<p>The trainer expects three Parquet files inside <code>examples/spider/data</code>: <code>train_spider.parquet</code>, <code>test_dev_500.parquet</code>, and <code>test_dev.parquet</code>.</p> <p>Download the curated dataset bundle provided with the repository:</p> <pre><code>cd examples/spider\npip install gdown  # included in the 'experiment' optional dependency\ngdown --fuzzy https://drive.google.com/file/d/1oi9J1jZP9TyM35L85CL3qeGWl2jqlnL6/view\nunzip -q spider-data.zip -d data\nrm spider-data.zip\n</code></pre> <p>If you prefer to generate the files yourself, download Spider 1.0 and run:</p> <pre><code>python spider_eval/convert_dataset.py\n</code></pre> <p>Set <code>VERL_SPIDER_DATA_DIR</code> if you store the dataset outside the default <code>data</code> directory.</p>"},{"location":"how-to/train-sql-agent/#dependencies","title":"Dependencies","text":"<p>Create a clean virtual environment, activate it, and install Agent-lightning with the VERL extras required by this tutorial. Install LangChain-related dependencies as needed.</p> <p>For full training profiles, plan to use a GPU with at least 40 GB of memory.</p>"},{"location":"how-to/train-sql-agent/#launch-training","title":"Launch Training","text":"<p>From <code>examples/spider</code>, run one of the helper scripts depending on your model preference:</p> <pre><code>python train_sql_agent.py qwen   # Default Qwen-2.5-Coder-1.5B run\npython train_sql_agent.py llama  # LLaMA-3.2-1B with llama3_json tool parser\n</code></pre> <p>The script instantiates <code>LitSQLAgent</code> and launches <code>trainer.fit</code>. Provide <code>--active-agent my_agent_variant</code> if you only want to train one of the agents in the graph.</p> <p>For the LLaMA profile, export an <code>HF_TOKEN</code> before running so VERL can download the model weights.</p> <p>Troubleshooting</p> <p>If you have got some Ray worker errors on either <code>WANDB_API_KEY</code> not set, or <code>HF_TOKEN</code> not set, or data not found, please try to restart the Ray cluster with the helper script: scripts/restart_ray.sh, which essentially stops the ray cluster if any, and starts a new one:</p> <pre><code>env RAY_DEBUG=legacy HYDRA_FULL_ERROR=1 VLLM_USE_V1=1 ray start --head --dashboard-host=0.0.0.0\n</code></pre>"},{"location":"how-to/train-sql-agent/#debugging-the-agent-without-verl","title":"Debugging the Agent without VERL","text":"<p><code>sql_agent.py</code> also provides a <code>debug_sql_agent()</code> helper to run the LangGraph workflow directly against a local or hosted OpenAI-compatible endpoint before using VERL.</p> <p>Set the following environment variables, then execute the file:</p> <pre><code>export OPENAI_API_BASE=&lt;your_api_base&gt;\nexport OPENAI_API_KEY=&lt;your_api_key&gt;\ncd examples/spider\npython sql_agent.py\n</code></pre> <p>This allows you to verify that the workflow and prompts behave as expected before reinforcement learning is introduced.</p>"},{"location":"how-to/train-sql-agent/#evaluation","title":"Evaluation","text":"<p>The following results were obtained by running <code>python train_sql_agent.py qwen</code> on a single 80 GB GPU. Training completes in approximately 12 hours. The training curves below are smoothed by aggregating every 16 steps for better visualization.</p> <p>Additional evaluation results were collected with a legacy version \u2014 Agent-lightning v0.1.1, <code>verl==0.5.0</code>, and <code>vllm==0.10.0</code>. You can find them in this write-up: Training AI Agents to Write and Self-Correct SQL with Reinforcement Learning</p>"},{"location":"how-to/unsloth-sft/","title":"Unsloth SFT","text":"<p>Article to be written.</p>"},{"location":"how-to/write-first-algorithm/","title":"Write the First Algorithm with Agent-lightning","text":"<p>In the first tutorial, \"Train the First Agent,\" we introduced the Trainer and showed how to use a pre-built algorithm like Automatic Prompt Optimization (APO) to improve an agent's performance. The Trainer handled all the complex interactions, letting us focus on the agent's logic.</p> <p>Now, we'll go a step deeper. What if you have a unique training idea that doesn't fit a standard algorithm? This tutorial will show you how to write your own custom algorithm from scratch. We'll build a simple algorithm that systematically tests a list of prompt templates and identifies the one with the highest reward.</p> <p>By the end, you'll understand the core mechanics of how the Algorithm, Runner, and a new component, the Store, work together to create the powerful training loop at the heart of Agent-lightning.</p> <p>Tip</p> <p>This tutorial helps you build a basic understanding of how to interact with Agent-lightning's core components. It's recommended that all users customizing algorithms should read this tutorial, even for those who are not planning to do prompt optimization.</p>"},{"location":"how-to/write-first-algorithm/#core-concepts-for-training","title":"Core Concepts for Training","text":"<p>Before diving into the LightningStore, let's define two key concepts that are central to any training process in Agent-lightning: Resources and the Tracer.</p>"},{"location":"how-to/write-first-algorithm/#resources-the-tunable-assets","title":"Resources: The Tunable Assets","text":"<p>Resources are the assets your algorithm is trying to improve. Think of them as the \"recipe\" an agent uses to perform its task. This recipe can be:</p> <ul> <li>A prompt template that guides an LLM.</li> <li>The weights of a machine learning model.</li> <li>Any other configuration or data your agent needs.</li> </ul> <p>The algorithm's job is to run experiments and iteratively update these resources to find the best-performing version.</p>"},{"location":"how-to/write-first-algorithm/#tracer-the-data-collector","title":"Tracer: The Data Collector","text":"<p>How does the algorithm know if a change was an improvement? It needs data. This is where the Tracer comes in.</p> <p>The Tracer automatically instruments (aka modifies / patches) the agent's code. This means it watches for important events, like an LLM call, a tool being used, or reward signals, and records a detailed log of what happened. Each of these logs is called a Span (which has already been introduced in the last tutorial).</p> <p>A collection of spans from a single task execution gives the algorithm a complete, step-by-step trace of the agent's behavior, which is essential for learning and making improvements. Our default tracer is built on the AgentOps SDK to support instrumenting code written in various Agent/non-agent frameworks.</p>"},{"location":"how-to/write-first-algorithm/#the-central-hub-the-lightningstore","title":"The Central Hub: The LightningStore","text":"<p>Now, where do all these resources, tasks, and spans live? They are all managed by the LightningStore.</p> <p>The LightningStore acts as the central database and message queue for the entire system. It's the single source of truth that decouples the Algorithm from the Runners.</p> <p>Note</p> <p>In the last tutorial we simplified the training loop, saying the Algorithm and Agent communicate \"via the Trainer.\" That's true at a high level, but the component that makes it all possible is actually the LightningStore.</p> <ul> <li>The Algorithm connects to the Store to <code>enqueue_rollout</code> (tasks) and <code>update_resources</code> (like new prompt templates). It also queries the Store to retrieve the resulting spans and rewards from completed rollouts.</li> <li>The Runners connect to the Store to <code>dequeue_rollout</code> (polling for available tasks). After executing a task, they use the <code>Tracer</code> to write the resulting spans and status updates back to the Store.</li> </ul> <p>This architecture is key to Agent-lightning's scalability. Since the Algorithm and Runners only talk to the Store, they can run in different processes or even on different machines.</p> <p></p> <p>A Mental Model of What the Store Contains</p> <p>The LightningStore isn't just a simple database; it's an organized system for managing the entire training lifecycle. Here's what it keeps track of:</p> <ul> <li>Task Queue: A queue of pending Rollouts waiting for a Runner to pick them up, interactable via <code>enqueue_rollout</code> and <code>dequeue_rollout</code>.</li> <li>Rollouts: The record of a single task. A rollout contains metadata about the task and tracks all Attempts to complete it, interactable via <code>query_rollouts</code> and <code>wait_for_rollouts</code>.</li> <li>Attempts: A single execution of a rollout. If an attempt fails (e.g., due to a network error), the Store can automatically schedules a retry if it's configured. Each attempt is linked to its parent rollout and contains the status and timing information. The rollout status is synced with its children's status. For beginners, you can assume each rollout has only one attempt unless you have explicitly configure the retry.</li> <li>Spans: The detailed, structured logs generated by the <code>Tracer</code> during an attempt. Each span is linked to its parent attempt and rollout.</li> <li>Resources: A versioned collection of the assets (like prompt templates) that the algorithm creates. Each rollout is linked to the specific version of the resources it should use.</li> </ul>"},{"location":"how-to/write-first-algorithm/#building-a-custom-algorithm","title":"Building a Custom Algorithm","text":"<p>Let's build an algorithm that finds the best system prompt from a predefined list. The logic is straightforward:</p> <ol> <li>Start with a list of candidate prompt templates.</li> <li>For each template, create a \"resource\" bundle in the Store.</li> <li>Enqueue a rollout (a task), telling the Runner to use this specific resource.</li> <li>Wait for a Runner to pick up the task and complete it.</li> <li>Query the Store to get the final reward from the rollout's spans.</li> <li>After testing all templates, compare the rewards and declare the best one.</li> </ol> <p>We can implement this as a simple Python function that interacts directly with the LightningStore.</p> <pre><code>async def find_best_prompt(store, prompts_to_test, task_input):\n    \"\"\"A simple algorithm to find the best prompt from a list.\"\"\"\n    results = []\n\n    # Iterate through each prompt to test it\n    for prompt in prompts_to_test:\n        print(f\"[Algo] Updating prompt template to: '{prompt}'\")\n\n        # 1. Update the resources in the store with the new prompt\n        resources_update = await store.add_resources(\n            resources={\"prompt_template\": prompt}\n        )\n\n        # 2. Enqueue a rollout task for a runner to execute\n        print(\"[Algo] Queuing task for clients...\")\n        rollout = await store.enqueue_rollout(\n            input=task_input,\n            resources_id=resources_update.resources_id,\n        )\n        print(f\"[Algo] Task '{rollout.rollout_id}' is now available for clients.\")\n\n        # 3. Wait for the rollout to be completed by a runner\n        await store.wait_for_rollouts([rollout.rollout_id])\n\n        # 4. Query the completed rollout and its spans\n        completed_rollout = (await store.query_rollouts([rollout.rollout_id]))[0]\n        print(f\"[Algo] Received Result: {completed_rollout.model_dump_json(indent=None)}\")\n\n        spans = await store.query_spans(rollout.rollout_id)\n        # We expect at least two spans: one for the LLM call and one for the final reward\n        print(f\"[Algo] Queried Spans:\\n  - \" + \"\\n  - \".join(str(span) for span in spans))\n        # find_final_reward is a helper function to extract the reward span\n        final_reward = find_final_reward(spans)\n        print(f\"[Algo] Final reward: {final_reward}\\n\")\n\n        results.append((prompt, final_reward))\n\n    # 5. Find and print the best prompt based on the collected rewards\n    print(f\"[Algo] All prompts and their rewards: {results}\")\n    best_prompt, best_reward = max(results, key=lambda item: item[1])\n    print(f\"[Algo] Best prompt found: '{best_prompt}' with reward {best_reward}\")\n</code></pre> <p>Asynchronous Operations</p> <p>You'll notice the <code>async</code> and <code>await</code> keywords. Agent-lightning is built on asyncio to handle concurrent operations efficiently. All interactions with the store are asynchronous network calls, so they must be awaited.</p>"},{"location":"how-to/write-first-algorithm/#the-agent-and-runner","title":"The Agent and Runner","text":"<p>Our algorithm needs an agent to execute the tasks and a runner to manage the process.</p> <p>The runner is a long-lived worker process. Its job is simple:</p> <ol> <li>Connect to the LightningStore via a LightningStoreClient.</li> <li>Enter a loop, constantly asking the LightningStore for new tasks (<code>dequeue_rollout</code>).</li> <li>When it gets a task, it runs the <code>simple_agent</code> function.</li> <li>Crucially, the runner wraps the agent execution with a Tracer. The tracer automatically captures all the important events (like the LLM call and the final reward) as spans and sends them back to the LightningStore.</li> </ol> <pre><code># Connecting to Store\nstore = agl.LightningStoreClient(\"http://localhost:4747\")  # or some other address\nrunner = LitAgentRunner[str](tracer=AgentOpsTracer())\nwith runner.run_context(agent=simple_agent, store=store):  # &lt;-- where the wrapping and instrumentation happens\n    await runner.iter()  # polling for new tasks forever\n</code></pre> <p>For this example, the agent's job is to take the prompt from the resources, use it to ask an LLM a question, and return a score.</p> <pre><code>def simple_agent(task: str, prompt_template: PromptTemplate) -&gt; float:\n    \"\"\"An agent that answers a question and gets judged by an LLM.\"\"\"\n    client = OpenAI()\n\n    # Generate a response using the provided prompt template\n    prompt = prompt_template.format(any_question=task)\n    response = client.chat.completions.create(\n        model=\"gpt-4.1-nano\", messages=[{\"role\": \"user\", \"content\": prompt}]\n    )\n    llm_output = response.choices[0].message.content\n    print(f\"[Rollout] LLM returned: {llm_output}\")\n\n    # This llm_output and the final score are automatically logged as spans by the Tracer\n    score = random.uniform(0, 1)  # Replace with actual scoring logic if needed\n    return score\n</code></pre>"},{"location":"how-to/write-first-algorithm/#running-the-example","title":"Running the Example","text":"<p>To see everything in action, you'll need three separate terminal windows.</p> <p>Tip</p> <p>If you want to follow along, you can find the complete code for this example in the apo_custom_algorithm.py file.</p> <p>1. Start the Store: In the first terminal, start the LightningStore server. This component will wait for connections from the algorithm and the runner. The store will be listening on port <code>4747</code> \u26a1 by default.</p> <pre><code>agl store\n</code></pre> <p>2. Start the Runner: In the second terminal, start the runner process. It will connect to the store and wait for tasks.</p> <p>The code to start the runner looks like the following:</p> <pre><code>export OPENAI_API_KEY=sk-... # Your OpenAI API key\npython apo_custom_algorithm.py runner\n</code></pre> <p>You will see output indicating the runner has started and is waiting for rollouts.</p> <pre><code>2025-10-14 22:23:41,339 [INFO] ... [Worker 0] Setting up tracer...\n2025-10-14 22:23:41,343 [INFO] ... [Worker 0] Instrumentation applied.\n2025-10-14 22:23:41,494 [INFO] ... [Worker 0] AgentOps client initialized.\n2025-10-14 22:23:41,494 [INFO] ... [Worker 0] Started async rollouts (max: unlimited).\n</code></pre> <p>3. Start the Algorithm: In the third terminal, run the algorithm. This will kick off the entire process.</p> <p>For example, we run the algorithm code shown above with the following parameters:</p> <pre><code>prompts_to_test = [\n    \"You are a helpful assistant. {any_question}\",\n    \"You are a knowledgeable AI. {any_question}\",\n    \"You are a friendly chatbot. {any_question}\",\n]\ntask_input = \"Why is the sky blue?\"\nstore = agl.LightningStoreClient(\"http://localhost:4747\")\nfind_best_prompt(store, prompts_to_test, task_input)\n</code></pre> <p>Or you can simply use our pre-written script to try out:</p> <pre><code>python apo_custom_algorithm.py algo\n</code></pre>"},{"location":"how-to/write-first-algorithm/#understanding-the-output","title":"Understanding the Output","text":"<p>As the algorithm runs, you'll see logs appear across all three terminals, showing the components interacting in real-time.</p> <p>Algorithm Output: The algorithm terminal shows the main control flow: updating prompts, queuing tasks, and receiving the final results. You can also see the raw span data it retrieves from the store.</p> <pre><code>[Algo] Updating prompt template to: 'You are a helpful assistant. {any_question}'\n[Algo] Queuing task for clients...\n[Algo] Task 'ro-1d18988581cd' is now available for clients.\n[Algo] Received Result: rollout_id='ro-1d18988581cd' ... status='succeeded' ...\n[Algo] Queried Spans:\n  - Span(name='openai.chat.completion', attributes={'gen_ai.prompt.0.content': 'You are a helpful assistant...', 'gen_ai.completion.0.content': 'The sky appears blue...'})\n  - Span(name='reward', attributes={'value': 0.95})\n[Algo] Final reward: 0.95\n\n[Algo] Updating prompt template to: 'You are a knowledgeable AI. {any_question}'\n...\n[Algo] Final reward: 0.95\n\n[Algo] Updating prompt template to: 'You are a friendly chatbot. {any_question}'\n...\n[Algo] Final reward: 1.0\n\n[Algo] All prompts and their rewards: [('You are a helpful assistant. {any_question}', 0.95), ('You are a knowledgeable AI. {any_question}', 0.95), ('You are a friendly chatbot. {any_question}', 1.0)]\n[Algo] Best prompt found: 'You are a friendly chatbot. {any_question}' with reward 1.0\n</code></pre> <p>Runner Output: The runner terminal shows it picking up each task, executing the agent logic, and reporting the completion.</p> <pre><code>[Rollout] LLM returned: The sky appears blue due to Rayleigh scattering...\n2025-10-14 22:25:50,803 [INFO] ... [Worker 0 | Rollout ro-a9f54ac19af5] Completed in 4.24s. ...\n\n[Rollout] LLM returned: The sky looks blue because of a process called Rayleigh scattering...\n2025-10-14 22:25:59,863 [INFO] ... [Worker 0 | Rollout ro-c67eaa9016b6] Completed in 4.06s. ...\n</code></pre> <p>Store Server Output: The store terminal shows a detailed log of every interaction, confirming its role as the central hub. You can see requests to enqueue and dequeue rollouts, add spans, and update statuses.</p> <pre><code>... \"POST /enqueue_rollout HTTP/1.1\" 200 ...\n... \"GET /dequeue_rollout HTTP/1.1\" 200 ...\n... \"POST /add_span HTTP/1.1\" 200 ...\n... \"POST /update_attempt HTTP/1.1\" 200 ...\n... \"POST /wait_for_rollouts HTTP/1.1\" 200 ...\n... \"GET /query_spans/ro-c67eaa9016b6 HTTP/1.1\" 200 ...\n</code></pre> <p>So Where is Trainer?</p> <p>You might be wondering why the last tutorial focused on the Trainer class, but we haven't used it here.</p> <p>Think of the Trainer as a convenient wrapper that manages the entire training process for you. It's perfect when you want to apply a pre-built algorithm to your agent without worrying about the underlying mechanics. The Trainer handles starting the LightningStore, coordinating the Runners, managing their lifecycles, and handling errors.</p> <p>In this tutorial, however, our goal is to build a new algorithm. To do that, we need to interact directly with the core components: the Store, the Runner, and the algorithm logic itself. Running them separately gives you more control and clearer, isolated logs, which is ideal for development and debugging.</p> <p>Once your custom algorithm is mature, you can package it to comply with our standard interface (@algo or Algorithm). This allows you to use it with the Trainer again, getting all the benefits of automated lifecycle management while using your own custom logic. A sample code doing this is available in apo_custom_algorithm_trainer.py.</p>"},{"location":"reference/agent/","title":"Agent Developer APIs","text":""},{"location":"reference/agent/#customizing-agents-decorators","title":"Customizing Agents - Decorators","text":"<p>Tip</p> <p>These are convenient helpers for creating agents from functions. First-time users are recommended to use these decorators to create agents.</p> <p>Warning</p> <p>The following two decorators are implementations of <code>agentlightning.rollout</code>. They are not recommended for new users.</p>"},{"location":"reference/agent/#agentlightning.rollout","title":"<code>agentlightning.rollout(func)</code>","text":"<p>Create a LitAgent from a function, automatically detecting the appropriate type.</p> <p>This function inspects the provided callable and creates the appropriate agent type based on its signature. It supports both LLM-based and prompt-template-based agents. The returned agent instance is callable, preserving the original function's behavior and type hints.</p> <p>Parameters:</p> Name Type Description Default <code>func</code> <code>Union[LlmRolloutFunc[T], PromptRolloutFunc[T], Callable[..., Any]]</code> <p>A function that defines the agent's behavior. Supported signatures:   - (task, llm[, rollout]) for LLM-based agents   - (task, prompt_template[, rollout]) for prompt-template-based agents</p> required <p>Returns:</p> Type Description <code>FunctionalLitAgent[T]</code> <p>A callable FunctionalLitAgent instance that preserves the original function's</p> <code>FunctionalLitAgent[T]</code> <p>type hints and behavior while providing all agent functionality.</p> Example <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>If the function signature doesn't match any known patterns.</p> Source code in <code>agentlightning/litagent/decorator.py</code> <pre><code>def rollout(func: Union[LlmRolloutFunc[T], PromptRolloutFunc[T], Callable[..., Any]]) -&gt; FunctionalLitAgent[T]:\n    \"\"\"Create a LitAgent from a function, automatically detecting the appropriate type.\n\n    This function inspects the provided callable and creates the appropriate\n    agent type based on its signature. It supports both LLM-based and prompt-template-based\n    agents. The returned agent instance is callable, preserving the original function's\n    behavior and type hints.\n\n    Args:\n        func: A function that defines the agent's behavior. Supported signatures:\n              - (task, llm[, rollout]) for LLM-based agents\n              - (task, prompt_template[, rollout]) for prompt-template-based agents\n\n    Returns:\n        A callable FunctionalLitAgent instance that preserves the original function's\n        type hints and behavior while providing all agent functionality.\n\n    Example:\n        # LLM-based agent\n        @rollout\n        def my_llm_agent(task, llm):\n            client = OpenAI(base_url=llm.endpoint)\n            response = client.chat.completions.create(\n                model=llm.model,\n                messages=[{\"role\": \"user\", \"content\": task.input}],\n            )\n            return response\n\n        # Prompt-template-based agent\n        @rollout\n        def my_prompt_agent(task, prompt_template):\n            messages = prompt_template.format(task=task.input)\n            # ... perform rollout with the formatted prompt\n            return response\n\n        # Function is still callable with original behavior\n        result = my_llm_agent(task, llm)\n\n        # Agent methods are also available\n        result = my_llm_agent.rollout(task, resources, rollout)\n\n    Raises:\n        NotImplementedError: If the function signature doesn't match any known patterns.\n    \"\"\"\n    # Check if it matches the LLM rollout API pattern\n    sig = inspect.signature(func)\n\n    try:\n        if _validate_llm_rollout_func(func):\n            return llm_rollout(func)\n    except ValueError:\n        pass\n\n    try:\n        if _validate_prompt_rollout_func(func):\n            return prompt_rollout(func)\n    except ValueError:\n        pass\n\n    raise NotImplementedError(\n        f\"Function signature {sig} does not match any known agent patterns. \"\n        \"Expected signatures: (task, llm[, rollout]) or (task, prompt_template[, rollout]). \"\n        \"Functions can be sync or async.\"\n    )\n</code></pre>"},{"location":"reference/agent/#agentlightning.rollout--llm-based-agent","title":"LLM-based agent","text":"<p>@rollout def my_llm_agent(task, llm):     client = OpenAI(base_url=llm.endpoint)     response = client.chat.completions.create(         model=llm.model,         messages=[{\"role\": \"user\", \"content\": task.input}],     )     return response</p>"},{"location":"reference/agent/#agentlightning.rollout--prompt-template-based-agent","title":"Prompt-template-based agent","text":"<p>@rollout def my_prompt_agent(task, prompt_template):     messages = prompt_template.format(task=task.input)     # ... perform rollout with the formatted prompt     return response</p>"},{"location":"reference/agent/#agentlightning.rollout--function-is-still-callable-with-original-behavior","title":"Function is still callable with original behavior","text":"<p>result = my_llm_agent(task, llm)</p>"},{"location":"reference/agent/#agentlightning.rollout--agent-methods-are-also-available","title":"Agent methods are also available","text":"<p>result = my_llm_agent.rollout(task, resources, rollout)</p>"},{"location":"reference/agent/#agentlightning.llm_rollout","title":"<code>agentlightning.llm_rollout(func=None, *, strip_proxy=True)</code>","text":"<pre><code>llm_rollout(\n    func: LlmRolloutFunc[T],\n) -&gt; FunctionalLitAgent[T]\n</code></pre><pre><code>llm_rollout(\n    *, strip_proxy: bool = True\n) -&gt; Callable[[LlmRolloutFunc[T]], FunctionalLitAgent[T]]\n</code></pre> <p>Create a FunctionalLitAgent from a function that takes (task, llm[, rollout]).</p> <p>This decorator allows you to define an agent using a simple function instead of creating a full LitAgent subclass. The returned FunctionalLitAgent instance is callable, preserving the original function's behavior.</p> <p>Parameters:</p> Name Type Description Default <code>func</code> <code>LlmRolloutFunc[T] | None</code> <p>A function that defines the agent's behavior. Can be:   - sync: (task, llm) -&gt; result   - sync with rollout: (task, llm, rollout) -&gt; result   - async: async (task, llm) -&gt; result   - async with rollout: async (task, llm, rollout) -&gt; result</p> <code>None</code> <code>strip_proxy</code> <code>bool</code> <p>Whether to strip the ProxyLLM resource into a LLM resource.          Defaults to True.</p> <code>True</code> <p>Returns:</p> Type Description <code>FunctionalLitAgent[T] | Callable[[LlmRolloutFunc[T]], FunctionalLitAgent[T]]</code> <p>A callable FunctionalLitAgent instance that preserves the original function's</p> <code>FunctionalLitAgent[T] | Callable[[LlmRolloutFunc[T]], FunctionalLitAgent[T]]</code> <p>type hints and behavior while providing all agent functionality.</p> Example <p>@llm_rollout def my_agent(task, llm):     # Agent logic here     return response</p> <p>@llm_rollout(strip_proxy=False) def my_agent_no_strip(task, llm):     # Agent logic here     return response</p> Source code in <code>agentlightning/litagent/decorator.py</code> <pre><code>def llm_rollout(\n    func: LlmRolloutFunc[T] | None = None, *, strip_proxy: bool = True\n) -&gt; FunctionalLitAgent[T] | Callable[[LlmRolloutFunc[T]], FunctionalLitAgent[T]]:\n    \"\"\"Create a FunctionalLitAgent from a function that takes (task, llm[, rollout]).\n\n    This decorator allows you to define an agent using a simple function\n    instead of creating a full LitAgent subclass. The returned FunctionalLitAgent\n    instance is callable, preserving the original function's behavior.\n\n    Args:\n        func: A function that defines the agent's behavior. Can be:\n              - sync: (task, llm) -&gt; result\n              - sync with rollout: (task, llm, rollout) -&gt; result\n              - async: async (task, llm) -&gt; result\n              - async with rollout: async (task, llm, rollout) -&gt; result\n        strip_proxy: Whether to strip the ProxyLLM resource into a LLM resource.\n                     Defaults to True.\n\n    Returns:\n        A callable FunctionalLitAgent instance that preserves the original function's\n        type hints and behavior while providing all agent functionality.\n\n    Example:\n        @llm_rollout\n        def my_agent(task, llm):\n            # Agent logic here\n            return response\n\n        @llm_rollout(strip_proxy=False)\n        def my_agent_no_strip(task, llm):\n            # Agent logic here\n            return response\n\n        # Function is still callable with original behavior\n        result = my_agent(task, llm)\n\n        # Agent methods are also available\n        result = my_agent.rollout(task, resources, rollout)\n    \"\"\"\n\n    def decorator(f: LlmRolloutFunc[T]) -&gt; FunctionalLitAgent[T]:\n        _validate_llm_rollout_func(f)\n        return FunctionalLitAgent(f, strip_proxy=strip_proxy)\n\n    if func is None:\n        # Called with arguments: @llm_rollout(strip_proxy=False)\n        return decorator\n    else:\n        # Called without arguments: @llm_rollout\n        return decorator(func)\n</code></pre>"},{"location":"reference/agent/#agentlightning.llm_rollout--function-is-still-callable-with-original-behavior","title":"Function is still callable with original behavior","text":"<p>result = my_agent(task, llm)</p>"},{"location":"reference/agent/#agentlightning.llm_rollout--agent-methods-are-also-available","title":"Agent methods are also available","text":"<p>result = my_agent.rollout(task, resources, rollout)</p>"},{"location":"reference/agent/#agentlightning.prompt_rollout","title":"<code>agentlightning.prompt_rollout(func=None)</code>","text":"<pre><code>prompt_rollout(\n    func: PromptRolloutFunc[T],\n) -&gt; FunctionalLitAgent[T]\n</code></pre><pre><code>prompt_rollout() -&gt; (\n    Callable[[PromptRolloutFunc[T]], FunctionalLitAgent[T]]\n)\n</code></pre> <p>Create a FunctionalLitAgent from a function that takes (task, prompt_template[, rollout]).</p> <p>This decorator is designed for agents that work with tunable prompt templates. It enables a workflow where algorithms manage and optimize the prompt template, while agents consume the template to perform rollouts. This is particularly useful for prompt optimization scenarios.</p> <p>Parameters:</p> Name Type Description Default <code>func</code> <code>PromptRolloutFunc[T] | None</code> <p>A function that defines the agent's behavior. Can be:   - sync: (task, prompt_template) -&gt; result   - sync with rollout: (task, prompt_template, rollout) -&gt; result   - async: async (task, prompt_template) -&gt; result   - async with rollout: async (task, prompt_template, rollout) -&gt; result</p> <code>None</code> <p>Returns:</p> Type Description <code>FunctionalLitAgent[T] | Callable[[PromptRolloutFunc[T]], FunctionalLitAgent[T]]</code> <p>A callable FunctionalLitAgent instance that preserves the original function's</p> <code>FunctionalLitAgent[T] | Callable[[PromptRolloutFunc[T]], FunctionalLitAgent[T]]</code> <p>type hints and behavior while providing all agent functionality.</p> Example <p>@prompt_rollout def my_agent(task, prompt_template):     # Use the prompt template to generate a response     messages = prompt_template.format(task=task.input)     # ... perform rollout with the formatted prompt     return response</p> Source code in <code>agentlightning/litagent/decorator.py</code> <pre><code>def prompt_rollout(\n    func: PromptRolloutFunc[T] | None = None,\n) -&gt; FunctionalLitAgent[T] | Callable[[PromptRolloutFunc[T]], FunctionalLitAgent[T]]:\n    \"\"\"Create a FunctionalLitAgent from a function that takes (task, prompt_template[, rollout]).\n\n    This decorator is designed for agents that work with tunable prompt templates. It enables\n    a workflow where algorithms manage and optimize the prompt template, while agents consume\n    the template to perform rollouts. This is particularly useful for prompt optimization scenarios.\n\n    Args:\n        func: A function that defines the agent's behavior. Can be:\n              - sync: (task, prompt_template) -&gt; result\n              - sync with rollout: (task, prompt_template, rollout) -&gt; result\n              - async: async (task, prompt_template) -&gt; result\n              - async with rollout: async (task, prompt_template, rollout) -&gt; result\n\n    Returns:\n        A callable FunctionalLitAgent instance that preserves the original function's\n        type hints and behavior while providing all agent functionality.\n\n    Example:\n        @prompt_rollout\n        def my_agent(task, prompt_template):\n            # Use the prompt template to generate a response\n            messages = prompt_template.format(task=task.input)\n            # ... perform rollout with the formatted prompt\n            return response\n\n        # Function is still callable with original behavior\n        result = my_agent(task, prompt_template)\n\n        # Agent methods are also available\n        result = my_agent.rollout(task, resources, rollout)\n    \"\"\"\n\n    def decorator(f: PromptRolloutFunc[T]) -&gt; FunctionalLitAgent[T]:\n        _validate_prompt_rollout_func(f)\n        return FunctionalLitAgent(f)\n\n    if func is None:\n        return decorator\n    else:\n        return decorator(func)\n</code></pre>"},{"location":"reference/agent/#agentlightning.prompt_rollout--function-is-still-callable-with-original-behavior","title":"Function is still callable with original behavior","text":"<p>result = my_agent(task, prompt_template)</p>"},{"location":"reference/agent/#agentlightning.prompt_rollout--agent-methods-are-also-available","title":"Agent methods are also available","text":"<p>result = my_agent.rollout(task, resources, rollout)</p>"},{"location":"reference/agent/#class-based-agents","title":"Class-based Agents","text":""},{"location":"reference/agent/#agentlightning.LitAgent","title":"<code>agentlightning.LitAgent</code>","text":"<p>               Bases: <code>Generic[T]</code></p> <p>Base class for the training and validation logic of an agent.</p> <p>Developers should subclass this class and implement the rollout methods to define the agent's behavior for a single task. The agent's logic is completely decoupled from the server communication and training infrastructure.</p> Source code in <code>agentlightning/litagent/litagent.py</code> <pre><code>class LitAgent(Generic[T]):\n    \"\"\"Base class for the training and validation logic of an agent.\n\n    Developers should subclass this class and implement the rollout methods\n    to define the agent's behavior for a single task. The agent's logic\n    is completely decoupled from the server communication and training\n    infrastructure.\n    \"\"\"\n\n    def __init__(self, *, trained_agents: Optional[str] = None) -&gt; None:  # FIXME: str | None won't work for cli\n        \"\"\"\n        Initialize the LitAgent.\n\n        Args:\n            trained_agents: Optional string representing the trained agents.\n                            This can be used to track which agents have been trained by this instance.\n                            Deprecated. Configure `agent_match` in adapter instead.\n        \"\"\"\n        if trained_agents is not None:\n            warnings.warn(\n                \"`trained_agents` is deprecated. Configure `agent_match` in adapter instead.\",\n                DeprecationWarning,\n                stacklevel=2,\n            )\n        self.trained_agents = trained_agents\n\n        self._trainer_ref: weakref.ReferenceType[Trainer] | None = None\n        self._runner_ref: weakref.ReferenceType[Runner[T]] | None = None\n\n    def is_async(self) -&gt; bool:\n        \"\"\"\n        Check if the agent implements asynchronous rollout methods.\n        Override this property for customized async detection logic.\n\n        Returns:\n            True if the agent has custom async rollout methods, False otherwise.\n        \"\"\"\n        return (\n            (\n                hasattr(self, \"training_rollout_async\")\n                and self.__class__.training_rollout_async is not LitAgent.training_rollout_async  # type: ignore\n            )\n            or (\n                hasattr(self, \"validation_rollout_async\")\n                and self.__class__.validation_rollout_async is not LitAgent.validation_rollout_async  # type: ignore\n            )\n            or (hasattr(self, \"rollout_async\") and self.__class__.rollout_async is not LitAgent.rollout_async)  # type: ignore\n        )\n\n    def set_trainer(self, trainer: Trainer) -&gt; None:\n        \"\"\"\n        Set the trainer for this agent.\n\n        Args:\n            trainer: The Trainer instance that will handle training and validation.\n        \"\"\"\n        self._trainer_ref = weakref.ref(trainer)\n\n    def get_trainer(self) -&gt; Trainer:\n        \"\"\"\n        Get the trainer for this agent.\n\n        Returns:\n            The Trainer instance associated with this agent.\n        \"\"\"\n        if self._trainer_ref is None:\n            raise ValueError(\"Trainer has not been set for this agent.\")\n        trainer = self._trainer_ref()\n        if trainer is None:\n            raise ValueError(\"Trainer reference is no longer valid (object has been garbage collected).\")\n        return trainer\n\n    @property\n    def trainer(self) -&gt; Trainer:\n        \"\"\"Convenient shortcut of self.get_trainer().\"\"\"\n        return self.get_trainer()\n\n    def get_tracer(self) -&gt; Tracer:\n        \"\"\"\n        Get the tracer for this agent.\n\n        Returns:\n            The Tracer instance associated with this agent.\n        \"\"\"\n        if hasattr(self.runner, \"tracer\"):\n            return self.runner.tracer  # type: ignore\n        else:\n            return self.trainer.tracer\n\n    @property\n    def tracer(self) -&gt; Tracer:\n        \"\"\"Convenient shortcut of self.get_tracer().\"\"\"\n        return self.get_tracer()\n\n    def set_runner(self, runner: Runner[T]) -&gt; None:\n        \"\"\"\n        Set the runner for this agent.\n\n        Args:\n            runner: The runner instance that will handle the execution of rollouts.\n        \"\"\"\n        self._runner_ref = weakref.ref(runner)\n\n    def get_runner(self) -&gt; Runner[T]:\n        \"\"\"\n        Get the runner for this agent.\n\n        Returns:\n            The runner instance associated with this agent.\n        \"\"\"\n        if self._runner_ref is None:\n            raise ValueError(\"Runner has not been set for this agent.\")\n        runner = self._runner_ref()\n        if runner is None:\n            raise ValueError(\"Runner reference is no longer valid (object has been garbage collected).\")\n        return runner\n\n    @property\n    def runner(self) -&gt; Runner[T]:\n        \"\"\"Convenient shortcut of self.get_runner().\"\"\"\n        return self.get_runner()\n\n    def on_rollout_start(self, task: Task, runner: Runner[T], tracer: Tracer) -&gt; None:\n        \"\"\"Hook called immediately before a rollout begins.\n\n        Deprecated in favor of `on_rollout_start` in the `Hook` interface.\n\n        Args:\n            task: The :class:`Task` object that will be processed.\n            runner: The :class:`Runner` managing the rollout.\n            tracer: The tracer instance associated with the runner.\n\n        Subclasses can override this method to implement custom logic such as\n        logging, metric collection, or resource setup. By default, this is a\n        no-op.\n        \"\"\"\n\n    def on_rollout_end(self, task: Task, rollout: Rollout, runner: Runner[T], tracer: Tracer) -&gt; None:\n        \"\"\"Hook called after a rollout completes.\n\n        Deprecated in favor of `on_rollout_end` in the `Hook` interface.\n\n        Args:\n            task: The :class:`Task` object that was processed.\n            rollout: The resulting :class:`Rollout` object.\n            runner: The :class:`Runner` managing the rollout.\n            tracer: The tracer instance associated with the runner.\n\n        Subclasses can override this method for cleanup or additional\n        logging. By default, this is a no-op.\n        \"\"\"\n\n    def rollout(self, task: T, resources: NamedResources, rollout: Rollout) -&gt; RolloutRawResult:\n        \"\"\"Main entry point for executing a rollout.\n\n        This method determines whether to call the synchronous or\n        asynchronous rollout method based on the agent's implementation.\n\n        If you don't wish to implement both training rollout and validation\n        rollout separately, you can just implement `rollout` which will work for both.\n\n        Args:\n            task: The task object received from the server, containing the\n                  input data and metadata.\n            resources: A dictionary of named resources (e.g., LLMs, prompt\n                       templates) for the agent to use.\n            rollout: The full rollout object, please avoid from directly modifying it.\n                     Most agents should only use `task` and `resources`. Use `rollout`\n                     only if you need to access metadata like `rollout_id`.\n\n        Returns:\n            The result of the rollout, which can be one of:\n            - None. The tracing should be handled by the agent runner.\n            - A float representing the final reward.\n            - A list of `Triplet` objects for detailed, step-by-step feedback.\n            - A list of `ReadableSpan` objects for OpenTelemetry tracing.\n            - A list of dictionaries for any trace spans.\n            - A complete `Rollout` object for full control over reporting.\n        \"\"\"\n        raise NotImplementedError(\"Agents must implement the `rollout` method.\")\n\n    async def rollout_async(self, task: T, resources: NamedResources, rollout: Rollout) -&gt; RolloutRawResult:\n        \"\"\"Asynchronous version of the main rollout method.\n\n        This method determines whether to call the synchronous or\n        asynchronous rollout method based on the agent's implementation.\n\n        Args:\n            task: The task object received from the server, containing the\n                  input data and metadata.\n            resources: A dictionary of named resources (e.g., LLMs, prompt\n                       templates) for the agent to use.\n            rollout: The full rollout object, please avoid from directly modifying it.\n                     Most agents should only use `task` and `resources`. Use `rollout`\n                     only if you need to access metadata like `rollout_id`.\n\n        Returns:\n            The result of the rollout, which can be one of:\n            - None. The tracing should be handled by the agent runner.\n            - A float representing the final reward.\n            - A list of `Triplet` objects for detailed, step-by-step feedback.\n            - A list of `ReadableSpan` objects for OpenTelemetry tracing.\n            - A list of dictionaries for any trace spans.\n            - A complete `Rollout` object for full control over reporting.\n        \"\"\"\n        raise NotImplementedError(\"Agents must implement the `rollout_async` method for async operations.\")\n\n    def training_rollout(self, task: T, resources: NamedResources, rollout: Rollout) -&gt; RolloutRawResult:\n        \"\"\"Defines the agent's behavior for a single training task.\n\n        This method should contain the logic for how the agent processes an\n        input, uses the provided resources (like LLMs or prompts), and\n        produces a result.\n\n        Args:\n            task: The task object received from the server, containing the\n                  input data and metadata.\n            resources: A dictionary of named resources (e.g., LLMs, prompt\n                       templates) for the agent to use.\n            rollout: The full rollout object, please avoid from directly modifying it.\n        \"\"\"\n        return self.rollout(task, resources, rollout)\n\n    def validation_rollout(self, task: T, resources: NamedResources, rollout: Rollout) -&gt; RolloutRawResult:\n        \"\"\"Defines the agent's behavior for a single validation task.\n\n        By default, this method redirects to `training_rollout`. Override it\n        if the agent should behave differently during validation.\n\n        Args:\n            task: The task object received from the server, containing the\n                  input data and metadata.\n            resources: A dictionary of named resources for the agent to use.\n            rollout: The full rollout object, avoid from modifying it.\n\n        Returns:\n            The result of the validation rollout. See `rollout` for\n            possible return types.\n        \"\"\"\n        return self.rollout(task, resources, rollout)\n\n    async def training_rollout_async(self, task: T, resources: NamedResources, rollout: Rollout) -&gt; RolloutRawResult:\n        \"\"\"Asynchronous version of `training_rollout`.\n\n        This method should be implemented by agents that perform asynchronous\n        operations (e.g., non-blocking I/O, concurrent API calls).\n\n        Args:\n            task: The task object received from the server.\n            resources: A dictionary of named resources for the agent to use.\n            rollout: The full rollout object, avoid from modifying it.\n\n        Returns:\n            The result of the asynchronous training rollout. See `rollout` for\n            possible return types.\n        \"\"\"\n        return await self.rollout_async(task, resources, rollout)\n\n    async def validation_rollout_async(self, task: T, resources: NamedResources, rollout: Rollout) -&gt; RolloutRawResult:\n        \"\"\"Asynchronous version of `validation_rollout`.\n\n        By default, this method redirects to `training_rollout_async`.\n        Override it for different asynchronous validation behavior.\n\n        Args:\n            task: The task object received from the server.\n            resources: A dictionary of named resources for the agent to use.\n            rollout: The full rollout object, avoid from modifying it.\n\n        Returns:\n            The result of the asynchronous validation rollout. See `rollout` for\n            possible return types.\n        \"\"\"\n        return await self.rollout_async(task, resources, rollout)\n</code></pre>"},{"location":"reference/agent/#agentlightning.LitAgent.runner","title":"<code>runner</code>  <code>property</code>","text":"<p>Convenient shortcut of self.get_runner().</p>"},{"location":"reference/agent/#agentlightning.LitAgent.tracer","title":"<code>tracer</code>  <code>property</code>","text":"<p>Convenient shortcut of self.get_tracer().</p>"},{"location":"reference/agent/#agentlightning.LitAgent.trainer","title":"<code>trainer</code>  <code>property</code>","text":"<p>Convenient shortcut of self.get_trainer().</p>"},{"location":"reference/agent/#agentlightning.LitAgent.__init__","title":"<code>__init__(*, trained_agents=None)</code>","text":"<p>Initialize the LitAgent.</p> <p>Parameters:</p> Name Type Description Default <code>trained_agents</code> <code>Optional[str]</code> <p>Optional string representing the trained agents.             This can be used to track which agents have been trained by this instance.             Deprecated. Configure <code>agent_match</code> in adapter instead.</p> <code>None</code> Source code in <code>agentlightning/litagent/litagent.py</code> <pre><code>def __init__(self, *, trained_agents: Optional[str] = None) -&gt; None:  # FIXME: str | None won't work for cli\n    \"\"\"\n    Initialize the LitAgent.\n\n    Args:\n        trained_agents: Optional string representing the trained agents.\n                        This can be used to track which agents have been trained by this instance.\n                        Deprecated. Configure `agent_match` in adapter instead.\n    \"\"\"\n    if trained_agents is not None:\n        warnings.warn(\n            \"`trained_agents` is deprecated. Configure `agent_match` in adapter instead.\",\n            DeprecationWarning,\n            stacklevel=2,\n        )\n    self.trained_agents = trained_agents\n\n    self._trainer_ref: weakref.ReferenceType[Trainer] | None = None\n    self._runner_ref: weakref.ReferenceType[Runner[T]] | None = None\n</code></pre>"},{"location":"reference/agent/#agentlightning.LitAgent.get_runner","title":"<code>get_runner()</code>","text":"<p>Get the runner for this agent.</p> <p>Returns:</p> Type Description <code>Runner[T]</code> <p>The runner instance associated with this agent.</p> Source code in <code>agentlightning/litagent/litagent.py</code> <pre><code>def get_runner(self) -&gt; Runner[T]:\n    \"\"\"\n    Get the runner for this agent.\n\n    Returns:\n        The runner instance associated with this agent.\n    \"\"\"\n    if self._runner_ref is None:\n        raise ValueError(\"Runner has not been set for this agent.\")\n    runner = self._runner_ref()\n    if runner is None:\n        raise ValueError(\"Runner reference is no longer valid (object has been garbage collected).\")\n    return runner\n</code></pre>"},{"location":"reference/agent/#agentlightning.LitAgent.get_tracer","title":"<code>get_tracer()</code>","text":"<p>Get the tracer for this agent.</p> <p>Returns:</p> Type Description <code>Tracer</code> <p>The Tracer instance associated with this agent.</p> Source code in <code>agentlightning/litagent/litagent.py</code> <pre><code>def get_tracer(self) -&gt; Tracer:\n    \"\"\"\n    Get the tracer for this agent.\n\n    Returns:\n        The Tracer instance associated with this agent.\n    \"\"\"\n    if hasattr(self.runner, \"tracer\"):\n        return self.runner.tracer  # type: ignore\n    else:\n        return self.trainer.tracer\n</code></pre>"},{"location":"reference/agent/#agentlightning.LitAgent.get_trainer","title":"<code>get_trainer()</code>","text":"<p>Get the trainer for this agent.</p> <p>Returns:</p> Type Description <code>Trainer</code> <p>The Trainer instance associated with this agent.</p> Source code in <code>agentlightning/litagent/litagent.py</code> <pre><code>def get_trainer(self) -&gt; Trainer:\n    \"\"\"\n    Get the trainer for this agent.\n\n    Returns:\n        The Trainer instance associated with this agent.\n    \"\"\"\n    if self._trainer_ref is None:\n        raise ValueError(\"Trainer has not been set for this agent.\")\n    trainer = self._trainer_ref()\n    if trainer is None:\n        raise ValueError(\"Trainer reference is no longer valid (object has been garbage collected).\")\n    return trainer\n</code></pre>"},{"location":"reference/agent/#agentlightning.LitAgent.is_async","title":"<code>is_async()</code>","text":"<p>Check if the agent implements asynchronous rollout methods. Override this property for customized async detection logic.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if the agent has custom async rollout methods, False otherwise.</p> Source code in <code>agentlightning/litagent/litagent.py</code> <pre><code>def is_async(self) -&gt; bool:\n    \"\"\"\n    Check if the agent implements asynchronous rollout methods.\n    Override this property for customized async detection logic.\n\n    Returns:\n        True if the agent has custom async rollout methods, False otherwise.\n    \"\"\"\n    return (\n        (\n            hasattr(self, \"training_rollout_async\")\n            and self.__class__.training_rollout_async is not LitAgent.training_rollout_async  # type: ignore\n        )\n        or (\n            hasattr(self, \"validation_rollout_async\")\n            and self.__class__.validation_rollout_async is not LitAgent.validation_rollout_async  # type: ignore\n        )\n        or (hasattr(self, \"rollout_async\") and self.__class__.rollout_async is not LitAgent.rollout_async)  # type: ignore\n    )\n</code></pre>"},{"location":"reference/agent/#agentlightning.LitAgent.on_rollout_end","title":"<code>on_rollout_end(task, rollout, runner, tracer)</code>","text":"<p>Hook called after a rollout completes.</p> <p>Deprecated in favor of <code>on_rollout_end</code> in the <code>Hook</code> interface.</p> <p>Parameters:</p> Name Type Description Default <code>task</code> <code>Task</code> <p>The :class:<code>Task</code> object that was processed.</p> required <code>rollout</code> <code>Rollout</code> <p>The resulting :class:<code>Rollout</code> object.</p> required <code>runner</code> <code>Runner[T]</code> <p>The :class:<code>Runner</code> managing the rollout.</p> required <code>tracer</code> <code>Tracer</code> <p>The tracer instance associated with the runner.</p> required <p>Subclasses can override this method for cleanup or additional logging. By default, this is a no-op.</p> Source code in <code>agentlightning/litagent/litagent.py</code> <pre><code>def on_rollout_end(self, task: Task, rollout: Rollout, runner: Runner[T], tracer: Tracer) -&gt; None:\n    \"\"\"Hook called after a rollout completes.\n\n    Deprecated in favor of `on_rollout_end` in the `Hook` interface.\n\n    Args:\n        task: The :class:`Task` object that was processed.\n        rollout: The resulting :class:`Rollout` object.\n        runner: The :class:`Runner` managing the rollout.\n        tracer: The tracer instance associated with the runner.\n\n    Subclasses can override this method for cleanup or additional\n    logging. By default, this is a no-op.\n    \"\"\"\n</code></pre>"},{"location":"reference/agent/#agentlightning.LitAgent.on_rollout_start","title":"<code>on_rollout_start(task, runner, tracer)</code>","text":"<p>Hook called immediately before a rollout begins.</p> <p>Deprecated in favor of <code>on_rollout_start</code> in the <code>Hook</code> interface.</p> <p>Parameters:</p> Name Type Description Default <code>task</code> <code>Task</code> <p>The :class:<code>Task</code> object that will be processed.</p> required <code>runner</code> <code>Runner[T]</code> <p>The :class:<code>Runner</code> managing the rollout.</p> required <code>tracer</code> <code>Tracer</code> <p>The tracer instance associated with the runner.</p> required <p>Subclasses can override this method to implement custom logic such as logging, metric collection, or resource setup. By default, this is a no-op.</p> Source code in <code>agentlightning/litagent/litagent.py</code> <pre><code>def on_rollout_start(self, task: Task, runner: Runner[T], tracer: Tracer) -&gt; None:\n    \"\"\"Hook called immediately before a rollout begins.\n\n    Deprecated in favor of `on_rollout_start` in the `Hook` interface.\n\n    Args:\n        task: The :class:`Task` object that will be processed.\n        runner: The :class:`Runner` managing the rollout.\n        tracer: The tracer instance associated with the runner.\n\n    Subclasses can override this method to implement custom logic such as\n    logging, metric collection, or resource setup. By default, this is a\n    no-op.\n    \"\"\"\n</code></pre>"},{"location":"reference/agent/#agentlightning.LitAgent.rollout","title":"<code>rollout(task, resources, rollout)</code>","text":"<p>Main entry point for executing a rollout.</p> <p>This method determines whether to call the synchronous or asynchronous rollout method based on the agent's implementation.</p> <p>If you don't wish to implement both training rollout and validation rollout separately, you can just implement <code>rollout</code> which will work for both.</p> <p>Parameters:</p> Name Type Description Default <code>task</code> <code>T</code> <p>The task object received from the server, containing the   input data and metadata.</p> required <code>resources</code> <code>NamedResources</code> <p>A dictionary of named resources (e.g., LLMs, prompt        templates) for the agent to use.</p> required <code>rollout</code> <code>Rollout</code> <p>The full rollout object, please avoid from directly modifying it.      Most agents should only use <code>task</code> and <code>resources</code>. Use <code>rollout</code>      only if you need to access metadata like <code>rollout_id</code>.</p> required <p>Returns:</p> Type Description <code>RolloutRawResult</code> <p>The result of the rollout, which can be one of:</p> <code>RolloutRawResult</code> <ul> <li>None. The tracing should be handled by the agent runner.</li> </ul> <code>RolloutRawResult</code> <ul> <li>A float representing the final reward.</li> </ul> <code>RolloutRawResult</code> <ul> <li>A list of <code>Triplet</code> objects for detailed, step-by-step feedback.</li> </ul> <code>RolloutRawResult</code> <ul> <li>A list of <code>ReadableSpan</code> objects for OpenTelemetry tracing.</li> </ul> <code>RolloutRawResult</code> <ul> <li>A list of dictionaries for any trace spans.</li> </ul> <code>RolloutRawResult</code> <ul> <li>A complete <code>Rollout</code> object for full control over reporting.</li> </ul> Source code in <code>agentlightning/litagent/litagent.py</code> <pre><code>def rollout(self, task: T, resources: NamedResources, rollout: Rollout) -&gt; RolloutRawResult:\n    \"\"\"Main entry point for executing a rollout.\n\n    This method determines whether to call the synchronous or\n    asynchronous rollout method based on the agent's implementation.\n\n    If you don't wish to implement both training rollout and validation\n    rollout separately, you can just implement `rollout` which will work for both.\n\n    Args:\n        task: The task object received from the server, containing the\n              input data and metadata.\n        resources: A dictionary of named resources (e.g., LLMs, prompt\n                   templates) for the agent to use.\n        rollout: The full rollout object, please avoid from directly modifying it.\n                 Most agents should only use `task` and `resources`. Use `rollout`\n                 only if you need to access metadata like `rollout_id`.\n\n    Returns:\n        The result of the rollout, which can be one of:\n        - None. The tracing should be handled by the agent runner.\n        - A float representing the final reward.\n        - A list of `Triplet` objects for detailed, step-by-step feedback.\n        - A list of `ReadableSpan` objects for OpenTelemetry tracing.\n        - A list of dictionaries for any trace spans.\n        - A complete `Rollout` object for full control over reporting.\n    \"\"\"\n    raise NotImplementedError(\"Agents must implement the `rollout` method.\")\n</code></pre>"},{"location":"reference/agent/#agentlightning.LitAgent.rollout_async","title":"<code>rollout_async(task, resources, rollout)</code>  <code>async</code>","text":"<p>Asynchronous version of the main rollout method.</p> <p>This method determines whether to call the synchronous or asynchronous rollout method based on the agent's implementation.</p> <p>Parameters:</p> Name Type Description Default <code>task</code> <code>T</code> <p>The task object received from the server, containing the   input data and metadata.</p> required <code>resources</code> <code>NamedResources</code> <p>A dictionary of named resources (e.g., LLMs, prompt        templates) for the agent to use.</p> required <code>rollout</code> <code>Rollout</code> <p>The full rollout object, please avoid from directly modifying it.      Most agents should only use <code>task</code> and <code>resources</code>. Use <code>rollout</code>      only if you need to access metadata like <code>rollout_id</code>.</p> required <p>Returns:</p> Type Description <code>RolloutRawResult</code> <p>The result of the rollout, which can be one of:</p> <code>RolloutRawResult</code> <ul> <li>None. The tracing should be handled by the agent runner.</li> </ul> <code>RolloutRawResult</code> <ul> <li>A float representing the final reward.</li> </ul> <code>RolloutRawResult</code> <ul> <li>A list of <code>Triplet</code> objects for detailed, step-by-step feedback.</li> </ul> <code>RolloutRawResult</code> <ul> <li>A list of <code>ReadableSpan</code> objects for OpenTelemetry tracing.</li> </ul> <code>RolloutRawResult</code> <ul> <li>A list of dictionaries for any trace spans.</li> </ul> <code>RolloutRawResult</code> <ul> <li>A complete <code>Rollout</code> object for full control over reporting.</li> </ul> Source code in <code>agentlightning/litagent/litagent.py</code> <pre><code>async def rollout_async(self, task: T, resources: NamedResources, rollout: Rollout) -&gt; RolloutRawResult:\n    \"\"\"Asynchronous version of the main rollout method.\n\n    This method determines whether to call the synchronous or\n    asynchronous rollout method based on the agent's implementation.\n\n    Args:\n        task: The task object received from the server, containing the\n              input data and metadata.\n        resources: A dictionary of named resources (e.g., LLMs, prompt\n                   templates) for the agent to use.\n        rollout: The full rollout object, please avoid from directly modifying it.\n                 Most agents should only use `task` and `resources`. Use `rollout`\n                 only if you need to access metadata like `rollout_id`.\n\n    Returns:\n        The result of the rollout, which can be one of:\n        - None. The tracing should be handled by the agent runner.\n        - A float representing the final reward.\n        - A list of `Triplet` objects for detailed, step-by-step feedback.\n        - A list of `ReadableSpan` objects for OpenTelemetry tracing.\n        - A list of dictionaries for any trace spans.\n        - A complete `Rollout` object for full control over reporting.\n    \"\"\"\n    raise NotImplementedError(\"Agents must implement the `rollout_async` method for async operations.\")\n</code></pre>"},{"location":"reference/agent/#agentlightning.LitAgent.set_runner","title":"<code>set_runner(runner)</code>","text":"<p>Set the runner for this agent.</p> <p>Parameters:</p> Name Type Description Default <code>runner</code> <code>Runner[T]</code> <p>The runner instance that will handle the execution of rollouts.</p> required Source code in <code>agentlightning/litagent/litagent.py</code> <pre><code>def set_runner(self, runner: Runner[T]) -&gt; None:\n    \"\"\"\n    Set the runner for this agent.\n\n    Args:\n        runner: The runner instance that will handle the execution of rollouts.\n    \"\"\"\n    self._runner_ref = weakref.ref(runner)\n</code></pre>"},{"location":"reference/agent/#agentlightning.LitAgent.set_trainer","title":"<code>set_trainer(trainer)</code>","text":"<p>Set the trainer for this agent.</p> <p>Parameters:</p> Name Type Description Default <code>trainer</code> <code>Trainer</code> <p>The Trainer instance that will handle training and validation.</p> required Source code in <code>agentlightning/litagent/litagent.py</code> <pre><code>def set_trainer(self, trainer: Trainer) -&gt; None:\n    \"\"\"\n    Set the trainer for this agent.\n\n    Args:\n        trainer: The Trainer instance that will handle training and validation.\n    \"\"\"\n    self._trainer_ref = weakref.ref(trainer)\n</code></pre>"},{"location":"reference/agent/#agentlightning.LitAgent.training_rollout","title":"<code>training_rollout(task, resources, rollout)</code>","text":"<p>Defines the agent's behavior for a single training task.</p> <p>This method should contain the logic for how the agent processes an input, uses the provided resources (like LLMs or prompts), and produces a result.</p> <p>Parameters:</p> Name Type Description Default <code>task</code> <code>T</code> <p>The task object received from the server, containing the   input data and metadata.</p> required <code>resources</code> <code>NamedResources</code> <p>A dictionary of named resources (e.g., LLMs, prompt        templates) for the agent to use.</p> required <code>rollout</code> <code>Rollout</code> <p>The full rollout object, please avoid from directly modifying it.</p> required Source code in <code>agentlightning/litagent/litagent.py</code> <pre><code>def training_rollout(self, task: T, resources: NamedResources, rollout: Rollout) -&gt; RolloutRawResult:\n    \"\"\"Defines the agent's behavior for a single training task.\n\n    This method should contain the logic for how the agent processes an\n    input, uses the provided resources (like LLMs or prompts), and\n    produces a result.\n\n    Args:\n        task: The task object received from the server, containing the\n              input data and metadata.\n        resources: A dictionary of named resources (e.g., LLMs, prompt\n                   templates) for the agent to use.\n        rollout: The full rollout object, please avoid from directly modifying it.\n    \"\"\"\n    return self.rollout(task, resources, rollout)\n</code></pre>"},{"location":"reference/agent/#agentlightning.LitAgent.training_rollout_async","title":"<code>training_rollout_async(task, resources, rollout)</code>  <code>async</code>","text":"<p>Asynchronous version of <code>training_rollout</code>.</p> <p>This method should be implemented by agents that perform asynchronous operations (e.g., non-blocking I/O, concurrent API calls).</p> <p>Parameters:</p> Name Type Description Default <code>task</code> <code>T</code> <p>The task object received from the server.</p> required <code>resources</code> <code>NamedResources</code> <p>A dictionary of named resources for the agent to use.</p> required <code>rollout</code> <code>Rollout</code> <p>The full rollout object, avoid from modifying it.</p> required <p>Returns:</p> Type Description <code>RolloutRawResult</code> <p>The result of the asynchronous training rollout. See <code>rollout</code> for</p> <code>RolloutRawResult</code> <p>possible return types.</p> Source code in <code>agentlightning/litagent/litagent.py</code> <pre><code>async def training_rollout_async(self, task: T, resources: NamedResources, rollout: Rollout) -&gt; RolloutRawResult:\n    \"\"\"Asynchronous version of `training_rollout`.\n\n    This method should be implemented by agents that perform asynchronous\n    operations (e.g., non-blocking I/O, concurrent API calls).\n\n    Args:\n        task: The task object received from the server.\n        resources: A dictionary of named resources for the agent to use.\n        rollout: The full rollout object, avoid from modifying it.\n\n    Returns:\n        The result of the asynchronous training rollout. See `rollout` for\n        possible return types.\n    \"\"\"\n    return await self.rollout_async(task, resources, rollout)\n</code></pre>"},{"location":"reference/agent/#agentlightning.LitAgent.validation_rollout","title":"<code>validation_rollout(task, resources, rollout)</code>","text":"<p>Defines the agent's behavior for a single validation task.</p> <p>By default, this method redirects to <code>training_rollout</code>. Override it if the agent should behave differently during validation.</p> <p>Parameters:</p> Name Type Description Default <code>task</code> <code>T</code> <p>The task object received from the server, containing the   input data and metadata.</p> required <code>resources</code> <code>NamedResources</code> <p>A dictionary of named resources for the agent to use.</p> required <code>rollout</code> <code>Rollout</code> <p>The full rollout object, avoid from modifying it.</p> required <p>Returns:</p> Type Description <code>RolloutRawResult</code> <p>The result of the validation rollout. See <code>rollout</code> for</p> <code>RolloutRawResult</code> <p>possible return types.</p> Source code in <code>agentlightning/litagent/litagent.py</code> <pre><code>def validation_rollout(self, task: T, resources: NamedResources, rollout: Rollout) -&gt; RolloutRawResult:\n    \"\"\"Defines the agent's behavior for a single validation task.\n\n    By default, this method redirects to `training_rollout`. Override it\n    if the agent should behave differently during validation.\n\n    Args:\n        task: The task object received from the server, containing the\n              input data and metadata.\n        resources: A dictionary of named resources for the agent to use.\n        rollout: The full rollout object, avoid from modifying it.\n\n    Returns:\n        The result of the validation rollout. See `rollout` for\n        possible return types.\n    \"\"\"\n    return self.rollout(task, resources, rollout)\n</code></pre>"},{"location":"reference/agent/#agentlightning.LitAgent.validation_rollout_async","title":"<code>validation_rollout_async(task, resources, rollout)</code>  <code>async</code>","text":"<p>Asynchronous version of <code>validation_rollout</code>.</p> <p>By default, this method redirects to <code>training_rollout_async</code>. Override it for different asynchronous validation behavior.</p> <p>Parameters:</p> Name Type Description Default <code>task</code> <code>T</code> <p>The task object received from the server.</p> required <code>resources</code> <code>NamedResources</code> <p>A dictionary of named resources for the agent to use.</p> required <code>rollout</code> <code>Rollout</code> <p>The full rollout object, avoid from modifying it.</p> required <p>Returns:</p> Type Description <code>RolloutRawResult</code> <p>The result of the asynchronous validation rollout. See <code>rollout</code> for</p> <code>RolloutRawResult</code> <p>possible return types.</p> Source code in <code>agentlightning/litagent/litagent.py</code> <pre><code>async def validation_rollout_async(self, task: T, resources: NamedResources, rollout: Rollout) -&gt; RolloutRawResult:\n    \"\"\"Asynchronous version of `validation_rollout`.\n\n    By default, this method redirects to `training_rollout_async`.\n    Override it for different asynchronous validation behavior.\n\n    Args:\n        task: The task object received from the server.\n        resources: A dictionary of named resources for the agent to use.\n        rollout: The full rollout object, avoid from modifying it.\n\n    Returns:\n        The result of the asynchronous validation rollout. See `rollout` for\n        possible return types.\n    \"\"\"\n    return await self.rollout_async(task, resources, rollout)\n</code></pre>"},{"location":"reference/agent/#emitter","title":"Emitter","text":""},{"location":"reference/agent/#agentlightning.emit_reward","title":"<code>agentlightning.emit_reward(reward)</code>","text":"<p>Record a new reward as a new span.</p> Source code in <code>agentlightning/emitter/reward.py</code> <pre><code>def emit_reward(reward: float) -&gt; ReadableSpan:\n    \"\"\"\n    Record a new reward as a new span.\n    \"\"\"\n    logger.debug(f\"Emitting reward: {reward}\")\n    if isinstance(reward, (int, bool)):\n        reward = float(reward)\n    if not isinstance(reward, float):\n        raise ValueError(f\"Reward must be a number, got: {type(reward)}\")\n\n    tracer = get_tracer()\n    span = tracer.start_span(SpanNames.REWARD.value, attributes={\"reward\": reward})\n    # Do nothing; it's just a number\n    with span:\n        pass\n    if not isinstance(span, ReadableSpan):\n        raise ValueError(f\"Span is not a ReadableSpan: {span}\")\n    return span\n</code></pre>"},{"location":"reference/agent/#agentlightning.emit_message","title":"<code>agentlightning.emit_message(message)</code>","text":"<p>Emit a string message as a span.</p> <p>OpenTelemetry has a dedicated design of logs by design, but we can also use spans to emit messages. So that it can all be unified in the data store and analyzed together.</p> Source code in <code>agentlightning/emitter/message.py</code> <pre><code>def emit_message(message: str) -&gt; None:\n    \"\"\"Emit a string message as a span.\n\n    OpenTelemetry has a dedicated design of logs by design, but we can also use spans to emit messages.\n    So that it can all be unified in the data store and analyzed together.\n    \"\"\"\n    if not isinstance(message, str):  # type: ignore\n        logger.error(f\"Message must be a string, got: {type(message)}. Skip emit_message.\")\n        return\n\n    tracer = get_tracer()\n    span = tracer.start_span(\n        SpanNames.MESSAGE.value,\n        attributes={SpanAttributeNames.MESSAGE.value: message},\n    )\n    logger.debug(\"Emitting message span with message: %s\", message)\n    with span:\n        pass\n</code></pre>"},{"location":"reference/agent/#agentlightning.emit_object","title":"<code>agentlightning.emit_object(object)</code>","text":"<p>Emit any object as a span. Make sure the object is JSON serializable.</p> Source code in <code>agentlightning/emitter/object.py</code> <pre><code>def emit_object(object: Any) -&gt; None:\n    \"\"\"Emit any object as a span. Make sure the object is JSON serializable.\"\"\"\n    try:\n        serialized = json.dumps(object)\n    except (TypeError, ValueError):\n        logger.error(f\"Object must be JSON serializable, got: {type(object)}. Skip emit_object.\")\n        return\n\n    tracer = get_tracer()\n    span = tracer.start_span(\n        SpanNames.OBJECT.value,\n        attributes={SpanAttributeNames.OBJECT.value: serialized},\n    )\n    logger.debug(\"Emitting object span with payload size %d characters\", len(serialized))\n    with span:\n        pass\n</code></pre>"},{"location":"reference/agent/#agentlightning.emit_exception","title":"<code>agentlightning.emit_exception(exception)</code>","text":"<p>Emit an exception as a span.</p> Source code in <code>agentlightning/emitter/exception.py</code> <pre><code>def emit_exception(exception: BaseException) -&gt; None:\n    \"\"\"Emit an exception as a span.\"\"\"\n    if not isinstance(exception, BaseException):  # type: ignore\n        logger.error(f\"Expected an BaseException instance, got: {type(exception)}. Skip emit_exception.\")\n        return\n\n    tracer = get_tracer()\n    stacktrace = \"\".join(traceback.format_exception(type(exception), exception, exception.__traceback__))\n    attributes = {\n        exception_attributes.EXCEPTION_TYPE: type(exception).__name__,\n        exception_attributes.EXCEPTION_MESSAGE: str(exception),\n        exception_attributes.EXCEPTION_ESCAPED: True,\n    }\n    if stacktrace.strip():\n        attributes[exception_attributes.EXCEPTION_STACKTRACE] = stacktrace\n\n    span = tracer.start_span(\n        SpanNames.EXCEPTION.value,\n        attributes=attributes,\n    )\n    logger.debug(\"Emitting exception span for %s\", type(exception).__name__)\n    with span:\n        span.record_exception(exception)\n</code></pre>"},{"location":"reference/agent/#reward-helpers","title":"Reward Helpers","text":""},{"location":"reference/agent/#agentlightning.find_final_reward","title":"<code>agentlightning.find_final_reward(spans)</code>","text":"<p>Get the last reward value from a list of spans.</p> <p>Parameters:</p> Name Type Description Default <code>spans</code> <code>Sequence[SpanLike]</code> <p>A list of spans (either ReadableSpan or Span).</p> required <p>Returns:</p> Type Description <code>Optional[float]</code> <p>The reward value from the last reward span, or None if not found.</p> Source code in <code>agentlightning/emitter/reward.py</code> <pre><code>def find_final_reward(spans: Sequence[SpanLike]) -&gt; Optional[float]:\n    \"\"\"\n    Get the last reward value from a list of spans.\n\n    Args:\n        spans: A list of spans (either ReadableSpan or Span).\n\n    Returns:\n        The reward value from the last reward span, or None if not found.\n    \"\"\"\n    for span in reversed(spans):\n        reward = get_reward_value(span)\n        if reward is not None:\n            return reward\n    return None\n</code></pre>"},{"location":"reference/agent/#agentlightning.find_reward_spans","title":"<code>agentlightning.find_reward_spans(spans)</code>","text":"<p>Find all reward spans in the given list of spans.</p> <p>Parameters:</p> Name Type Description Default <code>spans</code> <code>Sequence[SpanLike]</code> <p>A list of spans (either ReadableSpan or Span).</p> required <p>Returns:</p> Type Description <code>List[SpanLike]</code> <p>A list of spans whose name matches the reward span name.</p> Source code in <code>agentlightning/emitter/reward.py</code> <pre><code>def find_reward_spans(spans: Sequence[SpanLike]) -&gt; List[SpanLike]:\n    \"\"\"\n    Find all reward spans in the given list of spans.\n\n    Args:\n        spans: A list of spans (either ReadableSpan or Span).\n\n    Returns:\n        A list of spans whose name matches the reward span name.\n    \"\"\"\n    return [span for span in spans if is_reward_span(span)]\n</code></pre>"},{"location":"reference/agent/#agentlightning.get_reward_value","title":"<code>agentlightning.get_reward_value(span)</code>","text":"<p>Get the reward value from a span.</p> Source code in <code>agentlightning/emitter/reward.py</code> <pre><code>def get_reward_value(span: SpanLike) -&gt; Optional[float]:\n    \"\"\"\n    Get the reward value from a span.\n    \"\"\"\n    for key in [\n        \"agentops.task.output\",  # newer versions of agentops\n        \"agentops.entity.output\",\n    ]:\n        reward_dict: Dict[str, Any] | None = None\n        if span.attributes:\n            output = span.attributes.get(key)\n            if output:\n                if isinstance(output, dict):\n                    reward_dict = cast(Dict[str, Any], output)\n                elif isinstance(output, str):\n                    try:\n                        reward_dict = cast(Dict[str, Any], json.loads(output))\n                    except json.JSONDecodeError:\n                        reward_dict = None\n\n        if reward_dict and reward_dict.get(\"type\") == \"reward\":\n            reward_value = reward_dict.get(\"value\", None)\n            if reward_value is None:\n                return None\n            if not isinstance(reward_value, float):\n                logger.error(f\"Reward is not a number, got: {type(reward_value)}. This may cause undefined behaviors.\")\n            return cast(float, reward_value)\n\n    # Latest emit reward format\n    if span.name == SpanNames.REWARD.value and span.attributes:\n        reward_value = span.attributes.get(\"reward\", None)\n        if reward_value is None:\n            return None\n        if not isinstance(reward_value, float):\n            logger.error(f\"Reward is not a number, got: {type(reward_value)}. This may cause undefined behaviors.\")\n        return cast(float, reward_value)\n    return None\n</code></pre>"},{"location":"reference/agent/#agentlightning.is_reward_span","title":"<code>agentlightning.is_reward_span(span)</code>","text":"<p>Check if a span is a reward span.</p> Source code in <code>agentlightning/emitter/reward.py</code> <pre><code>def is_reward_span(span: SpanLike) -&gt; bool:\n    \"\"\"\n    Check if a span is a reward span.\n    \"\"\"\n    maybe_reward = get_reward_value(span)\n    return maybe_reward is not None\n</code></pre>"},{"location":"reference/agent/#legacy-emitter-decorators","title":"Legacy Emitter Decorators","text":""},{"location":"reference/agent/#agentlightning.reward.reward","title":"<code>agentlightning.reward.reward(fn)</code>","text":"<p>A decorator to wrap a function that computes rewards. It will automatically handle the input and output of the function.</p> Source code in <code>agentlightning/emitter/reward.py</code> <pre><code>def reward(fn: FnType) -&gt; FnType:\n    \"\"\"\n    A decorator to wrap a function that computes rewards.\n    It will automatically handle the input and output of the function.\n    \"\"\"\n\n    def wrap_result(result: Optional[float]) -&gt; RewardSpanData:\n        \"\"\"\n        Wrap the result of the function in a dict.\n        \"\"\"\n        if result is None:\n            return {\"type\": \"reward\", \"value\": None}\n        if not isinstance(result, (float, int)):  # type: ignore\n            warnings.warn(f\"Reward is ignored because it is not a number: {result}\")\n            return {\"type\": \"reward\", \"value\": None}\n        return {\"type\": \"reward\", \"value\": float(result)}\n\n    # Check if the function is async\n    is_async = asyncio.iscoroutinefunction(fn) or inspect.iscoroutinefunction(fn)\n\n    if is_async:\n\n        async def wrapper_async(*args: Any, **kwargs: Any) -&gt; Any:\n            if not _agentops_initialized():\n                # Track the reward without AgentOps\n                result = await fn(*args, **kwargs)\n                emit_reward(cast(float, result))\n                return result\n\n            result: Optional[float] = None\n\n            @operation\n            async def agentops_reward_operation() -&gt; RewardSpanData:\n                # The reward function we are interested in tracing\n                # It takes zero inputs and return a formatted dict\n                nonlocal result\n                result = await fn(*args, **kwargs)\n                return wrap_result(result)\n\n            await agentops_reward_operation()\n            return result\n\n        return wrapper_async  # type: ignore\n\n    else:\n\n        def wrapper(*args: Any, **kwargs: Any) -&gt; Any:\n            if not _agentops_initialized():\n                # Track the reward without AgentOps\n                result = fn(*args, **kwargs)\n                emit_reward(cast(float, result))\n                return result\n\n            result: Optional[float] = None\n\n            @operation\n            def agentops_reward_operation() -&gt; RewardSpanData:\n                nonlocal result\n                result = fn(*args, **kwargs)\n                return wrap_result(result)\n\n            agentops_reward_operation()\n            return result\n\n        return wrapper  # type: ignore\n</code></pre>"},{"location":"reference/algorithm/","title":"Algorithm","text":""},{"location":"reference/algorithm/#algorithm-side-references","title":"Algorithm-side References","text":"<p>Note</p> <p>This reference covers APIs that are designed to be used at \"Algorithm Side\". For built-in algorithms, see Algorithm Zoo.</p>"},{"location":"reference/algorithm/#base-class-and-decorators","title":"Base Class and Decorators","text":""},{"location":"reference/algorithm/#agentlightning.Algorithm","title":"<code>agentlightning.Algorithm</code>","text":"<p>Algorithm is the strategy, or tuner to train the agent.</p> Source code in <code>agentlightning/algorithm/base.py</code> <pre><code>class Algorithm:\n    \"\"\"Algorithm is the strategy, or tuner to train the agent.\"\"\"\n\n    _trainer_ref: weakref.ReferenceType[Trainer] | None = None\n    _llm_proxy_ref: weakref.ReferenceType[\"LLMProxy\"] | None = None\n    _store: LightningStore | None = None\n    _initial_resources: NamedResources | None = None\n    _adapter_ref: weakref.ReferenceType[TraceAdapter[Any]] | None = None\n\n    def is_async(self) -&gt; bool:\n        \"\"\"Return True if the algorithm is asynchronous.\"\"\"\n        return inspect.iscoroutinefunction(self.run)\n\n    def set_trainer(self, trainer: Trainer) -&gt; None:\n        \"\"\"\n        Set the trainer for this algorithm.\n\n        Args:\n            trainer: The Trainer instance that will handle training and validation.\n        \"\"\"\n        self._trainer_ref = weakref.ref(trainer)\n\n    def get_trainer(self) -&gt; Trainer:\n        \"\"\"\n        Get the trainer for this algorithm.\n\n        Returns:\n            The Trainer instance associated with this agent.\n        \"\"\"\n        if self._trainer_ref is None:\n            raise ValueError(\"Trainer has not been set for this agent.\")\n        trainer = self._trainer_ref()\n        if trainer is None:\n            raise ValueError(\"Trainer reference is no longer valid (object has been garbage collected).\")\n        return trainer\n\n    def set_llm_proxy(self, llm_proxy: LLMProxy | None) -&gt; None:\n        \"\"\"\n        Set the LLM proxy for this algorithm to reuse when available.\n\n        Args:\n            llm_proxy: The LLMProxy instance configured by the trainer, if any.\n        \"\"\"\n        self._llm_proxy_ref = weakref.ref(llm_proxy) if llm_proxy is not None else None\n\n    def get_llm_proxy(self) -&gt; Optional[LLMProxy]:\n        \"\"\"\n        Retrieve the configured LLM proxy instance, if one has been set.\n\n        Returns:\n            The active LLMProxy instance or None when not configured.\n        \"\"\"\n        if self._llm_proxy_ref is None:\n            return None\n\n        llm_proxy = self._llm_proxy_ref()\n        if llm_proxy is None:\n            raise ValueError(\"LLM proxy reference is no longer valid (object has been garbage collected).\")\n\n        return llm_proxy\n\n    def set_adapter(self, adapter: TraceAdapter[Any]) -&gt; None:\n        \"\"\"\n        Set the adapter for this algorithm to collect and convert traces.\n        \"\"\"\n        self._adapter_ref = weakref.ref(adapter)\n\n    def get_adapter(self) -&gt; TraceAdapter[Any]:\n        \"\"\"\n        Retrieve the adapter for this algorithm to communicate with the runners.\n        \"\"\"\n        if self._adapter_ref is None:\n            raise ValueError(\"Adapter has not been set for this algorithm.\")\n        adapter = self._adapter_ref()\n        if adapter is None:\n            raise ValueError(\"Adapter reference is no longer valid (object has been garbage collected).\")\n        return adapter\n\n    def set_store(self, store: LightningStore) -&gt; None:\n        \"\"\"\n        Set the store for this algorithm to communicate with the runners.\n\n        Store is set directly instead of using weakref because its copy is meant to be\n        maintained throughout the algorithm's lifecycle.\n        \"\"\"\n        self._store = store\n\n    def get_store(self) -&gt; LightningStore:\n        \"\"\"\n        Retrieve the store for this algorithm to communicate with the runners.\n        \"\"\"\n        if self._store is None:\n            raise ValueError(\"Store has not been set for this algorithm.\")\n        return self._store\n\n    def get_initial_resources(self) -&gt; Optional[NamedResources]:\n        \"\"\"\n        Get the initial resources for this algorithm.\n        \"\"\"\n        return self._initial_resources\n\n    def set_initial_resources(self, resources: NamedResources) -&gt; None:\n        \"\"\"\n        Set the initial resources for this algorithm.\n        \"\"\"\n        self._initial_resources = resources\n\n    def __call__(self, *args: Any, **kwargs: Any) -&gt; Any:\n        return self.run(*args, **kwargs)\n\n    def run(\n        self,\n        train_dataset: Optional[Dataset[Any]] = None,\n        val_dataset: Optional[Dataset[Any]] = None,\n    ) -&gt; Union[None, Awaitable[None]]:\n        \"\"\"Subclasses should implement this method to implement the algorithm.\n\n        Args:\n            train_dataset: The dataset to train on. Not all algorithms require a training dataset.\n            val_dataset: The dataset to validate on. Not all algorithms require a validation dataset.\n\n        Returns:\n            Algorithm should refrain from returning anything. It should just run the algorithm.\n        \"\"\"\n        raise NotImplementedError(\"Subclasses must implement run().\")\n\n    def get_client(self) -&gt; AgentLightningClient:\n        \"\"\"Get the client to communicate with the algorithm.\n\n        If the algorithm does not require a server-client communication, it can also create a mock client\n        that never communicates with itself.\n\n        Deprecated and will be removed in a future version.\n\n        Returns:\n            The AgentLightningClient instance associated with this algorithm.\n        \"\"\"\n        raise NotImplementedError(\"Subclasses must implement get_client().\")\n</code></pre>"},{"location":"reference/algorithm/#agentlightning.Algorithm.get_adapter","title":"<code>get_adapter()</code>","text":"<p>Retrieve the adapter for this algorithm to communicate with the runners.</p> Source code in <code>agentlightning/algorithm/base.py</code> <pre><code>def get_adapter(self) -&gt; TraceAdapter[Any]:\n    \"\"\"\n    Retrieve the adapter for this algorithm to communicate with the runners.\n    \"\"\"\n    if self._adapter_ref is None:\n        raise ValueError(\"Adapter has not been set for this algorithm.\")\n    adapter = self._adapter_ref()\n    if adapter is None:\n        raise ValueError(\"Adapter reference is no longer valid (object has been garbage collected).\")\n    return adapter\n</code></pre>"},{"location":"reference/algorithm/#agentlightning.Algorithm.get_client","title":"<code>get_client()</code>","text":"<p>Get the client to communicate with the algorithm.</p> <p>If the algorithm does not require a server-client communication, it can also create a mock client that never communicates with itself.</p> <p>Deprecated and will be removed in a future version.</p> <p>Returns:</p> Type Description <code>AgentLightningClient</code> <p>The AgentLightningClient instance associated with this algorithm.</p> Source code in <code>agentlightning/algorithm/base.py</code> <pre><code>def get_client(self) -&gt; AgentLightningClient:\n    \"\"\"Get the client to communicate with the algorithm.\n\n    If the algorithm does not require a server-client communication, it can also create a mock client\n    that never communicates with itself.\n\n    Deprecated and will be removed in a future version.\n\n    Returns:\n        The AgentLightningClient instance associated with this algorithm.\n    \"\"\"\n    raise NotImplementedError(\"Subclasses must implement get_client().\")\n</code></pre>"},{"location":"reference/algorithm/#agentlightning.Algorithm.get_initial_resources","title":"<code>get_initial_resources()</code>","text":"<p>Get the initial resources for this algorithm.</p> Source code in <code>agentlightning/algorithm/base.py</code> <pre><code>def get_initial_resources(self) -&gt; Optional[NamedResources]:\n    \"\"\"\n    Get the initial resources for this algorithm.\n    \"\"\"\n    return self._initial_resources\n</code></pre>"},{"location":"reference/algorithm/#agentlightning.Algorithm.get_llm_proxy","title":"<code>get_llm_proxy()</code>","text":"<p>Retrieve the configured LLM proxy instance, if one has been set.</p> <p>Returns:</p> Type Description <code>Optional[LLMProxy]</code> <p>The active LLMProxy instance or None when not configured.</p> Source code in <code>agentlightning/algorithm/base.py</code> <pre><code>def get_llm_proxy(self) -&gt; Optional[LLMProxy]:\n    \"\"\"\n    Retrieve the configured LLM proxy instance, if one has been set.\n\n    Returns:\n        The active LLMProxy instance or None when not configured.\n    \"\"\"\n    if self._llm_proxy_ref is None:\n        return None\n\n    llm_proxy = self._llm_proxy_ref()\n    if llm_proxy is None:\n        raise ValueError(\"LLM proxy reference is no longer valid (object has been garbage collected).\")\n\n    return llm_proxy\n</code></pre>"},{"location":"reference/algorithm/#agentlightning.Algorithm.get_store","title":"<code>get_store()</code>","text":"<p>Retrieve the store for this algorithm to communicate with the runners.</p> Source code in <code>agentlightning/algorithm/base.py</code> <pre><code>def get_store(self) -&gt; LightningStore:\n    \"\"\"\n    Retrieve the store for this algorithm to communicate with the runners.\n    \"\"\"\n    if self._store is None:\n        raise ValueError(\"Store has not been set for this algorithm.\")\n    return self._store\n</code></pre>"},{"location":"reference/algorithm/#agentlightning.Algorithm.get_trainer","title":"<code>get_trainer()</code>","text":"<p>Get the trainer for this algorithm.</p> <p>Returns:</p> Type Description <code>Trainer</code> <p>The Trainer instance associated with this agent.</p> Source code in <code>agentlightning/algorithm/base.py</code> <pre><code>def get_trainer(self) -&gt; Trainer:\n    \"\"\"\n    Get the trainer for this algorithm.\n\n    Returns:\n        The Trainer instance associated with this agent.\n    \"\"\"\n    if self._trainer_ref is None:\n        raise ValueError(\"Trainer has not been set for this agent.\")\n    trainer = self._trainer_ref()\n    if trainer is None:\n        raise ValueError(\"Trainer reference is no longer valid (object has been garbage collected).\")\n    return trainer\n</code></pre>"},{"location":"reference/algorithm/#agentlightning.Algorithm.is_async","title":"<code>is_async()</code>","text":"<p>Return True if the algorithm is asynchronous.</p> Source code in <code>agentlightning/algorithm/base.py</code> <pre><code>def is_async(self) -&gt; bool:\n    \"\"\"Return True if the algorithm is asynchronous.\"\"\"\n    return inspect.iscoroutinefunction(self.run)\n</code></pre>"},{"location":"reference/algorithm/#agentlightning.Algorithm.run","title":"<code>run(train_dataset=None, val_dataset=None)</code>","text":"<p>Subclasses should implement this method to implement the algorithm.</p> <p>Parameters:</p> Name Type Description Default <code>train_dataset</code> <code>Optional[Dataset[Any]]</code> <p>The dataset to train on. Not all algorithms require a training dataset.</p> <code>None</code> <code>val_dataset</code> <code>Optional[Dataset[Any]]</code> <p>The dataset to validate on. Not all algorithms require a validation dataset.</p> <code>None</code> <p>Returns:</p> Type Description <code>Union[None, Awaitable[None]]</code> <p>Algorithm should refrain from returning anything. It should just run the algorithm.</p> Source code in <code>agentlightning/algorithm/base.py</code> <pre><code>def run(\n    self,\n    train_dataset: Optional[Dataset[Any]] = None,\n    val_dataset: Optional[Dataset[Any]] = None,\n) -&gt; Union[None, Awaitable[None]]:\n    \"\"\"Subclasses should implement this method to implement the algorithm.\n\n    Args:\n        train_dataset: The dataset to train on. Not all algorithms require a training dataset.\n        val_dataset: The dataset to validate on. Not all algorithms require a validation dataset.\n\n    Returns:\n        Algorithm should refrain from returning anything. It should just run the algorithm.\n    \"\"\"\n    raise NotImplementedError(\"Subclasses must implement run().\")\n</code></pre>"},{"location":"reference/algorithm/#agentlightning.Algorithm.set_adapter","title":"<code>set_adapter(adapter)</code>","text":"<p>Set the adapter for this algorithm to collect and convert traces.</p> Source code in <code>agentlightning/algorithm/base.py</code> <pre><code>def set_adapter(self, adapter: TraceAdapter[Any]) -&gt; None:\n    \"\"\"\n    Set the adapter for this algorithm to collect and convert traces.\n    \"\"\"\n    self._adapter_ref = weakref.ref(adapter)\n</code></pre>"},{"location":"reference/algorithm/#agentlightning.Algorithm.set_initial_resources","title":"<code>set_initial_resources(resources)</code>","text":"<p>Set the initial resources for this algorithm.</p> Source code in <code>agentlightning/algorithm/base.py</code> <pre><code>def set_initial_resources(self, resources: NamedResources) -&gt; None:\n    \"\"\"\n    Set the initial resources for this algorithm.\n    \"\"\"\n    self._initial_resources = resources\n</code></pre>"},{"location":"reference/algorithm/#agentlightning.Algorithm.set_llm_proxy","title":"<code>set_llm_proxy(llm_proxy)</code>","text":"<p>Set the LLM proxy for this algorithm to reuse when available.</p> <p>Parameters:</p> Name Type Description Default <code>llm_proxy</code> <code>LLMProxy | None</code> <p>The LLMProxy instance configured by the trainer, if any.</p> required Source code in <code>agentlightning/algorithm/base.py</code> <pre><code>def set_llm_proxy(self, llm_proxy: LLMProxy | None) -&gt; None:\n    \"\"\"\n    Set the LLM proxy for this algorithm to reuse when available.\n\n    Args:\n        llm_proxy: The LLMProxy instance configured by the trainer, if any.\n    \"\"\"\n    self._llm_proxy_ref = weakref.ref(llm_proxy) if llm_proxy is not None else None\n</code></pre>"},{"location":"reference/algorithm/#agentlightning.Algorithm.set_store","title":"<code>set_store(store)</code>","text":"<p>Set the store for this algorithm to communicate with the runners.</p> <p>Store is set directly instead of using weakref because its copy is meant to be maintained throughout the algorithm's lifecycle.</p> Source code in <code>agentlightning/algorithm/base.py</code> <pre><code>def set_store(self, store: LightningStore) -&gt; None:\n    \"\"\"\n    Set the store for this algorithm to communicate with the runners.\n\n    Store is set directly instead of using weakref because its copy is meant to be\n    maintained throughout the algorithm's lifecycle.\n    \"\"\"\n    self._store = store\n</code></pre>"},{"location":"reference/algorithm/#agentlightning.Algorithm.set_trainer","title":"<code>set_trainer(trainer)</code>","text":"<p>Set the trainer for this algorithm.</p> <p>Parameters:</p> Name Type Description Default <code>trainer</code> <code>Trainer</code> <p>The Trainer instance that will handle training and validation.</p> required Source code in <code>agentlightning/algorithm/base.py</code> <pre><code>def set_trainer(self, trainer: Trainer) -&gt; None:\n    \"\"\"\n    Set the trainer for this algorithm.\n\n    Args:\n        trainer: The Trainer instance that will handle training and validation.\n    \"\"\"\n    self._trainer_ref = weakref.ref(trainer)\n</code></pre>"},{"location":"reference/algorithm/#agentlightning.algo","title":"<code>agentlightning.algo(func)</code>","text":"<pre><code>algo(\n    func: AlgorithmFuncAsync,\n) -&gt; FunctionalAlgorithm[Literal[True]]\n</code></pre><pre><code>algo(\n    func: AlgorithmFuncAsyncFallback,\n) -&gt; FunctionalAlgorithm[Any]\n</code></pre><pre><code>algo(\n    func: AlgorithmFuncSync,\n) -&gt; FunctionalAlgorithm[Literal[False]]\n</code></pre><pre><code>algo(\n    func: AlgorithmFuncSyncFallback,\n) -&gt; FunctionalAlgorithm[Any]\n</code></pre> <p>Create a Algorithm from a function.</p> <p>This decorator allows you to define an algorithm using a simple function instead of creating a full Algorithm subclass. The returned FunctionalAlgorithm instance is callable, preserving the original function's behavior.</p> <p>Parameters:</p> Name Type Description Default <code>func</code> <code>Union[AlgorithmFuncSync, AlgorithmFuncAsync, AlgorithmFuncSyncFallback, AlgorithmFuncAsyncFallback]</code> <p>A function that defines the algorithm's behavior with signature:   (train_dataset, val_dataset) -&gt; None   Can be sync or async.</p> required <p>Returns:</p> Type Description <code>Union[FunctionalAlgorithm[Literal[False]], FunctionalAlgorithm[Literal[True]]]</code> <p>A callable FunctionalAlgorithm instance that preserves the original function's</p> <code>Union[FunctionalAlgorithm[Literal[False]], FunctionalAlgorithm[Literal[True]]]</code> <p>type hints and behavior while providing all algorithm functionality.</p> Example <p>@algo def my_algorithm(train_dataset, val_dataset):     # Algorithm logic here     for task in train_dataset:         # Process training tasks         pass</p> <p>@algo async def my_async_algorithm(train_dataset, val_dataset):     # Async algorithm logic here     async for task in train_dataset:         # Process training tasks asynchronously         pass</p> Source code in <code>agentlightning/algorithm/decorator.py</code> <pre><code>def algo(\n    func: Union[\n        AlgorithmFuncSync,\n        AlgorithmFuncAsync,\n        AlgorithmFuncSyncFallback,\n        AlgorithmFuncAsyncFallback,\n    ],\n) -&gt; Union[FunctionalAlgorithm[Literal[False]], FunctionalAlgorithm[Literal[True]]]:\n    \"\"\"Create a Algorithm from a function.\n\n    This decorator allows you to define an algorithm using a simple function\n    instead of creating a full Algorithm subclass. The returned FunctionalAlgorithm\n    instance is callable, preserving the original function's behavior.\n\n    Args:\n        func: A function that defines the algorithm's behavior with signature:\n              (train_dataset, val_dataset) -&gt; None\n              Can be sync or async.\n\n    Returns:\n        A callable FunctionalAlgorithm instance that preserves the original function's\n        type hints and behavior while providing all algorithm functionality.\n\n    Example:\n        @algo\n        def my_algorithm(train_dataset, val_dataset):\n            # Algorithm logic here\n            for task in train_dataset:\n                # Process training tasks\n                pass\n\n        @algo\n        async def my_async_algorithm(train_dataset, val_dataset):\n            # Async algorithm logic here\n            async for task in train_dataset:\n                # Process training tasks asynchronously\n                pass\n\n        # Function is still callable with original behavior\n        my_algorithm(train_data, val_data)\n\n        # Algorithm methods are also available\n        my_algorithm.run(train_data, val_data)\n    \"\"\"\n    return FunctionalAlgorithm(func)\n</code></pre>"},{"location":"reference/algorithm/#agentlightning.algo--function-is-still-callable-with-original-behavior","title":"Function is still callable with original behavior","text":"<p>my_algorithm(train_data, val_data)</p>"},{"location":"reference/algorithm/#agentlightning.algo--algorithm-methods-are-also-available","title":"Algorithm methods are also available","text":"<p>my_algorithm.run(train_data, val_data)</p>"},{"location":"reference/algorithm/#fast-algorithms-for-debugging","title":"Fast Algorithms (for Debugging)","text":""},{"location":"reference/algorithm/#agentlightning.FastAlgorithm","title":"<code>agentlightning.FastAlgorithm</code>","text":"<p>               Bases: <code>Algorithm</code></p> <p>Algorithm that can run fast and qualify for dev mode.</p> <p>Fast algorithms enable agent developers to quickly iterate on agent development without waiting for a long training to complete.</p> Source code in <code>agentlightning/algorithm/fast.py</code> <pre><code>class FastAlgorithm(Algorithm):\n    \"\"\"Algorithm that can run fast and qualify for dev mode.\n\n    Fast algorithms enable agent developers to quickly iterate on agent development\n    without waiting for a long training to complete.\n    \"\"\"\n</code></pre>"},{"location":"reference/algorithm/#agentlightning.Baseline","title":"<code>agentlightning.Baseline</code>","text":"<p>               Bases: <code>FastAlgorithm</code></p> <p>A dummy implementation of algorithm interface that puts all dataset into the queue, and waits for all rollouts to complete.</p> <p>Logs all collected spans and rewards.</p> <p>Parameters:</p> Name Type Description Default <code>model_list</code> <code>Optional[List[ModelConfig]]</code> <p>Optional list of models to load into the llm proxy. If both model_list and llm_proxy is provided, llm_proxy will be launched. Not implemented yet.</p> <code>None</code> <code>n_epochs</code> <code>int</code> <p>Number of epochs to run through the dev dataset.</p> <code>1</code> <code>train_split</code> <code>float</code> <p>Fraction of dev dataset to use for training vs validation. Must be between 0 and 1.</p> <code>0.5</code> <code>polling_interval</code> <code>float</code> <p>Time interval (in seconds) to poll the store for queue length and for completed rollouts.</p> <code>5.0</code> <code>max_queue_length</code> <code>int</code> <p>Maximum number of rollouts to keep in the queue at any time.</p> <code>4</code> Source code in <code>agentlightning/algorithm/fast.py</code> <pre><code>class Baseline(FastAlgorithm):\n    \"\"\"A dummy implementation of algorithm interface that puts all dataset into the queue, and waits for all rollouts to complete.\n\n    Logs all collected spans and rewards.\n\n    Args:\n        model_list: Optional list of models to load into the llm proxy.\n            If both model_list and llm_proxy is provided, llm_proxy will be launched.\n            Not implemented yet.\n        n_epochs: Number of epochs to run through the dev dataset.\n        train_split: Fraction of dev dataset to use for training vs validation. Must be between 0 and 1.\n        polling_interval: Time interval (in seconds) to poll the store for queue length and for completed rollouts.\n        max_queue_length: Maximum number of rollouts to keep in the queue at any time.\n    \"\"\"\n\n    def __init__(\n        self,\n        *,\n        model_list: Optional[List[ModelConfig]] = None,\n        n_epochs: int = 1,\n        train_split: float = 0.5,\n        polling_interval: float = 5.0,\n        max_queue_length: int = 4,\n        span_verbosity: Literal[\"keys\", \"key_values\", \"none\"] = \"keys\",\n    ) -&gt; None:\n        super().__init__()\n        self.n_epochs = n_epochs\n        self.train_split = train_split\n        self.polling_interval = polling_interval\n        self.max_queue_length = max_queue_length\n        self.span_verbosity = span_verbosity\n        if not (0.0 &lt; self.train_split &lt; 1.0):\n            raise ValueError(\"train_split must be between 0 and 1.\")\n\n        self._finished_rollout_count = 0\n\n    def _span_to_string(self, rollout_id: str, attempt: Attempt, span: Span) -&gt; str:\n        if self.span_verbosity == \"none\":\n            return \"\"\n\n        prefix_msg = f\"[Rollout {rollout_id} | Attempt {attempt.attempt_id} | Span {span.span_id}] #{span.sequence_id} ({span.name}) \"\n        elapsed = f\"{span.end_time - span.start_time:.2f}\" if span.start_time and span.end_time else \"unknown\"\n\n        msg = (\n            prefix_msg\n            + f\"From {_timestamp_to_iso_str(span.start_time) if span.start_time else 'unknown'}, \"\n            + f\"to {_timestamp_to_iso_str(span.end_time) if span.end_time else 'unknown'}, \"\n            + f\"{elapsed} seconds. \"\n        )\n        if self.span_verbosity == \"key_values\":\n            msg += f\"Attributes: {span.attributes}\"\n        else:\n            msg += f\"Attribute keys: {list(span.attributes.keys())}\"\n        return msg\n\n    async def _handle_rollout_finish(self, rollout: Rollout) -&gt; None:\n        store = self.get_store()\n\n        rollout_id = rollout.rollout_id\n        rollout_end_time = rollout.end_time or asyncio.get_event_loop().time()\n        logger.info(\n            f\"[Rollout {rollout_id}] Finished with status {rollout.status} in {rollout_end_time - rollout.start_time:.2f} seconds.\"\n        )\n\n        # Logs all the attempts and their corresponding spans\n        attempts = await store.query_attempts(rollout_id)\n        for attempt in attempts:\n            logger.info(\n                f\"[Rollout {rollout_id} | Attempt {attempt.sequence_id}] ID: {attempt.attempt_id}. Status: {attempt.status}. Worker: {attempt.worker_id}\"\n            )\n            spans = await store.query_spans(rollout_id=rollout_id)\n            for span in spans:\n                if self.span_verbosity != \"none\":\n                    logger.info(self._span_to_string(rollout.rollout_id, attempt, span))\n\n        # Attempts to adapt the spans using the adapter if provided\n        try:\n            adapter = self.get_adapter()\n            spans = await store.query_spans(rollout_id=rollout_id, attempt_id=\"latest\")\n            transformed_data = adapter.adapt(spans)\n            logger.info(f\"[Rollout {rollout_id}] Adapted data: {transformed_data}\")\n        except ValueError:\n            logger.warning(\"No adapter set for MockAlgorithm. Skipping trace adaptation.\")\n\n    async def _enqueue_rollouts(\n        self, dataset: Dataset[Any], train_indices: List[int], val_indices: List[int], resources_id: str\n    ) -&gt; None:\n        store = self.get_store()\n\n        for index in train_indices + val_indices:\n            queuing_rollouts = await store.query_rollouts(status=[\"queuing\", \"requeuing\"])\n            if len(queuing_rollouts) &lt;= 1:\n                # Only enqueue a new rollout when there is at most 1 rollout in the queue.\n                sample = dataset[index]\n                mode = \"train\" if index in train_indices else \"val\"\n                rollout = await store.enqueue_rollout(input=sample, mode=mode, resources_id=resources_id)\n                logger.info(f\"[Rollout {rollout.rollout_id}] Enqueued in {mode} mode with sample: {sample}\")\n            await asyncio.sleep(self.polling_interval)\n\n    async def _harvest_rollout_spans(self, rollout_id: str):\n        store = self.get_store()\n        last_status: Optional[RolloutStatus] = None\n\n        while True:\n            rollout = await store.get_rollout_by_id(rollout_id)\n            if rollout is not None:\n                if rollout.status in [\"succeeded\", \"failed\", \"cancelled\"]:\n                    # Rollout is finished, log all the data.\n                    await self._handle_rollout_finish(rollout)\n                    # We are done here.\n                    self._finished_rollout_count += 1\n                    logger.info(f\"Finished {self._finished_rollout_count} rollouts.\")\n                    break\n\n                if last_status != rollout.status:\n                    if last_status is not None:\n                        logger.info(f\"[Rollout {rollout_id}] Status changed to {rollout.status}.\")\n                    else:\n                        logger.info(f\"[Rollout {rollout_id}] Status is initialized to {rollout.status}.\")\n                    last_status = rollout.status\n\n                else:\n                    logger.debug(f\"[Rollout {rollout_id}] Status is still {rollout.status}.\")\n\n            await asyncio.sleep(self.polling_interval)\n\n    async def run(\n        self,\n        train_dataset: Optional[Dataset[Any]] = None,\n        val_dataset: Optional[Dataset[Any]] = None,\n    ) -&gt; None:\n        train_dataset_length = len(train_dataset) if train_dataset is not None else 0\n        val_dataset_length = len(val_dataset) if val_dataset is not None else 0\n        if train_dataset_length == 0 and val_dataset_length == 0:\n            logger.error(\n                \"MockAlgorithm requires at least a train_dataset or val_dataset to run. No train_dataset or val_dataset is provided. Exiting.\"\n            )\n            return\n\n        concatenated_dataset = [train_dataset[i] for i in range(train_dataset_length) if train_dataset is not None] + [\n            val_dataset[i] for i in range(val_dataset_length) if val_dataset is not None\n        ]\n        train_indices = list(range(0, train_dataset_length))\n        val_indices = list(range(train_dataset_length, train_dataset_length + val_dataset_length))\n        logger.debug(f\"Train indices: {train_indices}\")\n        logger.debug(f\"Val indices: {val_indices}\")\n\n        store = self.get_store()\n\n        # Currently we only supports a single resource update at the start.\n        initial_resources = self.get_initial_resources()\n        if initial_resources is not None:\n            resource_update = await store.update_resources(\"default\", initial_resources)\n            resources_id = resource_update.resources_id\n            logger.info(f\"Initial resources set: {initial_resources}\")\n        else:\n            logger.warning(\"No initial resources provided. Skip initializing resources.\")\n            resources_id = None\n\n        for epoch in range(self.n_epochs):\n            harvest_tasks: List[asyncio.Task[None]] = []\n            logger.info(f\"Proceeding epoch {epoch + 1}/{self.n_epochs}.\")\n            for index in train_indices + val_indices:\n                logger.info(\n                    f\"Processing index {index}. {len(train_indices)} train indices and {len(val_indices)} val indices in total.\"\n                )\n                while True:\n                    queuing_rollouts = await store.query_rollouts(status=[\"queuing\", \"requeuing\"])\n                    if len(queuing_rollouts) &lt;= self.max_queue_length:\n                        # Only enqueue a new rollout when there is at most \"max_queue_length\" rollout in the queue.\n                        sample = concatenated_dataset[index]\n                        mode = \"train\" if index in train_indices else \"val\"\n                        rollout = await store.enqueue_rollout(input=sample, mode=mode, resources_id=resources_id)\n                        harvest_tasks.append(asyncio.create_task(self._harvest_rollout_spans(rollout.rollout_id)))\n                        logger.info(f\"Enqueued rollout {rollout.rollout_id} in {mode} mode with sample: {sample}\")\n                        break\n                    else:\n                        # Sleep a bit and try again later.\n                        await asyncio.sleep(self.polling_interval)\n\n            # Wait for all harvest tasks to complete\n            logger.info(f\"Waiting for {len(harvest_tasks)} harvest tasks to complete...\")\n            if len(harvest_tasks) &gt; 0:\n                await asyncio.gather(*harvest_tasks)\n</code></pre>"},{"location":"reference/algorithm/#adapter","title":"Adapter","text":""},{"location":"reference/algorithm/#agentlightning.Adapter","title":"<code>agentlightning.Adapter</code>","text":"<p>               Bases: <code>Generic[T_from, T_to]</code></p> <p>Base class for synchronous adapters that convert data from one format to another.</p> <p>This class defines a simple protocol for transformation:</p> <ul> <li>The <code>__call__</code> method makes adapters callable, so they can be used like functions.</li> <li>Subclasses must implement the <code>adapt</code> method to define the actual conversion logic.</li> </ul> <p>Type parameters:</p> <ul> <li>T_from: The source data type (input).</li> <li>T_to: The target data type (output).</li> </ul> <p>Example:</p> <pre><code>&gt;&gt;&gt; class IntToStrAdapter(Adapter[int, str]):\n...     def adapt(self, source: int) -&gt; str:\n...         return str(source)\n...\n&gt;&gt;&gt; adapter = IntToStrAdapter()\n&gt;&gt;&gt; adapter(42)\n'42'\n</code></pre> Source code in <code>agentlightning/adapter/base.py</code> <pre><code>class Adapter(Generic[T_from, T_to]):\n    \"\"\"Base class for synchronous adapters that convert data from one format to another.\n\n    This class defines a simple protocol for transformation:\n\n    - The `__call__` method makes adapters callable, so they can be used like functions.\n    - Subclasses must implement the `adapt` method to define the actual conversion logic.\n\n    Type parameters:\n\n    - T_from: The source data type (input).\n    - T_to: The target data type (output).\n\n    Example:\n\n        &gt;&gt;&gt; class IntToStrAdapter(Adapter[int, str]):\n        ...     def adapt(self, source: int) -&gt; str:\n        ...         return str(source)\n        ...\n        &gt;&gt;&gt; adapter = IntToStrAdapter()\n        &gt;&gt;&gt; adapter(42)\n        '42'\n    \"\"\"\n\n    def __call__(self, source: T_from, /) -&gt; T_to:\n        \"\"\"Convert the data to the target format.\n\n        This method delegates to `adapt` and allows the adapter\n        to be invoked as a function.\n\n        Args:\n            source: Input data in the source format.\n\n        Returns:\n            Data converted to the target format.\n        \"\"\"\n        return self.adapt(source)\n\n    def adapt(self, source: T_from, /) -&gt; T_to:\n        \"\"\"Convert the data to the target format.\n\n        Subclasses should override this method with the concrete\n        transformation logic.\n\n        Args:\n            source: Input data in the source format.\n\n        Returns:\n            Data converted to the target format.\n        \"\"\"\n        raise NotImplementedError(\"Adapter.adapt() is not implemented\")\n</code></pre>"},{"location":"reference/algorithm/#agentlightning.Adapter.__call__","title":"<code>__call__(source)</code>","text":"<p>Convert the data to the target format.</p> <p>This method delegates to <code>adapt</code> and allows the adapter to be invoked as a function.</p> <p>Parameters:</p> Name Type Description Default <code>source</code> <code>T_from</code> <p>Input data in the source format.</p> required <p>Returns:</p> Type Description <code>T_to</code> <p>Data converted to the target format.</p> Source code in <code>agentlightning/adapter/base.py</code> <pre><code>def __call__(self, source: T_from, /) -&gt; T_to:\n    \"\"\"Convert the data to the target format.\n\n    This method delegates to `adapt` and allows the adapter\n    to be invoked as a function.\n\n    Args:\n        source: Input data in the source format.\n\n    Returns:\n        Data converted to the target format.\n    \"\"\"\n    return self.adapt(source)\n</code></pre>"},{"location":"reference/algorithm/#agentlightning.Adapter.adapt","title":"<code>adapt(source)</code>","text":"<p>Convert the data to the target format.</p> <p>Subclasses should override this method with the concrete transformation logic.</p> <p>Parameters:</p> Name Type Description Default <code>source</code> <code>T_from</code> <p>Input data in the source format.</p> required <p>Returns:</p> Type Description <code>T_to</code> <p>Data converted to the target format.</p> Source code in <code>agentlightning/adapter/base.py</code> <pre><code>def adapt(self, source: T_from, /) -&gt; T_to:\n    \"\"\"Convert the data to the target format.\n\n    Subclasses should override this method with the concrete\n    transformation logic.\n\n    Args:\n        source: Input data in the source format.\n\n    Returns:\n        Data converted to the target format.\n    \"\"\"\n    raise NotImplementedError(\"Adapter.adapt() is not implemented\")\n</code></pre>"},{"location":"reference/algorithm/#agentlightning.TraceAdapter","title":"<code>agentlightning.TraceAdapter</code>","text":"<p>               Bases: <code>Adapter[List[Span], T_to]</code>, <code>Generic[T_to]</code></p> <p>Base class for adapters that convert trace spans into other formats.</p> <p>This class specializes <code>Adapter</code> for working with trace spans. It expects a list of Agent-lightning spans as input and produces a custom target format (e.g., reinforcement learning training data, SFT datasets, logs, metrics).</p> Source code in <code>agentlightning/adapter/base.py</code> <pre><code>class TraceAdapter(Adapter[List[Span], T_to], Generic[T_to]):\n    \"\"\"Base class for adapters that convert trace spans into other formats.\n\n    This class specializes `Adapter` for working with trace spans. It expects a list of\n    Agent-lightning spans as input and produces a custom target format\n    (e.g., reinforcement learning training data, SFT datasets, logs, metrics).\n    \"\"\"\n</code></pre>"},{"location":"reference/algorithm/#agentlightning.OtelTraceAdapter","title":"<code>agentlightning.OtelTraceAdapter</code>","text":"<p>               Bases: <code>Adapter[List[ReadableSpan], T_to]</code>, <code>Generic[T_to]</code></p> <p>Base class for adapters that convert OpenTelemetry trace spans into other formats.</p> <p>This class specializes <code>Adapter</code> for working with OpenTelemetry <code>ReadableSpan</code> objects. It expects a list of spans as input and produces a custom target format (e.g., reinforcement learning training data, SFT datasets, logs, metrics).</p> <p>Subclasses should override <code>adapt</code> to define the desired conversion.</p> Example <p>class TraceToDictAdapter(OtelTraceAdapter[dict]): ...     def adapt(self, spans: List[ReadableSpan]) -&gt; dict: ...         return {\"count\": len(spans)} ... adapter = TraceToDictAdapter() adapter([span1, span2])</p> Source code in <code>agentlightning/adapter/base.py</code> <pre><code>class OtelTraceAdapter(Adapter[List[ReadableSpan], T_to], Generic[T_to]):\n    \"\"\"Base class for adapters that convert OpenTelemetry trace spans into other formats.\n\n    This class specializes `Adapter` for working with OpenTelemetry `ReadableSpan`\n    objects. It expects a list of spans as input and produces a custom target format\n    (e.g., reinforcement learning training data, SFT datasets, logs, metrics).\n\n    Subclasses should override `adapt` to define the desired conversion.\n\n    Example:\n        &gt;&gt;&gt; class TraceToDictAdapter(OtelTraceAdapter[dict]):\n        ...     def adapt(self, spans: List[ReadableSpan]) -&gt; dict:\n        ...         return {\"count\": len(spans)}\n        ...\n        &gt;&gt;&gt; adapter = TraceToDictAdapter()\n        &gt;&gt;&gt; adapter([span1, span2])\n        {'count': 2}\n    \"\"\"\n</code></pre>"},{"location":"reference/algorithm/#agentlightning.TraceToTripletBase","title":"<code>agentlightning.TraceToTripletBase</code>","text":"<p>               Bases: <code>TraceAdapter[List[Triplet]]</code></p> <p>Base class for trace triplet adapters.</p> Source code in <code>agentlightning/adapter/triplet.py</code> <pre><code>class TraceToTripletBase(TraceAdapter[List[Triplet]]):\n    \"\"\"\n    Base class for trace triplet adapters.\n    \"\"\"\n</code></pre>"},{"location":"reference/algorithm/#agentlightning.TracerTraceToTriplet","title":"<code>agentlightning.TracerTraceToTriplet</code>","text":"<p>               Bases: <code>TraceToTripletBase</code></p> <p>An adapter to convert OpenTelemetry spans to triplet data.</p> <p>Attributes:</p> Name Type Description <code>repair_hierarchy</code> <p>When <code>repair_hierarchy</code> is set to True, the trace will be repaired with the time information. See <code>TraceTree.repair_hierarchy</code> for more details.</p> <code>llm_call_match</code> <p>Regular expression pattern to match LLM call span names.</p> <code>agent_match</code> <p>Optional regular expression pattern to match agent span names. If None, all agents are matched.</p> <code>exclude_llm_call_in_reward</code> <p>Whether to exclude LLM calls that occur within reward spans.</p> <code>reward_match</code> <p>Policy for matching rewards to LLM calls.</p> Source code in <code>agentlightning/adapter/triplet.py</code> <pre><code>class TracerTraceToTriplet(TraceToTripletBase):\n    \"\"\"\n    An adapter to convert OpenTelemetry spans to triplet data.\n\n    Attributes:\n        repair_hierarchy: When `repair_hierarchy` is set to True, the trace will be repaired with the time information.\n            See `TraceTree.repair_hierarchy` for more details.\n        llm_call_match: Regular expression pattern to match LLM call span names.\n        agent_match: Optional regular expression pattern to match agent span names. If None, all agents are matched.\n        exclude_llm_call_in_reward: Whether to exclude LLM calls that occur within reward spans.\n        reward_match: Policy for matching rewards to LLM calls.\n    \"\"\"\n\n    def __init__(\n        self,\n        repair_hierarchy: bool = True,\n        llm_call_match: str = r\"openai\\.chat\\.completion\",\n        agent_match: Optional[str] = None,\n        exclude_llm_call_in_reward: bool = True,\n        reward_match: RewardMatchPolicy = RewardMatchPolicy.FIRST_OCCURRENCE,\n    ):\n        self.repair_hierarchy = repair_hierarchy\n        self.llm_call_match = llm_call_match\n        self.agent_match = agent_match\n        self.exclude_llm_call_in_reward = exclude_llm_call_in_reward\n        self.reward_match = reward_match\n\n    def visualize(\n        self,\n        source: Union[List[Span], List[ReadableSpan]],\n        /,\n        filename: str = \"trace_tree\",\n        interested_span_match: str | None = None,\n    ) -&gt; TraceTree:\n        \"\"\"\n        Visualize the trace tree.\n\n        Args:\n            source (List[Span]): The list of OpenTelemetry spans to visualize.\n            filename (str): The base filename for the output visualization (default: \"trace_tree\").\n            interested_span_match (str | None): Optional regular expression pattern to highlight or focus on specific spans in the visualization.\n\n        Returns:\n            TraceTree: The constructed trace tree object.\n        \"\"\"\n        source_normalized = [\n            Span.from_opentelemetry(span, \"dummy\", \"dummy\", 0) if isinstance(span, ReadableSpan) else span\n            for span in source\n        ]\n        trace_tree = TraceTree.from_spans(source_normalized)\n        if self.repair_hierarchy:\n            trace_tree.repair_hierarchy()\n        trace_tree.visualize(filename, interested_span_match=interested_span_match)\n        return trace_tree\n\n    def adapt(self, source: Union[List[Span], List[ReadableSpan]], /) -&gt; List[Triplet]:  # type: ignore\n        \"\"\"Convert OpenTelemetry spans to a list of Triplet objects.\"\"\"\n        source_normalized = [\n            Span.from_opentelemetry(span, \"dummy\", \"dummy\", 0) if isinstance(span, ReadableSpan) else span\n            for span in source\n        ]\n        trace_tree = TraceTree.from_spans(source_normalized)\n        if self.repair_hierarchy:\n            trace_tree.repair_hierarchy()\n        trajectory = trace_tree.to_trajectory(\n            llm_call_match=self.llm_call_match,\n            agent_match=self.agent_match,\n            exclude_llm_call_in_reward=self.exclude_llm_call_in_reward,\n            reward_match=self.reward_match,\n        )\n        return trajectory\n</code></pre>"},{"location":"reference/algorithm/#agentlightning.TracerTraceToTriplet.adapt","title":"<code>adapt(source)</code>","text":"<p>Convert OpenTelemetry spans to a list of Triplet objects.</p> Source code in <code>agentlightning/adapter/triplet.py</code> <pre><code>def adapt(self, source: Union[List[Span], List[ReadableSpan]], /) -&gt; List[Triplet]:  # type: ignore\n    \"\"\"Convert OpenTelemetry spans to a list of Triplet objects.\"\"\"\n    source_normalized = [\n        Span.from_opentelemetry(span, \"dummy\", \"dummy\", 0) if isinstance(span, ReadableSpan) else span\n        for span in source\n    ]\n    trace_tree = TraceTree.from_spans(source_normalized)\n    if self.repair_hierarchy:\n        trace_tree.repair_hierarchy()\n    trajectory = trace_tree.to_trajectory(\n        llm_call_match=self.llm_call_match,\n        agent_match=self.agent_match,\n        exclude_llm_call_in_reward=self.exclude_llm_call_in_reward,\n        reward_match=self.reward_match,\n    )\n    return trajectory\n</code></pre>"},{"location":"reference/algorithm/#agentlightning.TracerTraceToTriplet.visualize","title":"<code>visualize(source, /, filename='trace_tree', interested_span_match=None)</code>","text":"<p>Visualize the trace tree.</p> <p>Parameters:</p> Name Type Description Default <code>source</code> <code>List[Span]</code> <p>The list of OpenTelemetry spans to visualize.</p> required <code>filename</code> <code>str</code> <p>The base filename for the output visualization (default: \"trace_tree\").</p> <code>'trace_tree'</code> <code>interested_span_match</code> <code>str | None</code> <p>Optional regular expression pattern to highlight or focus on specific spans in the visualization.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>TraceTree</code> <code>TraceTree</code> <p>The constructed trace tree object.</p> Source code in <code>agentlightning/adapter/triplet.py</code> <pre><code>def visualize(\n    self,\n    source: Union[List[Span], List[ReadableSpan]],\n    /,\n    filename: str = \"trace_tree\",\n    interested_span_match: str | None = None,\n) -&gt; TraceTree:\n    \"\"\"\n    Visualize the trace tree.\n\n    Args:\n        source (List[Span]): The list of OpenTelemetry spans to visualize.\n        filename (str): The base filename for the output visualization (default: \"trace_tree\").\n        interested_span_match (str | None): Optional regular expression pattern to highlight or focus on specific spans in the visualization.\n\n    Returns:\n        TraceTree: The constructed trace tree object.\n    \"\"\"\n    source_normalized = [\n        Span.from_opentelemetry(span, \"dummy\", \"dummy\", 0) if isinstance(span, ReadableSpan) else span\n        for span in source\n    ]\n    trace_tree = TraceTree.from_spans(source_normalized)\n    if self.repair_hierarchy:\n        trace_tree.repair_hierarchy()\n    trace_tree.visualize(filename, interested_span_match=interested_span_match)\n    return trace_tree\n</code></pre>"},{"location":"reference/algorithm/#agentlightning.LlmProxyTraceToTriplet","title":"<code>agentlightning.LlmProxyTraceToTriplet</code>","text":"<p>               Bases: <code>TraceToTripletBase</code></p> <p>Converting telemetry data emitted by the LLM Proxy to triplet data. This adapter is very experimental. Should only be used when the TracerTraceToTriplet does not work at all.</p> <p>IMPORTANT: Do NOT rely on timestamps here. Proxy spans can be emitted from different machines with unsynchronized clocks. We therefore treat <code>sequence_id</code> as the only reliable ordering primitive and perform \"first occurrence\" reward matching using sequence order only.</p> <p>Strategy:</p> <p>1) Sort spans by (sequence_id, start_time). 2) Extract LLM calls that expose prompt/response token IDs from either:    - litellm_request         (sometimes only metadata, ignore if no token ids)    - raw_gen_ai_request      (llm.hosted_vllm. stringified fields) 3) Extract rewards from spans whose attributes contain an AgentOps-style    reward payload or explicit REWARD span. 4) For each reward with sequence R, assign it to the most recent unmatched* LLM call    with sequence &lt; R. Ignore timestamps completely.</p> Source code in <code>agentlightning/adapter/triplet.py</code> <pre><code>class LlmProxyTraceToTriplet(TraceToTripletBase):\n    \"\"\"\n    Converting telemetry data emitted by the LLM Proxy to triplet data.\n    This adapter is very experimental. Should only be used when the TracerTraceToTriplet does not work at all.\n\n    IMPORTANT: Do NOT rely on timestamps here. Proxy spans can be emitted from different\n    machines with unsynchronized clocks. We therefore treat `sequence_id` as the only\n    reliable ordering primitive and perform \"first occurrence\" reward matching using\n    sequence order only.\n\n    Strategy:\n\n    1) Sort spans by (sequence_id, start_time).\n    2) Extract LLM calls that expose prompt/response token IDs from either:\n       - litellm_request         (sometimes only metadata, ignore if no token ids)\n       - raw_gen_ai_request      (llm.hosted_vllm.* stringified fields)\n    3) Extract rewards from spans whose attributes contain an AgentOps-style\n       reward payload or explicit REWARD span.\n    4) For each reward with sequence R, assign it to the most recent *unmatched* LLM call\n       with sequence &lt; R. Ignore timestamps completely.\n    \"\"\"\n\n    def _literal_eval_maybe(self, v: Any) -&gt; Any:\n        import ast\n\n        if isinstance(v, str):\n            try:\n                return ast.literal_eval(v)\n            except Exception:\n                return v\n        return v\n\n    def _extract_tokens_from_raw(self, attrs: Dict[str, Any]) -&gt; Tuple[List[int], List[int]]:\n        \"\"\"Extract token ids from raw_gen_ai_request attributes.\n\n        - llm.hosted_vllm.prompt_token_ids: string -&gt; List[int]\n        - llm.hosted_vllm.response_token_ids: string -&gt; List[List[int]] -&gt; take first\n        - llm.hosted_vllm.choices: string -&gt; [{'token_ids': [...]}] -&gt; take first\n        \"\"\"\n        prompt_ids: List[int] = []\n        resp_ids: List[int] = []\n\n        # prompt\n        p = attrs.get(\"llm.hosted_vllm.prompt_token_ids\")\n        p = self._literal_eval_maybe(p)\n        if isinstance(p, list) and all(isinstance(x, int) for x in p):  # type: ignore\n            prompt_ids = cast(List[int], p)\n\n        # response preferred path\n        r = attrs.get(\"llm.hosted_vllm.response_token_ids\")\n        r = self._literal_eval_maybe(r)\n        if isinstance(r, list) and len(r) &gt; 0 and isinstance(r[0], list):  # type: ignore\n            first = cast(List[Any], r[0])\n            if all(isinstance(x, int) for x in first):\n                resp_ids = cast(List[int], first)\n\n        # fallback via choices\n        if not resp_ids:\n            choices = attrs.get(\"llm.hosted_vllm.choices\")\n            choices = self._literal_eval_maybe(choices)\n            if isinstance(choices, list) and choices:\n                cand = cast(Any, choices[0])\n                if isinstance(cand, dict):\n                    tids = cast(Dict[str, Any], cand).get(\"token_ids\")\n                    if isinstance(tids, list) and all(isinstance(x, int) for x in tids):  # type: ignore\n                        resp_ids = cast(List[int], tids)\n\n        return prompt_ids, resp_ids\n\n    def _extract_tokens_from_openai(self, attrs: Dict[str, Any]) -&gt; Tuple[List[int], List[int]]:\n        prompt_ids = cast(Any, attrs.get(\"prompt_token_ids\") or [])\n        resp_ids = cast(Any, attrs.get(\"response_token_ids\") or [])\n        prompt_ids = self._literal_eval_maybe(prompt_ids)\n        resp_ids = self._literal_eval_maybe(resp_ids)\n        if not (isinstance(prompt_ids, list) and all(isinstance(x, int) for x in prompt_ids)):  # type: ignore\n            prompt_ids = []\n        if not (isinstance(resp_ids, list) and all(isinstance(x, int) for x in resp_ids)):  # type: ignore\n            resp_ids = []\n        return cast(List[int], prompt_ids), cast(List[int], resp_ids)\n\n    def _maybe_reward_value(self, span: Span) -&gt; Optional[float]:\n        \"\"\"\n        Parse reward from typical AgentOps payload or explicit REWARD span.\n        \"\"\"\n        attrs = span.attributes or {}\n\n        # AgentOps new/old keys\n        for k in (\"agentops.task.output\", \"agentops.entity.output\"):\n            v = attrs.get(k)\n            v = self._literal_eval_maybe(v)\n            if isinstance(v, dict) and cast(Dict[str, Any], v).get(\"type\") == \"reward\":\n                rv = cast(Dict[str, Any], v).get(\"value\", None)\n                if rv is None or isinstance(rv, (int, float)):\n                    return None if rv is None else float(rv)\n\n        # Explicit reward span\n        if span.name == SpanNames.REWARD.value:\n            rv = attrs.get(\"reward\", None)\n            if rv is None or isinstance(rv, (int, float)):\n                return None if rv is None else float(rv)\n\n        return None\n\n    def _request_id_from_attrs(self, attrs: Dict[str, Any]) -&gt; Optional[str]:\n        # Prefer OpenAI-like id if present, else proxy raw id.\n        rid = attrs.get(\"gen_ai.response.id\") or attrs.get(\"llm.hosted_vllm.id\")\n        return str(rid) if isinstance(rid, str) and rid else None\n\n    def adapt(self, source: List[Span], /) -&gt; List[Triplet]:  # type: ignore\n        # 1) Sort deterministically by (sequence_id, start_time).\n        spans = sorted(\n            source,\n            key=lambda s: (s.sequence_id, s.start_time),\n        )\n\n        # 2) Collect LLM calls with token IDs.\n        llm_items: List[Dict[str, Any]] = []\n        seen_request_ids: set[str] = set()\n        for s in spans:\n            attrs = s.attributes or {}\n            prompt_ids: List[int] = []\n            resp_ids: List[int] = []\n\n            if s.name == \"raw_gen_ai_request\":\n                prompt_ids, resp_ids = self._extract_tokens_from_raw(attrs)\n            elif s.name == \"litellm_request\":\n                # Some proxies never include token ids here. Ignore unless present.\n                prompt_ids, resp_ids = self._extract_tokens_from_openai(attrs)\n\n            if prompt_ids and resp_ids:\n                rid = self._request_id_from_attrs(attrs)\n                if rid:\n                    # Duplicated request ID. This request is already handled.\n                    if rid in seen_request_ids:\n                        continue\n                    seen_request_ids.add(rid)\n                llm_items.append(\n                    dict(\n                        span=s,\n                        seq=s.sequence_id,\n                        response_ids=resp_ids,\n                        prompt_ids=prompt_ids,\n                        request_id=rid,\n                    )\n                )\n\n        # Order LLM items by sequence only.\n        llm_items.sort(key=lambda x: x[\"seq\"])\n\n        # Collect rewards by sequence only.\n        rewards: List[Tuple[int, Optional[float]]] = []\n        for s in spans:\n            val = self._maybe_reward_value(s)\n            if val is not None:\n                rewards.append((s.sequence_id, val))\n\n        # First-occurrence matching by sequence_id only:\n        # For reward at sequence R, assign to the most recent unmatched LLM with seq &lt; R.\n        assigned: Dict[str, Optional[float]] = {}\n        for r_seq, r_val in sorted(rewards, key=lambda x: x[0]):\n            for item in reversed(llm_items):\n                sid = item[\"span\"].span_id\n                if sid in assigned:\n                    continue\n                if item[\"seq\"] &lt; r_seq:\n                    assigned[sid] = r_val\n                    break\n\n        # Build triplets in LLM sequence order.\n        triplets: List[Triplet] = []\n        for item in llm_items:\n            s = item[\"span\"]\n            triplets.append(\n                Triplet(\n                    prompt={\"token_ids\": item[\"prompt_ids\"]},\n                    response={\"token_ids\": item[\"response_ids\"]},\n                    reward=assigned.get(s.span_id, None),\n                    metadata=dict(\n                        # This is called response_id to align with the other adapters.\n                        response_id=item[\"request_id\"],\n                    ),\n                )\n            )\n\n        return triplets\n</code></pre>"},{"location":"reference/algorithm/#agentlightning.TraceToMessages","title":"<code>agentlightning.TraceToMessages</code>","text":"<p>               Bases: <code>TraceAdapter[List[OpenAIMessages]]</code></p> <p>Adapter that converts OpenTelemetry trace spans into OpenAI-compatible message format.</p> <p>This adapter processes trace spans containing LLM conversation data and transforms them into structured OpenAI message format suitable for fine-tuning or analysis. It extracts prompts, completions, tool calls, and function definitions from trace attributes and reconstructs the conversation flow.</p> <p>The adapter handles: - Converting flat trace attributes into structured message objects - Extracting and matching tool calls with their corresponding requests - Building proper OpenAI ChatCompletionMessage objects with roles, content, and tool calls - Generating function definitions for tools used in conversations</p> Source code in <code>agentlightning/adapter/messages.py</code> <pre><code>class TraceToMessages(TraceAdapter[List[OpenAIMessages]]):\n    \"\"\"\n    Adapter that converts OpenTelemetry trace spans into OpenAI-compatible message format.\n\n    This adapter processes trace spans containing LLM conversation data and transforms them\n    into structured OpenAI message format suitable for fine-tuning or analysis. It extracts\n    prompts, completions, tool calls, and function definitions from trace attributes and\n    reconstructs the conversation flow.\n\n    The adapter handles:\n    - Converting flat trace attributes into structured message objects\n    - Extracting and matching tool calls with their corresponding requests\n    - Building proper OpenAI ChatCompletionMessage objects with roles, content, and tool calls\n    - Generating function definitions for tools used in conversations\n    \"\"\"\n\n    def get_tool_calls(self, completion: Span, all_spans: List[Span], /) -&gt; Iterable[Dict[str, Any]]:\n        \"\"\"Find tool calls in the trace. Returns a dict with the tool call id, name, and arguments.\n\n        The spans that are direct children of the completion span are the tool calls.\n        \"\"\"\n        # Get all the spans that are children of the completion span\n        children = [span for span in all_spans if span.parent_id == completion.span_id]\n        # Get the tool calls from the children\n        for maybe_tool_call in children:\n            tool_call = group_genai_dict(maybe_tool_call.attributes, \"tool\")\n            if not isinstance(tool_call, dict):\n                raise ValueError(f\"Extracted tool call from trace is not a dict: {tool_call}\")\n            if tool_call:\n                yield tool_call\n\n    def adapt(self, source: List[Span], /) -&gt; List[OpenAIMessages]:\n        raw_prompt_completions: List[_RawSpanInfo] = []\n\n        for span in source:\n            attributes = {k: v for k, v in span.attributes.items()}\n\n            # Get all related information from the trace span\n            prompt = group_genai_dict(attributes, \"gen_ai.prompt\") or []\n            completion = group_genai_dict(attributes, \"gen_ai.completion\") or []\n            request = group_genai_dict(attributes, \"gen_ai.request\") or {}\n            response = group_genai_dict(attributes, \"gen_ai.response\") or {}\n            if not isinstance(prompt, list):\n                raise ValueError(f\"Extracted prompt from trace is not a list: {prompt}\")\n            if not isinstance(completion, list):\n                raise ValueError(f\"Extracted completion from trace is not a list: {completion}\")\n            if not isinstance(request, dict):\n                raise ValueError(f\"Extracted request from trace is not a dict: {request}\")\n            if not isinstance(response, dict):\n                raise ValueError(f\"Extracted response from trace is not a dict: {response}\")\n            if prompt or completion or request or response:\n                tools = list(self.get_tool_calls(span, source)) or []\n                raw_prompt_completions.append(\n                    _RawSpanInfo(\n                        prompt=prompt or [], completion=completion, request=request, response=response, tools=tools\n                    )\n                )\n\n        return list(convert_to_openai_messages(raw_prompt_completions))\n</code></pre>"},{"location":"reference/algorithm/#agentlightning.TraceToMessages.get_tool_calls","title":"<code>get_tool_calls(completion, all_spans)</code>","text":"<p>Find tool calls in the trace. Returns a dict with the tool call id, name, and arguments.</p> <p>The spans that are direct children of the completion span are the tool calls.</p> Source code in <code>agentlightning/adapter/messages.py</code> <pre><code>def get_tool_calls(self, completion: Span, all_spans: List[Span], /) -&gt; Iterable[Dict[str, Any]]:\n    \"\"\"Find tool calls in the trace. Returns a dict with the tool call id, name, and arguments.\n\n    The spans that are direct children of the completion span are the tool calls.\n    \"\"\"\n    # Get all the spans that are children of the completion span\n    children = [span for span in all_spans if span.parent_id == completion.span_id]\n    # Get the tool calls from the children\n    for maybe_tool_call in children:\n        tool_call = group_genai_dict(maybe_tool_call.attributes, \"tool\")\n        if not isinstance(tool_call, dict):\n            raise ValueError(f\"Extracted tool call from trace is not a dict: {tool_call}\")\n        if tool_call:\n            yield tool_call\n</code></pre>"},{"location":"reference/algorithm/#llm-proxy","title":"LLM Proxy","text":""},{"location":"reference/algorithm/#agentlightning.LLMProxy","title":"<code>agentlightning.LLMProxy</code>","text":"<p>Host a LiteLLM OpenAI-compatible proxy bound to a LightningStore.</p> <p>The proxy:</p> <ul> <li>Serves an OpenAI-compatible API via uvicorn.</li> <li>Adds rollout/attempt routing and headers via middleware.</li> <li>Registers OTEL export and token-id callbacks.</li> <li>Writes a LiteLLM worker config file with <code>model_list</code> and settings.</li> </ul> <p>Lifecycle:</p> <ul> <li><code>start()</code> writes config, starts uvicorn server in a thread, and waits until ready.</li> <li><code>stop()</code> tears down the server and removes the temp config file.</li> <li><code>restart()</code> convenience wrapper to stop then start.</li> </ul> <p>Usage Note: As the LLM Proxy sets up an OpenTelemetry tracer, it's recommended to run it in a different process from the main runner (i.e., tracer from agents).</p> <p>Parameters:</p> Name Type Description Default <code>port</code> <code>int</code> <p>TCP port to bind.</p> required <code>model_list</code> <code>List[ModelConfig] | None</code> <p>LiteLLM <code>model_list</code> entries.</p> <code>None</code> <code>store</code> <code>Optional[LightningStore]</code> <p>LightningStore used for span sequence and persistence.</p> <code>None</code> <code>host</code> <code>str | None</code> <p>Publicly reachable host used in resource endpoints. Defaults to best-guess IPv4.</p> <code>None</code> <code>litellm_config</code> <code>Dict[str, Any] | None</code> <p>Extra LiteLLM proxy config merged with <code>model_list</code>.</p> <code>None</code> <code>num_retries</code> <code>int</code> <p>Default LiteLLM retry count injected into <code>litellm_settings</code>.</p> <code>0</code> Source code in <code>agentlightning/llm_proxy.py</code> <pre><code>class LLMProxy:\n    \"\"\"Host a LiteLLM OpenAI-compatible proxy bound to a LightningStore.\n\n    The proxy:\n\n    * Serves an OpenAI-compatible API via uvicorn.\n    * Adds rollout/attempt routing and headers via middleware.\n    * Registers OTEL export and token-id callbacks.\n    * Writes a LiteLLM worker config file with ``model_list`` and settings.\n\n    Lifecycle:\n\n    * ``start()`` writes config, starts uvicorn server in a thread, and waits until ready.\n    * ``stop()`` tears down the server and removes the temp config file.\n    * ``restart()`` convenience wrapper to stop then start.\n\n    Usage Note:\n    As the LLM Proxy sets up an OpenTelemetry tracer, it's recommended to run it in a different\n    process from the main runner (i.e., tracer from agents).\n\n    Args:\n        port: TCP port to bind.\n        model_list: LiteLLM ``model_list`` entries.\n        store: LightningStore used for span sequence and persistence.\n        host: Publicly reachable host used in resource endpoints. Defaults to best-guess IPv4.\n        litellm_config: Extra LiteLLM proxy config merged with ``model_list``.\n        num_retries: Default LiteLLM retry count injected into ``litellm_settings``.\n    \"\"\"\n\n    def __init__(\n        self,\n        port: int,\n        model_list: List[ModelConfig] | None = None,\n        store: Optional[LightningStore] = None,\n        host: str | None = None,\n        litellm_config: Dict[str, Any] | None = None,\n        num_retries: int = 0,\n    ):\n        self.store = store\n        self.host = host or _get_default_ipv4_address()\n        self.port = port\n        self.model_list = model_list or []\n        self.litellm_config = litellm_config or {}\n\n        # Ensure num_retries is present inside the litellm_settings block.\n        self.litellm_config.setdefault(\"litellm_settings\", {})\n        self.litellm_config[\"litellm_settings\"].setdefault(\"num_retries\", num_retries)\n\n        self._server_thread = None\n        self._config_file = None\n        self._uvicorn_server = None\n        self._ready_event = threading.Event()\n\n    def set_store(self, store: LightningStore) -&gt; None:\n        \"\"\"Set the store for the proxy.\n\n        Args:\n            store: The store to use for the proxy.\n        \"\"\"\n        self.store = store\n\n    def update_model_list(self, model_list: List[ModelConfig]) -&gt; None:\n        \"\"\"Replace the in-memory model list and hot-restart if running.\n\n        Args:\n            model_list: New list of model entries.\n        \"\"\"\n        self.model_list = model_list\n        logger.info(f\"Updating LLMProxy model list to: {model_list}\")\n        if self.is_running():\n            self.restart()\n        # Do nothing if the server is not running.\n\n    def update_port(self, port: int) -&gt; None:\n        \"\"\"Update the port for the proxy.\n\n        Args:\n            port: The new port to use for the proxy.\n        \"\"\"\n        self.port = port\n\n    def _wait_until_started(self, startup_timeout: float = 20.0):\n        \"\"\"Block until the uvicorn server reports started or timeout.\n\n        Args:\n            startup_timeout: Maximum seconds to wait.\n        \"\"\"\n        start = time.time()\n        while True:\n            if self._uvicorn_server is None:\n                break\n            if self._uvicorn_server.started:\n                self._ready_event.set()\n                break\n            if self._uvicorn_server.should_exit:\n                break\n            if time.time() - start &gt; startup_timeout:\n                break\n            time.sleep(0.01)\n\n    def start(self):\n        \"\"\"Start the proxy server thread and initialize global wiring.\n\n        Side effects:\n\n        * Sets the module-level global store for middleware/exporter access.\n        * Calls ``initialize()`` once to register middleware and callbacks.\n        * Writes a temporary YAML config consumed by LiteLLM worker.\n        * Launches uvicorn in a daemon thread and waits for readiness.\n        \"\"\"\n        if self.is_running():\n            # Trigger restart\n            self.stop()\n\n        if not self.store:\n            raise ValueError(\"Store is not set. Please set the store before starting the LLMProxy.\")\n\n        global _global_store\n\n        _global_store = self.store\n\n        # Initialize global middleware and callbacks once.\n        initialize()\n\n        # Persist a temp worker config for LiteLLM and point the proxy at it.\n        self._config_file = tempfile.NamedTemporaryFile(suffix=\".yaml\", delete=False).name\n        with open(self._config_file, \"w\") as fp:\n            yaml.safe_dump(\n                {\n                    \"model_list\": self.model_list,\n                    **self.litellm_config,\n                },\n                fp,\n            )\n\n        save_worker_config(config=self._config_file)\n\n        # Bind to all interfaces to allow other hosts to reach it if needed.\n        self._uvicorn_server = uvicorn.Server(uvicorn.Config(app, host=\"0.0.0.0\", port=self.port))\n\n        def run_server():\n            # Serve uvicorn in this background thread with its own event loop.\n            assert self._uvicorn_server is not None\n            asyncio.run(self._uvicorn_server.serve())\n\n        logger.info(\"Starting LLMProxy server thread...\")\n        self._ready_event.clear()\n        # FIXME: This thread should either be reused or the whole proxy should live in another process.\n        # Problem 1: in litellm worker, &lt;Queue at 0x70f1d028cd90 maxsize=50000&gt; is bound to a different event loop\n        # Problem 2: Proxy has conflicted opentelemetry setup with the main process.\n        self._server_thread = threading.Thread(target=run_server, daemon=True)\n        self._server_thread.start()\n        self._wait_until_started()\n\n    def stop(self):\n        \"\"\"Stop the proxy server and clean up temporary artifacts.\n\n        This is a best-effort graceful shutdown with a bounded join timeout.\n        \"\"\"\n        if not self.is_running():\n            logger.warning(\"LLMProxy is not running. Nothing to stop.\")\n            return\n\n        # Remove worker config to avoid stale references.\n        if self._config_file and os.path.exists(self._config_file):\n            os.unlink(self._config_file)\n\n        logger.info(\"Stopping LLMProxy server thread...\")\n        stop_success = True\n        if self._server_thread is not None and self._uvicorn_server is not None and self._uvicorn_server.started:\n            self._uvicorn_server.should_exit = True\n            self._server_thread.join(timeout=10.0)  # Allow time for graceful shutdown.\n            if self._server_thread.is_alive():\n                logger.error(\n                    \"LLMProxy server thread is still alive after 10 seconds. Cannot kill it because it's a thread.\"\n                )\n                stop_success = False\n            self._server_thread = None\n            self._uvicorn_server = None\n            self._config_file = None\n            self._ready_event.clear()\n            if not _check_port(self.host, self.port):\n                logger.error(f\"Port {self.port} is still in use. Stopping LLMProxy is not successful.\")\n                stop_success = False\n        if stop_success:\n            logger.info(\"LLMProxy server thread stopped.\")\n        else:\n            logger.error(\"LLMProxy server is not stopped successfully.\")\n\n    def restart(self, *, _port: int | None = None) -&gt; None:\n        \"\"\"Restart the proxy if running, else start it.\n\n        Convenience wrapper calling ``stop()`` followed by ``start()``.\n        \"\"\"\n        logger.info(\"Restarting LLMProxy server...\")\n        if self.is_running():\n            self.stop()\n        if _port is not None:\n            self.port = _port\n        self.start()\n\n    def is_running(self) -&gt; bool:\n        \"\"\"Return whether the uvicorn server is active.\n\n        Returns:\n            bool: True if server was started and did not signal exit.\n        \"\"\"\n        return self._uvicorn_server is not None and self._uvicorn_server.started\n\n    def as_resource(\n        self,\n        rollout_id: str | None = None,\n        attempt_id: str | None = None,\n        model: str | None = None,\n        sampling_parameters: Dict[str, Any] | None = None,\n    ) -&gt; LLM:\n        \"\"\"Create an ``LLM`` resource pointing at this proxy with rollout context.\n\n        The returned endpoint is:\n            ``http://{host}:{port}/rollout/{rollout_id}/attempt/{attempt_id}``\n\n        Args:\n            rollout_id: Rollout identifier used for span attribution. If None, will instantiate a ProxyLLM resource.\n            attempt_id: Attempt identifier used for span attribution. If None, will instantiate a ProxyLLM resource.\n            model: Logical model name to use. If omitted and exactly one model\n                is configured, that model is used.\n            sampling_parameters: Optional default sampling parameters.\n\n        Returns:\n            LLM: Configured resource ready for OpenAI-compatible calls.\n\n        Raises:\n            ValueError: If ``model`` is omitted and zero or multiple models are configured.\n        \"\"\"\n        if model is None:\n            if len(self.model_list) == 1:\n                model = self.model_list[0][\"model_name\"]\n            else:\n                raise ValueError(\n                    f\"Multiple or zero models found in model_list: {self.model_list}. Please specify the model.\"\n                )\n\n        if rollout_id is None and attempt_id is None:\n            return ProxyLLM(\n                endpoint=f\"http://{self.host}:{self.port}\",\n                model=model,\n                sampling_parameters=dict(sampling_parameters or {}),\n            )\n        elif rollout_id is not None and attempt_id is not None:\n            return LLM(\n                endpoint=f\"http://{self.host}:{self.port}/rollout/{rollout_id}/attempt/{attempt_id}\",\n                model=model,\n                sampling_parameters=dict(sampling_parameters or {}),\n            )\n        else:\n            raise ValueError(\"Either rollout_id and attempt_id must be provided, or neither.\")\n</code></pre>"},{"location":"reference/algorithm/#agentlightning.LLMProxy.as_resource","title":"<code>as_resource(rollout_id=None, attempt_id=None, model=None, sampling_parameters=None)</code>","text":"<p>Create an <code>LLM</code> resource pointing at this proxy with rollout context.</p> The returned endpoint is <p><code>http://{host}:{port}/rollout/{rollout_id}/attempt/{attempt_id}</code></p> <p>Parameters:</p> Name Type Description Default <code>rollout_id</code> <code>str | None</code> <p>Rollout identifier used for span attribution. If None, will instantiate a ProxyLLM resource.</p> <code>None</code> <code>attempt_id</code> <code>str | None</code> <p>Attempt identifier used for span attribution. If None, will instantiate a ProxyLLM resource.</p> <code>None</code> <code>model</code> <code>str | None</code> <p>Logical model name to use. If omitted and exactly one model is configured, that model is used.</p> <code>None</code> <code>sampling_parameters</code> <code>Dict[str, Any] | None</code> <p>Optional default sampling parameters.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>LLM</code> <code>LLM</code> <p>Configured resource ready for OpenAI-compatible calls.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If <code>model</code> is omitted and zero or multiple models are configured.</p> Source code in <code>agentlightning/llm_proxy.py</code> <pre><code>def as_resource(\n    self,\n    rollout_id: str | None = None,\n    attempt_id: str | None = None,\n    model: str | None = None,\n    sampling_parameters: Dict[str, Any] | None = None,\n) -&gt; LLM:\n    \"\"\"Create an ``LLM`` resource pointing at this proxy with rollout context.\n\n    The returned endpoint is:\n        ``http://{host}:{port}/rollout/{rollout_id}/attempt/{attempt_id}``\n\n    Args:\n        rollout_id: Rollout identifier used for span attribution. If None, will instantiate a ProxyLLM resource.\n        attempt_id: Attempt identifier used for span attribution. If None, will instantiate a ProxyLLM resource.\n        model: Logical model name to use. If omitted and exactly one model\n            is configured, that model is used.\n        sampling_parameters: Optional default sampling parameters.\n\n    Returns:\n        LLM: Configured resource ready for OpenAI-compatible calls.\n\n    Raises:\n        ValueError: If ``model`` is omitted and zero or multiple models are configured.\n    \"\"\"\n    if model is None:\n        if len(self.model_list) == 1:\n            model = self.model_list[0][\"model_name\"]\n        else:\n            raise ValueError(\n                f\"Multiple or zero models found in model_list: {self.model_list}. Please specify the model.\"\n            )\n\n    if rollout_id is None and attempt_id is None:\n        return ProxyLLM(\n            endpoint=f\"http://{self.host}:{self.port}\",\n            model=model,\n            sampling_parameters=dict(sampling_parameters or {}),\n        )\n    elif rollout_id is not None and attempt_id is not None:\n        return LLM(\n            endpoint=f\"http://{self.host}:{self.port}/rollout/{rollout_id}/attempt/{attempt_id}\",\n            model=model,\n            sampling_parameters=dict(sampling_parameters or {}),\n        )\n    else:\n        raise ValueError(\"Either rollout_id and attempt_id must be provided, or neither.\")\n</code></pre>"},{"location":"reference/algorithm/#agentlightning.LLMProxy.is_running","title":"<code>is_running()</code>","text":"<p>Return whether the uvicorn server is active.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if server was started and did not signal exit.</p> Source code in <code>agentlightning/llm_proxy.py</code> <pre><code>def is_running(self) -&gt; bool:\n    \"\"\"Return whether the uvicorn server is active.\n\n    Returns:\n        bool: True if server was started and did not signal exit.\n    \"\"\"\n    return self._uvicorn_server is not None and self._uvicorn_server.started\n</code></pre>"},{"location":"reference/algorithm/#agentlightning.LLMProxy.restart","title":"<code>restart(*, _port=None)</code>","text":"<p>Restart the proxy if running, else start it.</p> <p>Convenience wrapper calling <code>stop()</code> followed by <code>start()</code>.</p> Source code in <code>agentlightning/llm_proxy.py</code> <pre><code>def restart(self, *, _port: int | None = None) -&gt; None:\n    \"\"\"Restart the proxy if running, else start it.\n\n    Convenience wrapper calling ``stop()`` followed by ``start()``.\n    \"\"\"\n    logger.info(\"Restarting LLMProxy server...\")\n    if self.is_running():\n        self.stop()\n    if _port is not None:\n        self.port = _port\n    self.start()\n</code></pre>"},{"location":"reference/algorithm/#agentlightning.LLMProxy.set_store","title":"<code>set_store(store)</code>","text":"<p>Set the store for the proxy.</p> <p>Parameters:</p> Name Type Description Default <code>store</code> <code>LightningStore</code> <p>The store to use for the proxy.</p> required Source code in <code>agentlightning/llm_proxy.py</code> <pre><code>def set_store(self, store: LightningStore) -&gt; None:\n    \"\"\"Set the store for the proxy.\n\n    Args:\n        store: The store to use for the proxy.\n    \"\"\"\n    self.store = store\n</code></pre>"},{"location":"reference/algorithm/#agentlightning.LLMProxy.start","title":"<code>start()</code>","text":"<p>Start the proxy server thread and initialize global wiring.</p> <p>Side effects:</p> <ul> <li>Sets the module-level global store for middleware/exporter access.</li> <li>Calls <code>initialize()</code> once to register middleware and callbacks.</li> <li>Writes a temporary YAML config consumed by LiteLLM worker.</li> <li>Launches uvicorn in a daemon thread and waits for readiness.</li> </ul> Source code in <code>agentlightning/llm_proxy.py</code> <pre><code>def start(self):\n    \"\"\"Start the proxy server thread and initialize global wiring.\n\n    Side effects:\n\n    * Sets the module-level global store for middleware/exporter access.\n    * Calls ``initialize()`` once to register middleware and callbacks.\n    * Writes a temporary YAML config consumed by LiteLLM worker.\n    * Launches uvicorn in a daemon thread and waits for readiness.\n    \"\"\"\n    if self.is_running():\n        # Trigger restart\n        self.stop()\n\n    if not self.store:\n        raise ValueError(\"Store is not set. Please set the store before starting the LLMProxy.\")\n\n    global _global_store\n\n    _global_store = self.store\n\n    # Initialize global middleware and callbacks once.\n    initialize()\n\n    # Persist a temp worker config for LiteLLM and point the proxy at it.\n    self._config_file = tempfile.NamedTemporaryFile(suffix=\".yaml\", delete=False).name\n    with open(self._config_file, \"w\") as fp:\n        yaml.safe_dump(\n            {\n                \"model_list\": self.model_list,\n                **self.litellm_config,\n            },\n            fp,\n        )\n\n    save_worker_config(config=self._config_file)\n\n    # Bind to all interfaces to allow other hosts to reach it if needed.\n    self._uvicorn_server = uvicorn.Server(uvicorn.Config(app, host=\"0.0.0.0\", port=self.port))\n\n    def run_server():\n        # Serve uvicorn in this background thread with its own event loop.\n        assert self._uvicorn_server is not None\n        asyncio.run(self._uvicorn_server.serve())\n\n    logger.info(\"Starting LLMProxy server thread...\")\n    self._ready_event.clear()\n    # FIXME: This thread should either be reused or the whole proxy should live in another process.\n    # Problem 1: in litellm worker, &lt;Queue at 0x70f1d028cd90 maxsize=50000&gt; is bound to a different event loop\n    # Problem 2: Proxy has conflicted opentelemetry setup with the main process.\n    self._server_thread = threading.Thread(target=run_server, daemon=True)\n    self._server_thread.start()\n    self._wait_until_started()\n</code></pre>"},{"location":"reference/algorithm/#agentlightning.LLMProxy.stop","title":"<code>stop()</code>","text":"<p>Stop the proxy server and clean up temporary artifacts.</p> <p>This is a best-effort graceful shutdown with a bounded join timeout.</p> Source code in <code>agentlightning/llm_proxy.py</code> <pre><code>def stop(self):\n    \"\"\"Stop the proxy server and clean up temporary artifacts.\n\n    This is a best-effort graceful shutdown with a bounded join timeout.\n    \"\"\"\n    if not self.is_running():\n        logger.warning(\"LLMProxy is not running. Nothing to stop.\")\n        return\n\n    # Remove worker config to avoid stale references.\n    if self._config_file and os.path.exists(self._config_file):\n        os.unlink(self._config_file)\n\n    logger.info(\"Stopping LLMProxy server thread...\")\n    stop_success = True\n    if self._server_thread is not None and self._uvicorn_server is not None and self._uvicorn_server.started:\n        self._uvicorn_server.should_exit = True\n        self._server_thread.join(timeout=10.0)  # Allow time for graceful shutdown.\n        if self._server_thread.is_alive():\n            logger.error(\n                \"LLMProxy server thread is still alive after 10 seconds. Cannot kill it because it's a thread.\"\n            )\n            stop_success = False\n        self._server_thread = None\n        self._uvicorn_server = None\n        self._config_file = None\n        self._ready_event.clear()\n        if not _check_port(self.host, self.port):\n            logger.error(f\"Port {self.port} is still in use. Stopping LLMProxy is not successful.\")\n            stop_success = False\n    if stop_success:\n        logger.info(\"LLMProxy server thread stopped.\")\n    else:\n        logger.error(\"LLMProxy server is not stopped successfully.\")\n</code></pre>"},{"location":"reference/algorithm/#agentlightning.LLMProxy.update_model_list","title":"<code>update_model_list(model_list)</code>","text":"<p>Replace the in-memory model list and hot-restart if running.</p> <p>Parameters:</p> Name Type Description Default <code>model_list</code> <code>List[ModelConfig]</code> <p>New list of model entries.</p> required Source code in <code>agentlightning/llm_proxy.py</code> <pre><code>def update_model_list(self, model_list: List[ModelConfig]) -&gt; None:\n    \"\"\"Replace the in-memory model list and hot-restart if running.\n\n    Args:\n        model_list: New list of model entries.\n    \"\"\"\n    self.model_list = model_list\n    logger.info(f\"Updating LLMProxy model list to: {model_list}\")\n    if self.is_running():\n        self.restart()\n</code></pre>"},{"location":"reference/algorithm/#agentlightning.LLMProxy.update_port","title":"<code>update_port(port)</code>","text":"<p>Update the port for the proxy.</p> <p>Parameters:</p> Name Type Description Default <code>port</code> <code>int</code> <p>The new port to use for the proxy.</p> required Source code in <code>agentlightning/llm_proxy.py</code> <pre><code>def update_port(self, port: int) -&gt; None:\n    \"\"\"Update the port for the proxy.\n\n    Args:\n        port: The new port to use for the proxy.\n    \"\"\"\n    self.port = port\n</code></pre>"},{"location":"reference/algorithm/#agentlightning.llm_proxy.ModelConfig","title":"<code>agentlightning.llm_proxy.ModelConfig</code>","text":"<p>               Bases: <code>TypedDict</code></p> <p>LiteLLM model registration entry.</p> <p>This mirrors the items in LiteLLM's <code>model_list</code> section.</p> <p>Attributes:</p> Name Type Description <code>model_name</code> <code>str</code> <p>Logical model name exposed by the proxy.</p> <code>litellm_params</code> <code>Dict[str, Any]</code> <p>Parameters passed to LiteLLM for this model (e.g., backend model id, api_base, additional options).</p> Source code in <code>agentlightning/llm_proxy.py</code> <pre><code>class ModelConfig(TypedDict):\n    \"\"\"LiteLLM model registration entry.\n\n    This mirrors the items in LiteLLM's ``model_list`` section.\n\n    Attributes:\n        model_name: Logical model name exposed by the proxy.\n        litellm_params: Parameters passed to LiteLLM for this model\n            (e.g., backend model id, api_base, additional options).\n    \"\"\"  # Google style kept concise.\n\n    model_name: str\n    litellm_params: Dict[str, Any]\n</code></pre>"},{"location":"reference/algorithm/#agentlightning.llm_proxy.LightningSpanExporter","title":"<code>agentlightning.llm_proxy.LightningSpanExporter</code>","text":"<p>               Bases: <code>SpanExporter</code></p> <p>Buffered OTEL span exporter with subtree flushing and training-store sink.</p> <p>Design:</p> <ul> <li>Spans are buffered until a root span's entire subtree is available.</li> <li>A private event loop on a daemon thread runs async flush logic.</li> <li>Rollout/attempt/sequence metadata is reconstructed by merging headers   from any span within a subtree.</li> </ul> <p>Thread-safety:</p> <ul> <li>Buffer access is protected by a re-entrant lock.</li> <li>Export is synchronous to the caller yet schedules an async flush on the   internal loop, then waits for completion.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>store</code> <code>Optional[LightningStore]</code> <p>Optional explicit LightningStore. If None, uses <code>get_global_store()</code>.</p> <code>None</code> Source code in <code>agentlightning/llm_proxy.py</code> <pre><code>class LightningSpanExporter(SpanExporter):\n    \"\"\"Buffered OTEL span exporter with subtree flushing and training-store sink.\n\n    Design:\n\n    * Spans are buffered until a root span's entire subtree is available.\n    * A private event loop on a daemon thread runs async flush logic.\n    * Rollout/attempt/sequence metadata is reconstructed by merging headers\n      from any span within a subtree.\n\n    Thread-safety:\n\n    * Buffer access is protected by a re-entrant lock.\n    * Export is synchronous to the caller yet schedules an async flush on the\n      internal loop, then waits for completion.\n\n    Args:\n        store: Optional explicit LightningStore. If None, uses ``get_global_store()``.\n    \"\"\"\n\n    def __init__(self, store: Optional[LightningStore] = None):\n        self._store = store\n        self._buffer: List[ReadableSpan] = []\n        self._lock: Optional[threading.RLock] = None\n\n        # Single dedicated event loop running in a daemon thread.\n        # This decouples OTEL SDK threads from our async store I/O.\n        # Deferred creation until first use.\n        self._loop: Optional[asyncio.AbstractEventLoop] = None\n        self._loop_thread: Optional[threading.Thread] = None\n\n    def _ensure_loop(self) -&gt; asyncio.AbstractEventLoop:\n        \"\"\"Lazily initialize the event loop and thread on first use.\n\n        Returns:\n            asyncio.AbstractEventLoop: The initialized event loop.\n        \"\"\"\n        if self._loop is None:\n            self._loop = asyncio.new_event_loop()\n            self._loop_thread = threading.Thread(target=self._run_loop, name=\"LightningSpanExporterLoop\", daemon=True)\n            self._loop_thread.start()\n        return self._loop\n\n    def _ensure_lock(self) -&gt; threading.RLock:\n        \"\"\"Lazily initialize the lock on first use.\n\n        Returns:\n            threading.RLock: The initialized lock.\n        \"\"\"\n        if self._lock is None:\n            self._lock = threading.RLock()\n        return self._lock\n\n    def _get_store(self) -&gt; LightningStore:\n        \"\"\"Return the LightningStore to use.\n\n        Returns:\n            LightningStore: Explicit store if provided, else the global store.\n\n        Raises:\n            ValueError: If no global store is configured and no explicit store was given.\n        \"\"\"\n        if self._store is None:\n            return get_global_store()\n        return self._store\n\n    def _run_loop(self) -&gt; None:\n        \"\"\"Run the private asyncio loop forever on the exporter thread.\"\"\"\n        assert self._loop is not None, \"Loop should be initialized before thread starts\"\n        asyncio.set_event_loop(self._loop)\n        self._loop.run_forever()\n\n    def shutdown(self) -&gt; None:\n        \"\"\"Shut down the exporter event loop.\n\n        Safe to call at process exit.\n\n        \"\"\"\n        if self._loop is None:\n            return\n\n        try:\n\n            def _stop():\n                assert self._loop is not None\n                self._loop.stop()\n\n            self._loop.call_soon_threadsafe(_stop)\n            if self._loop_thread is not None:\n                self._loop_thread.join(timeout=2.0)\n            self._loop.close()\n        except Exception:\n            logger.exception(\"Error during exporter shutdown\")\n\n    def export(self, spans: Sequence[ReadableSpan]) -&gt; SpanExportResult:\n        \"\"\"Export spans via buffered subtree flush.\n\n        Appends spans to the internal buffer, then triggers an async flush on the\n        private event loop. Blocks until that flush completes.\n\n        Args:\n            spans: Sequence of spans to export.\n\n        Returns:\n            SpanExportResult: SUCCESS on flush success, else FAILURE.\n        \"\"\"\n        # Buffer append under lock to protect against concurrent exporters.\n        with self._ensure_lock():\n            for span in spans:\n                self._buffer.append(span)\n\n        # Run the async flush on our private loop, synchronously from caller's POV.\n        async def _locked_flush():\n            # Take the lock inside the coroutine to serialize with other flushes.\n            with self._ensure_lock():\n                return await self._maybe_flush()\n\n        try:\n            loop = self._ensure_loop()\n            fut = asyncio.run_coroutine_threadsafe(_locked_flush(), loop)\n            fut.result()  # Bubble up any exceptions from the coroutine.\n        except Exception as e:\n            logger.exception(\"Export flush failed: %s\", e)\n            return SpanExportResult.FAILURE\n\n        return SpanExportResult.SUCCESS\n\n    async def _maybe_flush(self):\n        \"\"\"Flush ready subtrees from the buffer.\n\n        Strategy:\n            We consider a subtree \"ready\" if we can identify a root span. We\n            then take that root and all its descendants out of the buffer and\n            try to reconstruct rollout/attempt/sequence headers by merging any\n            span's ``metadata.requester_custom_headers`` within the subtree.\n\n        Required headers:\n            ``x-rollout-id`` (str), ``x-attempt-id`` (str), ``x-sequence-id`` (str of int)\n\n        Raises:\n            None directly. Logs and skips malformed spans.\n\n        \"\"\"\n        # Iterate over current roots. Each iteration pops a whole subtree.\n        for root_span_id in self._get_root_span_ids():\n            subtree_spans = self._pop_subtrees(root_span_id)\n            if not subtree_spans:\n                continue\n\n            # Merge all custom headers found in the subtree.\n            headers_merged: Dict[str, Any] = {}\n\n            for span in subtree_spans:\n                if span.attributes is None:\n                    continue\n                headers_str = span.attributes.get(\"metadata.requester_custom_headers\")\n                if headers_str is None:\n                    continue\n                if not isinstance(headers_str, str):\n                    logger.error(\n                        f\"metadata.requester_custom_headers is not stored as a string: {headers_str}. Skipping the span.\"\n                    )\n                    continue\n                try:\n                    # Use literal_eval to parse the stringified dict safely.\n                    headers = ast.literal_eval(headers_str)\n                except Exception as e:\n                    logger.error(\n                        f\"Failed to parse metadata.requester_custom_headers: {headers_str}, error: {e}. Skipping the span.\"\n                    )\n                    continue\n                if not isinstance(headers, dict):\n                    logger.error(\n                        f\"metadata.requester_custom_headers is not parsed as a dict: {headers}. Skipping the span.\"\n                    )\n                    continue\n                headers_merged.update(cast(Dict[str, Any], headers))\n\n            if not headers_merged:\n                logger.warning(f\"No headers found in {len(subtree_spans)} subtree spans. Cannot log to store.\")\n                continue\n\n            # Validate and normalize required header fields.\n            rollout_id = headers_merged.get(\"x-rollout-id\")\n            attempt_id = headers_merged.get(\"x-attempt-id\")\n            sequence_id = headers_merged.get(\"x-sequence-id\")\n            if not rollout_id or not attempt_id or not sequence_id or not sequence_id.isdigit():\n                logger.warning(\n                    f\"Missing or invalid rollout_id, attempt_id, or sequence_id in headers: {headers_merged}. Cannot log to store.\"\n                )\n                continue\n            if not isinstance(rollout_id, str) or not isinstance(attempt_id, str):\n                logger.warning(\n                    f\"rollout_id or attempt_id is not a string: {rollout_id}, {attempt_id}. Cannot log to store.\"\n                )\n                continue\n            sequence_id_decimal = int(sequence_id)\n\n            # Persist each span in the subtree with the resolved identifiers.\n            for span in subtree_spans:\n                await self._get_store().add_otel_span(\n                    rollout_id=rollout_id, attempt_id=attempt_id, sequence_id=sequence_id_decimal, readable_span=span\n                )\n\n    def _get_root_span_ids(self) -&gt; Iterable[int]:\n        \"\"\"Yield span_ids for root spans currently in the buffer.\n\n        A root span is defined as one with ``parent is None``.\n\n        Yields:\n            int: Span id for each root span found.\n        \"\"\"\n        for span in self._buffer:\n            if span.parent is None:\n                span_context = span.get_span_context()\n                if span_context is not None:\n                    yield span_context.span_id\n\n    def _get_subtrees(self, root_span_id: int) -&gt; Iterable[int]:\n        \"\"\"Yield span_ids in the subtree rooted at ``root_span_id``.\n\n        Depth-first traversal over the current buffer.\n\n        Args:\n            root_span_id: The span id of the root.\n\n        Yields:\n            int: Span ids including the root and all descendants found.\n        \"\"\"\n        # Yield the root span id first.\n        yield root_span_id\n        for span in self._buffer:\n            # Check whether the span's parent is the root_span_id.\n            if span.parent is not None and span.parent.span_id == root_span_id:\n                span_context = span.get_span_context()\n                if span_context is not None:\n                    # Recursively get child spans.\n                    yield from self._get_subtrees(span_context.span_id)\n\n    def _pop_subtrees(self, root_span_id: int) -&gt; List[ReadableSpan]:\n        \"\"\"Remove and return the subtree for a particular root from the buffer.\n\n        Args:\n            root_span_id: Root span id identifying the subtree.\n\n        Returns:\n            list[ReadableSpan]: Spans that were part of the subtree. Order follows buffer order.\n        \"\"\"\n        subtree_span_ids = set(self._get_subtrees(root_span_id))\n        subtree_spans: List[ReadableSpan] = []\n        new_buffer: List[ReadableSpan] = []\n        for span in self._buffer:\n            span_context = span.get_span_context()\n            if span_context is not None and span_context.span_id in subtree_span_ids:\n                subtree_spans.append(span)\n            else:\n                new_buffer.append(span)\n        # Replace buffer with remaining spans to avoid re-processing.\n        self._buffer = new_buffer\n        return subtree_spans\n</code></pre>"},{"location":"reference/algorithm/#agentlightning.llm_proxy.LightningSpanExporter.export","title":"<code>export(spans)</code>","text":"<p>Export spans via buffered subtree flush.</p> <p>Appends spans to the internal buffer, then triggers an async flush on the private event loop. Blocks until that flush completes.</p> <p>Parameters:</p> Name Type Description Default <code>spans</code> <code>Sequence[ReadableSpan]</code> <p>Sequence of spans to export.</p> required <p>Returns:</p> Name Type Description <code>SpanExportResult</code> <code>SpanExportResult</code> <p>SUCCESS on flush success, else FAILURE.</p> Source code in <code>agentlightning/llm_proxy.py</code> <pre><code>def export(self, spans: Sequence[ReadableSpan]) -&gt; SpanExportResult:\n    \"\"\"Export spans via buffered subtree flush.\n\n    Appends spans to the internal buffer, then triggers an async flush on the\n    private event loop. Blocks until that flush completes.\n\n    Args:\n        spans: Sequence of spans to export.\n\n    Returns:\n        SpanExportResult: SUCCESS on flush success, else FAILURE.\n    \"\"\"\n    # Buffer append under lock to protect against concurrent exporters.\n    with self._ensure_lock():\n        for span in spans:\n            self._buffer.append(span)\n\n    # Run the async flush on our private loop, synchronously from caller's POV.\n    async def _locked_flush():\n        # Take the lock inside the coroutine to serialize with other flushes.\n        with self._ensure_lock():\n            return await self._maybe_flush()\n\n    try:\n        loop = self._ensure_loop()\n        fut = asyncio.run_coroutine_threadsafe(_locked_flush(), loop)\n        fut.result()  # Bubble up any exceptions from the coroutine.\n    except Exception as e:\n        logger.exception(\"Export flush failed: %s\", e)\n        return SpanExportResult.FAILURE\n\n    return SpanExportResult.SUCCESS\n</code></pre>"},{"location":"reference/algorithm/#agentlightning.llm_proxy.LightningSpanExporter.shutdown","title":"<code>shutdown()</code>","text":"<p>Shut down the exporter event loop.</p> <p>Safe to call at process exit.</p> Source code in <code>agentlightning/llm_proxy.py</code> <pre><code>def shutdown(self) -&gt; None:\n    \"\"\"Shut down the exporter event loop.\n\n    Safe to call at process exit.\n\n    \"\"\"\n    if self._loop is None:\n        return\n\n    try:\n\n        def _stop():\n            assert self._loop is not None\n            self._loop.stop()\n\n        self._loop.call_soon_threadsafe(_stop)\n        if self._loop_thread is not None:\n            self._loop_thread.join(timeout=2.0)\n        self._loop.close()\n    except Exception:\n        logger.exception(\"Error during exporter shutdown\")\n</code></pre>"},{"location":"reference/algorithm/#agentlightning.llm_proxy.AddReturnTokenIds","title":"<code>agentlightning.llm_proxy.AddReturnTokenIds</code>","text":"<p>               Bases: <code>CustomLogger</code></p> <p>LiteLLM logger hook to request token ids from vLLM.</p> <p>This mutates the outgoing request payload to include <code>return_token_ids=True</code> for backends that support token id return (e.g., vLLM).</p> See <p>https://github.com/vllm-project/vllm/pull/22587</p> Source code in <code>agentlightning/llm_proxy.py</code> <pre><code>class AddReturnTokenIds(CustomLogger):\n    \"\"\"LiteLLM logger hook to request token ids from vLLM.\n\n    This mutates the outgoing request payload to include ``return_token_ids=True``\n    for backends that support token id return (e.g., vLLM).\n\n    See:\n        https://github.com/vllm-project/vllm/pull/22587\n    \"\"\"\n\n    async def async_pre_call_hook(self, *args: Any, **kwargs: Any) -&gt; Optional[Union[Exception, str, Dict[str, Any]]]:\n        \"\"\"Async pre-call hook to adjust request payload.\n\n        Args:\n            args: Positional args from LiteLLM.\n            kwargs: Keyword args from LiteLLM.\n\n        Returns:\n            Either an updated payload dict or an Exception to short-circuit.\n        \"\"\"\n        try:\n            data = _get_pre_call_data(args, kwargs)\n        except Exception as e:\n            return e\n\n        # Ensure token ids are requested from the backend when supported.\n        return {**data, \"return_token_ids\": True}\n</code></pre>"},{"location":"reference/algorithm/#agentlightning.llm_proxy.AddReturnTokenIds.async_pre_call_hook","title":"<code>async_pre_call_hook(*args, **kwargs)</code>  <code>async</code>","text":"<p>Async pre-call hook to adjust request payload.</p> <p>Parameters:</p> Name Type Description Default <code>args</code> <code>Any</code> <p>Positional args from LiteLLM.</p> <code>()</code> <code>kwargs</code> <code>Any</code> <p>Keyword args from LiteLLM.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Optional[Union[Exception, str, Dict[str, Any]]]</code> <p>Either an updated payload dict or an Exception to short-circuit.</p> Source code in <code>agentlightning/llm_proxy.py</code> <pre><code>async def async_pre_call_hook(self, *args: Any, **kwargs: Any) -&gt; Optional[Union[Exception, str, Dict[str, Any]]]:\n    \"\"\"Async pre-call hook to adjust request payload.\n\n    Args:\n        args: Positional args from LiteLLM.\n        kwargs: Keyword args from LiteLLM.\n\n    Returns:\n        Either an updated payload dict or an Exception to short-circuit.\n    \"\"\"\n    try:\n        data = _get_pre_call_data(args, kwargs)\n    except Exception as e:\n        return e\n\n    # Ensure token ids are requested from the backend when supported.\n    return {**data, \"return_token_ids\": True}\n</code></pre>"},{"location":"reference/cli/","title":"Command Line Interface","text":"<p>Warning</p> <p>This document is a work in progress and might not be updated with the latest changes. Try to use <code>agl -h</code> to get the latest help message.</p> <p>Tip</p> <p>Agent-lightning also provides utilities to help you build your own CLI for LitAgent and Trainer. See Trainer for references.</p>"},{"location":"reference/cli/#agl","title":"agl","text":"<pre><code>usage: agl [-h] {vllm,store,agentops}\n\nAgent Lightning CLI entry point.\n\nAvailable subcommands:\n  vllm      Run the vLLM CLI with Agent Lightning instrumentation.\n  store     Run a LightningStore server.\n  agentops  Start the AgentOps server manager.\n\npositional arguments:\n  {vllm,store,agentops}\n                        Subcommand to run.\n\noptions:\n  -h, --help            show this help message and exit\n</code></pre>"},{"location":"reference/cli/#agl-vllm","title":"agl vllm","text":"<p>Agent-lightning's instrumented vLLM CLI.</p> <pre><code>usage: agl vllm [-h] [-v] {chat,complete,serve,bench,collect-env,run-batch} ...\n\nvLLM CLI\n\npositional arguments:\n  {chat,complete,serve,bench,collect-env,run-batch}\n    chat                Generate chat completions via the running API server.\n    complete            Generate text completions based on the given prompt via the running API server.\n    collect-env         Start collecting environment information.\n    run-batch           Run batch prompts and write results to file.\n\noptions:\n  -h, --help            show this help message and exit\n  -v, --version         show program's version number and exit\n\nFor full list:            vllm [subcommand] --help=all\nFor a section:            vllm [subcommand] --help=ModelConfig    (case-insensitive)\nFor a flag:               vllm [subcommand] --help=max-model-len  (_ or - accepted)\nDocumentation:            https://docs.vllm.ai\n</code></pre>"},{"location":"reference/cli/#agl-store","title":"agl store","text":"<p>Agent-lightning's LightningStore CLI. Use it to start an independent LightningStore server.</p> <p>Currently the store data are stored in memory and will be lost when the server is stopped.</p> <pre><code>usage: agl store [-h] [--port PORT]\n\nRun a LightningStore server\n\noptions:\n  -h, --help   show this help message and exit\n  --port PORT  Port to run the server on\n</code></pre>"},{"location":"reference/cli/#agl-agentops","title":"agl agentops","text":"<p>Start a mock AgentOps server to bypass the online service of AgentOps.</p> <pre><code>usage: agl agentops [-h] [--daemon] [--port PORT]\n\nStart AgentOps server\n\noptions:\n  -h, --help   show this help message and exit\n  --daemon     Run server as a daemon\n  --port PORT  Port to run the server on\n</code></pre>"},{"location":"reference/instrumentation/","title":"Instrumentation API","text":""},{"location":"reference/instrumentation/#agentlightning.instrumentation.instrument_all","title":"<code>agentlightning.instrumentation.instrument_all()</code>","text":"<p>Instrument all the instrumentation libraries.</p> Source code in <code>agentlightning/instrumentation/__init__.py</code> <pre><code>def instrument_all():\n    \"\"\"Instrument all the instrumentation libraries.\"\"\"\n    if AGENTOPS_INSTALLED:\n        from .agentops import instrument_agentops\n\n        instrument_agentops()\n    else:\n        warnings.warn(\"agentops is not installed. It's therefore not instrumented.\")\n\n    if LITELLM_INSTALLED:\n        from .litellm import instrument_litellm\n\n        instrument_litellm()\n    else:\n        warnings.warn(\"litellm is not installed. It's therefore not instrumented.\")\n\n    if VLLM_INSTALLED:\n        from .vllm import instrument_vllm\n\n        instrument_vllm()\n    else:\n        warnings.warn(\"vllm is not installed. It's therefore not instrumented.\")\n\n    if AGENTOPS_LANGCHAIN_INSTALLED:\n        from .agentops_langchain import instrument_agentops_langchain\n\n        instrument_agentops_langchain()\n    else:\n        warnings.warn(\"Agentops-langchain integration is not installed. It's therefore not instrumented.\")\n</code></pre>"},{"location":"reference/instrumentation/#agentlightning.instrumentation.uninstrument_all","title":"<code>agentlightning.instrumentation.uninstrument_all()</code>","text":"<p>Uninstrument all the instrumentation libraries.</p> Source code in <code>agentlightning/instrumentation/__init__.py</code> <pre><code>def uninstrument_all():\n    \"\"\"Uninstrument all the instrumentation libraries.\"\"\"\n    if AGENTOPS_INSTALLED:\n        try:\n            from .agentops import uninstrument_agentops\n\n            uninstrument_agentops()\n        except ImportError:\n            warnings.warn(\"agentops is installed but uninstrument_agentops could not be imported.\")\n    else:\n        warnings.warn(\"agentops is not installed. It's therefore not uninstrumented.\")\n\n    if LITELLM_INSTALLED:\n        try:\n            from .litellm import uninstrument_litellm\n\n            uninstrument_litellm()\n        except ImportError:\n            warnings.warn(\"litellm is installed but uninstrument_litellm could not be imported.\")\n    else:\n        warnings.warn(\"litellm is not installed. It's therefore not uninstrumented.\")\n\n    if VLLM_INSTALLED:\n        try:\n            from .vllm import uninstrument_vllm\n\n            uninstrument_vllm()\n        except ImportError:\n            warnings.warn(\"vllm is installed but uninstrument_vllm could not be imported.\")\n    else:\n        warnings.warn(\"vllm is not installed. It's therefore not uninstrumented.\")\n\n    if AGENTOPS_LANGCHAIN_INSTALLED:\n        try:\n            from .agentops_langchain import uninstrument_agentops_langchain\n\n            uninstrument_agentops_langchain()\n        except ImportError:\n            warnings.warn(\"agentops_langchain is installed but uninstrument_agentops_langchain could not be imported.\")\n    else:\n        warnings.warn(\"Agentops-langchain integration is not installed. It's therefore not uninstrumented.\")\n</code></pre>"},{"location":"reference/instrumentation/#agentops-langchain","title":"AgentOps LangChain","text":""},{"location":"reference/instrumentation/#agentlightning.instrumentation.agentops_langchain","title":"<code>agentlightning.instrumentation.agentops_langchain</code>","text":""},{"location":"reference/instrumentation/#agentlightning.instrumentation.agentops_langchain.instrument_agentops_langchain","title":"<code>instrument_agentops_langchain()</code>","text":"<p>Bypass AgentOp's native support for Langchain.</p> Source code in <code>agentlightning/instrumentation/agentops_langchain.py</code> <pre><code>def instrument_agentops_langchain():\n    \"\"\"Bypass AgentOp's native support for Langchain.\"\"\"\n    global langgraph_entry\n    langgraph_entry = instrumentation.AGENTIC_LIBRARIES.pop(\"langgraph\", None)\n    LangchainCallbackHandler.on_chain_start = on_chain_start\n</code></pre>"},{"location":"reference/instrumentation/#agentlightning.instrumentation.agentops_langchain.uninstrument_agentops_langchain","title":"<code>uninstrument_agentops_langchain()</code>","text":"<p>Restore AgentOp's native support for Langchain.</p> Source code in <code>agentlightning/instrumentation/agentops_langchain.py</code> <pre><code>def uninstrument_agentops_langchain():\n    \"\"\"Restore AgentOp's native support for Langchain.\"\"\"\n    global langgraph_entry\n    if langgraph_entry is not None:\n        instrumentation.AGENTIC_LIBRARIES[\"langgraph\"] = langgraph_entry\n        langgraph_entry = None\n    LangchainCallbackHandler.on_chain_start = original_on_chain_start\n</code></pre>"},{"location":"reference/instrumentation/#agentops","title":"AgentOps","text":""},{"location":"reference/instrumentation/#agentlightning.instrumentation.agentops","title":"<code>agentlightning.instrumentation.agentops</code>","text":""},{"location":"reference/instrumentation/#agentlightning.instrumentation.agentops.AgentOpsServerManager","title":"<code>AgentOpsServerManager</code>","text":"<p>Manages a AgentOps local server to bypass the online service of AgentOps.</p> Source code in <code>agentlightning/instrumentation/agentops.py</code> <pre><code>class AgentOpsServerManager:\n    \"\"\"Manages a AgentOps local server to bypass the online service of AgentOps.\"\"\"\n\n    def __init__(self, daemon: bool = True, port: int | None = None):\n        self.server_process: multiprocessing.Process | None = None\n        self.server_port = port\n        self.daemon = daemon\n        logger.info(\"AgentOpsServerManager initialized.\")\n\n    def _find_available_port(self) -&gt; int:\n        with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n            s.bind((\"\", 0))\n            return s.getsockname()[1]\n\n    def start(self):\n        if self.server_process and self.server_process.is_alive():\n            logger.warning(\"AgentOps server process appears to be already running.\")\n            return\n\n        if self.server_port is None:\n            self.server_port = self._find_available_port()\n\n        logger.info(f\"Starting AgentOps local server on port {self.server_port}...\")\n\n        self.server_process = multiprocessing.Process(\n            target=_run_server,\n            kwargs={\"host\": \"127.0.0.1\", \"port\": self.server_port, \"use_reloader\": False, \"debug\": False},\n            daemon=self.daemon,\n            name=\"AgentLightning-AgentOpsServer\",\n        )\n        self.server_process.start()\n        logger.info(\n            f\"AgentOps local server process (PID: {self.server_process.pid}) started, targeting port {self.server_port}.\"\n        )\n        time.sleep(0.5)  # Brief wait for server to start up\n        if not self.server_process.is_alive():\n            logger.error(f\"AgentOps local server failed to start or exited prematurely.\")\n\n    def is_alive(self) -&gt; bool:\n        if self.server_process and self.server_process.is_alive():\n            return True\n        return False\n\n    def stop(self):\n        if self.server_process is not None and self.server_process.is_alive():\n            logger.info(f\"Stopping AgentOps local server (PID: {self.server_process.pid})...\")\n            self.server_process.terminate()  # Send SIGTERM\n            self.server_process.join(timeout=5)  # Wait for clean exit\n            if self.server_process.is_alive():\n                logger.warning(\n                    f\"AgentOps server (PID: {self.server_process.pid}) did not terminate gracefully, killing...\"\n                )\n                self.server_process.kill()  # Force kill\n                self.server_process.join(timeout=10)  # Wait for kill\n            self.server_process = None\n            logger.info(f\"AgentOps local server stopped.\")\n        else:\n            logger.info(\"AgentOps local server was not running or already stopped.\")\n\n    def get_port(self) -&gt; int | None:\n        # Check liveness again in case it died since start()\n        if self.is_alive() and self.server_port is not None:\n            return self.server_port\n        # If called after server stopped or failed, port might be stale or None\n        if self.server_port is not None and (self.server_process is None or not self.server_process.is_alive()):\n            logger.warning(\n                f\"AgentOps server port {self.server_port} is stored, but server process is not alive. Returning stored port.\"\n            )\n        return self.server_port\n</code></pre>"},{"location":"reference/instrumentation/#agentlightning.instrumentation.agentops.agentops_local_server","title":"<code>agentops_local_server()</code>","text":"<p>Returns a Flask app that can be used to test agentops integration. This server provides endpoints for token fetching and a catch-all endpoint.</p> Source code in <code>agentlightning/instrumentation/agentops.py</code> <pre><code>def agentops_local_server():\n    \"\"\"\n    Returns a Flask app that can be used to test agentops integration.\n    This server provides endpoints for token fetching and a catch-all endpoint.\n    \"\"\"\n    app = flask.Flask(__name__)\n\n    @app.route(\"/v3/auth/token\", methods=[\"POST\"])\n    def fetch_token():  # type: ignore\n        return {\"token\": \"dummy\", \"project_id\": \"dummy\"}\n\n    @app.route(\"/\", defaults={\"path\": \"\"}, methods=[\"GET\", \"POST\"])\n    @app.route(\"/&lt;path:path&gt;\", methods=[\"GET\", \"POST\"])\n    def catch_all(path: str):  # type: ignore\n        return {\"path\": path}\n\n    return app\n</code></pre>"},{"location":"reference/instrumentation/#agentlightning.instrumentation.agentops.instrument_agentops","title":"<code>instrument_agentops()</code>","text":"<p>Instrument agentops to capture token IDs. Automatically detects and uses the appropriate patching method based on the installed agentops version.</p> Source code in <code>agentlightning/instrumentation/agentops.py</code> <pre><code>def instrument_agentops():\n    \"\"\"\n    Instrument agentops to capture token IDs.\n    Automatically detects and uses the appropriate patching method based on the installed agentops version.\n    \"\"\"\n    # Try newest version first (tested for 0.4.16)\n    try:\n        return _patch_new_agentops()\n    except ImportError as e:\n        logger.debug(f\"Couldn't patch newer version of agentops: {str(e)}\")\n\n    # Note: 0.4.15 needs another patching method, but it's too shortlived to be worth handling separately.\n\n    # Try older version (tested for 0.4.13)\n    try:\n        return _patch_old_agentops()\n    except ImportError as e:\n        logger.warning(f\"Couldn't patch older version of agentops: {str(e)}\")\n        logger.error(\"Failed to instrument agentops - neither patching method was successful\")\n        return False\n</code></pre>"},{"location":"reference/instrumentation/#agentlightning.instrumentation.agentops.uninstrument_agentops","title":"<code>uninstrument_agentops()</code>","text":"<p>Uninstrument agentops to stop capturing token IDs.</p> Source code in <code>agentlightning/instrumentation/agentops.py</code> <pre><code>def uninstrument_agentops():\n    \"\"\"Uninstrument agentops to stop capturing token IDs.\"\"\"\n    try:\n        _unpatch_new_agentops()\n    except Exception:\n        pass\n    try:\n        _unpatch_old_agentops()\n    except Exception:\n        pass\n</code></pre>"},{"location":"reference/instrumentation/#litellm","title":"LiteLLM","text":""},{"location":"reference/instrumentation/#agentlightning.instrumentation.litellm","title":"<code>agentlightning.instrumentation.litellm</code>","text":"<p>LiteLLM instrumentations.</p> <p>It's unclear whether or not this file is useful. It seems that LiteLLM owns its own telemetry from their own entrance https://docs.litellm.ai/docs/observability/agentops_integration</p>"},{"location":"reference/instrumentation/#agentlightning.instrumentation.litellm.instrument_litellm","title":"<code>instrument_litellm()</code>","text":"<p>Instrument litellm to capture token IDs.</p> Source code in <code>agentlightning/instrumentation/litellm.py</code> <pre><code>def instrument_litellm():\n    \"\"\"Instrument litellm to capture token IDs.\"\"\"\n    OpenTelemetry.set_attributes = patched_set_attributes\n</code></pre>"},{"location":"reference/instrumentation/#agentlightning.instrumentation.litellm.uninstrument_litellm","title":"<code>uninstrument_litellm()</code>","text":"<p>Uninstrument litellm to stop capturing token IDs.</p> Source code in <code>agentlightning/instrumentation/litellm.py</code> <pre><code>def uninstrument_litellm():\n    \"\"\"Uninstrument litellm to stop capturing token IDs.\"\"\"\n    OpenTelemetry.set_attributes = original_set_attributes\n</code></pre>"},{"location":"reference/instrumentation/#vllm","title":"vLLM","text":""},{"location":"reference/instrumentation/#agentlightning.instrumentation.vllm","title":"<code>agentlightning.instrumentation.vllm</code>","text":""},{"location":"reference/instrumentation/#agentlightning.instrumentation.vllm.instrument_vllm","title":"<code>instrument_vllm()</code>","text":"<p>Instrument vLLM to capture token IDs generated by engine.</p> <p>This instrumentation has been merged to upstream vLLM since v0.10.2.</p> Source code in <code>agentlightning/instrumentation/vllm.py</code> <pre><code>def instrument_vllm():\n    \"\"\"Instrument vLLM to capture token IDs generated by engine.\n\n    This instrumentation has been merged to upstream vLLM since v0.10.2.\n    \"\"\"\n    if vllm.entrypoints.openai.protocol.ChatCompletionResponse is ChatCompletionResponsePatched:\n        warnings.warn(\"vllm is already instrumented. Skip the instrumentation.\")\n        return\n\n    vllm.entrypoints.openai.protocol.ChatCompletionResponse = ChatCompletionResponsePatched\n    OpenAIServingChat.chat_completion_full_generator = chat_completion_full_generator\n</code></pre>"},{"location":"reference/instrumentation/#agentlightning.instrumentation.vllm.uninstrument_vllm","title":"<code>uninstrument_vllm()</code>","text":"<p>Uninstrument vLLM to stop capturing token IDs generated by engine.</p> Source code in <code>agentlightning/instrumentation/vllm.py</code> <pre><code>def uninstrument_vllm():\n    \"\"\"Uninstrument vLLM to stop capturing token IDs generated by engine.\"\"\"\n    OpenAIServingChat.chat_completion_full_generator = original_chat_completion_full_generator\n</code></pre>"},{"location":"reference/runner/","title":"Runner-side References","text":"<p>Note</p> <p>This reference covers APIs that are designed to be used at \"Runner Side\".</p>"},{"location":"reference/runner/#runners","title":"Runners","text":""},{"location":"reference/runner/#agentlightning.LitAgentRunner","title":"<code>agentlightning.LitAgentRunner</code>","text":"<p>               Bases: <code>Runner[T_task]</code></p> <p>Runner implementation for executing agent tasks with distributed support.</p> <p>This runner manages the complete lifecycle of agent rollout execution, including task polling, resource management, tracing, and hooks. It supports both continuous iteration over tasks from the store and single-step execution.</p> <p>Attributes:</p> Name Type Description <code>worker_id</code> <code>Optional[int]</code> <p>The unique identifier for this worker process.</p> Source code in <code>agentlightning/runner/agent.py</code> <pre><code>class LitAgentRunner(Runner[T_task]):\n    \"\"\"Runner implementation for executing agent tasks with distributed support.\n\n    This runner manages the complete lifecycle of agent rollout execution,\n    including task polling, resource management, tracing, and hooks. It supports\n    both continuous iteration over tasks from the store and single-step execution.\n\n    Attributes:\n        worker_id: The unique identifier for this worker process.\n    \"\"\"\n\n    def __init__(self, tracer: Tracer, max_rollouts: Optional[int] = None, poll_interval: float = 5.0) -&gt; None:\n        \"\"\"Initialize the agent runner.\n\n        Args:\n            tracer: The tracer instance for recording execution traces and spans.\n            max_rollouts: Maximum number of tasks to process in iter() mode. If None,\n                the runner will continue indefinitely until interrupted.\n            poll_interval: Time in seconds to wait between polling attempts when\n                no tasks are available in the store.\n        \"\"\"\n        super().__init__()\n        self._tracer = tracer\n        self._max_rollouts = max_rollouts\n        self._poll_interval = poll_interval\n\n        # Set later\n        self._agent: Optional[LitAgent[T_task]] = None\n        self._hooks: Sequence[Hook] = []\n        self._store: Optional[LightningStore] = None\n        self.worker_id: Optional[int] = None\n\n    def init(self, agent: LitAgent[T_task], *, hooks: Optional[Sequence[Hook]] = None, **kwargs: Any) -&gt; None:\n        \"\"\"Initialize the runner with the agent.\n\n        This sets up the agent-runner relationship, registers hooks, and\n        initializes the tracer.\n\n        Args:\n            agent: The LitAgent instance to be managed by this runner.\n            hooks: Optional sequence of Hook objects to be called at various\n                lifecycle stages (on_trace_start, on_trace_end, on_rollout_start,\n                on_rollout_end).\n            **kwargs: Additional initialization arguments (currently unused).\n        \"\"\"\n        self._agent = agent\n        self._agent.set_runner(self)\n        self._hooks = [*hooks] if hooks is not None else []\n\n        self._tracer.init()\n\n    def init_worker(self, worker_id: int, store: LightningStore, **kwargs: Any) -&gt; None:\n        \"\"\"Initialize the runner for each worker with worker_id and store.\n\n        This method is called once per worker in a distributed setup to provide\n        the worker with its ID and store connection.\n\n        Args:\n            worker_id: Unique identifier for this worker process.\n            store: The LightningStore instance for task coordination and data persistence.\n            **kwargs: Additional worker-specific initialization arguments (currently unused).\n        \"\"\"\n        self._store = store\n        self.worker_id = worker_id\n\n        self._tracer.init_worker(worker_id)\n\n    def teardown(self, *args: Any, **kwargs: Any) -&gt; None:\n        \"\"\"Teardown the runner and clean up all resources.\n\n        This method resets all internal state including the agent, store,\n        hooks, and worker ID, and calls the tracer's teardown method.\n\n        Args:\n            *args: Additional teardown arguments (currently unused).\n            **kwargs: Additional teardown keyword arguments (currently unused).\n        \"\"\"\n        self._agent = None\n        self._store = None\n        self.worker_id = None\n        self._hooks = []\n\n        self._tracer.teardown()\n\n    def teardown_worker(self, worker_id: int, *args: Any, **kwargs: Any) -&gt; None:\n        \"\"\"Teardown the runner for a specific worker.\n\n        This method cleans up worker-specific resources and resets the worker ID.\n\n        Args:\n            worker_id: The unique identifier of the worker being torn down.\n            *args: Additional teardown arguments (currently unused).\n            **kwargs: Additional teardown keyword arguments (currently unused).\n        \"\"\"\n        self.worker_id = None\n\n        self._tracer.teardown_worker(worker_id)\n\n    @property\n    def tracer(self) -&gt; Tracer:\n        \"\"\"Get the tracer instance.\n\n        Returns:\n            The Tracer instance used by this runner.\n        \"\"\"\n        return self._tracer\n\n    def get_agent(self) -&gt; LitAgent[T_task]:\n        \"\"\"Get the agent instance.\n\n        Returns:\n            The LitAgent instance managed by this runner.\n\n        Raises:\n            ValueError: If the agent has not been initialized via init().\n        \"\"\"\n        if self._agent is None:\n            raise ValueError(\"Agent not initialized. Call init() first.\")\n        return self._agent\n\n    def get_store(self) -&gt; LightningStore:\n        \"\"\"Get the store instance.\n\n        Returns:\n            The LightningStore instance for this worker.\n\n        Raises:\n            ValueError: If the store has not been initialized via init_worker().\n        \"\"\"\n        if self._store is None:\n            raise ValueError(\"Store not initialized. Call init_worker() first.\")\n        return self._store\n\n    def get_worker_id(self) -&gt; str:\n        \"\"\"Get the formatted worker ID string.\n\n        Returns:\n            A formatted string like \"Worker-0\" if initialized, or \"Worker-Unknown\"\n            if the worker ID has not been set.\n        \"\"\"\n        return f\"Worker-{self.worker_id}\" if self.worker_id is not None else \"Worker-Unknown\"\n\n    def _log_prefix(self, rollout_id: Optional[str] = None) -&gt; str:\n        \"\"\"Generate a standardized log prefix for the current worker.\n\n        This creates a consistent prefix format for log messages to identify\n        which worker and rollout the message is associated with.\n\n        Args:\n            rollout_id: Optional rollout ID to include in the prefix.\n\n        Returns:\n            A formatted log prefix string like \"[Worker 0 | Rollout xyz]\",\n            \"[Worker 0]\", \"[Rollout xyz]\", or \"[Default Worker]\".\n        \"\"\"\n        if self.worker_id is not None:\n            if rollout_id:\n                return f\"[Worker {self.worker_id} | Rollout {rollout_id}]\"\n            else:\n                return f\"[Worker {self.worker_id}]\"\n        if rollout_id:\n            return f\"[Rollout {rollout_id}]\"\n        return \"[Default Worker]\"\n\n    async def _trigger_hooks(\n        self,\n        hook_type: Literal[\"on_trace_start\", \"on_trace_end\", \"on_rollout_start\", \"on_rollout_end\"],\n        *args: Any,\n        **kwargs: Any,\n    ) -&gt; None:\n        \"\"\"Trigger all registered hooks of a specific type.\n\n        This method calls the specified hook method on all registered hooks,\n        catching and logging any exceptions that occur during hook execution\n        to prevent them from disrupting the main execution flow.\n\n        Args:\n            hook_type: The type of hook to trigger. Valid values are:\n                \"on_trace_start\", \"on_trace_end\", \"on_rollout_start\", \"on_rollout_end\".\n            *args: Positional arguments to pass to the hook methods.\n            **kwargs: Keyword arguments to pass to the hook methods.\n        \"\"\"\n        for hook in self._hooks:\n            try:\n                await getattr(hook, hook_type)(*args, **kwargs)\n            except Exception:\n                logger.exception(f\"{self._log_prefix()} Exception during {hook_type} hook {hook}.\")\n\n    async def _post_process_rollout_result(\n        self, rollout: AttemptedRollout, raw_result: RolloutRawResult\n    ) -&gt; List[ReadableSpan] | List[Span]:\n        \"\"\"Standardizes the agent's return value and report what's needed to report to the store.\n\n        Args:\n            rollout: The rollout object for the current task.\n            raw_result: The output from the agent's rollout method.\n\n        Returns:\n            The spans that are assumed to be added to the store.\n            This only serves as an estimation for logging purposes. For precise tracking, use the store directly.\n        \"\"\"\n        store = self.get_store()\n\n        trace_spans: list[ReadableSpan] | list[Span] = []\n\n        # Case 0: result is None\n        if raw_result is None:\n            trace_spans = self._tracer.get_last_trace()\n\n        # Case 1: result is a float (final reward)\n        if isinstance(raw_result, float):\n            # Preserve the existing spans before another span is emitted\n            trace_spans = list(self._tracer.get_last_trace())\n            # This will emit another span to the tracer\n            reward_span = emit_reward(raw_result)\n            await store.add_otel_span(rollout.rollout_id, rollout.attempt.attempt_id, reward_span)\n            trace_spans.append(reward_span)\n\n        if isinstance(raw_result, list):\n            # For rollout methods that return a list, we assume that the returned spans\n            # are the complete span set from the whole rollout\n            trace_spans = raw_result\n\n            # Case 2: result is a list of ReadableSpan (OpenTelemetry spans)\n            if len(raw_result) &gt; 0 and all(isinstance(t, ReadableSpan) for t in raw_result):\n\n                if not isinstance(\n                    self._tracer, AgentOpsTracer\n                ):  # TODO: this should be replaced with general OpenTelemetry tracer in next version\n                    for span in raw_result:\n                        await store.add_otel_span(\n                            rollout.rollout_id, rollout.attempt.attempt_id, cast(ReadableSpan, span)\n                        )\n                else:\n                    logger.warning(\n                        f\"{self._log_prefix(rollout.rollout_id)} Tracer is already an OpenTelemetry tracer. \"\n                        \"The traces should have already been added to the store. \"\n                        \"No need to return anything from rollout.\"\n                    )\n\n            # Case 3: result is a list of Span (agentlightning spans)\n            elif len(raw_result) &gt; 0 and all(isinstance(t, Span) for t in raw_result):\n                # Add the spans directly to the store\n                for span in raw_result:\n                    await store.add_span(cast(Span, span))\n                trace_spans = raw_result\n\n            # Left over cases for list\n            elif len(raw_result) == 0:\n                logger.warning(\n                    f\"{self._log_prefix(rollout.rollout_id)} The rollout returns an empty list. \"\n                    \"Please check your rollout implementation.\"\n                )\n                trace_spans = raw_result\n\n            else:\n                types = [type(t).__name__ for t in raw_result][:10]\n                raise ValueError(\n                    f\"Invalid raw result type. It's expected to be a list of ReadableSpan or Span, \"\n                    f\"but got: {', '.join(types)}...\"\n                )\n\n        return trace_spans\n\n    async def _sleep_until_next_poll(self, event: Optional[ExecutionEvent] = None) -&gt; None:\n        \"\"\"Sleep until the next poll interval, with optional event-based interruption.\n\n        If an event is provided, the method will check it periodically (every 0.1s)\n        and return early if the event is set.\n\n        Args:\n            event: Optional ExecutionEvent object that can be used to interrupt the sleep.\n                If set during the sleep period, the method returns immediately.\n        \"\"\"\n        if event is None:\n            await asyncio.sleep(self._poll_interval)\n            return\n        current_time = time.time()\n        next_time = current_time + self._poll_interval\n        while time.time() &lt; next_time:\n            await asyncio.sleep(0.1)\n            if event.is_set():\n                return\n\n    async def _step_impl(self, next_rollout: AttemptedRollout, raise_on_exception: bool = False) -&gt; str:\n        \"\"\"Execute a single rollout implementation.\n\n        This is the core method that handles the execution of a single rollout,\n        including resource fetching, hook triggering, agent invocation, tracing,\n        and result processing.\n\n        Args:\n            next_rollout: The rollout to execute, containing input data, mode,\n                and resources information.\n            raise_on_exception: If True, exceptions during rollout execution will\n                be re-raised. If False, exceptions are logged but not propagated.\n        \"\"\"\n        store = self.get_store()\n        agent = self.get_agent()\n\n        rollout_id = next_rollout.rollout_id\n\n        resources_id = next_rollout.resources_id\n        resources_update = None\n        if resources_id:\n            resources_update = await store.get_resources_by_id(resources_id)\n        else:\n            logger.debug(f\"{self._log_prefix(rollout_id)} No 'resources_id'. Fetching latest resources.\")\n            resources_update = await store.get_latest_resources()\n        if not resources_update:\n            if raise_on_exception:\n                raise RuntimeError(f\"{self._log_prefix(rollout_id)} Failed to fetch resources\")\n            else:\n                logger.error(f\"{self._log_prefix(rollout_id)} Failed to fetch resources. Skipping.\")\n                return rollout_id\n\n        trace_spans: List[ReadableSpan] | List[Span] = []\n        has_exception: bool = False\n\n        try:\n            await self._trigger_hooks(hook_type=\"on_rollout_start\", agent=agent, runner=self, rollout=next_rollout)\n\n            start_time = time.time()\n            async with self._tracer.trace_context(\n                name=rollout_id, store=store, rollout_id=rollout_id, attempt_id=next_rollout.attempt.attempt_id\n            ):\n                await self._trigger_hooks(\n                    hook_type=\"on_trace_start\", agent=agent, runner=self, tracer=self._tracer, rollout=next_rollout\n                )\n\n                # NOTE: This is the most costly step in the whole function\n                # If the rollout method becomes unresponsive or timeouts, there is nothing we can do within the runner.\n                # We might need some mechanisms in execution strategy to restart the runner. But that's a future work.\n                if agent.is_async():\n                    rollout_method = (\n                        agent.training_rollout_async if next_rollout.mode == \"train\" else agent.validation_rollout_async\n                    )\n                    result = await rollout_method(\n                        next_rollout.input, resources=resources_update.resources, rollout=next_rollout\n                    )\n                else:\n                    rollout_method = (\n                        agent.training_rollout if next_rollout.mode == \"train\" else agent.validation_rollout\n                    )\n                    result = rollout_method(\n                        next_rollout.input, resources=resources_update.resources, rollout=next_rollout\n                    )\n\n                await self._trigger_hooks(\n                    hook_type=\"on_trace_end\", agent=agent, runner=self, tracer=self._tracer, rollout=next_rollout\n                )\n\n            # Possible exceptions in post_process will be caught in the overall exception handler\n            trace_spans = await self._post_process_rollout_result(next_rollout, result)\n            last_reward = find_final_reward(trace_spans)\n\n            end_time = time.time()\n            logger.info(\n                f\"{self._log_prefix(rollout_id)} Completed in \"\n                f\"{end_time - start_time:.2f}s. Collected {len(trace_spans)} span(s). \"\n                f\"Final reward: {last_reward}\"\n            )\n\n        except Exception:\n            logger.exception(f\"{self._log_prefix(rollout_id)} Exception during rollout.\")\n            has_exception = True\n\n            if raise_on_exception:\n                raise\n        finally:\n            try:\n                await self._trigger_hooks(\n                    hook_type=\"on_rollout_end\", agent=agent, runner=self, rollout=next_rollout, spans=trace_spans\n                )\n            except Exception:\n                logger.exception(f\"{self._log_prefix(rollout_id)} Exception during on_rollout_end hook.\")\n\n            try:\n                if has_exception:\n                    # possibly timed out and cancelled?\n                    await store.update_attempt(rollout_id, next_rollout.attempt.attempt_id, status=\"failed\")\n                else:\n                    await store.update_attempt(rollout_id, next_rollout.attempt.attempt_id, status=\"succeeded\")\n            except Exception:\n                logger.exception(\n                    f\"{self._log_prefix(rollout_id)} Exception during update_attempt. Giving up the update.\"\n                )\n\n        return rollout_id\n\n    async def iter(self, *, event: Optional[ExecutionEvent] = None) -&gt; None:\n        \"\"\"Run the runner, continuously iterating over tasks in the store.\n\n        This method polls the store for new rollouts and executes them until:\n        - The event is set (if provided)\n        - The max_rollouts limit is reached (if configured)\n        - No more tasks are available\n\n        All exceptions during rollout execution are caught and logged but not\n        propagated, allowing the runner to continue processing subsequent tasks.\n\n        Args:\n            event: Optional ExecutionEvent object to signal the runner to stop. The runner\n                will check this event periodically and stop gracefully when set.\n        \"\"\"\n        num_tasks_processed = 0\n        logger.info(f\"{self._log_prefix()} Started async rollouts (max: {self._max_rollouts or 'unlimited'}).\")\n        store = self.get_store()\n\n        while not (event is not None and event.is_set()) and (\n            self._max_rollouts is None or num_tasks_processed &lt; self._max_rollouts\n        ):\n            # Retrieve the next rollout\n            next_rollout: Optional[Rollout] = None\n            while not (event is not None and event.is_set()):\n                logger.debug(f\"{self._log_prefix()} Try to poll for next rollout.\")\n                next_rollout = await store.dequeue_rollout()\n                if next_rollout is None:\n                    logger.debug(f\"{self._log_prefix()} No rollout to poll. Waiting for {self._poll_interval} seconds.\")\n                    await self._sleep_until_next_poll(event)\n                else:\n                    break\n\n            if next_rollout is None:\n                return\n\n            try:\n                # Claim the rollout but updating the current worker id\n                await store.update_attempt(\n                    next_rollout.rollout_id, next_rollout.attempt.attempt_id, worker_id=self.get_worker_id()\n                )\n            except Exception:\n                # This exception could happen if the rollout is dequeued and the other end died for some reason\n                logger.exception(f\"{self._log_prefix()} Exception during update_attempt, giving up the rollout.\")\n                continue\n\n            # Execute the step\n            await self._step_impl(next_rollout)\n\n            num_tasks_processed += 1\n            if num_tasks_processed % 10 == 0 or num_tasks_processed == 1:\n                logger.info(f\"{self._log_prefix()} Progress: {num_tasks_processed}/{self._max_rollouts or 'unlimited'}\")\n\n        logger.info(f\"{self._log_prefix()} Finished async rollouts. Processed {num_tasks_processed} tasks.\")\n\n    async def step(\n        self,\n        input: T_task,\n        *,\n        resources: Optional[NamedResources] = None,\n        mode: Optional[RolloutMode] = None,\n        event: Optional[ExecutionEvent] = None,\n    ) -&gt; Rollout:\n        \"\"\"Execute a single task directly, bypassing the task queue.\n\n        This method creates a new rollout for the given input and executes it\n        immediately. Unlike iter(), exceptions are propagated to the caller.\n\n        Args:\n            input: The task input to be processed by the agent.\n            resources: Optional named resources to be used for this specific task.\n                If provided, a new resources entry will be created in the store.\n                If not provided, the latest resources from the store will be used.\n            mode: Optional rollout mode (\"train\" or \"validation\"). If not provided,\n                the agent's default mode will be used.\n            event: Optional ExecutionEvent object to signal interruption (currently unused\n                but included for interface consistency).\n\n        Returns:\n            The completed rollout.\n\n        Raises:\n            Exception: Any exception that occurs during rollout execution will be\n                re-raised to the caller.\n        \"\"\"\n        store = self.get_store()\n\n        if resources is not None:\n            resources_update = await store.add_resources(resources)\n            resources_id = resources_update.resources_id\n        else:\n            resources_id = None\n\n        attempted_rollout = await self.get_store().start_rollout(input=input, mode=mode, resources_id=resources_id)\n        rollout_id = await self._step_impl(attempted_rollout, raise_on_exception=True)\n\n        completed_rollout = await store.get_rollout_by_id(rollout_id)\n        if completed_rollout is None:\n            raise RuntimeError(f\"{self._log_prefix()} Failed to fetch completed rollout by id after step: {rollout_id}\")\n        return completed_rollout\n</code></pre>"},{"location":"reference/runner/#agentlightning.LitAgentRunner.tracer","title":"<code>tracer</code>  <code>property</code>","text":"<p>Get the tracer instance.</p> <p>Returns:</p> Type Description <code>Tracer</code> <p>The Tracer instance used by this runner.</p>"},{"location":"reference/runner/#agentlightning.LitAgentRunner.__init__","title":"<code>__init__(tracer, max_rollouts=None, poll_interval=5.0)</code>","text":"<p>Initialize the agent runner.</p> <p>Parameters:</p> Name Type Description Default <code>tracer</code> <code>Tracer</code> <p>The tracer instance for recording execution traces and spans.</p> required <code>max_rollouts</code> <code>Optional[int]</code> <p>Maximum number of tasks to process in iter() mode. If None, the runner will continue indefinitely until interrupted.</p> <code>None</code> <code>poll_interval</code> <code>float</code> <p>Time in seconds to wait between polling attempts when no tasks are available in the store.</p> <code>5.0</code> Source code in <code>agentlightning/runner/agent.py</code> <pre><code>def __init__(self, tracer: Tracer, max_rollouts: Optional[int] = None, poll_interval: float = 5.0) -&gt; None:\n    \"\"\"Initialize the agent runner.\n\n    Args:\n        tracer: The tracer instance for recording execution traces and spans.\n        max_rollouts: Maximum number of tasks to process in iter() mode. If None,\n            the runner will continue indefinitely until interrupted.\n        poll_interval: Time in seconds to wait between polling attempts when\n            no tasks are available in the store.\n    \"\"\"\n    super().__init__()\n    self._tracer = tracer\n    self._max_rollouts = max_rollouts\n    self._poll_interval = poll_interval\n\n    # Set later\n    self._agent: Optional[LitAgent[T_task]] = None\n    self._hooks: Sequence[Hook] = []\n    self._store: Optional[LightningStore] = None\n    self.worker_id: Optional[int] = None\n</code></pre>"},{"location":"reference/runner/#agentlightning.LitAgentRunner.get_agent","title":"<code>get_agent()</code>","text":"<p>Get the agent instance.</p> <p>Returns:</p> Type Description <code>LitAgent[T_task]</code> <p>The LitAgent instance managed by this runner.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the agent has not been initialized via init().</p> Source code in <code>agentlightning/runner/agent.py</code> <pre><code>def get_agent(self) -&gt; LitAgent[T_task]:\n    \"\"\"Get the agent instance.\n\n    Returns:\n        The LitAgent instance managed by this runner.\n\n    Raises:\n        ValueError: If the agent has not been initialized via init().\n    \"\"\"\n    if self._agent is None:\n        raise ValueError(\"Agent not initialized. Call init() first.\")\n    return self._agent\n</code></pre>"},{"location":"reference/runner/#agentlightning.LitAgentRunner.get_store","title":"<code>get_store()</code>","text":"<p>Get the store instance.</p> <p>Returns:</p> Type Description <code>LightningStore</code> <p>The LightningStore instance for this worker.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the store has not been initialized via init_worker().</p> Source code in <code>agentlightning/runner/agent.py</code> <pre><code>def get_store(self) -&gt; LightningStore:\n    \"\"\"Get the store instance.\n\n    Returns:\n        The LightningStore instance for this worker.\n\n    Raises:\n        ValueError: If the store has not been initialized via init_worker().\n    \"\"\"\n    if self._store is None:\n        raise ValueError(\"Store not initialized. Call init_worker() first.\")\n    return self._store\n</code></pre>"},{"location":"reference/runner/#agentlightning.LitAgentRunner.get_worker_id","title":"<code>get_worker_id()</code>","text":"<p>Get the formatted worker ID string.</p> <p>Returns:</p> Type Description <code>str</code> <p>A formatted string like \"Worker-0\" if initialized, or \"Worker-Unknown\"</p> <code>str</code> <p>if the worker ID has not been set.</p> Source code in <code>agentlightning/runner/agent.py</code> <pre><code>def get_worker_id(self) -&gt; str:\n    \"\"\"Get the formatted worker ID string.\n\n    Returns:\n        A formatted string like \"Worker-0\" if initialized, or \"Worker-Unknown\"\n        if the worker ID has not been set.\n    \"\"\"\n    return f\"Worker-{self.worker_id}\" if self.worker_id is not None else \"Worker-Unknown\"\n</code></pre>"},{"location":"reference/runner/#agentlightning.LitAgentRunner.init","title":"<code>init(agent, *, hooks=None, **kwargs)</code>","text":"<p>Initialize the runner with the agent.</p> <p>This sets up the agent-runner relationship, registers hooks, and initializes the tracer.</p> <p>Parameters:</p> Name Type Description Default <code>agent</code> <code>LitAgent[T_task]</code> <p>The LitAgent instance to be managed by this runner.</p> required <code>hooks</code> <code>Optional[Sequence[Hook]]</code> <p>Optional sequence of Hook objects to be called at various lifecycle stages (on_trace_start, on_trace_end, on_rollout_start, on_rollout_end).</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional initialization arguments (currently unused).</p> <code>{}</code> Source code in <code>agentlightning/runner/agent.py</code> <pre><code>def init(self, agent: LitAgent[T_task], *, hooks: Optional[Sequence[Hook]] = None, **kwargs: Any) -&gt; None:\n    \"\"\"Initialize the runner with the agent.\n\n    This sets up the agent-runner relationship, registers hooks, and\n    initializes the tracer.\n\n    Args:\n        agent: The LitAgent instance to be managed by this runner.\n        hooks: Optional sequence of Hook objects to be called at various\n            lifecycle stages (on_trace_start, on_trace_end, on_rollout_start,\n            on_rollout_end).\n        **kwargs: Additional initialization arguments (currently unused).\n    \"\"\"\n    self._agent = agent\n    self._agent.set_runner(self)\n    self._hooks = [*hooks] if hooks is not None else []\n\n    self._tracer.init()\n</code></pre>"},{"location":"reference/runner/#agentlightning.LitAgentRunner.init_worker","title":"<code>init_worker(worker_id, store, **kwargs)</code>","text":"<p>Initialize the runner for each worker with worker_id and store.</p> <p>This method is called once per worker in a distributed setup to provide the worker with its ID and store connection.</p> <p>Parameters:</p> Name Type Description Default <code>worker_id</code> <code>int</code> <p>Unique identifier for this worker process.</p> required <code>store</code> <code>LightningStore</code> <p>The LightningStore instance for task coordination and data persistence.</p> required <code>**kwargs</code> <code>Any</code> <p>Additional worker-specific initialization arguments (currently unused).</p> <code>{}</code> Source code in <code>agentlightning/runner/agent.py</code> <pre><code>def init_worker(self, worker_id: int, store: LightningStore, **kwargs: Any) -&gt; None:\n    \"\"\"Initialize the runner for each worker with worker_id and store.\n\n    This method is called once per worker in a distributed setup to provide\n    the worker with its ID and store connection.\n\n    Args:\n        worker_id: Unique identifier for this worker process.\n        store: The LightningStore instance for task coordination and data persistence.\n        **kwargs: Additional worker-specific initialization arguments (currently unused).\n    \"\"\"\n    self._store = store\n    self.worker_id = worker_id\n\n    self._tracer.init_worker(worker_id)\n</code></pre>"},{"location":"reference/runner/#agentlightning.LitAgentRunner.iter","title":"<code>iter(*, event=None)</code>  <code>async</code>","text":"<p>Run the runner, continuously iterating over tasks in the store.</p> <p>This method polls the store for new rollouts and executes them until: - The event is set (if provided) - The max_rollouts limit is reached (if configured) - No more tasks are available</p> <p>All exceptions during rollout execution are caught and logged but not propagated, allowing the runner to continue processing subsequent tasks.</p> <p>Parameters:</p> Name Type Description Default <code>event</code> <code>Optional[ExecutionEvent]</code> <p>Optional ExecutionEvent object to signal the runner to stop. The runner will check this event periodically and stop gracefully when set.</p> <code>None</code> Source code in <code>agentlightning/runner/agent.py</code> <pre><code>async def iter(self, *, event: Optional[ExecutionEvent] = None) -&gt; None:\n    \"\"\"Run the runner, continuously iterating over tasks in the store.\n\n    This method polls the store for new rollouts and executes them until:\n    - The event is set (if provided)\n    - The max_rollouts limit is reached (if configured)\n    - No more tasks are available\n\n    All exceptions during rollout execution are caught and logged but not\n    propagated, allowing the runner to continue processing subsequent tasks.\n\n    Args:\n        event: Optional ExecutionEvent object to signal the runner to stop. The runner\n            will check this event periodically and stop gracefully when set.\n    \"\"\"\n    num_tasks_processed = 0\n    logger.info(f\"{self._log_prefix()} Started async rollouts (max: {self._max_rollouts or 'unlimited'}).\")\n    store = self.get_store()\n\n    while not (event is not None and event.is_set()) and (\n        self._max_rollouts is None or num_tasks_processed &lt; self._max_rollouts\n    ):\n        # Retrieve the next rollout\n        next_rollout: Optional[Rollout] = None\n        while not (event is not None and event.is_set()):\n            logger.debug(f\"{self._log_prefix()} Try to poll for next rollout.\")\n            next_rollout = await store.dequeue_rollout()\n            if next_rollout is None:\n                logger.debug(f\"{self._log_prefix()} No rollout to poll. Waiting for {self._poll_interval} seconds.\")\n                await self._sleep_until_next_poll(event)\n            else:\n                break\n\n        if next_rollout is None:\n            return\n\n        try:\n            # Claim the rollout but updating the current worker id\n            await store.update_attempt(\n                next_rollout.rollout_id, next_rollout.attempt.attempt_id, worker_id=self.get_worker_id()\n            )\n        except Exception:\n            # This exception could happen if the rollout is dequeued and the other end died for some reason\n            logger.exception(f\"{self._log_prefix()} Exception during update_attempt, giving up the rollout.\")\n            continue\n\n        # Execute the step\n        await self._step_impl(next_rollout)\n\n        num_tasks_processed += 1\n        if num_tasks_processed % 10 == 0 or num_tasks_processed == 1:\n            logger.info(f\"{self._log_prefix()} Progress: {num_tasks_processed}/{self._max_rollouts or 'unlimited'}\")\n\n    logger.info(f\"{self._log_prefix()} Finished async rollouts. Processed {num_tasks_processed} tasks.\")\n</code></pre>"},{"location":"reference/runner/#agentlightning.LitAgentRunner.step","title":"<code>step(input, *, resources=None, mode=None, event=None)</code>  <code>async</code>","text":"<p>Execute a single task directly, bypassing the task queue.</p> <p>This method creates a new rollout for the given input and executes it immediately. Unlike iter(), exceptions are propagated to the caller.</p> <p>Parameters:</p> Name Type Description Default <code>input</code> <code>T_task</code> <p>The task input to be processed by the agent.</p> required <code>resources</code> <code>Optional[NamedResources]</code> <p>Optional named resources to be used for this specific task. If provided, a new resources entry will be created in the store. If not provided, the latest resources from the store will be used.</p> <code>None</code> <code>mode</code> <code>Optional[RolloutMode]</code> <p>Optional rollout mode (\"train\" or \"validation\"). If not provided, the agent's default mode will be used.</p> <code>None</code> <code>event</code> <code>Optional[ExecutionEvent]</code> <p>Optional ExecutionEvent object to signal interruption (currently unused but included for interface consistency).</p> <code>None</code> <p>Returns:</p> Type Description <code>Rollout</code> <p>The completed rollout.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>Any exception that occurs during rollout execution will be re-raised to the caller.</p> Source code in <code>agentlightning/runner/agent.py</code> <pre><code>async def step(\n    self,\n    input: T_task,\n    *,\n    resources: Optional[NamedResources] = None,\n    mode: Optional[RolloutMode] = None,\n    event: Optional[ExecutionEvent] = None,\n) -&gt; Rollout:\n    \"\"\"Execute a single task directly, bypassing the task queue.\n\n    This method creates a new rollout for the given input and executes it\n    immediately. Unlike iter(), exceptions are propagated to the caller.\n\n    Args:\n        input: The task input to be processed by the agent.\n        resources: Optional named resources to be used for this specific task.\n            If provided, a new resources entry will be created in the store.\n            If not provided, the latest resources from the store will be used.\n        mode: Optional rollout mode (\"train\" or \"validation\"). If not provided,\n            the agent's default mode will be used.\n        event: Optional ExecutionEvent object to signal interruption (currently unused\n            but included for interface consistency).\n\n    Returns:\n        The completed rollout.\n\n    Raises:\n        Exception: Any exception that occurs during rollout execution will be\n            re-raised to the caller.\n    \"\"\"\n    store = self.get_store()\n\n    if resources is not None:\n        resources_update = await store.add_resources(resources)\n        resources_id = resources_update.resources_id\n    else:\n        resources_id = None\n\n    attempted_rollout = await self.get_store().start_rollout(input=input, mode=mode, resources_id=resources_id)\n    rollout_id = await self._step_impl(attempted_rollout, raise_on_exception=True)\n\n    completed_rollout = await store.get_rollout_by_id(rollout_id)\n    if completed_rollout is None:\n        raise RuntimeError(f\"{self._log_prefix()} Failed to fetch completed rollout by id after step: {rollout_id}\")\n    return completed_rollout\n</code></pre>"},{"location":"reference/runner/#agentlightning.LitAgentRunner.teardown","title":"<code>teardown(*args, **kwargs)</code>","text":"<p>Teardown the runner and clean up all resources.</p> <p>This method resets all internal state including the agent, store, hooks, and worker ID, and calls the tracer's teardown method.</p> <p>Parameters:</p> Name Type Description Default <code>*args</code> <code>Any</code> <p>Additional teardown arguments (currently unused).</p> <code>()</code> <code>**kwargs</code> <code>Any</code> <p>Additional teardown keyword arguments (currently unused).</p> <code>{}</code> Source code in <code>agentlightning/runner/agent.py</code> <pre><code>def teardown(self, *args: Any, **kwargs: Any) -&gt; None:\n    \"\"\"Teardown the runner and clean up all resources.\n\n    This method resets all internal state including the agent, store,\n    hooks, and worker ID, and calls the tracer's teardown method.\n\n    Args:\n        *args: Additional teardown arguments (currently unused).\n        **kwargs: Additional teardown keyword arguments (currently unused).\n    \"\"\"\n    self._agent = None\n    self._store = None\n    self.worker_id = None\n    self._hooks = []\n\n    self._tracer.teardown()\n</code></pre>"},{"location":"reference/runner/#agentlightning.LitAgentRunner.teardown_worker","title":"<code>teardown_worker(worker_id, *args, **kwargs)</code>","text":"<p>Teardown the runner for a specific worker.</p> <p>This method cleans up worker-specific resources and resets the worker ID.</p> <p>Parameters:</p> Name Type Description Default <code>worker_id</code> <code>int</code> <p>The unique identifier of the worker being torn down.</p> required <code>*args</code> <code>Any</code> <p>Additional teardown arguments (currently unused).</p> <code>()</code> <code>**kwargs</code> <code>Any</code> <p>Additional teardown keyword arguments (currently unused).</p> <code>{}</code> Source code in <code>agentlightning/runner/agent.py</code> <pre><code>def teardown_worker(self, worker_id: int, *args: Any, **kwargs: Any) -&gt; None:\n    \"\"\"Teardown the runner for a specific worker.\n\n    This method cleans up worker-specific resources and resets the worker ID.\n\n    Args:\n        worker_id: The unique identifier of the worker being torn down.\n        *args: Additional teardown arguments (currently unused).\n        **kwargs: Additional teardown keyword arguments (currently unused).\n    \"\"\"\n    self.worker_id = None\n\n    self._tracer.teardown_worker(worker_id)\n</code></pre>"},{"location":"reference/runner/#agentlightning.Runner","title":"<code>agentlightning.Runner</code>","text":"<p>               Bases: <code>ParallelWorkerBase</code>, <code>Generic[T_task]</code></p> <p>Base class for all runners.</p> <p>This abstract base class defines the interface that all runner implementations must follow. Runners are responsible for executing agent tasks, managing the execution lifecycle, and coordinating with the store.</p> Source code in <code>agentlightning/runner/base.py</code> <pre><code>class Runner(ParallelWorkerBase, Generic[T_task]):\n    \"\"\"Base class for all runners.\n\n    This abstract base class defines the interface that all runner implementations\n    must follow. Runners are responsible for executing agent tasks, managing the\n    execution lifecycle, and coordinating with the store.\n    \"\"\"\n\n    def init(self, agent: LitAgent[T_task], **kwargs: Any) -&gt; None:\n        \"\"\"Initialize the runner with the agent.\n\n        This method is called once during setup to configure the runner with\n        the agent it will execute.\n\n        Args:\n            agent: The LitAgent instance to be managed by this runner.\n            **kwargs: Additional initialization arguments specific to the runner implementation.\n\n        Raises:\n            NotImplementedError: Must be implemented by subclasses.\n        \"\"\"\n        raise NotImplementedError()\n\n    def init_worker(self, worker_id: int, store: LightningStore, **kwargs: Any) -&gt; None:\n        \"\"\"Initialize the runner for each worker with worker_id and store.\n\n        This method is called once per worker process in a distributed setup.\n        It provides the worker with its unique ID and the store instance for\n        task coordination.\n\n        Args:\n            worker_id: Unique identifier for this worker process.\n            store: The LightningStore instance for task coordination and data persistence.\n            **kwargs: Additional worker-specific initialization arguments.\n\n        Raises:\n            NotImplementedError: Must be implemented by subclasses.\n        \"\"\"\n        raise NotImplementedError()\n\n    def run(self, *args: Any, **kwargs: Any) -&gt; None:\n        \"\"\"Undefined method - use iter() or step() instead.\n\n        This method is intentionally not implemented as the execution behavior\n        should be defined through iter() for continuous execution or step()\n        for single-task execution.\n\n        Args:\n            *args: Unused positional arguments.\n            **kwargs: Unused keyword arguments.\n\n        Raises:\n            RuntimeError: Always raised to indicate this method should not be used.\n        \"\"\"\n        raise RuntimeError(\"The behavior of run() of Runner is undefined. Use iter() or step() instead.\")\n\n    def teardown(self, *args: Any, **kwargs: Any) -&gt; None:\n        \"\"\"Clean up runner resources and reset state.\n\n        This method is called once during shutdown to clean up any resources\n        allocated during initialization and reset the runner state.\n\n        Args:\n            *args: Additional teardown arguments.\n            **kwargs: Additional teardown keyword arguments.\n\n        Raises:\n            NotImplementedError: Must be implemented by subclasses.\n        \"\"\"\n        raise NotImplementedError()\n\n    def teardown_worker(self, worker_id: int, *args: Any, **kwargs: Any) -&gt; None:\n        \"\"\"Clean up worker-specific resources.\n\n        This method is called once per worker during shutdown to clean up\n        any resources specific to that worker.\n\n        Args:\n            worker_id: The unique identifier of the worker being torn down.\n            *args: Additional teardown arguments.\n            **kwargs: Additional teardown keyword arguments.\n\n        Raises:\n            NotImplementedError: Must be implemented by subclasses.\n        \"\"\"\n        raise NotImplementedError()\n\n    @contextmanager\n    def run_context(\n        self,\n        *,\n        agent: LitAgent[T_task],\n        store: LightningStore,\n        hooks: Optional[Sequence[Hook]] = None,\n        worker_id: Optional[int] = None,\n    ) -&gt; Iterator[Runner[T_task]]:\n        \"\"\"Context manager for quickly init and teardown the runner,\n        so that you can debug the runner without a trainer environment.\n\n        Args:\n            agent: The LitAgent instance to be managed by this runner.\n                   It should be the same agent that is to be run within the context.\n            store: The LightningStore instance for task coordination and data persistence.\n                   If you don't have one, you can easily create one with `InMemoryLightningStore()`.\n            hooks: Optional sequence of Hook instances to be used by the runner.\n                   Only some runners support hooks.\n            worker_id: Optional worker ID to be used by the runner.\n        \"\"\"\n        _initialized: bool = False\n        _worker_initialized: bool = False\n        try:\n            self.init(agent=agent, hooks=hooks)\n            _initialized = True\n            self.init_worker(worker_id=0, store=store)\n            _worker_initialized = True\n            yield self\n        finally:\n            try:\n                if _worker_initialized:\n                    self.teardown_worker(worker_id=worker_id if worker_id is not None else 0)\n            except Exception:\n                logger.error(\"Error during runner worker teardown\", exc_info=True)\n\n            try:\n                if _initialized:\n                    self.teardown()\n            except Exception:\n                logger.error(\"Error during runner teardown\", exc_info=True)\n\n    async def iter(self, *, event: Optional[ExecutionEvent] = None) -&gt; None:\n        \"\"\"Run the runner, continuously iterating over tasks in the store.\n\n        This method runs in a loop, polling the store for new tasks and executing\n        them until interrupted by the event or when no more tasks are available.\n\n        Args:\n            event: Optional ExecutionEvent object that can be used to signal the runner\n                to stop gracefully. When set, the runner should finish its current\n                task and exit the iteration loop.\n\n        Raises:\n            NotImplementedError: Must be implemented by subclasses.\n        \"\"\"\n        raise NotImplementedError()\n\n    async def step(\n        self,\n        input: T_task,\n        *,\n        resources: Optional[NamedResources] = None,\n        mode: Optional[RolloutMode] = None,\n        event: Optional[ExecutionEvent] = None,\n    ) -&gt; Rollout:\n        \"\"\"Execute a single task with the given input.\n\n        This method provides fine-grained control for executing individual tasks\n        directly, bypassing the store's task queue.\n\n        Args:\n            input: The task input to be processed by the agent.\n            resources: Optional named resources to be used for this specific task.\n                If not provided, the latest resources from the store will be used.\n            mode: Optional rollout mode (e.g., \"train\", \"test\"). If not provided,\n                the default mode will be used.\n            event: Optional ExecutionEvent object to signal interruption. When set, the\n                runner may abort the current execution.\n\n        Returns:\n            The completed rollout.\n\n        Raises:\n            NotImplementedError: Must be implemented by subclasses.\n        \"\"\"\n        raise NotImplementedError()\n</code></pre>"},{"location":"reference/runner/#agentlightning.Runner.init","title":"<code>init(agent, **kwargs)</code>","text":"<p>Initialize the runner with the agent.</p> <p>This method is called once during setup to configure the runner with the agent it will execute.</p> <p>Parameters:</p> Name Type Description Default <code>agent</code> <code>LitAgent[T_task]</code> <p>The LitAgent instance to be managed by this runner.</p> required <code>**kwargs</code> <code>Any</code> <p>Additional initialization arguments specific to the runner implementation.</p> <code>{}</code> <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>Must be implemented by subclasses.</p> Source code in <code>agentlightning/runner/base.py</code> <pre><code>def init(self, agent: LitAgent[T_task], **kwargs: Any) -&gt; None:\n    \"\"\"Initialize the runner with the agent.\n\n    This method is called once during setup to configure the runner with\n    the agent it will execute.\n\n    Args:\n        agent: The LitAgent instance to be managed by this runner.\n        **kwargs: Additional initialization arguments specific to the runner implementation.\n\n    Raises:\n        NotImplementedError: Must be implemented by subclasses.\n    \"\"\"\n    raise NotImplementedError()\n</code></pre>"},{"location":"reference/runner/#agentlightning.Runner.init_worker","title":"<code>init_worker(worker_id, store, **kwargs)</code>","text":"<p>Initialize the runner for each worker with worker_id and store.</p> <p>This method is called once per worker process in a distributed setup. It provides the worker with its unique ID and the store instance for task coordination.</p> <p>Parameters:</p> Name Type Description Default <code>worker_id</code> <code>int</code> <p>Unique identifier for this worker process.</p> required <code>store</code> <code>LightningStore</code> <p>The LightningStore instance for task coordination and data persistence.</p> required <code>**kwargs</code> <code>Any</code> <p>Additional worker-specific initialization arguments.</p> <code>{}</code> <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>Must be implemented by subclasses.</p> Source code in <code>agentlightning/runner/base.py</code> <pre><code>def init_worker(self, worker_id: int, store: LightningStore, **kwargs: Any) -&gt; None:\n    \"\"\"Initialize the runner for each worker with worker_id and store.\n\n    This method is called once per worker process in a distributed setup.\n    It provides the worker with its unique ID and the store instance for\n    task coordination.\n\n    Args:\n        worker_id: Unique identifier for this worker process.\n        store: The LightningStore instance for task coordination and data persistence.\n        **kwargs: Additional worker-specific initialization arguments.\n\n    Raises:\n        NotImplementedError: Must be implemented by subclasses.\n    \"\"\"\n    raise NotImplementedError()\n</code></pre>"},{"location":"reference/runner/#agentlightning.Runner.iter","title":"<code>iter(*, event=None)</code>  <code>async</code>","text":"<p>Run the runner, continuously iterating over tasks in the store.</p> <p>This method runs in a loop, polling the store for new tasks and executing them until interrupted by the event or when no more tasks are available.</p> <p>Parameters:</p> Name Type Description Default <code>event</code> <code>Optional[ExecutionEvent]</code> <p>Optional ExecutionEvent object that can be used to signal the runner to stop gracefully. When set, the runner should finish its current task and exit the iteration loop.</p> <code>None</code> <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>Must be implemented by subclasses.</p> Source code in <code>agentlightning/runner/base.py</code> <pre><code>async def iter(self, *, event: Optional[ExecutionEvent] = None) -&gt; None:\n    \"\"\"Run the runner, continuously iterating over tasks in the store.\n\n    This method runs in a loop, polling the store for new tasks and executing\n    them until interrupted by the event or when no more tasks are available.\n\n    Args:\n        event: Optional ExecutionEvent object that can be used to signal the runner\n            to stop gracefully. When set, the runner should finish its current\n            task and exit the iteration loop.\n\n    Raises:\n        NotImplementedError: Must be implemented by subclasses.\n    \"\"\"\n    raise NotImplementedError()\n</code></pre>"},{"location":"reference/runner/#agentlightning.Runner.run","title":"<code>run(*args, **kwargs)</code>","text":"<p>Undefined method - use iter() or step() instead.</p> <p>This method is intentionally not implemented as the execution behavior should be defined through iter() for continuous execution or step() for single-task execution.</p> <p>Parameters:</p> Name Type Description Default <code>*args</code> <code>Any</code> <p>Unused positional arguments.</p> <code>()</code> <code>**kwargs</code> <code>Any</code> <p>Unused keyword arguments.</p> <code>{}</code> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>Always raised to indicate this method should not be used.</p> Source code in <code>agentlightning/runner/base.py</code> <pre><code>def run(self, *args: Any, **kwargs: Any) -&gt; None:\n    \"\"\"Undefined method - use iter() or step() instead.\n\n    This method is intentionally not implemented as the execution behavior\n    should be defined through iter() for continuous execution or step()\n    for single-task execution.\n\n    Args:\n        *args: Unused positional arguments.\n        **kwargs: Unused keyword arguments.\n\n    Raises:\n        RuntimeError: Always raised to indicate this method should not be used.\n    \"\"\"\n    raise RuntimeError(\"The behavior of run() of Runner is undefined. Use iter() or step() instead.\")\n</code></pre>"},{"location":"reference/runner/#agentlightning.Runner.run_context","title":"<code>run_context(*, agent, store, hooks=None, worker_id=None)</code>","text":"<p>Context manager for quickly init and teardown the runner, so that you can debug the runner without a trainer environment.</p> <p>Parameters:</p> Name Type Description Default <code>agent</code> <code>LitAgent[T_task]</code> <p>The LitAgent instance to be managed by this runner.    It should be the same agent that is to be run within the context.</p> required <code>store</code> <code>LightningStore</code> <p>The LightningStore instance for task coordination and data persistence.    If you don't have one, you can easily create one with <code>InMemoryLightningStore()</code>.</p> required <code>hooks</code> <code>Optional[Sequence[Hook]]</code> <p>Optional sequence of Hook instances to be used by the runner.    Only some runners support hooks.</p> <code>None</code> <code>worker_id</code> <code>Optional[int]</code> <p>Optional worker ID to be used by the runner.</p> <code>None</code> Source code in <code>agentlightning/runner/base.py</code> <pre><code>@contextmanager\ndef run_context(\n    self,\n    *,\n    agent: LitAgent[T_task],\n    store: LightningStore,\n    hooks: Optional[Sequence[Hook]] = None,\n    worker_id: Optional[int] = None,\n) -&gt; Iterator[Runner[T_task]]:\n    \"\"\"Context manager for quickly init and teardown the runner,\n    so that you can debug the runner without a trainer environment.\n\n    Args:\n        agent: The LitAgent instance to be managed by this runner.\n               It should be the same agent that is to be run within the context.\n        store: The LightningStore instance for task coordination and data persistence.\n               If you don't have one, you can easily create one with `InMemoryLightningStore()`.\n        hooks: Optional sequence of Hook instances to be used by the runner.\n               Only some runners support hooks.\n        worker_id: Optional worker ID to be used by the runner.\n    \"\"\"\n    _initialized: bool = False\n    _worker_initialized: bool = False\n    try:\n        self.init(agent=agent, hooks=hooks)\n        _initialized = True\n        self.init_worker(worker_id=0, store=store)\n        _worker_initialized = True\n        yield self\n    finally:\n        try:\n            if _worker_initialized:\n                self.teardown_worker(worker_id=worker_id if worker_id is not None else 0)\n        except Exception:\n            logger.error(\"Error during runner worker teardown\", exc_info=True)\n\n        try:\n            if _initialized:\n                self.teardown()\n        except Exception:\n            logger.error(\"Error during runner teardown\", exc_info=True)\n</code></pre>"},{"location":"reference/runner/#agentlightning.Runner.step","title":"<code>step(input, *, resources=None, mode=None, event=None)</code>  <code>async</code>","text":"<p>Execute a single task with the given input.</p> <p>This method provides fine-grained control for executing individual tasks directly, bypassing the store's task queue.</p> <p>Parameters:</p> Name Type Description Default <code>input</code> <code>T_task</code> <p>The task input to be processed by the agent.</p> required <code>resources</code> <code>Optional[NamedResources]</code> <p>Optional named resources to be used for this specific task. If not provided, the latest resources from the store will be used.</p> <code>None</code> <code>mode</code> <code>Optional[RolloutMode]</code> <p>Optional rollout mode (e.g., \"train\", \"test\"). If not provided, the default mode will be used.</p> <code>None</code> <code>event</code> <code>Optional[ExecutionEvent]</code> <p>Optional ExecutionEvent object to signal interruption. When set, the runner may abort the current execution.</p> <code>None</code> <p>Returns:</p> Type Description <code>Rollout</code> <p>The completed rollout.</p> <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>Must be implemented by subclasses.</p> Source code in <code>agentlightning/runner/base.py</code> <pre><code>async def step(\n    self,\n    input: T_task,\n    *,\n    resources: Optional[NamedResources] = None,\n    mode: Optional[RolloutMode] = None,\n    event: Optional[ExecutionEvent] = None,\n) -&gt; Rollout:\n    \"\"\"Execute a single task with the given input.\n\n    This method provides fine-grained control for executing individual tasks\n    directly, bypassing the store's task queue.\n\n    Args:\n        input: The task input to be processed by the agent.\n        resources: Optional named resources to be used for this specific task.\n            If not provided, the latest resources from the store will be used.\n        mode: Optional rollout mode (e.g., \"train\", \"test\"). If not provided,\n            the default mode will be used.\n        event: Optional ExecutionEvent object to signal interruption. When set, the\n            runner may abort the current execution.\n\n    Returns:\n        The completed rollout.\n\n    Raises:\n        NotImplementedError: Must be implemented by subclasses.\n    \"\"\"\n    raise NotImplementedError()\n</code></pre>"},{"location":"reference/runner/#agentlightning.Runner.teardown","title":"<code>teardown(*args, **kwargs)</code>","text":"<p>Clean up runner resources and reset state.</p> <p>This method is called once during shutdown to clean up any resources allocated during initialization and reset the runner state.</p> <p>Parameters:</p> Name Type Description Default <code>*args</code> <code>Any</code> <p>Additional teardown arguments.</p> <code>()</code> <code>**kwargs</code> <code>Any</code> <p>Additional teardown keyword arguments.</p> <code>{}</code> <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>Must be implemented by subclasses.</p> Source code in <code>agentlightning/runner/base.py</code> <pre><code>def teardown(self, *args: Any, **kwargs: Any) -&gt; None:\n    \"\"\"Clean up runner resources and reset state.\n\n    This method is called once during shutdown to clean up any resources\n    allocated during initialization and reset the runner state.\n\n    Args:\n        *args: Additional teardown arguments.\n        **kwargs: Additional teardown keyword arguments.\n\n    Raises:\n        NotImplementedError: Must be implemented by subclasses.\n    \"\"\"\n    raise NotImplementedError()\n</code></pre>"},{"location":"reference/runner/#agentlightning.Runner.teardown_worker","title":"<code>teardown_worker(worker_id, *args, **kwargs)</code>","text":"<p>Clean up worker-specific resources.</p> <p>This method is called once per worker during shutdown to clean up any resources specific to that worker.</p> <p>Parameters:</p> Name Type Description Default <code>worker_id</code> <code>int</code> <p>The unique identifier of the worker being torn down.</p> required <code>*args</code> <code>Any</code> <p>Additional teardown arguments.</p> <code>()</code> <code>**kwargs</code> <code>Any</code> <p>Additional teardown keyword arguments.</p> <code>{}</code> <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>Must be implemented by subclasses.</p> Source code in <code>agentlightning/runner/base.py</code> <pre><code>def teardown_worker(self, worker_id: int, *args: Any, **kwargs: Any) -&gt; None:\n    \"\"\"Clean up worker-specific resources.\n\n    This method is called once per worker during shutdown to clean up\n    any resources specific to that worker.\n\n    Args:\n        worker_id: The unique identifier of the worker being torn down.\n        *args: Additional teardown arguments.\n        **kwargs: Additional teardown keyword arguments.\n\n    Raises:\n        NotImplementedError: Must be implemented by subclasses.\n    \"\"\"\n    raise NotImplementedError()\n</code></pre>"},{"location":"reference/runner/#tracer","title":"Tracer","text":""},{"location":"reference/runner/#agentlightning.AgentOpsTracer","title":"<code>agentlightning.AgentOpsTracer</code>","text":"<p>               Bases: <code>Tracer</code></p> <p>Traces agent execution using AgentOps.</p> <p>This tracer provides functionality to capture execution details using the AgentOps library. It manages the AgentOps client initialization, server setup, and integration with the OpenTelemetry tracing ecosystem.</p> <p>Attributes:</p> Name Type Description <code>agentops_managed</code> <p>Whether to automatically manage <code>agentops</code>.               When set to true, tracer calls <code>agentops.init()</code>               automatically and launches an agentops endpoint locally.               If not, you are responsible for calling and using it               before using the tracer.</p> <code>instrument_managed</code> <p>Whether to automatically manage instrumentation.                 When set to false, you will manage the instrumentation                 yourself and the tracer might not work as expected.</p> <code>daemon</code> <p>Whether the AgentOps server runs as a daemon process.     Only applicable if <code>agentops_managed</code> is True.</p> Source code in <code>agentlightning/tracer/agentops.py</code> <pre><code>class AgentOpsTracer(Tracer):\n    \"\"\"Traces agent execution using AgentOps.\n\n    This tracer provides functionality to capture execution details using the\n    AgentOps library. It manages the AgentOps client initialization, server setup,\n    and integration with the OpenTelemetry tracing ecosystem.\n\n    Attributes:\n        agentops_managed: Whether to automatically manage `agentops`.\n                          When set to true, tracer calls `agentops.init()`\n                          automatically and launches an agentops endpoint locally.\n                          If not, you are responsible for calling and using it\n                          before using the tracer.\n        instrument_managed: Whether to automatically manage instrumentation.\n                            When set to false, you will manage the instrumentation\n                            yourself and the tracer might not work as expected.\n        daemon: Whether the AgentOps server runs as a daemon process.\n                Only applicable if `agentops_managed` is True.\n    \"\"\"\n\n    def __init__(self, *, agentops_managed: bool = True, instrument_managed: bool = True, daemon: bool = True):\n        super().__init__()\n        self._lightning_span_processor: Optional[LightningSpanProcessor] = None\n        self.agentops_managed = agentops_managed\n        self.instrument_managed = instrument_managed\n        self.daemon = daemon\n\n        self._agentops_server_manager = AgentOpsServerManager(self.daemon)\n        self._agentops_server_port_val: Optional[int] = None\n\n        if not self.agentops_managed:\n            logger.warning(\"agentops_managed=False. You are responsible for AgentOps setup.\")\n        if not self.instrument_managed:\n            logger.warning(\"instrument_managed=False. You are responsible for all instrumentation.\")\n\n    def __getstate__(self):\n        state = self.__dict__.copy()\n        state[\"_agentops_server_manager\"] = None  # Exclude the unpicklable server manager\n        # _agentops_server_port_val (int) is inherently picklable and will be included.\n        logger.debug(f\"Getting state for pickling Trainer (PID {os.getpid()}). _agentops_server_manager excluded.\")\n        return state\n\n    def __setstate__(self, state: Any):\n        self.__dict__.update(state)\n        # In child process, self._agentops_server_manager will be None.\n        logger.debug(f\"Setting state for unpickled Trainer (PID {os.getpid()}). _agentops_server_manager is None.\")\n\n    def init(self, *args: Any, **kwargs: Any):\n        if self.agentops_managed and self._agentops_server_manager:\n            self._agentops_server_manager.start()\n            self._agentops_server_port_val = self._agentops_server_manager.get_port()\n            if self._agentops_server_port_val is None:\n                if (\n                    self._agentops_server_manager.server_process is not None\n                    and self._agentops_server_manager.server_process.is_alive()\n                ):\n                    raise RuntimeError(\"AgentOps server started but port is None. Check server manager logic.\")\n                elif (\n                    self._agentops_server_port_val is None and self._agentops_server_manager.server_process is None\n                ):  # Server failed to start\n                    raise RuntimeError(\"AgentOps server manager indicates server is not running and port is None.\")\n\n    def teardown(self):\n        if self.agentops_managed:\n            self._agentops_server_manager.stop()\n            logger.info(\"AgentOps server stopped.\")\n\n    def instrument(self, worker_id: int):\n        instrument_all()\n\n    def uninstrument(self, worker_id: int):\n        uninstrument_all()\n\n    def init_worker(self, worker_id: int):\n        super().init_worker(worker_id)\n        logger.info(f\"[Worker {worker_id}] Setting up tracer...\")  # worker_id included in process name\n\n        if self.instrument_managed:\n            self.instrument(worker_id)\n            logger.info(f\"[Worker {worker_id}] Instrumentation applied.\")\n\n        if self.agentops_managed:\n            if self._agentops_server_port_val:  # Use the stored, picklable port value\n                base_url = f\"http://localhost:{self._agentops_server_port_val}\"\n                env_vars_to_set = {\n                    \"AGENTOPS_API_KEY\": \"dummy\",\n                    \"AGENTOPS_API_ENDPOINT\": base_url,\n                    \"AGENTOPS_APP_URL\": f\"{base_url}/notavailable\",\n                    \"AGENTOPS_EXPORTER_ENDPOINT\": f\"{base_url}/traces\",\n                }\n                for key, value in env_vars_to_set.items():\n                    os.environ[key] = value\n                    logger.info(f\"[Worker {worker_id}] Env var set: {key}={value}\")\n            else:\n                logger.warning(\n                    f\"[Worker {worker_id}] AgentOps managed, but local server port is not available. Client may not connect as expected.\"\n                )\n\n            if not agentops.get_client().initialized:\n                agentops.init()  # type: ignore\n                logger.info(f\"[Worker {worker_id}] AgentOps client initialized.\")\n            else:\n                logger.warning(f\"[Worker {worker_id}] AgentOps client was already initialized.\")\n\n        self._lightning_span_processor = LightningSpanProcessor()\n\n        try:\n            # new versions\n            instance = agentops.sdk.core.tracer\n            # TODO: The span processor cannot be deleted once added.\n            # This might be a problem if the tracer is entered and exited multiple times.\n            instance.provider.add_span_processor(self._lightning_span_processor)  # type: ignore\n        except AttributeError:\n            # old versions\n            instance = TracingCore.get_instance()  # type: ignore\n            instance._provider.add_span_processor(self._lightning_span_processor)  # type: ignore\n\n    def teardown_worker(self, worker_id: int) -&gt; None:\n        super().teardown_worker(worker_id)\n\n        if self.instrument_managed:\n            self.uninstrument(worker_id)\n            logger.info(f\"[Worker {worker_id}] Instrumentation removed.\")\n\n    @asynccontextmanager\n    async def trace_context(\n        self,\n        name: Optional[str] = None,\n        *,\n        store: Optional[LightningStore] = None,\n        rollout_id: Optional[str] = None,\n        attempt_id: Optional[str] = None,\n    ) -&gt; AsyncGenerator[LightningSpanProcessor, None]:\n        \"\"\"\n        Starts a new tracing context. This should be used as a context manager.\n\n        Args:\n            name: Optional name for the tracing context.\n            store: Optional store to add the spans to.\n            rollout_id: Optional rollout ID to add the spans to.\n            attempt_id: Optional attempt ID to add the spans to.\n\n        Yields:\n            The LightningSpanProcessor instance to collect spans.\n        \"\"\"\n        with self._trace_context_sync(\n            name=name, store=store, rollout_id=rollout_id, attempt_id=attempt_id\n        ) as processor:\n            yield processor\n\n    @contextmanager\n    def _trace_context_sync(\n        self,\n        name: Optional[str] = None,\n        *,\n        store: Optional[LightningStore] = None,\n        rollout_id: Optional[str] = None,\n        attempt_id: Optional[str] = None,\n    ) -&gt; Iterator[LightningSpanProcessor]:\n        \"\"\"Implementation of `trace_context` for synchronous execution.\"\"\"\n        if not self._lightning_span_processor:\n            raise RuntimeError(\"LightningSpanProcessor is not initialized. Call init_worker() first.\")\n\n        if store is not None and rollout_id is not None and attempt_id is not None:\n            ctx = self._lightning_span_processor.with_context(store=store, rollout_id=rollout_id, attempt_id=attempt_id)\n            with ctx as processor:\n                yield processor\n        elif store is None and rollout_id is None and attempt_id is None:\n            with self._lightning_span_processor:\n                yield self._lightning_span_processor\n        else:\n            raise ValueError(\"store, rollout_id, and attempt_id must be either all provided or all None\")\n\n    def get_last_trace(self) -&gt; List[ReadableSpan]:\n        \"\"\"\n        Retrieves the raw list of captured spans from the most recent trace.\n\n        Returns:\n            A list of OpenTelemetry `ReadableSpan` objects.\n        \"\"\"\n        if not self._lightning_span_processor:\n            raise RuntimeError(\"LightningSpanProcessor is not initialized. Call init_worker() first.\")\n        return self._lightning_span_processor.spans()\n\n    def get_langchain_handler(self, tags: List[str] | None = None) -&gt; LangchainCallbackHandler:\n        \"\"\"\n        Get the Langchain callback handler for integrating with Langchain.\n\n        Args:\n            tags: Optional list of tags to apply to the Langchain callback handler.\n\n        Returns:\n            An instance of the Langchain callback handler.\n        \"\"\"\n        import agentops\n        from agentops.integration.callbacks.langchain import LangchainCallbackHandler\n\n        tags = tags or []\n        client_instance = agentops.get_client()\n        api_key = None\n        if client_instance.initialized:\n            api_key = client_instance.config.api_key\n        else:\n            logger.warning(\n                \"AgentOps client not initialized when creating LangchainCallbackHandler. API key may be missing.\"\n            )\n        return LangchainCallbackHandler(api_key=api_key, tags=tags)\n\n    get_langchain_callback_handler = get_langchain_handler  # alias\n</code></pre>"},{"location":"reference/runner/#agentlightning.AgentOpsTracer.get_langchain_handler","title":"<code>get_langchain_handler(tags=None)</code>","text":"<p>Get the Langchain callback handler for integrating with Langchain.</p> <p>Parameters:</p> Name Type Description Default <code>tags</code> <code>List[str] | None</code> <p>Optional list of tags to apply to the Langchain callback handler.</p> <code>None</code> <p>Returns:</p> Type Description <code>LangchainCallbackHandler</code> <p>An instance of the Langchain callback handler.</p> Source code in <code>agentlightning/tracer/agentops.py</code> <pre><code>def get_langchain_handler(self, tags: List[str] | None = None) -&gt; LangchainCallbackHandler:\n    \"\"\"\n    Get the Langchain callback handler for integrating with Langchain.\n\n    Args:\n        tags: Optional list of tags to apply to the Langchain callback handler.\n\n    Returns:\n        An instance of the Langchain callback handler.\n    \"\"\"\n    import agentops\n    from agentops.integration.callbacks.langchain import LangchainCallbackHandler\n\n    tags = tags or []\n    client_instance = agentops.get_client()\n    api_key = None\n    if client_instance.initialized:\n        api_key = client_instance.config.api_key\n    else:\n        logger.warning(\n            \"AgentOps client not initialized when creating LangchainCallbackHandler. API key may be missing.\"\n        )\n    return LangchainCallbackHandler(api_key=api_key, tags=tags)\n</code></pre>"},{"location":"reference/runner/#agentlightning.AgentOpsTracer.get_last_trace","title":"<code>get_last_trace()</code>","text":"<p>Retrieves the raw list of captured spans from the most recent trace.</p> <p>Returns:</p> Type Description <code>List[ReadableSpan]</code> <p>A list of OpenTelemetry <code>ReadableSpan</code> objects.</p> Source code in <code>agentlightning/tracer/agentops.py</code> <pre><code>def get_last_trace(self) -&gt; List[ReadableSpan]:\n    \"\"\"\n    Retrieves the raw list of captured spans from the most recent trace.\n\n    Returns:\n        A list of OpenTelemetry `ReadableSpan` objects.\n    \"\"\"\n    if not self._lightning_span_processor:\n        raise RuntimeError(\"LightningSpanProcessor is not initialized. Call init_worker() first.\")\n    return self._lightning_span_processor.spans()\n</code></pre>"},{"location":"reference/runner/#agentlightning.AgentOpsTracer.trace_context","title":"<code>trace_context(name=None, *, store=None, rollout_id=None, attempt_id=None)</code>  <code>async</code>","text":"<p>Starts a new tracing context. This should be used as a context manager.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>Optional[str]</code> <p>Optional name for the tracing context.</p> <code>None</code> <code>store</code> <code>Optional[LightningStore]</code> <p>Optional store to add the spans to.</p> <code>None</code> <code>rollout_id</code> <code>Optional[str]</code> <p>Optional rollout ID to add the spans to.</p> <code>None</code> <code>attempt_id</code> <code>Optional[str]</code> <p>Optional attempt ID to add the spans to.</p> <code>None</code> <p>Yields:</p> Type Description <code>AsyncGenerator[LightningSpanProcessor, None]</code> <p>The LightningSpanProcessor instance to collect spans.</p> Source code in <code>agentlightning/tracer/agentops.py</code> <pre><code>@asynccontextmanager\nasync def trace_context(\n    self,\n    name: Optional[str] = None,\n    *,\n    store: Optional[LightningStore] = None,\n    rollout_id: Optional[str] = None,\n    attempt_id: Optional[str] = None,\n) -&gt; AsyncGenerator[LightningSpanProcessor, None]:\n    \"\"\"\n    Starts a new tracing context. This should be used as a context manager.\n\n    Args:\n        name: Optional name for the tracing context.\n        store: Optional store to add the spans to.\n        rollout_id: Optional rollout ID to add the spans to.\n        attempt_id: Optional attempt ID to add the spans to.\n\n    Yields:\n        The LightningSpanProcessor instance to collect spans.\n    \"\"\"\n    with self._trace_context_sync(\n        name=name, store=store, rollout_id=rollout_id, attempt_id=attempt_id\n    ) as processor:\n        yield processor\n</code></pre>"},{"location":"reference/runner/#agentlightning.OtelTracer","title":"<code>agentlightning.OtelTracer</code>","text":"<p>               Bases: <code>Tracer</code></p> <p>Tracer that provides a basic OpenTelemetry tracer provider.</p> <p>You should be able to collect agent-lightning signals like rewards with this tracer, but no other function instrumentations like <code>openai.chat.completion</code>.</p> Source code in <code>agentlightning/tracer/otel.py</code> <pre><code>class OtelTracer(Tracer):\n    \"\"\"Tracer that provides a basic OpenTelemetry tracer provider.\n\n    You should be able to collect agent-lightning signals like rewards with this tracer,\n    but no other function instrumentations like `openai.chat.completion`.\n    \"\"\"\n\n    def __init__(self):\n        super().__init__()\n        # This provider is only initialized when the worker is initialized.\n        self._tracer_provider: Optional[TracerProvider] = None\n        self._lightning_span_processor: Optional[LightningSpanProcessor] = None\n        self._initialized: bool = False\n\n    def init_worker(self, worker_id: int):\n        super().init_worker(worker_id)\n        logger.info(f\"[Worker {worker_id}] Setting up OpenTelemetry tracer...\")\n\n        if self._initialized:\n            logger.error(\"Tracer provider is already initialized. OpenTelemetry may not work as expected.\")\n\n        tracer_provider = TracerProvider()\n        trace_api.set_tracer_provider(tracer_provider)\n        self._lightning_span_processor = LightningSpanProcessor()\n        tracer_provider.add_span_processor(self._lightning_span_processor)\n        self._initialized = True\n\n    def teardown_worker(self, worker_id: int):\n        super().teardown_worker(worker_id)\n        logger.info(f\"[Worker {worker_id}] Tearing down OpenTelemetry tracer...\")\n        self._tracer_provider = None\n\n    @asynccontextmanager\n    async def trace_context(\n        self,\n        name: Optional[str] = None,\n        *,\n        store: Optional[LightningStore] = None,\n        rollout_id: Optional[str] = None,\n        attempt_id: Optional[str] = None,\n    ) -&gt; AsyncGenerator[LightningSpanProcessor, None]:\n        \"\"\"\n        Starts a new tracing context. This should be used as a context manager.\n\n        Args:\n            name: Optional name for the tracing context.\n            store: Optional store to add the spans to.\n            rollout_id: Optional rollout ID to add the spans to.\n            attempt_id: Optional attempt ID to add the spans to.\n\n        Yields:\n            The LightningSpanProcessor instance to collect spans.\n        \"\"\"\n        if not self._lightning_span_processor:\n            raise RuntimeError(\"LightningSpanProcessor is not initialized. Call init_worker() first.\")\n\n        if store is not None and rollout_id is not None and attempt_id is not None:\n            ctx = self._lightning_span_processor.with_context(store=store, rollout_id=rollout_id, attempt_id=attempt_id)\n            with ctx as processor:\n                yield processor\n        elif store is None and rollout_id is None and attempt_id is None:\n            with self._lightning_span_processor:\n                yield self._lightning_span_processor\n        else:\n            raise ValueError(\"store, rollout_id, and attempt_id must be either all provided or all None\")\n\n    def get_last_trace(self) -&gt; List[ReadableSpan]:\n        \"\"\"\n        Retrieves the raw list of captured spans from the most recent trace.\n\n        Returns:\n            A list of OpenTelemetry `ReadableSpan` objects.\n        \"\"\"\n        if not self._lightning_span_processor:\n            raise RuntimeError(\"LightningSpanProcessor is not initialized. Call init_worker() first.\")\n        return self._lightning_span_processor.spans()\n</code></pre>"},{"location":"reference/runner/#agentlightning.OtelTracer.get_last_trace","title":"<code>get_last_trace()</code>","text":"<p>Retrieves the raw list of captured spans from the most recent trace.</p> <p>Returns:</p> Type Description <code>List[ReadableSpan]</code> <p>A list of OpenTelemetry <code>ReadableSpan</code> objects.</p> Source code in <code>agentlightning/tracer/otel.py</code> <pre><code>def get_last_trace(self) -&gt; List[ReadableSpan]:\n    \"\"\"\n    Retrieves the raw list of captured spans from the most recent trace.\n\n    Returns:\n        A list of OpenTelemetry `ReadableSpan` objects.\n    \"\"\"\n    if not self._lightning_span_processor:\n        raise RuntimeError(\"LightningSpanProcessor is not initialized. Call init_worker() first.\")\n    return self._lightning_span_processor.spans()\n</code></pre>"},{"location":"reference/runner/#agentlightning.OtelTracer.trace_context","title":"<code>trace_context(name=None, *, store=None, rollout_id=None, attempt_id=None)</code>  <code>async</code>","text":"<p>Starts a new tracing context. This should be used as a context manager.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>Optional[str]</code> <p>Optional name for the tracing context.</p> <code>None</code> <code>store</code> <code>Optional[LightningStore]</code> <p>Optional store to add the spans to.</p> <code>None</code> <code>rollout_id</code> <code>Optional[str]</code> <p>Optional rollout ID to add the spans to.</p> <code>None</code> <code>attempt_id</code> <code>Optional[str]</code> <p>Optional attempt ID to add the spans to.</p> <code>None</code> <p>Yields:</p> Type Description <code>AsyncGenerator[LightningSpanProcessor, None]</code> <p>The LightningSpanProcessor instance to collect spans.</p> Source code in <code>agentlightning/tracer/otel.py</code> <pre><code>@asynccontextmanager\nasync def trace_context(\n    self,\n    name: Optional[str] = None,\n    *,\n    store: Optional[LightningStore] = None,\n    rollout_id: Optional[str] = None,\n    attempt_id: Optional[str] = None,\n) -&gt; AsyncGenerator[LightningSpanProcessor, None]:\n    \"\"\"\n    Starts a new tracing context. This should be used as a context manager.\n\n    Args:\n        name: Optional name for the tracing context.\n        store: Optional store to add the spans to.\n        rollout_id: Optional rollout ID to add the spans to.\n        attempt_id: Optional attempt ID to add the spans to.\n\n    Yields:\n        The LightningSpanProcessor instance to collect spans.\n    \"\"\"\n    if not self._lightning_span_processor:\n        raise RuntimeError(\"LightningSpanProcessor is not initialized. Call init_worker() first.\")\n\n    if store is not None and rollout_id is not None and attempt_id is not None:\n        ctx = self._lightning_span_processor.with_context(store=store, rollout_id=rollout_id, attempt_id=attempt_id)\n        with ctx as processor:\n            yield processor\n    elif store is None and rollout_id is None and attempt_id is None:\n        with self._lightning_span_processor:\n            yield self._lightning_span_processor\n    else:\n        raise ValueError(\"store, rollout_id, and attempt_id must be either all provided or all None\")\n</code></pre>"},{"location":"reference/runner/#agentlightning.Tracer","title":"<code>agentlightning.Tracer</code>","text":"<p>               Bases: <code>ParallelWorkerBase</code></p> <p>An abstract base class for tracers.</p> <p>This class defines a standard interface for tracing code execution, capturing the resulting spans, and providing them for analysis. It is designed to be backend-agnostic, allowing for different implementations (e.g., for AgentOps, OpenTelemetry, Docker, etc.).</p> <p>The primary interaction pattern is through the <code>trace_context</code> context manager, which ensures that traces are properly started and captured, even in the case of exceptions.</p> <p>A typical workflow:</p> <pre><code>tracer = YourTracerImplementation()\n\ntry:\n    async with tracer.trace_context(name=\"my_traced_task\"):\n        # ... code to be traced ...\n        await run_my_agent_logic()\nexcept Exception as e:\n    print(f\"An error occurred: {e}\")\n\n# Retrieve the trace data after the context block\nspans: list[ReadableSpan] = tracer.get_last_trace()\n\n# Process the trace data\nif trace_tree:\n    rl_triplets = TracerTraceToTriplet().adapt(spans)\n    # ... do something with the triplets\n</code></pre> Source code in <code>agentlightning/tracer/base.py</code> <pre><code>class Tracer(ParallelWorkerBase):\n    \"\"\"\n    An abstract base class for tracers.\n\n    This class defines a standard interface for tracing code execution,\n    capturing the resulting spans, and providing them for analysis. It is\n    designed to be backend-agnostic, allowing for different implementations\n    (e.g., for AgentOps, OpenTelemetry, Docker, etc.).\n\n    The primary interaction pattern is through the `trace_context`\n    context manager, which ensures that traces are properly started and captured,\n    even in the case of exceptions.\n\n    A typical workflow:\n\n    ```python\n    tracer = YourTracerImplementation()\n\n    try:\n        async with tracer.trace_context(name=\"my_traced_task\"):\n            # ... code to be traced ...\n            await run_my_agent_logic()\n    except Exception as e:\n        print(f\"An error occurred: {e}\")\n\n    # Retrieve the trace data after the context block\n    spans: list[ReadableSpan] = tracer.get_last_trace()\n\n    # Process the trace data\n    if trace_tree:\n        rl_triplets = TracerTraceToTriplet().adapt(spans)\n        # ... do something with the triplets\n    ```\n    \"\"\"\n\n    def trace_context(\n        self,\n        name: Optional[str] = None,\n        *,\n        store: Optional[LightningStore] = None,\n        rollout_id: Optional[str] = None,\n        attempt_id: Optional[str] = None,\n    ) -&gt; AsyncContextManager[Any]:\n        \"\"\"\n        Starts a new tracing context. This should be used as a context manager.\n\n        The implementation should handle the setup and teardown of the tracing\n        for the enclosed code block. It must ensure that any spans generated\n        within the `with` block are collected and made available via\n        `get_last_trace`.\n\n        If a store is provided, the spans will be added to the store when tracing.\n\n        Args:\n            name: The name for the root span of this trace context.\n            store: The store to add the spans to.\n            rollout_id: The rollout ID to add the spans to.\n            attempt_id: The attempt ID to add the spans to.\n        \"\"\"\n        raise NotImplementedError()\n\n    def _trace_context_sync(\n        self,\n        name: Optional[str] = None,\n        *,\n        store: Optional[LightningStore] = None,\n        rollout_id: Optional[str] = None,\n        attempt_id: Optional[str] = None,\n    ) -&gt; ContextManager[Any]:\n        \"\"\"Internal API for CI backward compatibility.\"\"\"\n        raise NotImplementedError()\n\n    def get_last_trace(self) -&gt; List[ReadableSpan]:\n        \"\"\"\n        Retrieves the raw list of captured spans from the most recent trace.\n\n        Returns:\n            A list of OpenTelemetry `ReadableSpan` objects.\n        \"\"\"\n        raise NotImplementedError()\n\n    def trace_run(self, func: Callable[..., Any], *args: Any, **kwargs: Any) -&gt; Any:\n        \"\"\"\n        A convenience wrapper to trace the execution of a single synchronous function.\n\n        Deprecated in favor of customizing Runners.\n\n        Args:\n            func: The synchronous function to execute and trace.\n            *args: Positional arguments to pass to the function.\n            **kwargs: Keyword arguments to pass to the function.\n\n        Returns:\n            The return value of the function.\n        \"\"\"\n        with self._trace_context_sync(name=func.__name__):\n            return func(*args, **kwargs)\n\n    async def trace_run_async(self, func: Callable[..., Awaitable[Any]], *args: Any, **kwargs: Any) -&gt; Any:\n        \"\"\"\n        A convenience wrapper to trace the execution of a single asynchronous function.\n\n        Deprecated in favor of customizing Runners.\n\n        Args:\n            func: The asynchronous function to execute and trace.\n            *args: Positional arguments to pass to the function.\n            **kwargs: Keyword arguments to pass to the function.\n\n        Returns:\n            The return value of the function.\n        \"\"\"\n        async with self.trace_context(name=func.__name__):\n            return await func(*args, **kwargs)\n\n    def get_langchain_handler(self) -&gt; Optional[BaseCallbackHandler]:  # type: ignore\n        \"\"\"Get a handler to install in langchain agent callback.\n\n        Agents are expected to use this handler in their agents to enable tracing.\n        \"\"\"\n        logger.warning(f\"{self.__class__.__name__} does not provide a LangChain callback handler.\")\n        return None\n</code></pre>"},{"location":"reference/runner/#agentlightning.Tracer.get_langchain_handler","title":"<code>get_langchain_handler()</code>","text":"<p>Get a handler to install in langchain agent callback.</p> <p>Agents are expected to use this handler in their agents to enable tracing.</p> Source code in <code>agentlightning/tracer/base.py</code> <pre><code>def get_langchain_handler(self) -&gt; Optional[BaseCallbackHandler]:  # type: ignore\n    \"\"\"Get a handler to install in langchain agent callback.\n\n    Agents are expected to use this handler in their agents to enable tracing.\n    \"\"\"\n    logger.warning(f\"{self.__class__.__name__} does not provide a LangChain callback handler.\")\n    return None\n</code></pre>"},{"location":"reference/runner/#agentlightning.Tracer.get_last_trace","title":"<code>get_last_trace()</code>","text":"<p>Retrieves the raw list of captured spans from the most recent trace.</p> <p>Returns:</p> Type Description <code>List[ReadableSpan]</code> <p>A list of OpenTelemetry <code>ReadableSpan</code> objects.</p> Source code in <code>agentlightning/tracer/base.py</code> <pre><code>def get_last_trace(self) -&gt; List[ReadableSpan]:\n    \"\"\"\n    Retrieves the raw list of captured spans from the most recent trace.\n\n    Returns:\n        A list of OpenTelemetry `ReadableSpan` objects.\n    \"\"\"\n    raise NotImplementedError()\n</code></pre>"},{"location":"reference/runner/#agentlightning.Tracer.trace_context","title":"<code>trace_context(name=None, *, store=None, rollout_id=None, attempt_id=None)</code>","text":"<p>Starts a new tracing context. This should be used as a context manager.</p> <p>The implementation should handle the setup and teardown of the tracing for the enclosed code block. It must ensure that any spans generated within the <code>with</code> block are collected and made available via <code>get_last_trace</code>.</p> <p>If a store is provided, the spans will be added to the store when tracing.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>Optional[str]</code> <p>The name for the root span of this trace context.</p> <code>None</code> <code>store</code> <code>Optional[LightningStore]</code> <p>The store to add the spans to.</p> <code>None</code> <code>rollout_id</code> <code>Optional[str]</code> <p>The rollout ID to add the spans to.</p> <code>None</code> <code>attempt_id</code> <code>Optional[str]</code> <p>The attempt ID to add the spans to.</p> <code>None</code> Source code in <code>agentlightning/tracer/base.py</code> <pre><code>def trace_context(\n    self,\n    name: Optional[str] = None,\n    *,\n    store: Optional[LightningStore] = None,\n    rollout_id: Optional[str] = None,\n    attempt_id: Optional[str] = None,\n) -&gt; AsyncContextManager[Any]:\n    \"\"\"\n    Starts a new tracing context. This should be used as a context manager.\n\n    The implementation should handle the setup and teardown of the tracing\n    for the enclosed code block. It must ensure that any spans generated\n    within the `with` block are collected and made available via\n    `get_last_trace`.\n\n    If a store is provided, the spans will be added to the store when tracing.\n\n    Args:\n        name: The name for the root span of this trace context.\n        store: The store to add the spans to.\n        rollout_id: The rollout ID to add the spans to.\n        attempt_id: The attempt ID to add the spans to.\n    \"\"\"\n    raise NotImplementedError()\n</code></pre>"},{"location":"reference/runner/#agentlightning.Tracer.trace_run","title":"<code>trace_run(func, *args, **kwargs)</code>","text":"<p>A convenience wrapper to trace the execution of a single synchronous function.</p> <p>Deprecated in favor of customizing Runners.</p> <p>Parameters:</p> Name Type Description Default <code>func</code> <code>Callable[..., Any]</code> <p>The synchronous function to execute and trace.</p> required <code>*args</code> <code>Any</code> <p>Positional arguments to pass to the function.</p> <code>()</code> <code>**kwargs</code> <code>Any</code> <p>Keyword arguments to pass to the function.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Any</code> <p>The return value of the function.</p> Source code in <code>agentlightning/tracer/base.py</code> <pre><code>def trace_run(self, func: Callable[..., Any], *args: Any, **kwargs: Any) -&gt; Any:\n    \"\"\"\n    A convenience wrapper to trace the execution of a single synchronous function.\n\n    Deprecated in favor of customizing Runners.\n\n    Args:\n        func: The synchronous function to execute and trace.\n        *args: Positional arguments to pass to the function.\n        **kwargs: Keyword arguments to pass to the function.\n\n    Returns:\n        The return value of the function.\n    \"\"\"\n    with self._trace_context_sync(name=func.__name__):\n        return func(*args, **kwargs)\n</code></pre>"},{"location":"reference/runner/#agentlightning.Tracer.trace_run_async","title":"<code>trace_run_async(func, *args, **kwargs)</code>  <code>async</code>","text":"<p>A convenience wrapper to trace the execution of a single asynchronous function.</p> <p>Deprecated in favor of customizing Runners.</p> <p>Parameters:</p> Name Type Description Default <code>func</code> <code>Callable[..., Awaitable[Any]]</code> <p>The asynchronous function to execute and trace.</p> required <code>*args</code> <code>Any</code> <p>Positional arguments to pass to the function.</p> <code>()</code> <code>**kwargs</code> <code>Any</code> <p>Keyword arguments to pass to the function.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Any</code> <p>The return value of the function.</p> Source code in <code>agentlightning/tracer/base.py</code> <pre><code>async def trace_run_async(self, func: Callable[..., Awaitable[Any]], *args: Any, **kwargs: Any) -&gt; Any:\n    \"\"\"\n    A convenience wrapper to trace the execution of a single asynchronous function.\n\n    Deprecated in favor of customizing Runners.\n\n    Args:\n        func: The asynchronous function to execute and trace.\n        *args: Positional arguments to pass to the function.\n        **kwargs: Keyword arguments to pass to the function.\n\n    Returns:\n        The return value of the function.\n    \"\"\"\n    async with self.trace_context(name=func.__name__):\n        return await func(*args, **kwargs)\n</code></pre>"},{"location":"reference/store/","title":"Store References","text":""},{"location":"reference/store/#agentlightning.LightningStore","title":"<code>agentlightning.LightningStore</code>","text":"<p>A centralized, thread-safe, async, data store for the lightning's state. This holds the task queue, versioned resources, and completed rollouts.</p> <p>The store has a built-in clock and it should be responsible for tracking the times. All the time-based operations like retry, timeout, etc. should be handled by the store.</p> Source code in <code>agentlightning/store/base.py</code> <pre><code>class LightningStore:\n    \"\"\"\n    A centralized, thread-safe, async, data store for the lightning's state.\n    This holds the task queue, versioned resources, and completed rollouts.\n\n    The store has a built-in clock and it should be responsible for tracking the times.\n    All the time-based operations like retry, timeout, etc. should be handled by the store.\n    \"\"\"\n\n    async def start_rollout(\n        self,\n        input: TaskInput,\n        mode: Literal[\"train\", \"val\", \"test\"] | None = None,\n        resources_id: str | None = None,\n        config: RolloutConfig | None = None,\n        metadata: Dict[str, Any] | None = None,\n    ) -&gt; AttemptedRollout:\n        \"\"\"\n        Add one incomplete rollout to the store, and get an attempt created for it.\n        This will immediately sets the rollout to a preparing state, and should be\n        used by whoever is going to execute the rollout.\n\n        Return a special rollout with attempt object. Do not update it directly.\n\n        But if the rollout fails or timeouts, it's still possible that the watchdog\n        sends it back to the queue for retry.\n\n        To enqueue a rollout to the task queue, use `enqueue_rollout` instead.\n        \"\"\"\n        raise NotImplementedError()\n\n    async def enqueue_rollout(\n        self,\n        input: TaskInput,\n        mode: Literal[\"train\", \"val\", \"test\"] | None = None,\n        resources_id: str | None = None,\n        config: RolloutConfig | None = None,\n        metadata: Dict[str, Any] | None = None,\n    ) -&gt; Rollout:\n        \"\"\"\n        Adds a new task to the queue with specific metadata and\n        returns the rollout object with its unique ID.\n        \"\"\"\n        raise NotImplementedError()\n\n    async def dequeue_rollout(self) -&gt; Optional[AttemptedRollout]:\n        \"\"\"\n        Retrieves the next task from the queue without blocking.\n        Returns None if the queue is empty.\n\n        Will set the rollout status to preparing.\n        \"\"\"\n        raise NotImplementedError()\n\n    async def start_attempt(self, rollout_id: str) -&gt; AttemptedRollout:\n        \"\"\"\n        Create a new attempt for a given rollout ID and return the attempt details.\n        \"\"\"\n        raise NotImplementedError()\n\n    async def add_span(self, span: Span) -&gt; Span:\n        \"\"\"\n        Add a span to the store.\n\n        This method is responsible for updating the rollout/attempt status to \"running\" if needed.\n        \"\"\"\n        raise NotImplementedError()\n\n    async def add_otel_span(\n        self,\n        rollout_id: str,\n        attempt_id: str,\n        readable_span: ReadableSpan,\n        sequence_id: int | None = None,\n    ) -&gt; Span:\n        \"\"\"\n        Add an opentelemetry span to the store.\n\n        If sequence_id is not provided, it will be fetched from `get_next_span_sequence_id` and assigned automatically.\n        \"\"\"\n        raise NotImplementedError()\n\n    async def query_rollouts(\n        self, *, status: Optional[Sequence[RolloutStatus]] = None, rollout_ids: Optional[Sequence[str]] = None\n    ) -&gt; List[Rollout]:\n        \"\"\"\n        Query and retrieve rollouts filtered by their status.\n        If no status is provided, returns all rollouts.\n        \"\"\"\n        raise NotImplementedError()\n\n    async def query_attempts(self, rollout_id: str) -&gt; List[Attempt]:\n        \"\"\"\n        Query and retrieve all attempts associated with a specific rollout ID.\n        Returns an empty list if no attempts are found.\n        \"\"\"\n        raise NotImplementedError()\n\n    async def get_rollout_by_id(self, rollout_id: str) -&gt; Optional[Rollout]:\n        \"\"\"\n        Safely retrieves a specific rollout by its ID.\n        \"\"\"\n        raise NotImplementedError()\n\n    async def get_latest_attempt(self, rollout_id: str) -&gt; Optional[Attempt]:\n        \"\"\"\n        Safely retrieves the latest attempt for a given rollout ID.\n        \"\"\"\n        raise NotImplementedError()\n\n    async def get_resources_by_id(self, resources_id: str) -&gt; Optional[ResourcesUpdate]:\n        \"\"\"\n        Safely retrieves a specific version of named resources by its ID.\n        \"\"\"\n        raise NotImplementedError()\n\n    async def get_latest_resources(self) -&gt; Optional[ResourcesUpdate]:\n        \"\"\"\n        Safely retrieves the latest version of named resources.\n        \"\"\"\n        raise NotImplementedError()\n\n    async def get_next_span_sequence_id(self, rollout_id: str, attempt_id: str) -&gt; int:\n        \"\"\"\n        Get the next span sequence ID for a given rollout and attempt.\n        This should be used to assign a unique sequence ID to each span within an attempt.\n\n        Recommend getting the ID before the operation even begins to avoid racing conditions.\n        \"\"\"\n        raise NotImplementedError()\n\n    async def wait_for_rollouts(self, *, rollout_ids: List[str], timeout: Optional[float] = None) -&gt; List[Rollout]:\n        \"\"\"\n        Wait for specified rollouts to complete with a timeout.\n        Returns the completed rollouts, potentially incomplete if timeout is reached.\n\n        TODO: Add support for waiting for 20 new rollouts, or wait until 80% of the pending ids are completed.\n        \"\"\"\n        raise NotImplementedError()\n\n    async def query_spans(self, rollout_id: str, attempt_id: str | Literal[\"latest\"] | None = None) -&gt; List[Span]:\n        \"\"\"\n        Query and retrieve all spans associated with a specific rollout ID.\n        Returns an empty list if no spans are found.\n        \"\"\"\n        raise NotImplementedError()\n\n    async def add_resources(self, resources: NamedResources) -&gt; ResourcesUpdate:\n        \"\"\"\n        Safely stores a new version of named resources and sets it as the latest.\n        Not implemented by many stores yet.\n        \"\"\"\n        raise NotImplementedError()\n\n    async def update_resources(self, resources_id: str, resources: NamedResources) -&gt; ResourcesUpdate:\n        \"\"\"\n        Safely stores a new version or updates an existing version of named resources and sets it as the latest.\n        \"\"\"\n        raise NotImplementedError()\n\n    async def update_rollout(\n        self,\n        rollout_id: str,\n        input: TaskInput | Unset = UNSET,\n        mode: Optional[Literal[\"train\", \"val\", \"test\"]] | Unset = UNSET,\n        resources_id: Optional[str] | Unset = UNSET,\n        status: RolloutStatus | Unset = UNSET,\n        config: RolloutConfig | Unset = UNSET,\n        metadata: Optional[Dict[str, Any]] | Unset = UNSET,\n    ) -&gt; Rollout:\n        \"\"\"\n        Update the rollout status and related metadata.\n\n        Not-listed fields here either cannot be updated, or should be auto-updated (e.g., end_time).\n\n        When status is updated to a finished / problematic state, other states like task\n        queues will be updated accordingly.\n\n        Args:\n            rollout_id: Unique identifier for the rollout to update\n            input: New input data for the rollout. If set, will be updated. Can be updated to None\n            mode: New mode for the rollout. If set, will be updated. Can be updated to None\n            resources_id: New resources ID for the rollout. If set, will be updated. Can be updated to None\n            status: New status for the rollout. If set, will be updated\n            config: New config for the rollout. If set, will be updated\n            metadata: Dictionary of additional metadata to update. If set, will replace the existing metadata\n        \"\"\"\n        raise NotImplementedError()\n\n    async def update_attempt(\n        self,\n        rollout_id: str,\n        attempt_id: str | Literal[\"latest\"],\n        status: AttemptStatus | Unset = UNSET,\n        worker_id: str | Unset = UNSET,\n        last_heartbeat_time: float | Unset = UNSET,\n        metadata: Optional[Dict[str, Any]] | Unset = UNSET,\n    ) -&gt; Attempt:\n        \"\"\"\n        Update a specific or latest attempt for a given rollout.\n\n        Update the latest attempt will NOT affect the corresponding rollout status.\n\n\n        Args:\n            rollout_id: Unique identifier for the rollout\n            attempt_id: Unique identifier for the attempt\n            status: Status to set for the attempt, update if provided\n            worker_id: Worker identifier, update if provided\n            last_heartbeat_time: Timestamp of the last heartbeat from the worker\n            metadata: Dictionary of additional metadata to update, will replace the existing metadata\n        \"\"\"\n        raise NotImplementedError()\n</code></pre>"},{"location":"reference/store/#agentlightning.LightningStore.add_otel_span","title":"<code>add_otel_span(rollout_id, attempt_id, readable_span, sequence_id=None)</code>  <code>async</code>","text":"<p>Add an opentelemetry span to the store.</p> <p>If sequence_id is not provided, it will be fetched from <code>get_next_span_sequence_id</code> and assigned automatically.</p> Source code in <code>agentlightning/store/base.py</code> <pre><code>async def add_otel_span(\n    self,\n    rollout_id: str,\n    attempt_id: str,\n    readable_span: ReadableSpan,\n    sequence_id: int | None = None,\n) -&gt; Span:\n    \"\"\"\n    Add an opentelemetry span to the store.\n\n    If sequence_id is not provided, it will be fetched from `get_next_span_sequence_id` and assigned automatically.\n    \"\"\"\n    raise NotImplementedError()\n</code></pre>"},{"location":"reference/store/#agentlightning.LightningStore.add_resources","title":"<code>add_resources(resources)</code>  <code>async</code>","text":"<p>Safely stores a new version of named resources and sets it as the latest. Not implemented by many stores yet.</p> Source code in <code>agentlightning/store/base.py</code> <pre><code>async def add_resources(self, resources: NamedResources) -&gt; ResourcesUpdate:\n    \"\"\"\n    Safely stores a new version of named resources and sets it as the latest.\n    Not implemented by many stores yet.\n    \"\"\"\n    raise NotImplementedError()\n</code></pre>"},{"location":"reference/store/#agentlightning.LightningStore.add_span","title":"<code>add_span(span)</code>  <code>async</code>","text":"<p>Add a span to the store.</p> <p>This method is responsible for updating the rollout/attempt status to \"running\" if needed.</p> Source code in <code>agentlightning/store/base.py</code> <pre><code>async def add_span(self, span: Span) -&gt; Span:\n    \"\"\"\n    Add a span to the store.\n\n    This method is responsible for updating the rollout/attempt status to \"running\" if needed.\n    \"\"\"\n    raise NotImplementedError()\n</code></pre>"},{"location":"reference/store/#agentlightning.LightningStore.dequeue_rollout","title":"<code>dequeue_rollout()</code>  <code>async</code>","text":"<p>Retrieves the next task from the queue without blocking. Returns None if the queue is empty.</p> <p>Will set the rollout status to preparing.</p> Source code in <code>agentlightning/store/base.py</code> <pre><code>async def dequeue_rollout(self) -&gt; Optional[AttemptedRollout]:\n    \"\"\"\n    Retrieves the next task from the queue without blocking.\n    Returns None if the queue is empty.\n\n    Will set the rollout status to preparing.\n    \"\"\"\n    raise NotImplementedError()\n</code></pre>"},{"location":"reference/store/#agentlightning.LightningStore.enqueue_rollout","title":"<code>enqueue_rollout(input, mode=None, resources_id=None, config=None, metadata=None)</code>  <code>async</code>","text":"<p>Adds a new task to the queue with specific metadata and returns the rollout object with its unique ID.</p> Source code in <code>agentlightning/store/base.py</code> <pre><code>async def enqueue_rollout(\n    self,\n    input: TaskInput,\n    mode: Literal[\"train\", \"val\", \"test\"] | None = None,\n    resources_id: str | None = None,\n    config: RolloutConfig | None = None,\n    metadata: Dict[str, Any] | None = None,\n) -&gt; Rollout:\n    \"\"\"\n    Adds a new task to the queue with specific metadata and\n    returns the rollout object with its unique ID.\n    \"\"\"\n    raise NotImplementedError()\n</code></pre>"},{"location":"reference/store/#agentlightning.LightningStore.get_latest_attempt","title":"<code>get_latest_attempt(rollout_id)</code>  <code>async</code>","text":"<p>Safely retrieves the latest attempt for a given rollout ID.</p> Source code in <code>agentlightning/store/base.py</code> <pre><code>async def get_latest_attempt(self, rollout_id: str) -&gt; Optional[Attempt]:\n    \"\"\"\n    Safely retrieves the latest attempt for a given rollout ID.\n    \"\"\"\n    raise NotImplementedError()\n</code></pre>"},{"location":"reference/store/#agentlightning.LightningStore.get_latest_resources","title":"<code>get_latest_resources()</code>  <code>async</code>","text":"<p>Safely retrieves the latest version of named resources.</p> Source code in <code>agentlightning/store/base.py</code> <pre><code>async def get_latest_resources(self) -&gt; Optional[ResourcesUpdate]:\n    \"\"\"\n    Safely retrieves the latest version of named resources.\n    \"\"\"\n    raise NotImplementedError()\n</code></pre>"},{"location":"reference/store/#agentlightning.LightningStore.get_next_span_sequence_id","title":"<code>get_next_span_sequence_id(rollout_id, attempt_id)</code>  <code>async</code>","text":"<p>Get the next span sequence ID for a given rollout and attempt. This should be used to assign a unique sequence ID to each span within an attempt.</p> <p>Recommend getting the ID before the operation even begins to avoid racing conditions.</p> Source code in <code>agentlightning/store/base.py</code> <pre><code>async def get_next_span_sequence_id(self, rollout_id: str, attempt_id: str) -&gt; int:\n    \"\"\"\n    Get the next span sequence ID for a given rollout and attempt.\n    This should be used to assign a unique sequence ID to each span within an attempt.\n\n    Recommend getting the ID before the operation even begins to avoid racing conditions.\n    \"\"\"\n    raise NotImplementedError()\n</code></pre>"},{"location":"reference/store/#agentlightning.LightningStore.get_resources_by_id","title":"<code>get_resources_by_id(resources_id)</code>  <code>async</code>","text":"<p>Safely retrieves a specific version of named resources by its ID.</p> Source code in <code>agentlightning/store/base.py</code> <pre><code>async def get_resources_by_id(self, resources_id: str) -&gt; Optional[ResourcesUpdate]:\n    \"\"\"\n    Safely retrieves a specific version of named resources by its ID.\n    \"\"\"\n    raise NotImplementedError()\n</code></pre>"},{"location":"reference/store/#agentlightning.LightningStore.get_rollout_by_id","title":"<code>get_rollout_by_id(rollout_id)</code>  <code>async</code>","text":"<p>Safely retrieves a specific rollout by its ID.</p> Source code in <code>agentlightning/store/base.py</code> <pre><code>async def get_rollout_by_id(self, rollout_id: str) -&gt; Optional[Rollout]:\n    \"\"\"\n    Safely retrieves a specific rollout by its ID.\n    \"\"\"\n    raise NotImplementedError()\n</code></pre>"},{"location":"reference/store/#agentlightning.LightningStore.query_attempts","title":"<code>query_attempts(rollout_id)</code>  <code>async</code>","text":"<p>Query and retrieve all attempts associated with a specific rollout ID. Returns an empty list if no attempts are found.</p> Source code in <code>agentlightning/store/base.py</code> <pre><code>async def query_attempts(self, rollout_id: str) -&gt; List[Attempt]:\n    \"\"\"\n    Query and retrieve all attempts associated with a specific rollout ID.\n    Returns an empty list if no attempts are found.\n    \"\"\"\n    raise NotImplementedError()\n</code></pre>"},{"location":"reference/store/#agentlightning.LightningStore.query_rollouts","title":"<code>query_rollouts(*, status=None, rollout_ids=None)</code>  <code>async</code>","text":"<p>Query and retrieve rollouts filtered by their status. If no status is provided, returns all rollouts.</p> Source code in <code>agentlightning/store/base.py</code> <pre><code>async def query_rollouts(\n    self, *, status: Optional[Sequence[RolloutStatus]] = None, rollout_ids: Optional[Sequence[str]] = None\n) -&gt; List[Rollout]:\n    \"\"\"\n    Query and retrieve rollouts filtered by their status.\n    If no status is provided, returns all rollouts.\n    \"\"\"\n    raise NotImplementedError()\n</code></pre>"},{"location":"reference/store/#agentlightning.LightningStore.query_spans","title":"<code>query_spans(rollout_id, attempt_id=None)</code>  <code>async</code>","text":"<p>Query and retrieve all spans associated with a specific rollout ID. Returns an empty list if no spans are found.</p> Source code in <code>agentlightning/store/base.py</code> <pre><code>async def query_spans(self, rollout_id: str, attempt_id: str | Literal[\"latest\"] | None = None) -&gt; List[Span]:\n    \"\"\"\n    Query and retrieve all spans associated with a specific rollout ID.\n    Returns an empty list if no spans are found.\n    \"\"\"\n    raise NotImplementedError()\n</code></pre>"},{"location":"reference/store/#agentlightning.LightningStore.start_attempt","title":"<code>start_attempt(rollout_id)</code>  <code>async</code>","text":"<p>Create a new attempt for a given rollout ID and return the attempt details.</p> Source code in <code>agentlightning/store/base.py</code> <pre><code>async def start_attempt(self, rollout_id: str) -&gt; AttemptedRollout:\n    \"\"\"\n    Create a new attempt for a given rollout ID and return the attempt details.\n    \"\"\"\n    raise NotImplementedError()\n</code></pre>"},{"location":"reference/store/#agentlightning.LightningStore.start_rollout","title":"<code>start_rollout(input, mode=None, resources_id=None, config=None, metadata=None)</code>  <code>async</code>","text":"<p>Add one incomplete rollout to the store, and get an attempt created for it. This will immediately sets the rollout to a preparing state, and should be used by whoever is going to execute the rollout.</p> <p>Return a special rollout with attempt object. Do not update it directly.</p> <p>But if the rollout fails or timeouts, it's still possible that the watchdog sends it back to the queue for retry.</p> <p>To enqueue a rollout to the task queue, use <code>enqueue_rollout</code> instead.</p> Source code in <code>agentlightning/store/base.py</code> <pre><code>async def start_rollout(\n    self,\n    input: TaskInput,\n    mode: Literal[\"train\", \"val\", \"test\"] | None = None,\n    resources_id: str | None = None,\n    config: RolloutConfig | None = None,\n    metadata: Dict[str, Any] | None = None,\n) -&gt; AttemptedRollout:\n    \"\"\"\n    Add one incomplete rollout to the store, and get an attempt created for it.\n    This will immediately sets the rollout to a preparing state, and should be\n    used by whoever is going to execute the rollout.\n\n    Return a special rollout with attempt object. Do not update it directly.\n\n    But if the rollout fails or timeouts, it's still possible that the watchdog\n    sends it back to the queue for retry.\n\n    To enqueue a rollout to the task queue, use `enqueue_rollout` instead.\n    \"\"\"\n    raise NotImplementedError()\n</code></pre>"},{"location":"reference/store/#agentlightning.LightningStore.update_attempt","title":"<code>update_attempt(rollout_id, attempt_id, status=UNSET, worker_id=UNSET, last_heartbeat_time=UNSET, metadata=UNSET)</code>  <code>async</code>","text":"<p>Update a specific or latest attempt for a given rollout.</p> <p>Update the latest attempt will NOT affect the corresponding rollout status.</p> <p>Parameters:</p> Name Type Description Default <code>rollout_id</code> <code>str</code> <p>Unique identifier for the rollout</p> required <code>attempt_id</code> <code>str | Literal['latest']</code> <p>Unique identifier for the attempt</p> required <code>status</code> <code>AttemptStatus | Unset</code> <p>Status to set for the attempt, update if provided</p> <code>UNSET</code> <code>worker_id</code> <code>str | Unset</code> <p>Worker identifier, update if provided</p> <code>UNSET</code> <code>last_heartbeat_time</code> <code>float | Unset</code> <p>Timestamp of the last heartbeat from the worker</p> <code>UNSET</code> <code>metadata</code> <code>Optional[Dict[str, Any]] | Unset</code> <p>Dictionary of additional metadata to update, will replace the existing metadata</p> <code>UNSET</code> Source code in <code>agentlightning/store/base.py</code> <pre><code>async def update_attempt(\n    self,\n    rollout_id: str,\n    attempt_id: str | Literal[\"latest\"],\n    status: AttemptStatus | Unset = UNSET,\n    worker_id: str | Unset = UNSET,\n    last_heartbeat_time: float | Unset = UNSET,\n    metadata: Optional[Dict[str, Any]] | Unset = UNSET,\n) -&gt; Attempt:\n    \"\"\"\n    Update a specific or latest attempt for a given rollout.\n\n    Update the latest attempt will NOT affect the corresponding rollout status.\n\n\n    Args:\n        rollout_id: Unique identifier for the rollout\n        attempt_id: Unique identifier for the attempt\n        status: Status to set for the attempt, update if provided\n        worker_id: Worker identifier, update if provided\n        last_heartbeat_time: Timestamp of the last heartbeat from the worker\n        metadata: Dictionary of additional metadata to update, will replace the existing metadata\n    \"\"\"\n    raise NotImplementedError()\n</code></pre>"},{"location":"reference/store/#agentlightning.LightningStore.update_resources","title":"<code>update_resources(resources_id, resources)</code>  <code>async</code>","text":"<p>Safely stores a new version or updates an existing version of named resources and sets it as the latest.</p> Source code in <code>agentlightning/store/base.py</code> <pre><code>async def update_resources(self, resources_id: str, resources: NamedResources) -&gt; ResourcesUpdate:\n    \"\"\"\n    Safely stores a new version or updates an existing version of named resources and sets it as the latest.\n    \"\"\"\n    raise NotImplementedError()\n</code></pre>"},{"location":"reference/store/#agentlightning.LightningStore.update_rollout","title":"<code>update_rollout(rollout_id, input=UNSET, mode=UNSET, resources_id=UNSET, status=UNSET, config=UNSET, metadata=UNSET)</code>  <code>async</code>","text":"<p>Update the rollout status and related metadata.</p> <p>Not-listed fields here either cannot be updated, or should be auto-updated (e.g., end_time).</p> <p>When status is updated to a finished / problematic state, other states like task queues will be updated accordingly.</p> <p>Parameters:</p> Name Type Description Default <code>rollout_id</code> <code>str</code> <p>Unique identifier for the rollout to update</p> required <code>input</code> <code>TaskInput | Unset</code> <p>New input data for the rollout. If set, will be updated. Can be updated to None</p> <code>UNSET</code> <code>mode</code> <code>Optional[Literal['train', 'val', 'test']] | Unset</code> <p>New mode for the rollout. If set, will be updated. Can be updated to None</p> <code>UNSET</code> <code>resources_id</code> <code>Optional[str] | Unset</code> <p>New resources ID for the rollout. If set, will be updated. Can be updated to None</p> <code>UNSET</code> <code>status</code> <code>RolloutStatus | Unset</code> <p>New status for the rollout. If set, will be updated</p> <code>UNSET</code> <code>config</code> <code>RolloutConfig | Unset</code> <p>New config for the rollout. If set, will be updated</p> <code>UNSET</code> <code>metadata</code> <code>Optional[Dict[str, Any]] | Unset</code> <p>Dictionary of additional metadata to update. If set, will replace the existing metadata</p> <code>UNSET</code> Source code in <code>agentlightning/store/base.py</code> <pre><code>async def update_rollout(\n    self,\n    rollout_id: str,\n    input: TaskInput | Unset = UNSET,\n    mode: Optional[Literal[\"train\", \"val\", \"test\"]] | Unset = UNSET,\n    resources_id: Optional[str] | Unset = UNSET,\n    status: RolloutStatus | Unset = UNSET,\n    config: RolloutConfig | Unset = UNSET,\n    metadata: Optional[Dict[str, Any]] | Unset = UNSET,\n) -&gt; Rollout:\n    \"\"\"\n    Update the rollout status and related metadata.\n\n    Not-listed fields here either cannot be updated, or should be auto-updated (e.g., end_time).\n\n    When status is updated to a finished / problematic state, other states like task\n    queues will be updated accordingly.\n\n    Args:\n        rollout_id: Unique identifier for the rollout to update\n        input: New input data for the rollout. If set, will be updated. Can be updated to None\n        mode: New mode for the rollout. If set, will be updated. Can be updated to None\n        resources_id: New resources ID for the rollout. If set, will be updated. Can be updated to None\n        status: New status for the rollout. If set, will be updated\n        config: New config for the rollout. If set, will be updated\n        metadata: Dictionary of additional metadata to update. If set, will replace the existing metadata\n    \"\"\"\n    raise NotImplementedError()\n</code></pre>"},{"location":"reference/store/#agentlightning.LightningStore.wait_for_rollouts","title":"<code>wait_for_rollouts(*, rollout_ids, timeout=None)</code>  <code>async</code>","text":"<p>Wait for specified rollouts to complete with a timeout. Returns the completed rollouts, potentially incomplete if timeout is reached.</p> <p>TODO: Add support for waiting for 20 new rollouts, or wait until 80% of the pending ids are completed.</p> Source code in <code>agentlightning/store/base.py</code> <pre><code>async def wait_for_rollouts(self, *, rollout_ids: List[str], timeout: Optional[float] = None) -&gt; List[Rollout]:\n    \"\"\"\n    Wait for specified rollouts to complete with a timeout.\n    Returns the completed rollouts, potentially incomplete if timeout is reached.\n\n    TODO: Add support for waiting for 20 new rollouts, or wait until 80% of the pending ids are completed.\n    \"\"\"\n    raise NotImplementedError()\n</code></pre>"},{"location":"reference/store/#store-implementations","title":"Store Implementations","text":""},{"location":"reference/store/#agentlightning.InMemoryLightningStore","title":"<code>agentlightning.InMemoryLightningStore</code>","text":"<p>               Bases: <code>LightningStore</code></p> <p>In-memory implementation of LightningStore using Python data structures. Thread-safe and async-compatible but data is not persistent.</p> <p>The methods in this class should generally not call each other, especially those that are locked.</p> <p>Parameters:</p> Name Type Description Default <code>eviction_memory_threshold</code> <code>float | int | None</code> <p>The threshold for evicting spans in bytes. By default, it's 70% of the total VRAM available.</p> <code>None</code> <code>safe_memory_threshold</code> <code>float | int | None</code> <p>The threshold for safe memory usage in bytes. By default, it's 80% of the eviction threshold.</p> <code>None</code> <code>span_size_estimator</code> <code>Callable[[Span], int] | None</code> <p>A function to estimate the size of a span in bytes. By default, it's a simple size estimator that uses sys.getsizeof.</p> <code>None</code> Source code in <code>agentlightning/store/memory.py</code> <pre><code>class InMemoryLightningStore(LightningStore):\n    \"\"\"\n    In-memory implementation of LightningStore using Python data structures.\n    Thread-safe and async-compatible but data is not persistent.\n\n    The methods in this class should generally not call each other,\n    especially those that are locked.\n\n    Args:\n        eviction_memory_threshold: The threshold for evicting spans in bytes.\n            By default, it's 70% of the total VRAM available.\n        safe_memory_threshold: The threshold for safe memory usage in bytes.\n            By default, it's 80% of the eviction threshold.\n        span_size_estimator: A function to estimate the size of a span in bytes.\n            By default, it's a simple size estimator that uses sys.getsizeof.\n    \"\"\"\n\n    def __init__(\n        self,\n        *,\n        eviction_memory_threshold: float | int | None = None,\n        safe_memory_threshold: float | int | None = None,\n        span_size_estimator: Callable[[Span], int] | None = None,\n    ):\n        self._lock = asyncio.Lock()\n\n        # Task queue and rollouts storage\n        self._task_queue: deque[Rollout] = deque()\n        self._rollouts: Dict[str, Rollout] = {}\n\n        # Resources storage (similar to legacy server.py)\n        self._resources: Dict[str, ResourcesUpdate] = {}\n        self._latest_resources_id: Optional[str] = None\n\n        # Spans storage\n        self._spans: Dict[str, List[Span]] = {}  # rollout_id -&gt; list of spans\n        self._span_sequence_ids: Dict[str, int] = Counter()  # rollout_id -&gt; sequence_id\n        self._span_bytes_by_rollout: Dict[str, int] = Counter()\n        self._total_span_bytes: int = 0\n        self._evicted_rollout_span_sets: Set[str] = set()\n\n        self._memory_capacity_bytes = _detect_total_memory_bytes()\n        if self._memory_capacity_bytes &lt;= 0:\n            raise ValueError(\"Detected memory capacity must be positive\")\n\n        self._eviction_threshold_bytes = self._resolve_memory_threshold(\n            eviction_memory_threshold,\n            default_ratio=0.7,\n            capacity_bytes=self._memory_capacity_bytes,\n            name=\"eviction_memory_threshold\",\n            minimum=1,\n        )\n\n        if safe_memory_threshold is None:\n            safe_memory_threshold = max(int(self._eviction_threshold_bytes * 0.8), 0)\n\n        self._safe_threshold_bytes = self._resolve_memory_threshold(\n            safe_memory_threshold,\n            default_ratio=self._eviction_threshold_bytes / self._memory_capacity_bytes,\n            capacity_bytes=self._memory_capacity_bytes,\n            name=\"safe_memory_threshold\",\n            minimum=0,\n        )\n\n        if not (0 &lt;= self._safe_threshold_bytes &lt; self._eviction_threshold_bytes):\n            raise ValueError(\"safe_memory_threshold must be smaller than eviction_memory_threshold\")\n        self._custom_span_size_estimator = span_size_estimator\n\n        # Attempt tracking\n        self._attempts: Dict[str, List[Attempt]] = {}  # rollout_id -&gt; list of attempts\n\n        # Completion tracking for wait_for_rollouts (cross-loop safe)\n        self._completion_events: Dict[str, threading.Event] = {}\n\n    @_healthcheck_wrapper\n    async def start_rollout(\n        self,\n        input: TaskInput,\n        mode: Literal[\"train\", \"val\", \"test\"] | None = None,\n        resources_id: str | None = None,\n        config: RolloutConfig | None = None,\n        metadata: Dict[str, Any] | None = None,\n    ) -&gt; AttemptedRollout:\n        \"\"\"\n        Notify the store that I'm about to run a rollout.\n        \"\"\"\n        async with self._lock:\n            rollout_id = _generate_rollout_id()\n            current_time = time.time()\n\n            rollout_config = config.model_copy(deep=True) if config is not None else RolloutConfig()\n            rollout_metadata = dict(metadata) if metadata is not None else {}\n\n            rollout = Rollout(\n                rollout_id=rollout_id,\n                input=input,\n                mode=mode,\n                resources_id=resources_id or self._latest_resources_id,\n                start_time=current_time,\n                status=\"preparing\",\n                config=rollout_config,\n                metadata=rollout_metadata,\n            )\n\n            # Create the initial attempt\n            attempt_id = _generate_attempt_id()\n            attempt = Attempt(\n                rollout_id=rollout.rollout_id,\n                attempt_id=attempt_id,\n                sequence_id=1,\n                start_time=current_time,\n                status=\"preparing\",\n            )\n\n            self._attempts[rollout.rollout_id] = [attempt]\n            self._rollouts[rollout.rollout_id] = rollout\n\n            # Manully added rollout is not added to task queue. It's already preparing\n            self._completion_events.setdefault(rollout.rollout_id, threading.Event())\n\n            return AttemptedRollout(**rollout.model_dump(), attempt=attempt)\n\n    @_healthcheck_wrapper\n    async def enqueue_rollout(\n        self,\n        input: TaskInput,\n        mode: Literal[\"train\", \"val\", \"test\"] | None = None,\n        resources_id: str | None = None,\n        config: RolloutConfig | None = None,\n        metadata: Dict[str, Any] | None = None,\n    ) -&gt; Rollout:\n        \"\"\"\n        Adds a new task to the queue with specific metadata and returns its unique ID.\n        \"\"\"\n        async with self._lock:\n            rollout_id = _generate_rollout_id()\n            current_time = time.time()\n\n            rollout_config = config.model_copy(deep=True) if config is not None else RolloutConfig()\n            rollout_metadata = dict(metadata) if metadata is not None else {}\n\n            rollout = Rollout(\n                rollout_id=rollout_id,\n                input=input,\n                mode=mode,\n                resources_id=resources_id or self._latest_resources_id,\n                start_time=current_time,\n                status=\"queuing\",  # should be queuing\n                config=rollout_config,\n                metadata=rollout_metadata,\n            )\n\n            self._rollouts[rollout.rollout_id] = rollout\n            self._task_queue.append(rollout)  # add it to the end of the queue\n            self._completion_events.setdefault(rollout.rollout_id, threading.Event())\n\n            return rollout\n\n    @_healthcheck_wrapper\n    async def dequeue_rollout(self) -&gt; Optional[AttemptedRollout]:\n        \"\"\"\n        Retrieves the next task from the queue without blocking.\n        Returns None if the queue is empty.\n\n        Will set the rollout status to preparing and create a new attempt.\n        \"\"\"\n        async with self._lock:\n            # Keep looking until we find a rollout that's still in queuing status\n            # or the queue is empty\n            while self._task_queue:\n                rollout = self._task_queue.popleft()\n\n                # Check if rollout is still in a queuing state\n                # (it might have been updated to a different status while in queue)\n                if is_queuing(rollout):\n                    # Update status to preparing\n                    rollout.status = \"preparing\"\n\n                    # Create a new attempt (could be first attempt or retry)\n                    attempt_id = _generate_attempt_id()\n                    current_time = time.time()\n\n                    # Get existing attempts to determine sequence number\n                    existing_attempts = self._attempts.get(rollout.rollout_id, [])\n                    sequence_id = len(existing_attempts) + 1\n\n                    attempt = Attempt(\n                        rollout_id=rollout.rollout_id,\n                        attempt_id=attempt_id,\n                        sequence_id=sequence_id,\n                        start_time=current_time,\n                        status=\"preparing\",\n                    )\n\n                    if rollout.rollout_id not in self._attempts:\n                        self._attempts[rollout.rollout_id] = []\n                    self._attempts[rollout.rollout_id].append(attempt)\n\n                    return AttemptedRollout(**rollout.model_dump(), attempt=attempt)\n\n                # If not in queuing state, skip this rollout and continue\n                # (it was updated externally and should not be processed)\n\n            # No valid rollouts found\n            return None\n\n    @_healthcheck_wrapper\n    async def start_attempt(self, rollout_id: str) -&gt; AttemptedRollout:\n        \"\"\"\n        Create a new attempt for a given rollout ID and return the attempt details.\n        \"\"\"\n        async with self._lock:\n            # Get the rollout\n            rollout = self._rollouts.get(rollout_id)\n            if not rollout:\n                raise ValueError(f\"Rollout {rollout_id} not found\")\n\n            # Get existing attempts to determine sequence number\n            existing_attempts = self._attempts.get(rollout_id, [])\n            sequence_id = len(existing_attempts) + 1\n\n            # We don't care whether the max attempts have reached or not\n            # This attempt is from user trigger\n\n            # Create new attempt\n            attempt_id = _generate_attempt_id()\n            current_time = time.time()\n\n            attempt = Attempt(\n                rollout_id=rollout_id,\n                attempt_id=attempt_id,\n                sequence_id=sequence_id,\n                start_time=current_time,\n                status=\"preparing\",\n            )\n\n            # Add attempt to storage\n            if rollout_id not in self._attempts:\n                self._attempts[rollout_id] = []\n            self._attempts[rollout_id].append(attempt)\n\n            self._completion_events.setdefault(rollout.rollout_id, threading.Event())\n\n            return AttemptedRollout(**rollout.model_dump(), attempt=attempt)\n\n    @_healthcheck_wrapper\n    async def query_rollouts(\n        self, *, status: Optional[Sequence[RolloutStatus]] = None, rollout_ids: Optional[Sequence[str]] = None\n    ) -&gt; List[Rollout]:\n        \"\"\"\n        Query and retrieve rollouts filtered by their status and rollout ids.\n        If no status is provided, returns all rollouts.\n        \"\"\"\n        async with self._lock:\n            rollouts = list(self._rollouts.values())\n\n            # Filter by rollout_ids if provided\n            if rollout_ids is not None:\n                rollout_ids_set = set(rollout_ids)\n                rollouts = [rollout for rollout in rollouts if rollout.rollout_id in rollout_ids_set]\n\n            # Filter by status if provided\n            if status is not None:\n                status_set = set(status)\n                rollouts = [rollout for rollout in rollouts if rollout.status in status_set]\n\n            return rollouts\n\n    @_healthcheck_wrapper\n    async def get_rollout_by_id(self, rollout_id: str) -&gt; Optional[Rollout]:\n        \"\"\"\n        Safely retrieves a specific rollout by its ID.\n        \"\"\"\n        async with self._lock:\n            return self._rollouts.get(rollout_id)\n\n    @_healthcheck_wrapper\n    async def query_attempts(self, rollout_id: str) -&gt; List[Attempt]:\n        \"\"\"\n        Query and retrieve all attempts associated with a specific rollout ID.\n        Returns an empty list if no attempts are found.\n        \"\"\"\n        async with self._lock:\n            return self._attempts.get(rollout_id, [])\n\n    @_healthcheck_wrapper\n    async def get_latest_attempt(self, rollout_id: str) -&gt; Optional[Attempt]:\n        \"\"\"\n        Safely retrieves the latest attempt for a given rollout ID.\n        \"\"\"\n        async with self._lock:\n            attempts = self._attempts.get(rollout_id, [])\n            if not attempts:\n                return None\n            return max(attempts, key=lambda a: a.sequence_id)\n\n    @_healthcheck_wrapper\n    async def add_resources(self, resources: NamedResources) -&gt; ResourcesUpdate:\n        \"\"\"\n        Safely stores a new version of named resources and sets it as the latest.\n        \"\"\"\n        resources_id = _generate_resources_id()\n        async with self._lock:\n            update = ResourcesUpdate(resources_id=resources_id, resources=resources)\n            self._resources[resources_id] = update\n            self._latest_resources_id = resources_id\n            return update\n\n    @_healthcheck_wrapper\n    async def update_resources(self, resources_id: str, resources: NamedResources) -&gt; ResourcesUpdate:\n        \"\"\"\n        Safely stores a new version of named resources and sets it as the latest.\n        \"\"\"\n        async with self._lock:\n            update = ResourcesUpdate(resources_id=resources_id, resources=resources)\n            self._resources[resources_id] = update\n            self._latest_resources_id = resources_id\n            return update\n\n    @_healthcheck_wrapper\n    async def get_resources_by_id(self, resources_id: str) -&gt; Optional[ResourcesUpdate]:\n        \"\"\"\n        Safely retrieves a specific version of named resources by its ID.\n        \"\"\"\n        async with self._lock:\n            return self._resources.get(resources_id)\n\n    @_healthcheck_wrapper\n    async def get_latest_resources(self) -&gt; Optional[ResourcesUpdate]:\n        \"\"\"\n        Safely retrieves the latest version of named resources.\n        \"\"\"\n        async with self._lock:\n            if self._latest_resources_id:\n                return self._resources.get(self._latest_resources_id)\n            return None\n\n    async def get_next_span_sequence_id(self, rollout_id: str, attempt_id: str) -&gt; int:\n        \"\"\"\n        Get the next span sequence ID for a given rollout and attempt.\n        The number is strictly increasing for each rollout.\n        The store will not issue the same sequence ID twice.\n        \"\"\"\n        async with self._lock:\n            self._span_sequence_ids[rollout_id] += 1\n            return self._span_sequence_ids[rollout_id]\n\n    async def add_span(self, span: Span) -&gt; Span:\n        \"\"\"Persist a pre-converted span.\"\"\"\n        async with self._lock:\n            self._span_sequence_ids[span.rollout_id] = max(self._span_sequence_ids[span.rollout_id], span.sequence_id)\n            return await self._add_span_unlocked(span)\n\n    async def add_otel_span(\n        self, rollout_id: str, attempt_id: str, readable_span: ReadableSpan, sequence_id: int | None = None\n    ) -&gt; Span:\n        \"\"\"Add an opentelemetry span to the store.\"\"\"\n        async with self._lock:\n            if sequence_id is None:\n                # Issue a new sequence ID for the rollout\n                self._span_sequence_ids[rollout_id] += 1\n                sequence_id = self._span_sequence_ids[rollout_id]\n            else:\n                # Comes from a provided sequence ID\n                # Make sure our counter is strictly increasing\n                self._span_sequence_ids[rollout_id] = max(self._span_sequence_ids[rollout_id], sequence_id)\n\n            span = Span.from_opentelemetry(\n                readable_span, rollout_id=rollout_id, attempt_id=attempt_id, sequence_id=sequence_id\n            )\n            await self._add_span_unlocked(span)\n            return span\n\n    async def _add_span_unlocked(self, span: Span) -&gt; Span:\n        rollout = self._rollouts.get(span.rollout_id)\n        if not rollout:\n            raise ValueError(f\"Rollout {span.rollout_id} not found\")\n        attempts = self._attempts.get(span.rollout_id, [])\n        current_attempt = next((a for a in attempts if a.attempt_id == span.attempt_id), None)\n        latest_attempt = max(attempts, key=lambda a: a.sequence_id) if attempts else None\n        if not current_attempt:\n            raise ValueError(f\"Attempt {span.attempt_id} not found for rollout {span.rollout_id}\")\n        if not latest_attempt:\n            raise ValueError(f\"No attempts found for rollout {span.rollout_id}\")\n\n        if span.rollout_id not in self._spans:\n            self._spans[span.rollout_id] = []\n        self._spans[span.rollout_id].append(span)\n        self._account_span_size(span)\n        self._maybe_evict_spans()\n\n        # Update attempt heartbeat\n        current_attempt.last_heartbeat_time = time.time()\n        if current_attempt.status in [\"preparing\", \"unresponsive\"]:\n            current_attempt.status = \"running\"\n\n        # If the status has already timed out or failed, do not change it\n\n        # Update rollout status if it's the latest attempt\n        if current_attempt == latest_attempt:\n            if rollout.status == \"preparing\":\n                rollout.status = \"running\"\n            elif rollout.status in [\"queuing\", \"requeuing\"]:\n                try:\n                    self._task_queue.remove(rollout)\n                except ValueError:\n                    logger.warning(\n                        f\"Trying to remove rollout {rollout.rollout_id} from the queue but it's not in the queue.\"\n                    )\n                rollout.status = \"running\"\n\n        return span\n\n    @staticmethod\n    def _resolve_memory_threshold(\n        value: float | int | None,\n        *,\n        default_ratio: float,\n        capacity_bytes: int,\n        name: str,\n        minimum: int,\n    ) -&gt; int:\n        if value is None:\n            resolved = int(capacity_bytes * default_ratio)\n        elif isinstance(value, float):\n            if minimum == 0:\n                if not (0 &lt;= value &lt;= 1):\n                    raise ValueError(f\"{name} ratio must be between 0 and 1 inclusive\")\n            else:\n                if not (0 &lt; value &lt;= 1):\n                    raise ValueError(f\"{name} ratio must be greater than 0 and at most 1\")\n            resolved = int(capacity_bytes * value)\n        else:\n            value_int = value\n            if value_int &lt; 0:\n                raise ValueError(f\"{name} must be non-negative\")\n            resolved = value_int\n\n        if resolved &lt; minimum:\n            raise ValueError(f\"{name} must be at least {minimum} bytes\")\n\n        return resolved\n\n    def _account_span_size(self, span: Span) -&gt; int:\n        if self._custom_span_size_estimator is not None:\n            size = max(int(self._custom_span_size_estimator(span)), 0)\n        else:\n            size = estimate_model_size(span)\n\n        self._span_bytes_by_rollout[span.rollout_id] += size\n        self._total_span_bytes += size\n        return size\n\n    def _maybe_evict_spans(self) -&gt; None:\n        if self._total_span_bytes &lt;= self._eviction_threshold_bytes:\n            return\n\n        candidates: List[tuple[float, str]] = []\n        for rollout_id, spans in self._spans.items():\n            if not spans:\n                continue\n            rollout = self._rollouts.get(rollout_id)\n            start_time = rollout.start_time if rollout is not None else (spans[0].start_time or 0.0)\n            candidates.append((start_time, rollout_id))\n\n        candidates.sort(key=lambda item: item[0])\n\n        logger.info(f\"Evicting spans for {len(candidates)} rollouts to free up memory...\")\n        memory_consumed_before = self._total_span_bytes\n        for _, rollout_id in candidates:\n            if self._total_span_bytes &lt;= self._safe_threshold_bytes:\n                break\n            logger.debug(f\"Evicting spans for rollout {rollout_id} to free up memory...\")\n            self._evict_spans_for_rollout(rollout_id)\n        logger.info(f\"Freed up {memory_consumed_before - self._total_span_bytes} bytes of memory\")\n\n    def _evict_spans_for_rollout(self, rollout_id: str) -&gt; None:\n        spans = self._spans.pop(rollout_id, [])\n        if not spans:\n            return\n        removed_bytes = self._span_bytes_by_rollout.pop(rollout_id, 0)\n        self._total_span_bytes = max(self._total_span_bytes - removed_bytes, 0)\n        self._evicted_rollout_span_sets.add(rollout_id)\n\n    @_healthcheck_wrapper\n    async def wait_for_rollouts(self, *, rollout_ids: List[str], timeout: Optional[float] = None) -&gt; List[Rollout]:\n        \"\"\"\n        Wait for specified rollouts to complete with a timeout.\n        Returns the completed rollouts, potentially incomplete if timeout is reached.\n\n        This method does not change the state of the store.\n        \"\"\"\n        completed_rollouts: List[Rollout] = []\n\n        async def wait_for_rollout(rollout_id: str):\n            # First check if already completed\n            async with self._lock:\n                rollout = self._rollouts.get(rollout_id)\n                if rollout and is_finished(rollout):\n                    completed_rollouts.append(rollout)\n                    return\n\n            # No timeout, return immediately\n            if timeout is not None and timeout &lt;= 0:\n                return\n\n            # If not completed and we have an event, wait for completion\n            if rollout_id in self._completion_events:\n                evt = self._completion_events[rollout_id]\n\n                # Wait for the event with proper timeout handling\n                # evt.wait() returns True if event was set, False if timeout occurred\n                if timeout is None:\n                    # Wait indefinitely by polling with finite timeouts\n                    # This allows threads to exit cleanly on shutdown\n                    while True:\n                        result = await asyncio.to_thread(evt.wait, 10.0)  # Poll every 10 seconds\n                        if result:  # Event was set\n                            break\n                        # Loop and check again (continues indefinitely since timeout=None)\n                else:\n                    # Wait with the specified timeout\n                    result = await asyncio.to_thread(evt.wait, timeout)\n\n                # If event was set (not timeout), check if rollout is finished\n                if result:\n                    async with self._lock:\n                        rollout = self._rollouts.get(rollout_id)\n                        if rollout and is_finished(rollout):\n                            completed_rollouts.append(rollout)\n\n            # Rollout not found, return\n\n        # Wait for all rollouts concurrently\n        await asyncio.gather(*[wait_for_rollout(rid) for rid in rollout_ids], return_exceptions=True)\n\n        return completed_rollouts\n\n    @_healthcheck_wrapper\n    async def query_spans(self, rollout_id: str, attempt_id: str | Literal[\"latest\"] | None = None) -&gt; List[Span]:\n        \"\"\"\n        Query and retrieve all spans associated with a specific rollout ID.\n        Returns an empty list if no spans are found.\n        \"\"\"\n        async with self._lock:\n            if rollout_id in self._evicted_rollout_span_sets:\n                raise RuntimeError(f\"Spans for rollout {rollout_id} have been evicted\")\n            spans = self._spans.get(rollout_id, [])\n            if attempt_id is None:\n                return spans\n            elif attempt_id == \"latest\":\n                # Find the latest attempt_id\n                if not spans:\n                    return []\n                latest_attempt = max(spans, key=lambda s: s.sequence_id if s.attempt_id else \"\").attempt_id\n                return [s for s in spans if s.attempt_id == latest_attempt]\n            else:\n                return [s for s in spans if s.attempt_id == attempt_id]\n\n    @_healthcheck_wrapper\n    async def update_rollout(\n        self,\n        rollout_id: str,\n        input: TaskInput | Unset = UNSET,\n        mode: Optional[Literal[\"train\", \"val\", \"test\"]] | Unset = UNSET,\n        resources_id: Optional[str] | Unset = UNSET,\n        status: RolloutStatus | Unset = UNSET,\n        config: RolloutConfig | Unset = UNSET,\n        metadata: Optional[Dict[str, Any]] | Unset = UNSET,\n    ) -&gt; Rollout:\n        \"\"\"\n        Update the rollout status and related metadata.\n        \"\"\"\n        async with self._lock:\n            return await self._update_rollout_unlocked(\n                rollout_id=rollout_id,\n                input=input,\n                mode=mode,\n                resources_id=resources_id,\n                status=status,\n                config=config,\n                metadata=metadata,\n            )\n\n    @_healthcheck_wrapper\n    async def update_attempt(\n        self,\n        rollout_id: str,\n        attempt_id: str | Literal[\"latest\"],\n        status: AttemptStatus | Unset = UNSET,\n        worker_id: str | Unset = UNSET,\n        last_heartbeat_time: float | Unset = UNSET,\n        metadata: Optional[Dict[str, Any]] | Unset = UNSET,\n    ) -&gt; Attempt:\n        \"\"\"\n        Update a specific or latest attempt for a given rollout.\n        \"\"\"\n        async with self._lock:\n            attempt = await self._update_attempt_unlocked(\n                rollout_id=rollout_id,\n                attempt_id=attempt_id,\n                status=status,\n                worker_id=worker_id,\n                last_heartbeat_time=last_heartbeat_time,\n                metadata=metadata,\n            )\n\n        return attempt\n\n    async def _update_rollout_unlocked(\n        self,\n        rollout_id: str,\n        input: TaskInput | Unset = UNSET,\n        mode: Optional[Literal[\"train\", \"val\", \"test\"]] | Unset = UNSET,\n        resources_id: Optional[str] | Unset = UNSET,\n        status: RolloutStatus | Unset = UNSET,\n        config: RolloutConfig | Unset = UNSET,\n        metadata: Optional[Dict[str, Any]] | Unset = UNSET,\n    ) -&gt; Rollout:\n        # No lock inside this one.\n        rollout = self._rollouts.get(rollout_id)\n        if not rollout:\n            raise ValueError(f\"Rollout {rollout_id} not found\")\n\n        # Update fields if they are not UNSET\n        if not isinstance(input, Unset):\n            rollout.input = input\n        if not isinstance(mode, Unset):\n            rollout.mode = mode\n        if not isinstance(resources_id, Unset):\n            rollout.resources_id = resources_id\n        if not isinstance(status, Unset):\n            rollout.status = status\n        if not isinstance(config, Unset):\n            rollout.config = config\n        if not isinstance(metadata, Unset):\n            rollout.metadata = metadata\n\n        # Set end time for finished rollouts\n        # Rollout is only finished when it succeeded or fail with no more retries.\n        if not isinstance(status, Unset) and is_finished(rollout):\n            rollout.end_time = time.time()\n            # Signal completion\n            if rollout_id in self._completion_events:\n                self._completion_events[rollout_id].set()\n\n        # If requeuing, add back to queue\n        elif is_queuing(rollout) and rollout not in self._task_queue:\n            self._task_queue.append(rollout)\n\n        # If the rollout is no longer in a queueing state, remove it from the queue.\n        if not isinstance(status, Unset) and not is_queuing(rollout) and rollout in self._task_queue:\n            try:\n                self._task_queue.remove(rollout)\n            except ValueError:\n                # Another coroutine may have already removed the rollout from the queue.\n                logger.warning(\n                    f\"Trying to remove rollout {rollout.rollout_id} from the queue but it's not in the queue.\"\n                )\n\n        # Re-validate the rollout to ensure legality\n        Rollout.model_validate(rollout.model_dump())\n\n        return rollout\n\n    async def _update_attempt_unlocked(\n        self,\n        rollout_id: str,\n        attempt_id: str | Literal[\"latest\"],\n        status: AttemptStatus | Unset = UNSET,\n        worker_id: str | Unset = UNSET,\n        last_heartbeat_time: float | Unset = UNSET,\n        metadata: Optional[Dict[str, Any]] | Unset = UNSET,\n    ) -&gt; Attempt:\n        # No lock, but with status propagation.\n        rollout = self._rollouts.get(rollout_id)\n        if not rollout:\n            raise ValueError(f\"Rollout {rollout_id} not found\")\n\n        attempts = self._attempts.get(rollout_id, [])\n        if not attempts:\n            raise ValueError(f\"No attempts found for rollout {rollout_id}\")\n\n        latest_attempt = max(attempts, key=lambda a: a.sequence_id)\n\n        # Find the attempt to update\n        if attempt_id == \"latest\":\n            attempt = latest_attempt\n        else:\n            attempt = next((a for a in attempts if a.attempt_id == attempt_id), None)\n            if not attempt:\n                raise ValueError(f\"Attempt {attempt_id} not found for rollout {rollout_id}\")\n\n        # Update fields if they are not UNSET\n        if not isinstance(status, Unset):\n            attempt.status = status\n            # Also update end_time if the status indicates completion\n            if status in [\"failed\", \"succeeded\"]:\n                attempt.end_time = time.time()\n        if not isinstance(worker_id, Unset):\n            attempt.worker_id = worker_id\n        if not isinstance(last_heartbeat_time, Unset):\n            attempt.last_heartbeat_time = last_heartbeat_time\n        if not isinstance(metadata, Unset):\n            attempt.metadata = metadata\n\n        # Re-validate the attempt to ensure legality\n        Attempt.model_validate(attempt.model_dump())\n\n        if attempt == latest_attempt:\n\n            async def _update_status(rollout_id: str, status: RolloutStatus) -&gt; Rollout:\n                return await self._update_rollout_unlocked(rollout_id, status=status)\n\n            # Propagate the status to the rollout\n            await propagate_status(\n                _update_status,\n                attempt,\n                rollout.config,\n            )\n\n        return attempt\n\n    async def _healthcheck(self) -&gt; None:\n        \"\"\"Perform healthcheck against all running rollouts in the store.\"\"\"\n        async with self._lock:\n            running_rollouts: List[AttemptedRollout] = []\n            for rollout in self._rollouts.values():\n                if rollout.status in [\"preparing\", \"running\"]:\n                    all_attempts = self._attempts.get(rollout.rollout_id, [])\n                    if not all_attempts:\n                        # The rollout is running but has no attempts, this should not happen\n                        logger.error(f\"Rollout {rollout.rollout_id} is running but has no attempts\")\n                        continue\n                    latest_attempt = max(all_attempts, key=lambda a: a.sequence_id)\n                    running_rollouts.append(AttemptedRollout(**rollout.model_dump(), attempt=latest_attempt))\n\n            async def _update_attempt_status(rollout_id: str, attempt_id: str, status: AttemptStatus) -&gt; Attempt:\n                return await self._update_attempt_unlocked(rollout_id, attempt_id, status=status)\n\n            async def _update_rollout_status(rollout_id: str, status: RolloutStatus) -&gt; Rollout:\n                return await self._update_rollout_unlocked(rollout_id, status=status)\n\n            await healthcheck(\n                running_rollouts,\n                _update_rollout_status,\n                _update_attempt_status,\n            )\n</code></pre>"},{"location":"reference/store/#agentlightning.InMemoryLightningStore.add_otel_span","title":"<code>add_otel_span(rollout_id, attempt_id, readable_span, sequence_id=None)</code>  <code>async</code>","text":"<p>Add an opentelemetry span to the store.</p> Source code in <code>agentlightning/store/memory.py</code> <pre><code>async def add_otel_span(\n    self, rollout_id: str, attempt_id: str, readable_span: ReadableSpan, sequence_id: int | None = None\n) -&gt; Span:\n    \"\"\"Add an opentelemetry span to the store.\"\"\"\n    async with self._lock:\n        if sequence_id is None:\n            # Issue a new sequence ID for the rollout\n            self._span_sequence_ids[rollout_id] += 1\n            sequence_id = self._span_sequence_ids[rollout_id]\n        else:\n            # Comes from a provided sequence ID\n            # Make sure our counter is strictly increasing\n            self._span_sequence_ids[rollout_id] = max(self._span_sequence_ids[rollout_id], sequence_id)\n\n        span = Span.from_opentelemetry(\n            readable_span, rollout_id=rollout_id, attempt_id=attempt_id, sequence_id=sequence_id\n        )\n        await self._add_span_unlocked(span)\n        return span\n</code></pre>"},{"location":"reference/store/#agentlightning.InMemoryLightningStore.add_resources","title":"<code>add_resources(resources)</code>  <code>async</code>","text":"<p>Safely stores a new version of named resources and sets it as the latest.</p> Source code in <code>agentlightning/store/memory.py</code> <pre><code>@_healthcheck_wrapper\nasync def add_resources(self, resources: NamedResources) -&gt; ResourcesUpdate:\n    \"\"\"\n    Safely stores a new version of named resources and sets it as the latest.\n    \"\"\"\n    resources_id = _generate_resources_id()\n    async with self._lock:\n        update = ResourcesUpdate(resources_id=resources_id, resources=resources)\n        self._resources[resources_id] = update\n        self._latest_resources_id = resources_id\n        return update\n</code></pre>"},{"location":"reference/store/#agentlightning.InMemoryLightningStore.add_span","title":"<code>add_span(span)</code>  <code>async</code>","text":"<p>Persist a pre-converted span.</p> Source code in <code>agentlightning/store/memory.py</code> <pre><code>async def add_span(self, span: Span) -&gt; Span:\n    \"\"\"Persist a pre-converted span.\"\"\"\n    async with self._lock:\n        self._span_sequence_ids[span.rollout_id] = max(self._span_sequence_ids[span.rollout_id], span.sequence_id)\n        return await self._add_span_unlocked(span)\n</code></pre>"},{"location":"reference/store/#agentlightning.InMemoryLightningStore.dequeue_rollout","title":"<code>dequeue_rollout()</code>  <code>async</code>","text":"<p>Retrieves the next task from the queue without blocking. Returns None if the queue is empty.</p> <p>Will set the rollout status to preparing and create a new attempt.</p> Source code in <code>agentlightning/store/memory.py</code> <pre><code>@_healthcheck_wrapper\nasync def dequeue_rollout(self) -&gt; Optional[AttemptedRollout]:\n    \"\"\"\n    Retrieves the next task from the queue without blocking.\n    Returns None if the queue is empty.\n\n    Will set the rollout status to preparing and create a new attempt.\n    \"\"\"\n    async with self._lock:\n        # Keep looking until we find a rollout that's still in queuing status\n        # or the queue is empty\n        while self._task_queue:\n            rollout = self._task_queue.popleft()\n\n            # Check if rollout is still in a queuing state\n            # (it might have been updated to a different status while in queue)\n            if is_queuing(rollout):\n                # Update status to preparing\n                rollout.status = \"preparing\"\n\n                # Create a new attempt (could be first attempt or retry)\n                attempt_id = _generate_attempt_id()\n                current_time = time.time()\n\n                # Get existing attempts to determine sequence number\n                existing_attempts = self._attempts.get(rollout.rollout_id, [])\n                sequence_id = len(existing_attempts) + 1\n\n                attempt = Attempt(\n                    rollout_id=rollout.rollout_id,\n                    attempt_id=attempt_id,\n                    sequence_id=sequence_id,\n                    start_time=current_time,\n                    status=\"preparing\",\n                )\n\n                if rollout.rollout_id not in self._attempts:\n                    self._attempts[rollout.rollout_id] = []\n                self._attempts[rollout.rollout_id].append(attempt)\n\n                return AttemptedRollout(**rollout.model_dump(), attempt=attempt)\n\n            # If not in queuing state, skip this rollout and continue\n            # (it was updated externally and should not be processed)\n\n        # No valid rollouts found\n        return None\n</code></pre>"},{"location":"reference/store/#agentlightning.InMemoryLightningStore.enqueue_rollout","title":"<code>enqueue_rollout(input, mode=None, resources_id=None, config=None, metadata=None)</code>  <code>async</code>","text":"<p>Adds a new task to the queue with specific metadata and returns its unique ID.</p> Source code in <code>agentlightning/store/memory.py</code> <pre><code>@_healthcheck_wrapper\nasync def enqueue_rollout(\n    self,\n    input: TaskInput,\n    mode: Literal[\"train\", \"val\", \"test\"] | None = None,\n    resources_id: str | None = None,\n    config: RolloutConfig | None = None,\n    metadata: Dict[str, Any] | None = None,\n) -&gt; Rollout:\n    \"\"\"\n    Adds a new task to the queue with specific metadata and returns its unique ID.\n    \"\"\"\n    async with self._lock:\n        rollout_id = _generate_rollout_id()\n        current_time = time.time()\n\n        rollout_config = config.model_copy(deep=True) if config is not None else RolloutConfig()\n        rollout_metadata = dict(metadata) if metadata is not None else {}\n\n        rollout = Rollout(\n            rollout_id=rollout_id,\n            input=input,\n            mode=mode,\n            resources_id=resources_id or self._latest_resources_id,\n            start_time=current_time,\n            status=\"queuing\",  # should be queuing\n            config=rollout_config,\n            metadata=rollout_metadata,\n        )\n\n        self._rollouts[rollout.rollout_id] = rollout\n        self._task_queue.append(rollout)  # add it to the end of the queue\n        self._completion_events.setdefault(rollout.rollout_id, threading.Event())\n\n        return rollout\n</code></pre>"},{"location":"reference/store/#agentlightning.InMemoryLightningStore.get_latest_attempt","title":"<code>get_latest_attempt(rollout_id)</code>  <code>async</code>","text":"<p>Safely retrieves the latest attempt for a given rollout ID.</p> Source code in <code>agentlightning/store/memory.py</code> <pre><code>@_healthcheck_wrapper\nasync def get_latest_attempt(self, rollout_id: str) -&gt; Optional[Attempt]:\n    \"\"\"\n    Safely retrieves the latest attempt for a given rollout ID.\n    \"\"\"\n    async with self._lock:\n        attempts = self._attempts.get(rollout_id, [])\n        if not attempts:\n            return None\n        return max(attempts, key=lambda a: a.sequence_id)\n</code></pre>"},{"location":"reference/store/#agentlightning.InMemoryLightningStore.get_latest_resources","title":"<code>get_latest_resources()</code>  <code>async</code>","text":"<p>Safely retrieves the latest version of named resources.</p> Source code in <code>agentlightning/store/memory.py</code> <pre><code>@_healthcheck_wrapper\nasync def get_latest_resources(self) -&gt; Optional[ResourcesUpdate]:\n    \"\"\"\n    Safely retrieves the latest version of named resources.\n    \"\"\"\n    async with self._lock:\n        if self._latest_resources_id:\n            return self._resources.get(self._latest_resources_id)\n        return None\n</code></pre>"},{"location":"reference/store/#agentlightning.InMemoryLightningStore.get_next_span_sequence_id","title":"<code>get_next_span_sequence_id(rollout_id, attempt_id)</code>  <code>async</code>","text":"<p>Get the next span sequence ID for a given rollout and attempt. The number is strictly increasing for each rollout. The store will not issue the same sequence ID twice.</p> Source code in <code>agentlightning/store/memory.py</code> <pre><code>async def get_next_span_sequence_id(self, rollout_id: str, attempt_id: str) -&gt; int:\n    \"\"\"\n    Get the next span sequence ID for a given rollout and attempt.\n    The number is strictly increasing for each rollout.\n    The store will not issue the same sequence ID twice.\n    \"\"\"\n    async with self._lock:\n        self._span_sequence_ids[rollout_id] += 1\n        return self._span_sequence_ids[rollout_id]\n</code></pre>"},{"location":"reference/store/#agentlightning.InMemoryLightningStore.get_resources_by_id","title":"<code>get_resources_by_id(resources_id)</code>  <code>async</code>","text":"<p>Safely retrieves a specific version of named resources by its ID.</p> Source code in <code>agentlightning/store/memory.py</code> <pre><code>@_healthcheck_wrapper\nasync def get_resources_by_id(self, resources_id: str) -&gt; Optional[ResourcesUpdate]:\n    \"\"\"\n    Safely retrieves a specific version of named resources by its ID.\n    \"\"\"\n    async with self._lock:\n        return self._resources.get(resources_id)\n</code></pre>"},{"location":"reference/store/#agentlightning.InMemoryLightningStore.get_rollout_by_id","title":"<code>get_rollout_by_id(rollout_id)</code>  <code>async</code>","text":"<p>Safely retrieves a specific rollout by its ID.</p> Source code in <code>agentlightning/store/memory.py</code> <pre><code>@_healthcheck_wrapper\nasync def get_rollout_by_id(self, rollout_id: str) -&gt; Optional[Rollout]:\n    \"\"\"\n    Safely retrieves a specific rollout by its ID.\n    \"\"\"\n    async with self._lock:\n        return self._rollouts.get(rollout_id)\n</code></pre>"},{"location":"reference/store/#agentlightning.InMemoryLightningStore.query_attempts","title":"<code>query_attempts(rollout_id)</code>  <code>async</code>","text":"<p>Query and retrieve all attempts associated with a specific rollout ID. Returns an empty list if no attempts are found.</p> Source code in <code>agentlightning/store/memory.py</code> <pre><code>@_healthcheck_wrapper\nasync def query_attempts(self, rollout_id: str) -&gt; List[Attempt]:\n    \"\"\"\n    Query and retrieve all attempts associated with a specific rollout ID.\n    Returns an empty list if no attempts are found.\n    \"\"\"\n    async with self._lock:\n        return self._attempts.get(rollout_id, [])\n</code></pre>"},{"location":"reference/store/#agentlightning.InMemoryLightningStore.query_rollouts","title":"<code>query_rollouts(*, status=None, rollout_ids=None)</code>  <code>async</code>","text":"<p>Query and retrieve rollouts filtered by their status and rollout ids. If no status is provided, returns all rollouts.</p> Source code in <code>agentlightning/store/memory.py</code> <pre><code>@_healthcheck_wrapper\nasync def query_rollouts(\n    self, *, status: Optional[Sequence[RolloutStatus]] = None, rollout_ids: Optional[Sequence[str]] = None\n) -&gt; List[Rollout]:\n    \"\"\"\n    Query and retrieve rollouts filtered by their status and rollout ids.\n    If no status is provided, returns all rollouts.\n    \"\"\"\n    async with self._lock:\n        rollouts = list(self._rollouts.values())\n\n        # Filter by rollout_ids if provided\n        if rollout_ids is not None:\n            rollout_ids_set = set(rollout_ids)\n            rollouts = [rollout for rollout in rollouts if rollout.rollout_id in rollout_ids_set]\n\n        # Filter by status if provided\n        if status is not None:\n            status_set = set(status)\n            rollouts = [rollout for rollout in rollouts if rollout.status in status_set]\n\n        return rollouts\n</code></pre>"},{"location":"reference/store/#agentlightning.InMemoryLightningStore.query_spans","title":"<code>query_spans(rollout_id, attempt_id=None)</code>  <code>async</code>","text":"<p>Query and retrieve all spans associated with a specific rollout ID. Returns an empty list if no spans are found.</p> Source code in <code>agentlightning/store/memory.py</code> <pre><code>@_healthcheck_wrapper\nasync def query_spans(self, rollout_id: str, attempt_id: str | Literal[\"latest\"] | None = None) -&gt; List[Span]:\n    \"\"\"\n    Query and retrieve all spans associated with a specific rollout ID.\n    Returns an empty list if no spans are found.\n    \"\"\"\n    async with self._lock:\n        if rollout_id in self._evicted_rollout_span_sets:\n            raise RuntimeError(f\"Spans for rollout {rollout_id} have been evicted\")\n        spans = self._spans.get(rollout_id, [])\n        if attempt_id is None:\n            return spans\n        elif attempt_id == \"latest\":\n            # Find the latest attempt_id\n            if not spans:\n                return []\n            latest_attempt = max(spans, key=lambda s: s.sequence_id if s.attempt_id else \"\").attempt_id\n            return [s for s in spans if s.attempt_id == latest_attempt]\n        else:\n            return [s for s in spans if s.attempt_id == attempt_id]\n</code></pre>"},{"location":"reference/store/#agentlightning.InMemoryLightningStore.start_attempt","title":"<code>start_attempt(rollout_id)</code>  <code>async</code>","text":"<p>Create a new attempt for a given rollout ID and return the attempt details.</p> Source code in <code>agentlightning/store/memory.py</code> <pre><code>@_healthcheck_wrapper\nasync def start_attempt(self, rollout_id: str) -&gt; AttemptedRollout:\n    \"\"\"\n    Create a new attempt for a given rollout ID and return the attempt details.\n    \"\"\"\n    async with self._lock:\n        # Get the rollout\n        rollout = self._rollouts.get(rollout_id)\n        if not rollout:\n            raise ValueError(f\"Rollout {rollout_id} not found\")\n\n        # Get existing attempts to determine sequence number\n        existing_attempts = self._attempts.get(rollout_id, [])\n        sequence_id = len(existing_attempts) + 1\n\n        # We don't care whether the max attempts have reached or not\n        # This attempt is from user trigger\n\n        # Create new attempt\n        attempt_id = _generate_attempt_id()\n        current_time = time.time()\n\n        attempt = Attempt(\n            rollout_id=rollout_id,\n            attempt_id=attempt_id,\n            sequence_id=sequence_id,\n            start_time=current_time,\n            status=\"preparing\",\n        )\n\n        # Add attempt to storage\n        if rollout_id not in self._attempts:\n            self._attempts[rollout_id] = []\n        self._attempts[rollout_id].append(attempt)\n\n        self._completion_events.setdefault(rollout.rollout_id, threading.Event())\n\n        return AttemptedRollout(**rollout.model_dump(), attempt=attempt)\n</code></pre>"},{"location":"reference/store/#agentlightning.InMemoryLightningStore.start_rollout","title":"<code>start_rollout(input, mode=None, resources_id=None, config=None, metadata=None)</code>  <code>async</code>","text":"<p>Notify the store that I'm about to run a rollout.</p> Source code in <code>agentlightning/store/memory.py</code> <pre><code>@_healthcheck_wrapper\nasync def start_rollout(\n    self,\n    input: TaskInput,\n    mode: Literal[\"train\", \"val\", \"test\"] | None = None,\n    resources_id: str | None = None,\n    config: RolloutConfig | None = None,\n    metadata: Dict[str, Any] | None = None,\n) -&gt; AttemptedRollout:\n    \"\"\"\n    Notify the store that I'm about to run a rollout.\n    \"\"\"\n    async with self._lock:\n        rollout_id = _generate_rollout_id()\n        current_time = time.time()\n\n        rollout_config = config.model_copy(deep=True) if config is not None else RolloutConfig()\n        rollout_metadata = dict(metadata) if metadata is not None else {}\n\n        rollout = Rollout(\n            rollout_id=rollout_id,\n            input=input,\n            mode=mode,\n            resources_id=resources_id or self._latest_resources_id,\n            start_time=current_time,\n            status=\"preparing\",\n            config=rollout_config,\n            metadata=rollout_metadata,\n        )\n\n        # Create the initial attempt\n        attempt_id = _generate_attempt_id()\n        attempt = Attempt(\n            rollout_id=rollout.rollout_id,\n            attempt_id=attempt_id,\n            sequence_id=1,\n            start_time=current_time,\n            status=\"preparing\",\n        )\n\n        self._attempts[rollout.rollout_id] = [attempt]\n        self._rollouts[rollout.rollout_id] = rollout\n\n        # Manully added rollout is not added to task queue. It's already preparing\n        self._completion_events.setdefault(rollout.rollout_id, threading.Event())\n\n        return AttemptedRollout(**rollout.model_dump(), attempt=attempt)\n</code></pre>"},{"location":"reference/store/#agentlightning.InMemoryLightningStore.update_attempt","title":"<code>update_attempt(rollout_id, attempt_id, status=UNSET, worker_id=UNSET, last_heartbeat_time=UNSET, metadata=UNSET)</code>  <code>async</code>","text":"<p>Update a specific or latest attempt for a given rollout.</p> Source code in <code>agentlightning/store/memory.py</code> <pre><code>@_healthcheck_wrapper\nasync def update_attempt(\n    self,\n    rollout_id: str,\n    attempt_id: str | Literal[\"latest\"],\n    status: AttemptStatus | Unset = UNSET,\n    worker_id: str | Unset = UNSET,\n    last_heartbeat_time: float | Unset = UNSET,\n    metadata: Optional[Dict[str, Any]] | Unset = UNSET,\n) -&gt; Attempt:\n    \"\"\"\n    Update a specific or latest attempt for a given rollout.\n    \"\"\"\n    async with self._lock:\n        attempt = await self._update_attempt_unlocked(\n            rollout_id=rollout_id,\n            attempt_id=attempt_id,\n            status=status,\n            worker_id=worker_id,\n            last_heartbeat_time=last_heartbeat_time,\n            metadata=metadata,\n        )\n\n    return attempt\n</code></pre>"},{"location":"reference/store/#agentlightning.InMemoryLightningStore.update_resources","title":"<code>update_resources(resources_id, resources)</code>  <code>async</code>","text":"<p>Safely stores a new version of named resources and sets it as the latest.</p> Source code in <code>agentlightning/store/memory.py</code> <pre><code>@_healthcheck_wrapper\nasync def update_resources(self, resources_id: str, resources: NamedResources) -&gt; ResourcesUpdate:\n    \"\"\"\n    Safely stores a new version of named resources and sets it as the latest.\n    \"\"\"\n    async with self._lock:\n        update = ResourcesUpdate(resources_id=resources_id, resources=resources)\n        self._resources[resources_id] = update\n        self._latest_resources_id = resources_id\n        return update\n</code></pre>"},{"location":"reference/store/#agentlightning.InMemoryLightningStore.update_rollout","title":"<code>update_rollout(rollout_id, input=UNSET, mode=UNSET, resources_id=UNSET, status=UNSET, config=UNSET, metadata=UNSET)</code>  <code>async</code>","text":"<p>Update the rollout status and related metadata.</p> Source code in <code>agentlightning/store/memory.py</code> <pre><code>@_healthcheck_wrapper\nasync def update_rollout(\n    self,\n    rollout_id: str,\n    input: TaskInput | Unset = UNSET,\n    mode: Optional[Literal[\"train\", \"val\", \"test\"]] | Unset = UNSET,\n    resources_id: Optional[str] | Unset = UNSET,\n    status: RolloutStatus | Unset = UNSET,\n    config: RolloutConfig | Unset = UNSET,\n    metadata: Optional[Dict[str, Any]] | Unset = UNSET,\n) -&gt; Rollout:\n    \"\"\"\n    Update the rollout status and related metadata.\n    \"\"\"\n    async with self._lock:\n        return await self._update_rollout_unlocked(\n            rollout_id=rollout_id,\n            input=input,\n            mode=mode,\n            resources_id=resources_id,\n            status=status,\n            config=config,\n            metadata=metadata,\n        )\n</code></pre>"},{"location":"reference/store/#agentlightning.InMemoryLightningStore.wait_for_rollouts","title":"<code>wait_for_rollouts(*, rollout_ids, timeout=None)</code>  <code>async</code>","text":"<p>Wait for specified rollouts to complete with a timeout. Returns the completed rollouts, potentially incomplete if timeout is reached.</p> <p>This method does not change the state of the store.</p> Source code in <code>agentlightning/store/memory.py</code> <pre><code>@_healthcheck_wrapper\nasync def wait_for_rollouts(self, *, rollout_ids: List[str], timeout: Optional[float] = None) -&gt; List[Rollout]:\n    \"\"\"\n    Wait for specified rollouts to complete with a timeout.\n    Returns the completed rollouts, potentially incomplete if timeout is reached.\n\n    This method does not change the state of the store.\n    \"\"\"\n    completed_rollouts: List[Rollout] = []\n\n    async def wait_for_rollout(rollout_id: str):\n        # First check if already completed\n        async with self._lock:\n            rollout = self._rollouts.get(rollout_id)\n            if rollout and is_finished(rollout):\n                completed_rollouts.append(rollout)\n                return\n\n        # No timeout, return immediately\n        if timeout is not None and timeout &lt;= 0:\n            return\n\n        # If not completed and we have an event, wait for completion\n        if rollout_id in self._completion_events:\n            evt = self._completion_events[rollout_id]\n\n            # Wait for the event with proper timeout handling\n            # evt.wait() returns True if event was set, False if timeout occurred\n            if timeout is None:\n                # Wait indefinitely by polling with finite timeouts\n                # This allows threads to exit cleanly on shutdown\n                while True:\n                    result = await asyncio.to_thread(evt.wait, 10.0)  # Poll every 10 seconds\n                    if result:  # Event was set\n                        break\n                    # Loop and check again (continues indefinitely since timeout=None)\n            else:\n                # Wait with the specified timeout\n                result = await asyncio.to_thread(evt.wait, timeout)\n\n            # If event was set (not timeout), check if rollout is finished\n            if result:\n                async with self._lock:\n                    rollout = self._rollouts.get(rollout_id)\n                    if rollout and is_finished(rollout):\n                        completed_rollouts.append(rollout)\n\n        # Rollout not found, return\n\n    # Wait for all rollouts concurrently\n    await asyncio.gather(*[wait_for_rollout(rid) for rid in rollout_ids], return_exceptions=True)\n\n    return completed_rollouts\n</code></pre>"},{"location":"reference/store/#client-server-and-thread-safe-wrappers","title":"Client-Server and Thread-safe Wrappers","text":""},{"location":"reference/store/#agentlightning.LightningStoreServer","title":"<code>agentlightning.LightningStoreServer</code>","text":"<p>               Bases: <code>LightningStore</code></p> <p>Server wrapper that exposes a LightningStore via HTTP API. Delegates all operations to an underlying store implementation.</p> <p>Healthcheck and watchdog relies on the underlying store.</p> <p><code>agl store</code> is a convenient CLI to start a store server.</p> Source code in <code>agentlightning/store/client_server.py</code> <pre><code>class LightningStoreServer(LightningStore):\n    \"\"\"\n    Server wrapper that exposes a LightningStore via HTTP API.\n    Delegates all operations to an underlying store implementation.\n\n    Healthcheck and watchdog relies on the underlying store.\n\n    `agl store` is a convenient CLI to start a store server.\n    \"\"\"\n\n    def __init__(self, store: LightningStore, host: str, port: int):\n        super().__init__()\n        self.store = store\n        self.host = host\n        self.port = port\n        self.app: FastAPI | None = FastAPI(title=\"LightningStore Server\")\n        self._setup_routes()\n        self._uvicorn_config: uvicorn.Config | None = uvicorn.Config(\n            self.app, host=\"0.0.0.0\", port=self.port, log_level=\"error\"\n        )\n        self._uvicorn_server: uvicorn.Server | None = uvicorn.Server(self._uvicorn_config)\n\n        self._serving_thread: Optional[threading.Thread] = None\n\n        # Process-awareness:\n        # LightningStoreServer holds a plain Python object (self.store) in one process\n        # (the process that runs uvicorn/FastAPI).\n        # When you multiprocessing.Process(...) and call methods on a different LightningStore instance\n        # (or on a copy inherited via fork), you\u2019re mutating another process\u2019s memory, not the server\u2019s memory.\n        # So we need to track the owner process (whoever creates the server),\n        # and only mutate the store in that process.\n        self._owner_pid = os.getpid()\n        self._client: Optional[LightningStoreClient] = None\n\n    def __getstate__(self):\n        \"\"\"\n        Control pickling to prevent server state from being sent to subprocesses.\n\n        When LightningStoreServer is pickled (e.g., passed to a subprocess), we only\n        serialize the underlying store and connection details. The FastAPI app and\n        uvicorn server are excluded as they should not be transferred between processes.\n\n        The subprocess should create its own server instance if needed.\n        \"\"\"\n        return {\n            \"store\": self.store,\n            \"host\": self.host,\n            \"port\": self.port,\n            \"_owner_pid\": self._owner_pid,\n        }\n\n    def __setstate__(self, state: Dict[str, Any]):\n        \"\"\"\n        Restore from pickle by reconstructing only the essential attributes.\n\n        Note: This creates a new server instance without FastAPI/uvicorn initialized.\n        Call __init__() pattern or create a new LightningStoreServer if you need\n        a fully functional server in the subprocess.\n        \"\"\"\n        self.store = state[\"store\"]\n        self.host = state[\"host\"]\n        self.port = state[\"port\"]\n        self._owner_pid = state[\"_owner_pid\"]\n        self._client = None\n        # Do NOT reconstruct app, _uvicorn_config, _uvicorn_server\n        # to avoid transferring server state to subprocess\n\n    @property\n    def endpoint(self) -&gt; str:\n        return f\"http://{self.host}:{self.port}\"\n\n    async def start(self):\n        \"\"\"Starts the FastAPI server in the background.\n\n        You need to call this method in the same process as the server was created in.\n        \"\"\"\n        assert self._uvicorn_server is not None\n        logger.info(f\"Starting server at {self.endpoint}\")\n\n        uvicorn_server = self._uvicorn_server\n\n        def run_server_forever():\n            asyncio.run(uvicorn_server.serve())\n\n        self._serving_thread = threading.Thread(target=run_server_forever, daemon=True)\n        self._serving_thread.start()\n\n        # Wait for /health to be available\n        if not await self._server_health_check():\n            raise RuntimeError(\"Server failed to start within the 10 seconds.\")\n\n    async def _server_health_check(self) -&gt; bool:\n        \"\"\"Checks if the server is healthy.\"\"\"\n        current_time = time.time()\n        while time.time() - current_time &lt; 10:\n            async with aiohttp.ClientSession() as session:\n                with suppress(Exception):\n                    async with session.get(f\"{self.endpoint}/health\") as response:\n                        if response.status == 200:\n                            return True\n            await asyncio.sleep(0.1)\n        return False\n\n    async def run_forever(self):\n        \"\"\"Runs the FastAPI server indefinitely.\n\n        You need to call this method in the same process as the server was created in.\n        \"\"\"\n        assert self._uvicorn_server is not None\n\n        async def _wait_till_healthy():\n            health = await self._server_health_check()\n            if not health:\n                raise RuntimeError(\"Server did not become healthy within the 10 seconds.\")\n            logger.info(\"Store server is online at %s\", self.endpoint)\n\n        # We run _wait_till_healthy and self._uvicorn_server.serve in parallel\n        # until one of them raises an exception.\n        await asyncio.gather(_wait_till_healthy(), self._uvicorn_server.serve())\n\n    async def stop(self):\n        \"\"\"Gracefully stops the running FastAPI server.\n\n        You need to call this method in the same process as the server was created in.\n        \"\"\"\n        assert self._uvicorn_server is not None\n        if self._uvicorn_server.started:\n            logger.info(\"Stopping server...\")\n            self._uvicorn_server.should_exit = True\n            if self._serving_thread is not None:\n                self._serving_thread.join(timeout=10)\n            self._serving_thread = None\n            logger.info(\"Server stopped.\")\n\n    def _backend(self) -&gt; LightningStore:\n        \"\"\"Returns the object to delegate to in *this* process.\n\n        - In the owner process: delegate to the in-process store.\n        - In a different process: delegate to a HTTP client talking to the server.\n        \"\"\"\n        if os.getpid() == self._owner_pid:\n            return self.store\n        if self._client is None:\n            self._client = LightningStoreClient(self.endpoint)\n        return self._client\n\n    def _setup_routes(self):\n        \"\"\"Set up FastAPI routes for all store operations.\"\"\"\n        assert self.app is not None\n\n        @self.app.exception_handler(Exception)\n        async def _app_exception_handler(request: Request, exc: Exception):  # pyright: ignore[reportUnusedFunction]\n            \"\"\"\n            Convert unhandled application exceptions into 400 responses.\n\n            - Client needs a reliable signal to distinguish \"app bug / bad request\"\n              from transport/session failures.\n            - 400 here means \"do not retry\"; network issues will surface as aiohttp\n              exceptions or 5xx and will be retried by the client shield.\n            \"\"\"\n            logger.exception(\"Unhandled application error\", exc_info=exc)\n            return JSONResponse(\n                status_code=400,\n                content={\n                    \"detail\": str(exc),\n                    \"error_type\": type(exc).__name__,\n                    \"traceback\": traceback.format_exc(),\n                },\n            )\n\n        @self.app.middleware(\"http\")\n        async def _log_time(  # pyright: ignore[reportUnusedFunction]\n            request: Request, call_next: Callable[[Request], Awaitable[Response]]\n        ):\n            start = time.perf_counter()\n            response = await call_next(request)\n            duration = (time.perf_counter() - start) * 1000\n            client = request.client\n            if client is None:\n                client_address = \"unknown\"\n            else:\n                client_address = f\"{client.host}:{client.port}\"\n            logger.info(\n                f\"{client_address} - \"\n                f'\"{request.method} {request.url.path} HTTP/{request.scope[\"http_version\"]}\" '\n                f\"{response.status_code} in {duration:.2f} ms\"\n            )\n            return response\n\n        @self.app.get(\"/health\")\n        async def health():  # pyright: ignore[reportUnusedFunction]\n            return {\"status\": \"ok\"}\n\n        @self.app.post(\"/start_rollout\", response_model=AttemptedRollout)\n        async def start_rollout(request: RolloutRequest):  # pyright: ignore[reportUnusedFunction]\n            return await self.store.start_rollout(\n                input=request.input,\n                mode=request.mode,\n                resources_id=request.resources_id,\n                config=request.config,\n                metadata=request.metadata,\n            )\n\n        @self.app.post(\"/enqueue_rollout\", response_model=Rollout)\n        async def enqueue_rollout(request: RolloutRequest):  # pyright: ignore[reportUnusedFunction]\n            return await self.store.enqueue_rollout(\n                input=request.input,\n                mode=request.mode,\n                resources_id=request.resources_id,\n                config=request.config,\n                metadata=request.metadata,\n            )\n\n        @self.app.get(\"/dequeue_rollout\", response_model=Optional[AttemptedRollout])\n        async def dequeue_rollout():  # pyright: ignore[reportUnusedFunction]\n            return await self.store.dequeue_rollout()\n\n        @self.app.post(\"/start_attempt\", response_model=AttemptedRollout)\n        async def start_attempt(request: RolloutId):  # pyright: ignore[reportUnusedFunction]\n            return await self.store.start_attempt(request.rollout_id)\n\n        @self.app.post(\"/query_rollouts\", response_model=List[Rollout])\n        async def query_rollouts(request: QueryRolloutsRequest):  # pyright: ignore[reportUnusedFunction]\n            return await self.store.query_rollouts(status=request.status)\n\n        @self.app.get(\"/query_attempts/{rollout_id}\", response_model=List[Attempt])\n        async def query_attempts(rollout_id: str):  # pyright: ignore[reportUnusedFunction]\n            return await self.store.query_attempts(rollout_id)\n\n        @self.app.get(\"/get_latest_attempt/{rollout_id}\", response_model=Optional[Attempt])\n        async def get_latest_attempt(rollout_id: str):  # pyright: ignore[reportUnusedFunction]\n            return await self.store.get_latest_attempt(rollout_id)\n\n        @self.app.get(\"/get_rollout_by_id/{rollout_id}\", response_model=Optional[Rollout])\n        async def get_rollout_by_id(rollout_id: str):  # pyright: ignore[reportUnusedFunction]\n            return await self.store.get_rollout_by_id(rollout_id)\n\n        @self.app.post(\"/add_resources\", response_model=ResourcesUpdate)\n        async def add_resources(resources: AddResourcesRequest):  # pyright: ignore[reportUnusedFunction]\n            return await self.store.add_resources(resources.resources)\n\n        @self.app.post(\"/update_resources\", response_model=ResourcesUpdate)\n        async def update_resources(update: ResourcesUpdate):  # pyright: ignore[reportUnusedFunction]\n            return await self.store.update_resources(update.resources_id, update.resources)\n\n        @self.app.get(\"/get_resources_by_id/{resources_id}\", response_model=Optional[ResourcesUpdate])\n        async def get_resources_by_id(resources_id: str):  # pyright: ignore[reportUnusedFunction]\n            return await self.store.get_resources_by_id(resources_id)\n\n        @self.app.get(\"/get_latest_resources\", response_model=Optional[ResourcesUpdate])\n        async def get_latest_resources():  # pyright: ignore[reportUnusedFunction]\n            return await self.store.get_latest_resources()\n\n        @self.app.post(\"/add_span\", response_model=Span)\n        async def add_span(span: Span):  # pyright: ignore[reportUnusedFunction]\n            return await self.store.add_span(span)\n\n        @self.app.get(\"/get_next_span_sequence_id/{rollout_id}/{attempt_id}\", response_model=int)\n        async def get_next_span_sequence_id(rollout_id: str, attempt_id: str):  # pyright: ignore[reportUnusedFunction]\n            return await self.store.get_next_span_sequence_id(rollout_id, attempt_id)\n\n        @self.app.post(\"/wait_for_rollouts\", response_model=List[Rollout])\n        async def wait_for_rollouts(request: WaitForRolloutsRequest):  # pyright: ignore[reportUnusedFunction]\n            return await self.store.wait_for_rollouts(rollout_ids=request.rollout_ids, timeout=request.timeout)\n\n        @self.app.get(\"/query_spans/{rollout_id}\", response_model=List[Span])\n        async def query_spans(  # pyright: ignore[reportUnusedFunction]\n            rollout_id: str, attempt_id: Optional[str] = None\n        ):\n            return await self.store.query_spans(rollout_id, attempt_id)\n\n        @self.app.post(\"/update_rollout\", response_model=Rollout)\n        async def update_rollout(request: UpdateRolloutRequest):  # pyright: ignore[reportUnusedFunction]\n            return await self.store.update_rollout(\n                rollout_id=request.rollout_id,\n                input=request.input if not isinstance(request.input, PydanticUnset) else UNSET,\n                mode=request.mode if not isinstance(request.mode, PydanticUnset) else UNSET,\n                resources_id=request.resources_id if not isinstance(request.resources_id, PydanticUnset) else UNSET,\n                status=request.status if not isinstance(request.status, PydanticUnset) else UNSET,\n                config=request.config if not isinstance(request.config, PydanticUnset) else UNSET,\n                metadata=request.metadata if not isinstance(request.metadata, PydanticUnset) else UNSET,\n            )\n\n        @self.app.post(\"/update_attempt\", response_model=Attempt)\n        async def update_attempt(request: UpdateAttemptRequest):  # pyright: ignore[reportUnusedFunction]\n            return await self.store.update_attempt(\n                rollout_id=request.rollout_id,\n                attempt_id=request.attempt_id,\n                status=request.status if not isinstance(request.status, PydanticUnset) else UNSET,\n                worker_id=request.worker_id if not isinstance(request.worker_id, PydanticUnset) else UNSET,\n                last_heartbeat_time=(\n                    request.last_heartbeat_time if not isinstance(request.last_heartbeat_time, PydanticUnset) else UNSET\n                ),\n                metadata=request.metadata if not isinstance(request.metadata, PydanticUnset) else UNSET,\n            )\n\n    # Delegate methods\n    async def start_rollout(\n        self,\n        input: TaskInput,\n        mode: Literal[\"train\", \"val\", \"test\"] | None = None,\n        resources_id: str | None = None,\n        config: RolloutConfig | None = None,\n        metadata: Dict[str, Any] | None = None,\n    ) -&gt; AttemptedRollout:\n        return await self._backend().start_rollout(input, mode, resources_id, config, metadata)\n\n    async def enqueue_rollout(\n        self,\n        input: TaskInput,\n        mode: Literal[\"train\", \"val\", \"test\"] | None = None,\n        resources_id: str | None = None,\n        config: RolloutConfig | None = None,\n        metadata: Dict[str, Any] | None = None,\n    ) -&gt; Rollout:\n        return await self._backend().enqueue_rollout(input, mode, resources_id, config, metadata)\n\n    async def dequeue_rollout(self) -&gt; Optional[AttemptedRollout]:\n        return await self._backend().dequeue_rollout()\n\n    async def start_attempt(self, rollout_id: str) -&gt; AttemptedRollout:\n        return await self._backend().start_attempt(rollout_id)\n\n    async def query_rollouts(\n        self, *, status: Optional[Sequence[RolloutStatus]] = None, rollout_ids: Optional[Sequence[str]] = None\n    ) -&gt; List[Rollout]:\n        return await self._backend().query_rollouts(status=status, rollout_ids=rollout_ids)\n\n    async def query_attempts(self, rollout_id: str) -&gt; List[Attempt]:\n        return await self._backend().query_attempts(rollout_id)\n\n    async def get_latest_attempt(self, rollout_id: str) -&gt; Optional[Attempt]:\n        return await self._backend().get_latest_attempt(rollout_id)\n\n    async def get_rollout_by_id(self, rollout_id: str) -&gt; Optional[Rollout]:\n        return await self._backend().get_rollout_by_id(rollout_id)\n\n    async def add_resources(self, resources: NamedResources) -&gt; ResourcesUpdate:\n        return await self._backend().add_resources(resources)\n\n    async def update_resources(self, resources_id: str, resources: NamedResources) -&gt; ResourcesUpdate:\n        return await self._backend().update_resources(resources_id, resources)\n\n    async def get_resources_by_id(self, resources_id: str) -&gt; Optional[ResourcesUpdate]:\n        return await self._backend().get_resources_by_id(resources_id)\n\n    async def get_latest_resources(self) -&gt; Optional[ResourcesUpdate]:\n        return await self._backend().get_latest_resources()\n\n    async def add_span(self, span: Span) -&gt; Span:\n        return await self._backend().add_span(span)\n\n    async def get_next_span_sequence_id(self, rollout_id: str, attempt_id: str) -&gt; int:\n        return await self._backend().get_next_span_sequence_id(rollout_id, attempt_id)\n\n    async def add_otel_span(\n        self,\n        rollout_id: str,\n        attempt_id: str,\n        readable_span: ReadableSpan,\n        sequence_id: int | None = None,\n    ) -&gt; Span:\n        return await self._backend().add_otel_span(rollout_id, attempt_id, readable_span, sequence_id)\n\n    async def wait_for_rollouts(self, *, rollout_ids: List[str], timeout: Optional[float] = None) -&gt; List[Rollout]:\n        return await self._backend().wait_for_rollouts(rollout_ids=rollout_ids, timeout=timeout)\n\n    async def query_spans(\n        self,\n        rollout_id: str,\n        attempt_id: str | Literal[\"latest\"] | None = None,\n    ) -&gt; List[Span]:\n        return await self._backend().query_spans(rollout_id, attempt_id)\n\n    async def update_rollout(\n        self,\n        rollout_id: str,\n        input: TaskInput | Unset = UNSET,\n        mode: Optional[Literal[\"train\", \"val\", \"test\"]] | Unset = UNSET,\n        resources_id: Optional[str] | Unset = UNSET,\n        status: RolloutStatus | Unset = UNSET,\n        config: RolloutConfig | Unset = UNSET,\n        metadata: Optional[Dict[str, Any]] | Unset = UNSET,\n    ) -&gt; Rollout:\n        return await self._backend().update_rollout(\n            rollout_id=rollout_id,\n            input=input,\n            mode=mode,\n            resources_id=resources_id,\n            status=status,\n            config=config,\n            metadata=metadata,\n        )\n\n    async def update_attempt(\n        self,\n        rollout_id: str,\n        attempt_id: str | Literal[\"latest\"],\n        status: AttemptStatus | Unset = UNSET,\n        worker_id: str | Unset = UNSET,\n        last_heartbeat_time: float | Unset = UNSET,\n        metadata: Optional[Dict[str, Any]] | Unset = UNSET,\n    ) -&gt; Attempt:\n        return await self._backend().update_attempt(\n            rollout_id=rollout_id,\n            attempt_id=attempt_id,\n            status=status,\n            worker_id=worker_id,\n            last_heartbeat_time=last_heartbeat_time,\n            metadata=metadata,\n        )\n</code></pre>"},{"location":"reference/store/#agentlightning.LightningStoreServer.__getstate__","title":"<code>__getstate__()</code>","text":"<p>Control pickling to prevent server state from being sent to subprocesses.</p> <p>When LightningStoreServer is pickled (e.g., passed to a subprocess), we only serialize the underlying store and connection details. The FastAPI app and uvicorn server are excluded as they should not be transferred between processes.</p> <p>The subprocess should create its own server instance if needed.</p> Source code in <code>agentlightning/store/client_server.py</code> <pre><code>def __getstate__(self):\n    \"\"\"\n    Control pickling to prevent server state from being sent to subprocesses.\n\n    When LightningStoreServer is pickled (e.g., passed to a subprocess), we only\n    serialize the underlying store and connection details. The FastAPI app and\n    uvicorn server are excluded as they should not be transferred between processes.\n\n    The subprocess should create its own server instance if needed.\n    \"\"\"\n    return {\n        \"store\": self.store,\n        \"host\": self.host,\n        \"port\": self.port,\n        \"_owner_pid\": self._owner_pid,\n    }\n</code></pre>"},{"location":"reference/store/#agentlightning.LightningStoreServer.__setstate__","title":"<code>__setstate__(state)</code>","text":"<p>Restore from pickle by reconstructing only the essential attributes.</p> <p>Note: This creates a new server instance without FastAPI/uvicorn initialized. Call init() pattern or create a new LightningStoreServer if you need a fully functional server in the subprocess.</p> Source code in <code>agentlightning/store/client_server.py</code> <pre><code>def __setstate__(self, state: Dict[str, Any]):\n    \"\"\"\n    Restore from pickle by reconstructing only the essential attributes.\n\n    Note: This creates a new server instance without FastAPI/uvicorn initialized.\n    Call __init__() pattern or create a new LightningStoreServer if you need\n    a fully functional server in the subprocess.\n    \"\"\"\n    self.store = state[\"store\"]\n    self.host = state[\"host\"]\n    self.port = state[\"port\"]\n    self._owner_pid = state[\"_owner_pid\"]\n    self._client = None\n</code></pre>"},{"location":"reference/store/#agentlightning.LightningStoreServer.run_forever","title":"<code>run_forever()</code>  <code>async</code>","text":"<p>Runs the FastAPI server indefinitely.</p> <p>You need to call this method in the same process as the server was created in.</p> Source code in <code>agentlightning/store/client_server.py</code> <pre><code>async def run_forever(self):\n    \"\"\"Runs the FastAPI server indefinitely.\n\n    You need to call this method in the same process as the server was created in.\n    \"\"\"\n    assert self._uvicorn_server is not None\n\n    async def _wait_till_healthy():\n        health = await self._server_health_check()\n        if not health:\n            raise RuntimeError(\"Server did not become healthy within the 10 seconds.\")\n        logger.info(\"Store server is online at %s\", self.endpoint)\n\n    # We run _wait_till_healthy and self._uvicorn_server.serve in parallel\n    # until one of them raises an exception.\n    await asyncio.gather(_wait_till_healthy(), self._uvicorn_server.serve())\n</code></pre>"},{"location":"reference/store/#agentlightning.LightningStoreServer.start","title":"<code>start()</code>  <code>async</code>","text":"<p>Starts the FastAPI server in the background.</p> <p>You need to call this method in the same process as the server was created in.</p> Source code in <code>agentlightning/store/client_server.py</code> <pre><code>async def start(self):\n    \"\"\"Starts the FastAPI server in the background.\n\n    You need to call this method in the same process as the server was created in.\n    \"\"\"\n    assert self._uvicorn_server is not None\n    logger.info(f\"Starting server at {self.endpoint}\")\n\n    uvicorn_server = self._uvicorn_server\n\n    def run_server_forever():\n        asyncio.run(uvicorn_server.serve())\n\n    self._serving_thread = threading.Thread(target=run_server_forever, daemon=True)\n    self._serving_thread.start()\n\n    # Wait for /health to be available\n    if not await self._server_health_check():\n        raise RuntimeError(\"Server failed to start within the 10 seconds.\")\n</code></pre>"},{"location":"reference/store/#agentlightning.LightningStoreServer.stop","title":"<code>stop()</code>  <code>async</code>","text":"<p>Gracefully stops the running FastAPI server.</p> <p>You need to call this method in the same process as the server was created in.</p> Source code in <code>agentlightning/store/client_server.py</code> <pre><code>async def stop(self):\n    \"\"\"Gracefully stops the running FastAPI server.\n\n    You need to call this method in the same process as the server was created in.\n    \"\"\"\n    assert self._uvicorn_server is not None\n    if self._uvicorn_server.started:\n        logger.info(\"Stopping server...\")\n        self._uvicorn_server.should_exit = True\n        if self._serving_thread is not None:\n            self._serving_thread.join(timeout=10)\n        self._serving_thread = None\n        logger.info(\"Server stopped.\")\n</code></pre>"},{"location":"reference/store/#agentlightning.LightningStoreClient","title":"<code>agentlightning.LightningStoreClient</code>","text":"<p>               Bases: <code>LightningStore</code></p> <p>HTTP client that talks to a remote LightningStoreServer.</p> <p>Parameters:</p> Name Type Description Default <code>server_address</code> <code>str</code> <p>The address of the LightningStoreServer to connect to.</p> required <code>retry_delays</code> <code>Sequence[float]</code> <p>Backoff schedule (seconds) used when the initial request fails for a non-application reason. Each entry is a retry attempt.</p> <code>(1.0, 2.0, 5.0)</code> <code>health_retry_delays</code> <code>Sequence[float]</code> <p>Delays between /health probes while waiting for the server to come back.</p> <code>(0.1, 0.2, 0.5)</code> Source code in <code>agentlightning/store/client_server.py</code> <pre><code>class LightningStoreClient(LightningStore):\n    \"\"\"HTTP client that talks to a remote LightningStoreServer.\n\n    Args:\n        server_address: The address of the LightningStoreServer to connect to.\n        retry_delays:\n            Backoff schedule (seconds) used when the initial request fails for a\n            non-application reason. Each entry is a retry attempt.\n        health_retry_delays:\n            Delays between /health probes while waiting for the server to come back.\n    \"\"\"\n\n    def __init__(\n        self,\n        server_address: str,\n        *,\n        retry_delays: Sequence[float] = (1.0, 2.0, 5.0),\n        health_retry_delays: Sequence[float] = (0.1, 0.2, 0.5),\n    ):\n        self.server_address = server_address.rstrip(\"/\")\n        self._sessions: Dict[int, aiohttp.ClientSession] = {}  # id(loop) -&gt; ClientSession\n        self._lock = threading.RLock()\n\n        # retry config\n        self._retry_delays = tuple(float(d) for d in retry_delays)\n        self._health_retry_delays = tuple(float(d) for d in health_retry_delays)\n\n        # Store whether the dequeue was successful in history\n        self._dequeue_was_successful: bool = False\n        self._dequeue_first_unsuccessful: bool = True\n\n    def __getstate__(self):\n        \"\"\"\n        When LightningStoreClient is pickled (e.g., passed to a subprocess), we only\n        serialize the server address and retry configurations. The ClientSessions\n        are excluded as they should not be transferred between processes.\n        \"\"\"\n        return {\n            \"server_address\": self.server_address,\n            \"_retry_delays\": self._retry_delays,\n            \"_health_retry_delays\": self._health_retry_delays,\n        }\n\n    def __setstate__(self, state: Dict[str, Any]):\n        \"\"\"\n        Restore from pickle by reconstructing only the essential attributes.\n\n        Replicating `__init__` logic to create another client instance in the subprocess.\n        \"\"\"\n        self.server_address = state[\"server_address\"]\n        self._sessions = {}\n        self._lock = threading.RLock()\n        self._retry_delays = state[\"_retry_delays\"]\n        self._health_retry_delays = state[\"_health_retry_delays\"]\n        self._dequeue_was_successful = False\n        self._dequeue_first_unsuccessful = True\n\n    async def _get_session(self) -&gt; aiohttp.ClientSession:\n        # In the proxy process, FastAPI middleware calls\n        # client_store.get_next_span_sequence_id(...). With\n        # reuse_session=True, _get_session() creates and caches a\n        # single ClientSession bound to the uvicorn event loop.\n        #\n        # Later, the OpenTelemetry exporter (LightningSpanExporter)\n        # runs its flush on its own private event loop (in a different\n        # thread) and calls client_store.add_otel_span(...) -&gt;\n        # client_store.add_span(...).\n        #\n        # If we reuse one session across all, the exporter tries to reuse the\n        # same cached ClientSession that was created on the uvicorn\n        # loop. aiohttp.ClientSession is not loop-agnostic or\n        # thread-safe. Using it from another loop can hang on the\n        # first request. That's why we need a map from loop to session.\n\n        loop = asyncio.get_running_loop()\n        key = id(loop)\n        with self._lock:\n            sess = self._sessions.get(key)\n            if sess is None or sess.closed:\n                timeout = aiohttp.ClientTimeout(total=30.0, connect=5.0, sock_connect=5.0, sock_read=30.0)\n                sess = aiohttp.ClientSession(timeout=timeout)\n                self._sessions[key] = sess\n        return sess\n\n    async def _wait_until_healthy(self, session: aiohttp.ClientSession) -&gt; bool:\n        \"\"\"\n        Probe the server's /health until it responds 200 or retries are exhausted.\n        Returns True if healthy, False otherwise.\n        \"\"\"\n        logger.info(f\"Waiting for server to be healthy at {self.server_address}/health\")\n        for delay in [*self._health_retry_delays, 0.0]:\n            try:\n                async with session.get(f\"{self.server_address}/health\") as r:\n                    if r.status == 200:\n                        logger.info(f\"Server is healthy at {self.server_address}/health\")\n                        return True\n            except Exception:\n                # swallow and retry\n                if delay &gt; 0.0:\n                    logger.warning(f\"Server is not healthy yet. Retrying in {delay} seconds.\")\n            if delay &gt; 0.0:\n                await asyncio.sleep(delay)\n        logger.error(\n            f\"Server is not healthy at {self.server_address}/health after {len(self._health_retry_delays)} retry attempts\"\n        )\n        return False\n\n    async def _request_json(\n        self,\n        method: Literal[\"get\", \"post\"],\n        path: str,\n        *,\n        json: Any | None = None,\n    ) -&gt; Any:\n        \"\"\"\n        Make an HTTP request with:\n\n        1) First attempt.\n        2) On network/session failures: probe /health until back, then retry\n           according to self._retry_delays.\n        3) On 4xx (e.g., 400 set by server exception handler): do not retry.\n\n        Returns parsed JSON (or raw JSON scalar like int).\n        Raises the last exception if all retries fail.\n        \"\"\"\n        session = await self._get_session()\n        url = f\"{self.server_address}{path if path.startswith('/') else '/'+path}\"\n\n        # attempt 0 is immediate, then follow retry schedule\n        attempts = (0.0,) + self._retry_delays\n        last_exc: Exception | None = None\n\n        for delay in attempts:\n            if delay:\n                logger.info(f\"Waiting {delay} seconds before retrying {method}: {path}\")\n                await asyncio.sleep(delay)\n            try:\n                http_call = getattr(session, method)\n                async with http_call(url, json=json) as resp:\n                    resp.raise_for_status()\n                    return await resp.json()\n            except aiohttp.ClientResponseError as cre:\n                # Respect app-level 4xx as final (server marks app faults as 400)\n                # 4xx =&gt; application issue; do not retry (except 408 which is transient)\n                logger.debug(f\"ClientResponseError: {cre.status} {cre.message}\", exc_info=True)\n                if 400 &lt;= cre.status &lt; 500 and cre.status != 408:\n                    raise\n                # 5xx and others will be retried below if they raise\n                last_exc = cre\n                logger.info(f\"5xx and other status codes will be retried. Retrying the request {method}: {path}\")\n                # before next retry, ensure server is healthy\n                if not await self._wait_until_healthy(session):\n                    break  # server is not healthy, do not retry\n            except (\n                aiohttp.ServerDisconnectedError,\n                aiohttp.ClientConnectorError,\n                aiohttp.ClientOSError,\n                asyncio.TimeoutError,\n            ) as net_exc:\n                # Network/session issue: probe health before retrying\n                logger.debug(f\"Network/session issue: {net_exc}\", exc_info=True)\n                last_exc = net_exc\n                logger.info(f\"Network/session issue will be retried. Retrying the request {method}: {path}\")\n                if not await self._wait_until_healthy(session):\n                    break  # server is not healthy, do not retry\n\n        # exhausted retries\n        assert last_exc is not None\n        raise last_exc\n\n    async def close(self):\n        \"\"\"Close the HTTP session.\"\"\"\n        with self._lock:\n            sessions = list(self._sessions.values())\n            self._sessions.clear()\n\n        # close them on their own loops to avoid warnings\n        async def _close(sess: aiohttp.ClientSession):\n            if not sess.closed:\n                await sess.close()\n\n        # If called from one loop, best-effort close here.\n        for s in sessions:\n            try:\n                await _close(s)\n            except RuntimeError:\n                # If created on a different loop/thread, schedule a thread-safe close\n                # Fallback: close without awaiting (library tolerates it in practice),\n                # or keep a per-loop shutdown hook where they were created.\n                pass\n\n    async def start_rollout(\n        self,\n        input: TaskInput,\n        mode: Literal[\"train\", \"val\", \"test\"] | None = None,\n        resources_id: str | None = None,\n        config: RolloutConfig | None = None,\n        metadata: Dict[str, Any] | None = None,\n    ) -&gt; AttemptedRollout:\n        data = await self._request_json(\n            \"post\",\n            \"/start_rollout\",\n            json=RolloutRequest(\n                input=input,\n                mode=mode,\n                resources_id=resources_id,\n                config=config,\n                metadata=metadata,\n            ).model_dump(exclude_none=False),\n        )\n        return AttemptedRollout.model_validate(data)\n\n    async def enqueue_rollout(\n        self,\n        input: TaskInput,\n        mode: Literal[\"train\", \"val\", \"test\"] | None = None,\n        resources_id: str | None = None,\n        config: RolloutConfig | None = None,\n        metadata: Dict[str, Any] | None = None,\n    ) -&gt; Rollout:\n        data = await self._request_json(\n            \"post\",\n            \"/enqueue_rollout\",\n            json=RolloutRequest(\n                input=input,\n                mode=mode,\n                resources_id=resources_id,\n                config=config,\n                metadata=metadata,\n            ).model_dump(exclude_none=False),\n        )\n        return Rollout.model_validate(data)\n\n    async def dequeue_rollout(self) -&gt; Optional[AttemptedRollout]:\n        \"\"\"\n        Dequeue a rollout from the server queue.\n\n        Returns:\n            AttemptedRollout if a rollout is available, None if queue is empty.\n\n        Note:\n            This method does NOT retry on failures. If any exception occurs (network error,\n            server error, etc.), it logs the error and returns None immediately.\n        \"\"\"\n        session = await self._get_session()\n        url = f\"{self.server_address}/dequeue_rollout\"\n        try:\n            async with session.get(url) as resp:\n                resp.raise_for_status()\n                data = await resp.json()\n                self._dequeue_was_successful = True\n                return AttemptedRollout.model_validate(data) if data else None\n        except Exception as e:\n            if self._dequeue_was_successful:\n                if self._dequeue_first_unsuccessful:\n                    logger.warning(f\"dequeue_rollout failed with exception: {e}\")\n                    self._dequeue_first_unsuccessful = False\n            logger.debug(\"dequeue_rollout failed with exception. Details:\", exc_info=True)\n            # Else ignore the exception because the server is not ready yet\n            return None\n\n    async def start_attempt(self, rollout_id: str) -&gt; AttemptedRollout:\n        data = await self._request_json(\n            \"post\",\n            \"/start_attempt\",\n            json=RolloutId(rollout_id=rollout_id).model_dump(),\n        )\n        return AttemptedRollout.model_validate(data)\n\n    async def query_rollouts(\n        self, *, status: Optional[Sequence[RolloutStatus]] = None, rollout_ids: Optional[Sequence[str]] = None\n    ) -&gt; List[Rollout]:\n        data = await self._request_json(\n            \"post\",\n            \"/query_rollouts\",\n            json=QueryRolloutsRequest(\n                status=list(status) if status else None,\n                rollout_ids=list(rollout_ids) if rollout_ids else None,\n            ).model_dump(),\n        )\n        return [Rollout.model_validate(item) for item in data]\n\n    async def query_attempts(self, rollout_id: str) -&gt; List[Attempt]:\n        data = await self._request_json(\"get\", f\"/query_attempts/{rollout_id}\")\n        return [Attempt.model_validate(item) for item in data]\n\n    async def get_latest_attempt(self, rollout_id: str) -&gt; Optional[Attempt]:\n        \"\"\"\n        Get the latest attempt for a rollout.\n\n        Args:\n            rollout_id: ID of the rollout to query.\n\n        Returns:\n            Attempt if found, None if not found or if all retries are exhausted.\n\n        Note:\n            This method retries on transient failures (network errors, 5xx status codes).\n            If all retries fail, it logs the error and returns None instead of raising an exception.\n        \"\"\"\n        try:\n            data = await self._request_json(\"get\", f\"/get_latest_attempt/{rollout_id}\")\n            return Attempt.model_validate(data) if data else None\n        except Exception as e:\n            logger.error(f\"get_latest_attempt failed after all retries for rollout_id={rollout_id}: {e}\", exc_info=True)\n            return None\n\n    async def get_rollout_by_id(self, rollout_id: str) -&gt; Optional[Rollout]:\n        \"\"\"\n        Get a rollout by its ID.\n\n        Args:\n            rollout_id: ID of the rollout to retrieve.\n\n        Returns:\n            Rollout if found, None if not found or if all retries are exhausted.\n\n        Note:\n            This method retries on transient failures (network errors, 5xx status codes).\n            If all retries fail, it logs the error and returns None instead of raising an exception.\n        \"\"\"\n        try:\n            data = await self._request_json(\"get\", f\"/get_rollout_by_id/{rollout_id}\")\n            return Rollout.model_validate(data) if data else None\n        except Exception as e:\n            logger.error(f\"get_rollout_by_id failed after all retries for rollout_id={rollout_id}: {e}\", exc_info=True)\n            return None\n\n    async def add_resources(self, resources: NamedResources) -&gt; ResourcesUpdate:\n        request = AddResourcesRequest(resources=resources)\n        data = await self._request_json(\"post\", \"/add_resources\", json=request.model_dump())\n        return ResourcesUpdate.model_validate(data)\n\n    async def update_resources(self, resources_id: str, resources: NamedResources) -&gt; ResourcesUpdate:\n        data = await self._request_json(\n            \"post\",\n            \"/update_resources\",\n            json=ResourcesUpdate(resources_id=resources_id, resources=resources).model_dump(),\n        )\n        return ResourcesUpdate.model_validate(data)\n\n    async def get_resources_by_id(self, resources_id: str) -&gt; Optional[ResourcesUpdate]:\n        \"\"\"\n        Get resources by their ID.\n\n        Args:\n            resources_id: ID of the resources to retrieve.\n\n        Returns:\n            ResourcesUpdate if found, None if not found or if all retries are exhausted.\n\n        Note:\n            This method retries on transient failures (network errors, 5xx status codes).\n            If all retries fail, it logs the error and returns None instead of raising an exception.\n        \"\"\"\n        try:\n            data = await self._request_json(\"get\", f\"/get_resources_by_id/{resources_id}\")\n            return ResourcesUpdate.model_validate(data) if data else None\n        except Exception as e:\n            logger.error(\n                f\"get_resources_by_id failed after all retries for resources_id={resources_id}: {e}\", exc_info=True\n            )\n            return None\n\n    async def get_latest_resources(self) -&gt; Optional[ResourcesUpdate]:\n        \"\"\"\n        Get the latest resources.\n\n        Returns:\n            ResourcesUpdate if found, None if not found or if all retries are exhausted.\n\n        Note:\n            This method retries on transient failures (network errors, 5xx status codes).\n            If all retries fail, it logs the error and returns None instead of raising an exception.\n        \"\"\"\n        try:\n            data = await self._request_json(\"get\", \"/get_latest_resources\")\n            return ResourcesUpdate.model_validate(data) if data else None\n        except Exception as e:\n            logger.error(f\"get_latest_resources failed after all retries: {e}\", exc_info=True)\n            return None\n\n    async def add_span(self, span: Span) -&gt; Span:\n        data = await self._request_json(\"post\", \"/add_span\", json=span.model_dump(mode=\"json\"))\n        return Span.model_validate(data)\n\n    async def get_next_span_sequence_id(self, rollout_id: str, attempt_id: str) -&gt; int:\n        data = await self._request_json(\"get\", f\"/get_next_span_sequence_id/{rollout_id}/{attempt_id}\")\n        # endpoint returns a plain JSON number\n        return int(data)\n\n    async def add_otel_span(\n        self,\n        rollout_id: str,\n        attempt_id: str,\n        readable_span: ReadableSpan,\n        sequence_id: int | None = None,\n    ) -&gt; Span:\n        # unchanged logic, now benefits from retries inside add_span/get_next_span_sequence_id\n        if sequence_id is None:\n            sequence_id = await self.get_next_span_sequence_id(rollout_id, attempt_id)\n        span = Span.from_opentelemetry(\n            readable_span,\n            rollout_id=rollout_id,\n            attempt_id=attempt_id,\n            sequence_id=sequence_id,\n        )\n        await self.add_span(span)\n        return span\n\n    async def wait_for_rollouts(self, *, rollout_ids: List[str], timeout: Optional[float] = None) -&gt; List[Rollout]:\n        \"\"\"Wait for rollouts to complete.\n\n        Args:\n            rollout_ids: List of rollout IDs to wait for.\n            timeout: Timeout in seconds. If not None, the method will raise a ValueError if the timeout is greater than 0.1 seconds.\n\n        Returns:\n            List of rollouts that are completed.\n        \"\"\"\n        if timeout is not None and timeout &gt; 0.1:\n            raise ValueError(\n                \"Timeout must be less than 0.1 seconds in LightningStoreClient to avoid blocking the event loop\"\n            )\n        data = await self._request_json(\n            \"post\",\n            \"/wait_for_rollouts\",\n            json=WaitForRolloutsRequest(rollout_ids=rollout_ids, timeout=timeout).model_dump(),\n        )\n        return [Rollout.model_validate(item) for item in data]\n\n    async def query_spans(\n        self,\n        rollout_id: str,\n        attempt_id: str | Literal[\"latest\"] | None = None,\n    ) -&gt; List[Span]:\n        path = f\"/query_spans/{rollout_id}\"\n        if attempt_id is not None:\n            path += f\"?attempt_id={attempt_id}\"\n        data = await self._request_json(\"get\", path)\n        return [Span.model_validate(item) for item in data]\n\n    async def update_rollout(\n        self,\n        rollout_id: str,\n        input: TaskInput | Unset = UNSET,\n        mode: Optional[Literal[\"train\", \"val\", \"test\"]] | Unset = UNSET,\n        resources_id: Optional[str] | Unset = UNSET,\n        status: RolloutStatus | Unset = UNSET,\n        config: RolloutConfig | Unset = UNSET,\n        metadata: Optional[Dict[str, Any]] | Unset = UNSET,\n    ) -&gt; Rollout:\n        payload: Dict[str, Any] = {\"rollout_id\": rollout_id}\n        if not isinstance(input, Unset):\n            payload[\"input\"] = input\n        if not isinstance(mode, Unset):\n            payload[\"mode\"] = mode\n        if not isinstance(resources_id, Unset):\n            payload[\"resources_id\"] = resources_id\n        if not isinstance(status, Unset):\n            payload[\"status\"] = status\n        if not isinstance(config, Unset):\n            payload[\"config\"] = config.model_dump()\n        if not isinstance(metadata, Unset):\n            payload[\"metadata\"] = metadata\n\n        data = await self._request_json(\"post\", \"/update_rollout\", json=payload)\n        return Rollout.model_validate(data)\n\n    async def update_attempt(\n        self,\n        rollout_id: str,\n        attempt_id: str | Literal[\"latest\"],\n        status: AttemptStatus | Unset = UNSET,\n        worker_id: str | Unset = UNSET,\n        last_heartbeat_time: float | Unset = UNSET,\n        metadata: Optional[Dict[str, Any]] | Unset = UNSET,\n    ) -&gt; Attempt:\n        payload: Dict[str, Any] = {\n            \"rollout_id\": rollout_id,\n            \"attempt_id\": attempt_id,\n        }\n        if not isinstance(status, Unset):\n            payload[\"status\"] = status\n        if not isinstance(worker_id, Unset):\n            payload[\"worker_id\"] = worker_id\n        if not isinstance(last_heartbeat_time, Unset):\n            payload[\"last_heartbeat_time\"] = last_heartbeat_time\n        if not isinstance(metadata, Unset):\n            payload[\"metadata\"] = metadata\n\n        data = await self._request_json(\"post\", \"/update_attempt\", json=payload)\n        return Attempt.model_validate(data)\n</code></pre>"},{"location":"reference/store/#agentlightning.LightningStoreClient.__getstate__","title":"<code>__getstate__()</code>","text":"<p>When LightningStoreClient is pickled (e.g., passed to a subprocess), we only serialize the server address and retry configurations. The ClientSessions are excluded as they should not be transferred between processes.</p> Source code in <code>agentlightning/store/client_server.py</code> <pre><code>def __getstate__(self):\n    \"\"\"\n    When LightningStoreClient is pickled (e.g., passed to a subprocess), we only\n    serialize the server address and retry configurations. The ClientSessions\n    are excluded as they should not be transferred between processes.\n    \"\"\"\n    return {\n        \"server_address\": self.server_address,\n        \"_retry_delays\": self._retry_delays,\n        \"_health_retry_delays\": self._health_retry_delays,\n    }\n</code></pre>"},{"location":"reference/store/#agentlightning.LightningStoreClient.__setstate__","title":"<code>__setstate__(state)</code>","text":"<p>Restore from pickle by reconstructing only the essential attributes.</p> <p>Replicating <code>__init__</code> logic to create another client instance in the subprocess.</p> Source code in <code>agentlightning/store/client_server.py</code> <pre><code>def __setstate__(self, state: Dict[str, Any]):\n    \"\"\"\n    Restore from pickle by reconstructing only the essential attributes.\n\n    Replicating `__init__` logic to create another client instance in the subprocess.\n    \"\"\"\n    self.server_address = state[\"server_address\"]\n    self._sessions = {}\n    self._lock = threading.RLock()\n    self._retry_delays = state[\"_retry_delays\"]\n    self._health_retry_delays = state[\"_health_retry_delays\"]\n    self._dequeue_was_successful = False\n    self._dequeue_first_unsuccessful = True\n</code></pre>"},{"location":"reference/store/#agentlightning.LightningStoreClient.close","title":"<code>close()</code>  <code>async</code>","text":"<p>Close the HTTP session.</p> Source code in <code>agentlightning/store/client_server.py</code> <pre><code>async def close(self):\n    \"\"\"Close the HTTP session.\"\"\"\n    with self._lock:\n        sessions = list(self._sessions.values())\n        self._sessions.clear()\n\n    # close them on their own loops to avoid warnings\n    async def _close(sess: aiohttp.ClientSession):\n        if not sess.closed:\n            await sess.close()\n\n    # If called from one loop, best-effort close here.\n    for s in sessions:\n        try:\n            await _close(s)\n        except RuntimeError:\n            # If created on a different loop/thread, schedule a thread-safe close\n            # Fallback: close without awaiting (library tolerates it in practice),\n            # or keep a per-loop shutdown hook where they were created.\n            pass\n</code></pre>"},{"location":"reference/store/#agentlightning.LightningStoreClient.dequeue_rollout","title":"<code>dequeue_rollout()</code>  <code>async</code>","text":"<p>Dequeue a rollout from the server queue.</p> <p>Returns:</p> Type Description <code>Optional[AttemptedRollout]</code> <p>AttemptedRollout if a rollout is available, None if queue is empty.</p> Note <p>This method does NOT retry on failures. If any exception occurs (network error, server error, etc.), it logs the error and returns None immediately.</p> Source code in <code>agentlightning/store/client_server.py</code> <pre><code>async def dequeue_rollout(self) -&gt; Optional[AttemptedRollout]:\n    \"\"\"\n    Dequeue a rollout from the server queue.\n\n    Returns:\n        AttemptedRollout if a rollout is available, None if queue is empty.\n\n    Note:\n        This method does NOT retry on failures. If any exception occurs (network error,\n        server error, etc.), it logs the error and returns None immediately.\n    \"\"\"\n    session = await self._get_session()\n    url = f\"{self.server_address}/dequeue_rollout\"\n    try:\n        async with session.get(url) as resp:\n            resp.raise_for_status()\n            data = await resp.json()\n            self._dequeue_was_successful = True\n            return AttemptedRollout.model_validate(data) if data else None\n    except Exception as e:\n        if self._dequeue_was_successful:\n            if self._dequeue_first_unsuccessful:\n                logger.warning(f\"dequeue_rollout failed with exception: {e}\")\n                self._dequeue_first_unsuccessful = False\n        logger.debug(\"dequeue_rollout failed with exception. Details:\", exc_info=True)\n        # Else ignore the exception because the server is not ready yet\n        return None\n</code></pre>"},{"location":"reference/store/#agentlightning.LightningStoreClient.get_latest_attempt","title":"<code>get_latest_attempt(rollout_id)</code>  <code>async</code>","text":"<p>Get the latest attempt for a rollout.</p> <p>Parameters:</p> Name Type Description Default <code>rollout_id</code> <code>str</code> <p>ID of the rollout to query.</p> required <p>Returns:</p> Type Description <code>Optional[Attempt]</code> <p>Attempt if found, None if not found or if all retries are exhausted.</p> Note <p>This method retries on transient failures (network errors, 5xx status codes). If all retries fail, it logs the error and returns None instead of raising an exception.</p> Source code in <code>agentlightning/store/client_server.py</code> <pre><code>async def get_latest_attempt(self, rollout_id: str) -&gt; Optional[Attempt]:\n    \"\"\"\n    Get the latest attempt for a rollout.\n\n    Args:\n        rollout_id: ID of the rollout to query.\n\n    Returns:\n        Attempt if found, None if not found or if all retries are exhausted.\n\n    Note:\n        This method retries on transient failures (network errors, 5xx status codes).\n        If all retries fail, it logs the error and returns None instead of raising an exception.\n    \"\"\"\n    try:\n        data = await self._request_json(\"get\", f\"/get_latest_attempt/{rollout_id}\")\n        return Attempt.model_validate(data) if data else None\n    except Exception as e:\n        logger.error(f\"get_latest_attempt failed after all retries for rollout_id={rollout_id}: {e}\", exc_info=True)\n        return None\n</code></pre>"},{"location":"reference/store/#agentlightning.LightningStoreClient.get_latest_resources","title":"<code>get_latest_resources()</code>  <code>async</code>","text":"<p>Get the latest resources.</p> <p>Returns:</p> Type Description <code>Optional[ResourcesUpdate]</code> <p>ResourcesUpdate if found, None if not found or if all retries are exhausted.</p> Note <p>This method retries on transient failures (network errors, 5xx status codes). If all retries fail, it logs the error and returns None instead of raising an exception.</p> Source code in <code>agentlightning/store/client_server.py</code> <pre><code>async def get_latest_resources(self) -&gt; Optional[ResourcesUpdate]:\n    \"\"\"\n    Get the latest resources.\n\n    Returns:\n        ResourcesUpdate if found, None if not found or if all retries are exhausted.\n\n    Note:\n        This method retries on transient failures (network errors, 5xx status codes).\n        If all retries fail, it logs the error and returns None instead of raising an exception.\n    \"\"\"\n    try:\n        data = await self._request_json(\"get\", \"/get_latest_resources\")\n        return ResourcesUpdate.model_validate(data) if data else None\n    except Exception as e:\n        logger.error(f\"get_latest_resources failed after all retries: {e}\", exc_info=True)\n        return None\n</code></pre>"},{"location":"reference/store/#agentlightning.LightningStoreClient.get_resources_by_id","title":"<code>get_resources_by_id(resources_id)</code>  <code>async</code>","text":"<p>Get resources by their ID.</p> <p>Parameters:</p> Name Type Description Default <code>resources_id</code> <code>str</code> <p>ID of the resources to retrieve.</p> required <p>Returns:</p> Type Description <code>Optional[ResourcesUpdate]</code> <p>ResourcesUpdate if found, None if not found or if all retries are exhausted.</p> Note <p>This method retries on transient failures (network errors, 5xx status codes). If all retries fail, it logs the error and returns None instead of raising an exception.</p> Source code in <code>agentlightning/store/client_server.py</code> <pre><code>async def get_resources_by_id(self, resources_id: str) -&gt; Optional[ResourcesUpdate]:\n    \"\"\"\n    Get resources by their ID.\n\n    Args:\n        resources_id: ID of the resources to retrieve.\n\n    Returns:\n        ResourcesUpdate if found, None if not found or if all retries are exhausted.\n\n    Note:\n        This method retries on transient failures (network errors, 5xx status codes).\n        If all retries fail, it logs the error and returns None instead of raising an exception.\n    \"\"\"\n    try:\n        data = await self._request_json(\"get\", f\"/get_resources_by_id/{resources_id}\")\n        return ResourcesUpdate.model_validate(data) if data else None\n    except Exception as e:\n        logger.error(\n            f\"get_resources_by_id failed after all retries for resources_id={resources_id}: {e}\", exc_info=True\n        )\n        return None\n</code></pre>"},{"location":"reference/store/#agentlightning.LightningStoreClient.get_rollout_by_id","title":"<code>get_rollout_by_id(rollout_id)</code>  <code>async</code>","text":"<p>Get a rollout by its ID.</p> <p>Parameters:</p> Name Type Description Default <code>rollout_id</code> <code>str</code> <p>ID of the rollout to retrieve.</p> required <p>Returns:</p> Type Description <code>Optional[Rollout]</code> <p>Rollout if found, None if not found or if all retries are exhausted.</p> Note <p>This method retries on transient failures (network errors, 5xx status codes). If all retries fail, it logs the error and returns None instead of raising an exception.</p> Source code in <code>agentlightning/store/client_server.py</code> <pre><code>async def get_rollout_by_id(self, rollout_id: str) -&gt; Optional[Rollout]:\n    \"\"\"\n    Get a rollout by its ID.\n\n    Args:\n        rollout_id: ID of the rollout to retrieve.\n\n    Returns:\n        Rollout if found, None if not found or if all retries are exhausted.\n\n    Note:\n        This method retries on transient failures (network errors, 5xx status codes).\n        If all retries fail, it logs the error and returns None instead of raising an exception.\n    \"\"\"\n    try:\n        data = await self._request_json(\"get\", f\"/get_rollout_by_id/{rollout_id}\")\n        return Rollout.model_validate(data) if data else None\n    except Exception as e:\n        logger.error(f\"get_rollout_by_id failed after all retries for rollout_id={rollout_id}: {e}\", exc_info=True)\n        return None\n</code></pre>"},{"location":"reference/store/#agentlightning.LightningStoreClient.wait_for_rollouts","title":"<code>wait_for_rollouts(*, rollout_ids, timeout=None)</code>  <code>async</code>","text":"<p>Wait for rollouts to complete.</p> <p>Parameters:</p> Name Type Description Default <code>rollout_ids</code> <code>List[str]</code> <p>List of rollout IDs to wait for.</p> required <code>timeout</code> <code>Optional[float]</code> <p>Timeout in seconds. If not None, the method will raise a ValueError if the timeout is greater than 0.1 seconds.</p> <code>None</code> <p>Returns:</p> Type Description <code>List[Rollout]</code> <p>List of rollouts that are completed.</p> Source code in <code>agentlightning/store/client_server.py</code> <pre><code>async def wait_for_rollouts(self, *, rollout_ids: List[str], timeout: Optional[float] = None) -&gt; List[Rollout]:\n    \"\"\"Wait for rollouts to complete.\n\n    Args:\n        rollout_ids: List of rollout IDs to wait for.\n        timeout: Timeout in seconds. If not None, the method will raise a ValueError if the timeout is greater than 0.1 seconds.\n\n    Returns:\n        List of rollouts that are completed.\n    \"\"\"\n    if timeout is not None and timeout &gt; 0.1:\n        raise ValueError(\n            \"Timeout must be less than 0.1 seconds in LightningStoreClient to avoid blocking the event loop\"\n        )\n    data = await self._request_json(\n        \"post\",\n        \"/wait_for_rollouts\",\n        json=WaitForRolloutsRequest(rollout_ids=rollout_ids, timeout=timeout).model_dump(),\n    )\n    return [Rollout.model_validate(item) for item in data]\n</code></pre>"},{"location":"reference/store/#agentlightning.LightningStoreThreaded","title":"<code>agentlightning.LightningStoreThreaded</code>","text":"<p>               Bases: <code>LightningStore</code></p> <p>Facade that delegates all store operations to a underlying store instance.</p> <p>The operations are guaranteed to be thread-safe. Make sure the threaded stores are instantiated before initializing the threads.</p> Source code in <code>agentlightning/store/threading.py</code> <pre><code>class LightningStoreThreaded(LightningStore):\n    \"\"\"Facade that delegates all store operations to a underlying store instance.\n\n    The operations are guaranteed to be thread-safe.\n    Make sure the threaded stores are instantiated before initializing the threads.\n    \"\"\"\n\n    def __init__(self, store: LightningStore) -&gt; None:\n        super().__init__()  # watchdog relies on the underlying store\n        self.store = store\n        self._lock = threading.Lock()\n\n    async def start_rollout(\n        self,\n        input: TaskInput,\n        mode: Literal[\"train\", \"val\", \"test\"] | None = None,\n        resources_id: str | None = None,\n        config: RolloutConfig | None = None,\n        metadata: Dict[str, Any] | None = None,\n    ) -&gt; AttemptedRollout:\n        with self._lock:\n            return await self.store.start_rollout(input, mode, resources_id, config, metadata)\n\n    async def enqueue_rollout(\n        self,\n        input: TaskInput,\n        mode: Literal[\"train\", \"val\", \"test\"] | None = None,\n        resources_id: str | None = None,\n        config: RolloutConfig | None = None,\n        metadata: Dict[str, Any] | None = None,\n    ) -&gt; Rollout:\n        with self._lock:\n            return await self.store.enqueue_rollout(input, mode, resources_id, config, metadata)\n\n    async def dequeue_rollout(self) -&gt; Optional[AttemptedRollout]:\n        with self._lock:\n            return await self.store.dequeue_rollout()\n\n    async def start_attempt(self, rollout_id: str) -&gt; AttemptedRollout:\n        with self._lock:\n            return await self.store.start_attempt(rollout_id)\n\n    async def query_rollouts(\n        self,\n        *,\n        status: Optional[Sequence[RolloutStatus]] = None,\n        rollout_ids: Optional[Sequence[str]] = None,\n    ) -&gt; List[Rollout]:\n        with self._lock:\n            return await self.store.query_rollouts(status=status, rollout_ids=rollout_ids)\n\n    async def query_attempts(self, rollout_id: str) -&gt; List[Attempt]:\n        with self._lock:\n            return await self.store.query_attempts(rollout_id)\n\n    async def get_rollout_by_id(self, rollout_id: str) -&gt; Optional[Rollout]:\n        with self._lock:\n            return await self.store.get_rollout_by_id(rollout_id)\n\n    async def get_latest_attempt(self, rollout_id: str) -&gt; Optional[Attempt]:\n        with self._lock:\n            return await self.store.get_latest_attempt(rollout_id)\n\n    async def add_resources(self, resources: NamedResources) -&gt; ResourcesUpdate:\n        with self._lock:\n            return await self.store.add_resources(resources)\n\n    async def update_resources(self, resources_id: str, resources: NamedResources) -&gt; ResourcesUpdate:\n        with self._lock:\n            return await self.store.update_resources(resources_id, resources)\n\n    async def get_resources_by_id(self, resources_id: str) -&gt; Optional[ResourcesUpdate]:\n        with self._lock:\n            return await self.store.get_resources_by_id(resources_id)\n\n    async def get_latest_resources(self) -&gt; Optional[ResourcesUpdate]:\n        with self._lock:\n            return await self.store.get_latest_resources()\n\n    async def add_span(self, span: Span) -&gt; Span:\n        with self._lock:\n            return await self.store.add_span(span)\n\n    async def add_otel_span(\n        self,\n        rollout_id: str,\n        attempt_id: str,\n        readable_span: ReadableSpan,\n        sequence_id: int | None = None,\n    ) -&gt; Span:\n        with self._lock:\n            return await self.store.add_otel_span(rollout_id, attempt_id, readable_span, sequence_id)\n\n    async def wait_for_rollouts(self, *, rollout_ids: List[str], timeout: Optional[float] = None) -&gt; List[Rollout]:\n        # This method does not change the state of the store, and it's not thread-safe.\n        return await self.store.wait_for_rollouts(rollout_ids=rollout_ids, timeout=timeout)\n\n    async def get_next_span_sequence_id(self, rollout_id: str, attempt_id: str) -&gt; int:\n        with self._lock:\n            return await self.store.get_next_span_sequence_id(rollout_id, attempt_id)\n\n    async def query_spans(\n        self,\n        rollout_id: str,\n        attempt_id: str | Literal[\"latest\"] | None = None,\n    ) -&gt; List[Span]:\n        with self._lock:\n            return await self.store.query_spans(rollout_id, attempt_id)\n\n    async def update_rollout(\n        self,\n        rollout_id: str,\n        input: TaskInput | Unset = UNSET,\n        mode: Optional[Literal[\"train\", \"val\", \"test\"]] | Unset = UNSET,\n        resources_id: Optional[str] | Unset = UNSET,\n        status: RolloutStatus | Unset = UNSET,\n        config: RolloutConfig | Unset = UNSET,\n        metadata: Optional[Dict[str, Any]] | Unset = UNSET,\n    ) -&gt; Rollout:\n        with self._lock:\n            return await self.store.update_rollout(\n                rollout_id=rollout_id,\n                input=input,\n                mode=mode,\n                resources_id=resources_id,\n                status=status,\n                config=config,\n                metadata=metadata,\n            )\n\n    async def update_attempt(\n        self,\n        rollout_id: str,\n        attempt_id: str | Literal[\"latest\"],\n        status: AttemptStatus | Unset = UNSET,\n        worker_id: str | Unset = UNSET,\n        last_heartbeat_time: float | Unset = UNSET,\n        metadata: Optional[Dict[str, Any]] | Unset = UNSET,\n    ) -&gt; Attempt:\n        with self._lock:\n            return await self.store.update_attempt(\n                rollout_id=rollout_id,\n                attempt_id=attempt_id,\n                status=status,\n                worker_id=worker_id,\n                last_heartbeat_time=last_heartbeat_time,\n                metadata=metadata,\n            )\n</code></pre>"},{"location":"reference/trainer/","title":"Agent-lightning Trainer","text":""},{"location":"reference/trainer/#agentlightning.Trainer","title":"<code>agentlightning.Trainer</code>","text":"<p>               Bases: <code>TrainerLegacy</code></p> <p>Orchestrates the distributed execution of agent rollouts.</p> <p>The Trainer is responsible for launching one or more worker processes that run the agent's execution loop. It manages multiprocessing, handles graceful shutdown, and serves as the main entry point for running a client-side agent fleet.</p> <p>Attributes:</p> Name Type Description <code>algorithm</code> <p>An instance of <code>Algorithm</code> to use for training.</p> <code>store</code> <p>An instance of <code>LightningStore</code> to use for storing tasks and traces.</p> <code>runner</code> <p>An instance of <code>Runner</code> to use for running the agent.</p> <code>initial_resources</code> <p>An instance of <code>Resources</code> to use for bootstrapping the fit/dev process. The resources will be handed over to the algorithm. Note that not all algorithms support seeding resources.</p> <code>n_runners</code> <p>Number of agent runners to run in parallel.</p> <code>max_rollouts</code> <p>Maximum number of rollouts to process per runner. If None,           workers run until no more rollouts are available.</p> <code>strategy</code> <p>An instance of <code>ExecutionStrategy</code> to use for spawning the algorithm and runners.</p> <code>tracer</code> <p>A tracer instance, or a string pointing to the class full name or a dictionary with a 'type' key     that specifies the class full name and other initialization parameters.     If None, a default <code>AgentOpsTracer</code> will be created with the current settings.</p> <code>hooks</code> <p>A sequence of <code>Hook</code> instances to be called at various lifecycle stages (e.g., on_trace_start,    on_trace_end, on_rollout_start, on_rollout_end).</p> <code>adapter</code> <p>An instance of <code>TracerTraceToTriplet</code> to export data consumble by algorithms from traces.</p> <code>llm_proxy</code> <p>An instance of <code>LLMProxy</code> to use for intercepting the LLM calls.        If not provided, algorithm will create one on its own.</p> <code>n_workers</code> <p>Number of agent workers to run in parallel. Deprecated in favor of <code>n_runners</code>.</p> <code>max_tasks</code> <p>Maximum number of tasks to process per runner. Deprecated in favor of <code>max_rollouts</code>.</p> <code>daemon</code> <p>Whether worker processes should be daemons. Daemon processes     are terminated automatically when the main process exits. Deprecated.     Only have effect with <code>fit_v0</code>.</p> <code>triplet_exporter</code> <p>An instance of <code>TracerTraceToTriplet</code> to export triplets from traces,               or a dictionary with the initialization parameters for the exporter.               Deprecated. Use <code>adapter</code> instead.</p> <code>dev</code> <code>None</code> <p>If True, rollouts are run against the dev endpoint provided in <code>fit</code>.  Deprecated in favor of <code>dev()</code> method.</p> Source code in <code>agentlightning/trainer/trainer.py</code> <pre><code>class Trainer(TrainerLegacy):\n    \"\"\"Orchestrates the distributed execution of agent rollouts.\n\n    The Trainer is responsible for launching one or more worker processes\n    that run the agent's execution loop. It manages multiprocessing,\n    handles graceful shutdown, and serves as the main entry point for\n    running a client-side agent fleet.\n\n    Attributes:\n        algorithm: An instance of `Algorithm` to use for training.\n        store: An instance of `LightningStore` to use for storing tasks and traces.\n        runner: An instance of `Runner` to use for running the agent.\n        initial_resources: An instance of `Resources` to use for bootstrapping the fit/dev process.\n            The resources will be handed over to the algorithm.\n            Note that not all algorithms support seeding resources.\n        n_runners: Number of agent runners to run in parallel.\n        max_rollouts: Maximum number of rollouts to process per runner. If None,\n                      workers run until no more rollouts are available.\n        strategy: An instance of `ExecutionStrategy` to use for spawning the algorithm and runners.\n        tracer: A tracer instance, or a string pointing to the class full name or a dictionary with a 'type' key\n                that specifies the class full name and other initialization parameters.\n                If None, a default `AgentOpsTracer` will be created with the current settings.\n        hooks: A sequence of `Hook` instances to be called at various lifecycle stages (e.g., on_trace_start,\n               on_trace_end, on_rollout_start, on_rollout_end).\n        adapter: An instance of `TracerTraceToTriplet` to export data consumble by algorithms from traces.\n        llm_proxy: An instance of `LLMProxy` to use for intercepting the LLM calls.\n                   If not provided, algorithm will create one on its own.\n        n_workers: Number of agent workers to run in parallel. Deprecated in favor of `n_runners`.\n        max_tasks: Maximum number of tasks to process per runner. Deprecated in favor of `max_rollouts`.\n        daemon: Whether worker processes should be daemons. Daemon processes\n                are terminated automatically when the main process exits. Deprecated.\n                Only have effect with `fit_v0`.\n        triplet_exporter: An instance of `TracerTraceToTriplet` to export triplets from traces,\n                          or a dictionary with the initialization parameters for the exporter.\n                          Deprecated. Use `adapter` instead.\n        dev: If True, rollouts are run against the dev endpoint provided in `fit`.\n             Deprecated in favor of `dev()` method.\n    \"\"\"\n\n    def __init__(\n        self,\n        *,\n        dev: bool = False,\n        n_runners: Optional[int] = None,\n        max_rollouts: Optional[int] = None,\n        initial_resources: Optional[NamedResources] = None,\n        tracer: ComponentSpec[Tracer] = None,\n        adapter: ComponentSpec[TraceAdapter[Any]] = None,\n        store: ComponentSpec[LightningStore] = None,\n        runner: ComponentSpec[Runner[Any]] = None,\n        strategy: ComponentSpec[ExecutionStrategy] = None,\n        algorithm: ComponentSpec[Algorithm] = None,\n        llm_proxy: ComponentSpec[LLMProxy] = None,\n        n_workers: Optional[int] = None,\n        max_tasks: Optional[int] = None,\n        daemon: bool = True,\n        triplet_exporter: ComponentSpec[TracerTraceToTriplet] = None,\n        hooks: Optional[Union[Hook, Sequence[Hook]]] = None,\n    ):\n        # Do not call super().__init__() here.\n        # super().__init__() will call TrainerLegacy's initialization, which is not intended.\n        self.worker_id: Optional[int] = None\n\n        self._dev = dev\n        self.daemon = daemon\n        self._client: AgentLightningClient | None = None  # Will be initialized in fit or fit_v0\n\n        if n_workers is not None:\n            warnings.warn(\n                \"`n_workers` is deprecated. Please use `n_runners`.\",\n                DeprecationWarning,\n                stacklevel=2,\n            )\n\n        if n_runners is None:\n            n_runners = n_workers if n_workers is not None else 1\n        else:\n            if n_workers is not None and n_workers != n_runners:\n                warnings.warn(\n                    \"`n_workers` is ignored when `n_runners` is provided.\",\n                    DeprecationWarning,\n                    stacklevel=2,\n                )\n\n        self.n_runners = n_runners\n        self.n_workers = n_runners  # Backwards compatibility for fit_v0\n\n        if max_tasks is not None:\n            warnings.warn(\n                \"`max_tasks` is deprecated. Please use `max_rollouts`.\",\n                DeprecationWarning,\n                stacklevel=2,\n            )\n\n        if max_rollouts is None:\n            max_rollouts = max_tasks\n        elif max_tasks is not None and max_tasks != max_rollouts:\n            warnings.warn(\n                \"`max_tasks` is ignored when `max_rollouts` is provided.\",\n                DeprecationWarning,\n                stacklevel=2,\n            )\n\n        self.max_rollouts = max_rollouts\n        self.max_tasks = max_tasks if max_tasks is not None else max_rollouts\n\n        self.tracer = self._make_tracer(tracer)\n\n        if adapter is not None and triplet_exporter is not None:\n            warnings.warn(\n                \"`triplet_exporter` is deprecated and ignored because `adapter` is provided.\",\n                DeprecationWarning,\n                stacklevel=2,\n            )\n\n        adapter_spec = adapter if adapter is not None else triplet_exporter\n        self.adapter = self._make_adapter(adapter_spec)\n        self.triplet_exporter = self.adapter  # Backwards compatibility\n\n        self.algorithm = self._make_algorithm(algorithm)\n\n        # We might be able to support a list of resources in future.\n        self.initial_resources = initial_resources\n\n        # The active store for the current execution context\n        self.store = self._make_store(store)\n        self.runner = self._make_runner(runner)\n\n        self.strategy = self._make_strategy(strategy, n_runners=self.n_runners)\n        if hasattr(self.strategy, \"n_runners\"):\n            strategy_runners = getattr(self.strategy, \"n_runners\")\n            if isinstance(strategy_runners, int) and strategy_runners &gt; 0:\n                self.n_runners = strategy_runners\n                self.n_workers = strategy_runners\n\n        self.llm_proxy = self._make_llm_proxy(llm_proxy, store=self.store)\n\n        self.hooks = self._normalize_hooks(hooks)\n\n        if not self.daemon:\n            logger.warning(\n                \"daemon=False. Worker processes are non-daemonic. \"\n                \"The worker processes will NOT be terminated when the main process exits. \"\n                \"The cleanup must be handled manually.\"\n            )\n\n    def _make_tracer(self, tracer: ComponentSpec[Tracer]) -&gt; Tracer:\n        \"\"\"Creates a tracer instance based on the provided configuration.\"\"\"\n        default_factory = lambda: AgentOpsTracer(\n            agentops_managed=True,\n            instrument_managed=True,\n            daemon=self.daemon,\n        )\n        return build_component(\n            tracer,\n            expected_type=Tracer,\n            spec_name=\"tracer\",\n            default_factory=default_factory,\n            dict_requires_type=True,\n            invalid_spec_error_fmt=\"Invalid tracer type: {actual_type}. Expected Tracer, str, dict, or None.\",\n            type_error_fmt=\"Tracer factory returned {type_name}, which is not a Tracer subclass.\",\n        )\n\n    def _make_algorithm(self, algorithm: ComponentSpec[Algorithm]) -&gt; Optional[Algorithm]:\n        \"\"\"Creates an algorithm instance based on the provided configuration.\"\"\"\n        return build_component(\n            algorithm,\n            expected_type=Algorithm,\n            spec_name=\"algorithm\",\n            allow_none=True,\n            invalid_spec_error_fmt=\"Invalid algorithm type: {actual_type}. Expected Algorithm, str, dict, or None.\",\n            type_error_fmt=\"Algorithm factory returned {type_name}, which is not a Algorithm subclass.\",\n        )\n\n    def _make_adapter(self, adapter: ComponentSpec[TraceAdapter[Any]]) -&gt; TraceAdapter[Any]:\n        return build_component(\n            adapter,\n            expected_type=TraceAdapter,\n            spec_name=\"adapter\",\n            default_factory=TracerTraceToTriplet,\n            dict_requires_type=False,\n            dict_default_cls=TracerTraceToTriplet,\n            invalid_spec_error_fmt=\"Invalid adapter type: {actual_type}. Expected TraceAdapter, dict, or None.\",\n            type_error_fmt=\"Adapter factory returned {type_name}, which is not a TraceAdapter subclass.\",\n        )\n\n    def _make_store(self, store: ComponentSpec[LightningStore]) -&gt; LightningStore:\n        return build_component(\n            store,\n            expected_type=LightningStore,\n            spec_name=\"store\",\n            default_factory=InMemoryLightningStore,\n            invalid_spec_error_fmt=\"Invalid store type: {actual_type}. Expected LightningStore, str, dict, or None.\",\n            type_error_fmt=\"Store factory returned {type_name}, which is not a LightningStore subclass.\",\n        )\n\n    def _make_strategy(\n        self,\n        strategy: ComponentSpec[ExecutionStrategy],\n        *,\n        n_runners: int,\n    ) -&gt; ExecutionStrategy:\n        if isinstance(strategy, ExecutionStrategy):\n            return strategy\n        optional_defaults: Dict[str, Callable[[], Any]] = {\"n_runners\": lambda: n_runners}\n\n        def default_factory() -&gt; ExecutionStrategy:\n            return ClientServerExecutionStrategy(n_runners=n_runners)\n\n        return build_component(\n            strategy,\n            expected_type=ExecutionStrategy,\n            spec_name=\"strategy\",\n            default_factory=default_factory,\n            optional_defaults=optional_defaults,\n            invalid_spec_error_fmt=\"Invalid strategy type: {actual_type}. Expected ExecutionStrategy, str, dict, or None.\",\n            type_error_fmt=\"Strategy factory returned {type_name}, which is not an ExecutionStrategy subclass.\",\n            registry=ExecutionStrategyRegistry,\n        )\n\n    def _make_llm_proxy(\n        self,\n        llm_proxy: ComponentSpec[LLMProxy],\n        *,\n        store: LightningStore,\n    ) -&gt; Optional[LLMProxy]:\n        if isinstance(llm_proxy, LLMProxy):\n            return llm_proxy\n\n        optional_defaults: Dict[str, Callable[[], Any]] = {\"store\": lambda: store}\n        if isinstance(llm_proxy, dict):\n            llm_proxy = {**llm_proxy}\n            llm_proxy.setdefault(\"store\", store)\n\n        return build_component(\n            llm_proxy,\n            expected_type=LLMProxy,\n            spec_name=\"llm_proxy\",\n            allow_none=True,\n            optional_defaults=optional_defaults,\n            invalid_spec_error_fmt=\"Invalid llm_proxy type: {actual_type}. Expected LLMProxy, dict, str, or None.\",\n            type_error_fmt=\"llm_proxy factory returned {type_name}, which is not an LLMProxy subclass.\",\n        )\n\n    def _make_runner(self, runner: ComponentSpec[Runner[Any]]) -&gt; Runner[Any]:\n        optional_defaults: Dict[str, Callable[[], Any]] = {\"tracer\": lambda: self.tracer}\n        if self.max_rollouts is not None:\n            optional_defaults[\"max_rollouts\"] = lambda: self.max_rollouts\n\n        def default_runner_factory() -&gt; Runner[Any]:\n            return instantiate_component(LitAgentRunner, optional_defaults=optional_defaults)\n\n        return build_component(\n            runner,\n            expected_type=Runner,\n            spec_name=\"runner\",\n            default_factory=default_runner_factory,\n            optional_defaults=optional_defaults,\n            invalid_spec_error_fmt=\"Invalid runner type: {actual_type}. Expected Runner, callable, str, dict, or None.\",\n            type_error_fmt=\"Runner factory returned {type_name}, which is not a Runner subclass.\",\n        )\n\n    def _normalize_hooks(self, hooks: Optional[Union[Hook, Sequence[Hook]]]) -&gt; Sequence[Hook]:\n        if hooks is None:\n            return ()\n        if isinstance(hooks, Hook):\n            return (hooks,)\n        return tuple(hooks)\n\n    def fit(\n        self,\n        agent: LitAgent[T_co],\n        train_dataset: Optional[Dataset[T_co]] = None,\n        *,\n        val_dataset: Optional[Dataset[T_co]] = None,\n    ) -&gt; None:\n        \"\"\"Run the training loop using the configured strategy, store, and runner.\n\n        Args:\n            agent: The LitAgent instance to be trained on.\n            train_dataset: The dataset to train on.\n            val_dataset: The dataset to validate on.\n        \"\"\"\n        if isinstance(train_dataset, str):\n            logger.warning(\n                \"Trainer.fit will no longer accepts a string URL in future version. \"\n                \"To continue using a string URL, please use Trainer.fit_v0 instead. \"\n                \"See documentation for how to migrate to latest version: https://microsoft.github.io/agent-lightning/stable/\"\n            )\n            return self.fit_v0(  # type: ignore\n                agent,\n                train_dataset,\n                val_dataset,  # type: ignore\n            )\n\n        agent.set_trainer(self)\n\n        algorithm_bundle = functools.partial(\n            self._algorithm_bundle,\n            train_dataset=train_dataset,\n            val_dataset=val_dataset,\n            algorithm=self.algorithm,\n        )\n        runner_bundle = functools.partial(self._runner_bundle, agent=agent)\n\n        self.strategy.execute(algorithm_bundle, runner_bundle, self.store)\n\n    def dev(\n        self,\n        agent: LitAgent[T_co],\n        train_dataset: Optional[Dataset[T_co]] = None,\n        *,\n        val_dataset: Optional[Dataset[T_co]] = None,\n    ) -&gt; None:\n        \"\"\"Dry run the training loop with a FastAlgorithm and the real runner.\n\n        Args:\n            agent: The LitAgent instance to be trained on.\n            train_dataset: The dataset to train on.\n            val_dataset: The dataset to validate on.\n\n        Raises:\n            TypeError: If the configured algorithm is not a :class:`FastAlgorithm`.\n        \"\"\"\n        agent.set_trainer(self)\n\n        # Sanity check\n        if self.algorithm is None:\n            algorithm = Baseline()\n        else:\n            algorithm = self.algorithm\n\n        if not isinstance(algorithm, FastAlgorithm):\n            raise TypeError(\n                \"Trainer.dev() requires an algorithm that inherits from FastAlgorithm. \"\n                f\"Received {type(algorithm).__name__}.\"\n            )\n\n        algorithm_bundle = functools.partial(\n            self._algorithm_bundle,\n            train_dataset=train_dataset,\n            val_dataset=val_dataset,\n            algorithm=algorithm,\n        )\n        runner_bundle = functools.partial(self._runner_bundle, agent=agent)\n        self.strategy.execute(algorithm_bundle, runner_bundle, self.store)\n\n    async def _algorithm_bundle(\n        self,\n        store: LightningStore,\n        event: ExecutionEvent,\n        train_dataset: Optional[Dataset[T_co]],\n        val_dataset: Optional[Dataset[T_co]],\n        algorithm: Optional[Algorithm],\n    ) -&gt; None:\n        if algorithm is not None:\n            algorithm.set_trainer(self)\n            algorithm.set_store(store)\n            algorithm.set_adapter(self.adapter)\n            if self.initial_resources is not None:\n                algorithm.set_initial_resources(self.initial_resources)\n            if self.llm_proxy is not None:\n                self.llm_proxy.set_store(store)\n                algorithm.set_llm_proxy(self.llm_proxy)\n\n        if algorithm is None:\n            while not event.is_set():\n                await asyncio.sleep(0.1)\n            return\n        try:\n            if algorithm.is_async():\n                await algorithm.run(  # type: ignore\n                    train_dataset=train_dataset,\n                    val_dataset=val_dataset,\n                )\n            else:\n                # This will block the event loop to maximize the debugging experience\n                # It's the responsibility of the execution strategy to enable async execution\n                algorithm.run(\n                    train_dataset=train_dataset,\n                    val_dataset=val_dataset,\n                )\n        except Exception:\n            logger.exception(\"Algorithm bundle encountered an error.\")\n            raise\n\n    async def _runner_bundle(\n        self, store: LightningStore, worker_id: int, event: ExecutionEvent, agent: LitAgent[T_co]\n    ) -&gt; None:\n        runner_instance: Runner[Any] | None = None\n        runner_initialized = False\n        worker_initialized = False\n        try:\n            # If not using shm execution strategy, we are already in the forked process\n            runner_instance = self.runner\n            runner_instance.init(agent=agent, hooks=self.hooks)\n            runner_initialized = True\n            runner_instance.init_worker(worker_id, store)\n            worker_initialized = True\n            await runner_instance.iter(event=event)\n        except Exception:\n            logger.exception(\"Runner bundle encountered an error (worker_id=%s).\", worker_id)\n            raise\n        finally:\n            if runner_instance is not None:\n                if worker_initialized:\n                    try:\n                        runner_instance.teardown_worker(worker_id)\n                    except Exception:\n                        logger.exception(\"Error during runner worker teardown (worker_id=%s).\", worker_id)\n                if runner_initialized:\n                    try:\n                        runner_instance.teardown()\n                    except Exception:\n                        logger.exception(\"Error during runner teardown (worker_id=%s).\", worker_id)\n</code></pre>"},{"location":"reference/trainer/#agentlightning.Trainer.dev","title":"<code>dev(agent, train_dataset=None, *, val_dataset=None)</code>","text":"<p>Dry run the training loop with a FastAlgorithm and the real runner.</p> <p>Parameters:</p> Name Type Description Default <code>agent</code> <code>LitAgent[T_co]</code> <p>The LitAgent instance to be trained on.</p> required <code>train_dataset</code> <code>Optional[Dataset[T_co]]</code> <p>The dataset to train on.</p> <code>None</code> <code>val_dataset</code> <code>Optional[Dataset[T_co]]</code> <p>The dataset to validate on.</p> <code>None</code> <p>Raises:</p> Type Description <code>TypeError</code> <p>If the configured algorithm is not a :class:<code>FastAlgorithm</code>.</p> Source code in <code>agentlightning/trainer/trainer.py</code> <pre><code>def dev(\n    self,\n    agent: LitAgent[T_co],\n    train_dataset: Optional[Dataset[T_co]] = None,\n    *,\n    val_dataset: Optional[Dataset[T_co]] = None,\n) -&gt; None:\n    \"\"\"Dry run the training loop with a FastAlgorithm and the real runner.\n\n    Args:\n        agent: The LitAgent instance to be trained on.\n        train_dataset: The dataset to train on.\n        val_dataset: The dataset to validate on.\n\n    Raises:\n        TypeError: If the configured algorithm is not a :class:`FastAlgorithm`.\n    \"\"\"\n    agent.set_trainer(self)\n\n    # Sanity check\n    if self.algorithm is None:\n        algorithm = Baseline()\n    else:\n        algorithm = self.algorithm\n\n    if not isinstance(algorithm, FastAlgorithm):\n        raise TypeError(\n            \"Trainer.dev() requires an algorithm that inherits from FastAlgorithm. \"\n            f\"Received {type(algorithm).__name__}.\"\n        )\n\n    algorithm_bundle = functools.partial(\n        self._algorithm_bundle,\n        train_dataset=train_dataset,\n        val_dataset=val_dataset,\n        algorithm=algorithm,\n    )\n    runner_bundle = functools.partial(self._runner_bundle, agent=agent)\n    self.strategy.execute(algorithm_bundle, runner_bundle, self.store)\n</code></pre>"},{"location":"reference/trainer/#agentlightning.Trainer.fit","title":"<code>fit(agent, train_dataset=None, *, val_dataset=None)</code>","text":"<p>Run the training loop using the configured strategy, store, and runner.</p> <p>Parameters:</p> Name Type Description Default <code>agent</code> <code>LitAgent[T_co]</code> <p>The LitAgent instance to be trained on.</p> required <code>train_dataset</code> <code>Optional[Dataset[T_co]]</code> <p>The dataset to train on.</p> <code>None</code> <code>val_dataset</code> <code>Optional[Dataset[T_co]]</code> <p>The dataset to validate on.</p> <code>None</code> Source code in <code>agentlightning/trainer/trainer.py</code> <pre><code>def fit(\n    self,\n    agent: LitAgent[T_co],\n    train_dataset: Optional[Dataset[T_co]] = None,\n    *,\n    val_dataset: Optional[Dataset[T_co]] = None,\n) -&gt; None:\n    \"\"\"Run the training loop using the configured strategy, store, and runner.\n\n    Args:\n        agent: The LitAgent instance to be trained on.\n        train_dataset: The dataset to train on.\n        val_dataset: The dataset to validate on.\n    \"\"\"\n    if isinstance(train_dataset, str):\n        logger.warning(\n            \"Trainer.fit will no longer accepts a string URL in future version. \"\n            \"To continue using a string URL, please use Trainer.fit_v0 instead. \"\n            \"See documentation for how to migrate to latest version: https://microsoft.github.io/agent-lightning/stable/\"\n        )\n        return self.fit_v0(  # type: ignore\n            agent,\n            train_dataset,\n            val_dataset,  # type: ignore\n        )\n\n    agent.set_trainer(self)\n\n    algorithm_bundle = functools.partial(\n        self._algorithm_bundle,\n        train_dataset=train_dataset,\n        val_dataset=val_dataset,\n        algorithm=self.algorithm,\n    )\n    runner_bundle = functools.partial(self._runner_bundle, agent=agent)\n\n    self.strategy.execute(algorithm_bundle, runner_bundle, self.store)\n</code></pre>"},{"location":"reference/trainer/#agentlightning.build_component","title":"<code>agentlightning.build_component(spec, *, expected_type, spec_name, default_factory=None, allow_none=False, optional_defaults=None, dict_requires_type=True, dict_default_cls=None, type_error_fmt=None, invalid_spec_error_fmt=None, registry=None)</code>","text":"<pre><code>build_component(\n    spec: Union[\n        T,\n        str,\n        Dict[str, Any],\n        type[T],\n        Callable[[], T],\n        None,\n    ],\n    *,\n    expected_type: type[T],\n    spec_name: str,\n    default_factory: Callable[[], T],\n    allow_none: bool = ...,\n    optional_defaults: Optional[OptionalDefaults] = ...,\n    dict_requires_type: bool = ...,\n    dict_default_cls: type[T] | None = ...,\n    type_error_fmt: str | None = ...,\n    invalid_spec_error_fmt: str | None = ...,\n    registry: Optional[Dict[str, str]] = ...\n) -&gt; T\n</code></pre><pre><code>build_component(\n    spec: Union[\n        T,\n        str,\n        Dict[str, Any],\n        type[T],\n        Callable[[], T],\n        None,\n    ],\n    *,\n    expected_type: type[T],\n    spec_name: str,\n    default_factory: None = ...,\n    allow_none: bool,\n    optional_defaults: Optional[OptionalDefaults] = ...,\n    dict_requires_type: bool = ...,\n    dict_default_cls: type[T] | None = ...,\n    type_error_fmt: str | None = ...,\n    invalid_spec_error_fmt: str | None = ...,\n    registry: Optional[Dict[str, str]] = ...\n) -&gt; T | None\n</code></pre><pre><code>build_component(\n    spec: Union[\n        T,\n        str,\n        Dict[str, Any],\n        type[T],\n        Callable[[], T],\n        None,\n    ],\n    *,\n    expected_type: type[T],\n    spec_name: str,\n    default_factory: None = ...,\n    allow_none: bool = ...,\n    optional_defaults: Optional[OptionalDefaults] = ...,\n    dict_requires_type: bool = ...,\n    dict_default_cls: type[T] | None = ...,\n    type_error_fmt: str | None = ...,\n    invalid_spec_error_fmt: str | None = ...,\n    registry: Optional[Dict[str, str]] = ...\n) -&gt; T | None\n</code></pre> <p>Build and return a component instance from a flexible specification.</p> <p>This function provides a flexible way to create component instances from various input formats including direct instances, class types, factory functions, import paths, or configuration dictionaries.</p> <p>Parameters:</p> Name Type Description Default <code>spec</code> <code>Union[T, str, Dict[str, Any], type[T], Callable[[], T], None]</code> <p>The component specification. Can be: - An instance of expected_type (returned as-is) - A string import path (e.g., 'module.Class') or registry key - A dict with 'type' key (import path or registry key) and constructor kwargs - A class type (will be instantiated) - A factory function (will be called) - None (uses default_factory or returns None if allow_none=True)</p> required <code>expected_type</code> <code>type[T]</code> <p>The type that the resulting instance must be or inherit from.</p> required <code>spec_name</code> <code>str</code> <p>Descriptive name for the spec, used in error messages.</p> required <code>default_factory</code> <code>Callable[[], T] | None</code> <p>Optional factory function called when spec is None.</p> <code>None</code> <code>allow_none</code> <code>bool</code> <p>If True, allows None to be returned when spec is None and no default_factory is provided.</p> <code>False</code> <code>optional_defaults</code> <code>Optional[OptionalDefaults]</code> <p>Dict mapping parameter names to default values or factory functions that will be injected if the constructor accepts them.</p> <code>None</code> <code>dict_requires_type</code> <code>bool</code> <p>If True, dict specs must include a 'type' key.</p> <code>True</code> <code>dict_default_cls</code> <code>type[T] | None</code> <p>Default class to use for dict specs without a 'type' key (only used when dict_requires_type=False).</p> <code>None</code> <code>type_error_fmt</code> <code>str | None</code> <p>Custom format string for type validation errors. Should include {type_name} and {expected_type} placeholders.</p> <code>None</code> <code>invalid_spec_error_fmt</code> <code>str | None</code> <p>Custom format string for invalid spec type errors. Should include {actual_type} and {expected_type} placeholders.</p> <code>None</code> <code>registry</code> <code>Optional[Dict[str, str]]</code> <p>Optional mapping of short names to fully qualified import paths. When provided, string specs or dict 'type'/'name' entries are first resolved through this registry before attempting to import.</p> <code>None</code> <p>Returns:</p> Type Description <code>T | None</code> <p>An instance of expected_type, or None if allow_none=True and spec is None</p> <code>T | None</code> <p>without a default_factory.</p> <p>Raises:</p> Type Description <code>TypeError</code> <p>If the instantiated object is not an instance of expected_type.</p> <code>ValueError</code> <p>If spec is None and neither default_factory nor allow_none is set, or if spec type is invalid, or if dict spec is invalid.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Direct instance\n&gt;&gt;&gt; optimizer = build_component(AdamW(), expected_type=Optimizer, spec_name='optimizer')\n&gt;&gt;&gt;\n&gt;&gt;&gt; # String import path\n&gt;&gt;&gt; optimizer = build_component('torch.optim.AdamW', expected_type=Optimizer, spec_name='optimizer')\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Dict with type and kwargs\n&gt;&gt;&gt; spec = {'type': 'torch.optim.AdamW', 'lr': 0.001}\n&gt;&gt;&gt; optimizer = build_component(spec, expected_type=Optimizer, spec_name='optimizer')\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Class type\n&gt;&gt;&gt; optimizer = build_component(AdamW, expected_type=Optimizer, spec_name='optimizer')\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Factory function\n&gt;&gt;&gt; optimizer = build_component(lambda: AdamW(lr=0.001), expected_type=Optimizer,\n...                            spec_name='optimizer')\n</code></pre> Source code in <code>agentlightning/trainer/init_utils.py</code> <pre><code>def build_component(\n    spec: Union[T, str, Dict[str, Any], type[T], Callable[[], T], None],\n    *,\n    expected_type: type[T],\n    spec_name: str,\n    default_factory: Callable[[], T] | None = None,\n    allow_none: bool = False,\n    optional_defaults: Optional[OptionalDefaults] = None,\n    dict_requires_type: bool = True,\n    dict_default_cls: type[T] | None = None,\n    type_error_fmt: str | None = None,\n    invalid_spec_error_fmt: str | None = None,\n    registry: Optional[Dict[str, str]] = None,\n) -&gt; T | None:\n    \"\"\"Build and return a component instance from a flexible specification.\n\n    This function provides a flexible way to create component instances from various\n    input formats including direct instances, class types, factory functions, import\n    paths, or configuration dictionaries.\n\n    Args:\n        spec: The component specification. Can be:\n            - An instance of expected_type (returned as-is)\n            - A string import path (e.g., 'module.Class') or registry key\n            - A dict with 'type' key (import path or registry key) and constructor kwargs\n            - A class type (will be instantiated)\n            - A factory function (will be called)\n            - None (uses default_factory or returns None if allow_none=True)\n        expected_type: The type that the resulting instance must be or inherit from.\n        spec_name: Descriptive name for the spec, used in error messages.\n        default_factory: Optional factory function called when spec is None.\n        allow_none: If True, allows None to be returned when spec is None and\n            no default_factory is provided.\n        optional_defaults: Dict mapping parameter names to default values or factory\n            functions that will be injected if the constructor accepts them.\n        dict_requires_type: If True, dict specs must include a 'type' key.\n        dict_default_cls: Default class to use for dict specs without a 'type' key\n            (only used when dict_requires_type=False).\n        type_error_fmt: Custom format string for type validation errors. Should include\n            {type_name} and {expected_type} placeholders.\n        invalid_spec_error_fmt: Custom format string for invalid spec type errors.\n            Should include {actual_type} and {expected_type} placeholders.\n        registry: Optional mapping of short names to fully qualified import paths.\n            When provided, string specs or dict 'type'/'name' entries are first\n            resolved through this registry before attempting to import.\n\n    Returns:\n        An instance of expected_type, or None if allow_none=True and spec is None\n        without a default_factory.\n\n    Raises:\n        TypeError: If the instantiated object is not an instance of expected_type.\n        ValueError: If spec is None and neither default_factory nor allow_none is set,\n            or if spec type is invalid, or if dict spec is invalid.\n\n    Examples:\n        &gt;&gt;&gt; # Direct instance\n        &gt;&gt;&gt; optimizer = build_component(AdamW(), expected_type=Optimizer, spec_name='optimizer')\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # String import path\n        &gt;&gt;&gt; optimizer = build_component('torch.optim.AdamW', expected_type=Optimizer, spec_name='optimizer')\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Dict with type and kwargs\n        &gt;&gt;&gt; spec = {'type': 'torch.optim.AdamW', 'lr': 0.001}\n        &gt;&gt;&gt; optimizer = build_component(spec, expected_type=Optimizer, spec_name='optimizer')\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Class type\n        &gt;&gt;&gt; optimizer = build_component(AdamW, expected_type=Optimizer, spec_name='optimizer')\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Factory function\n        &gt;&gt;&gt; optimizer = build_component(lambda: AdamW(lr=0.001), expected_type=Optimizer,\n        ...                            spec_name='optimizer')\n    \"\"\"\n    if isinstance(spec, expected_type):\n        return cast(T, spec)\n\n    if spec is None:\n        if default_factory is not None:\n            instance = default_factory()\n            return _ensure_expected_type(instance, expected_type, spec_name, type_error_fmt)\n        if allow_none:\n            return None\n        raise ValueError(\n            invalid_spec_error_fmt.format(actual_type=type(spec), expected_type=expected_type.__name__)\n            if invalid_spec_error_fmt\n            else f\"{spec_name} cannot be None.\"\n        )\n\n    if isinstance(spec, type) and issubclass(spec, expected_type):\n        instance = instantiate_component(spec, optional_defaults=optional_defaults)\n        return _ensure_expected_type(instance, expected_type, spec_name, type_error_fmt)\n\n    if callable(spec) and not isinstance(spec, type):  # type: ignore\n        instance = spec()\n        return _ensure_expected_type(instance, expected_type, spec_name, type_error_fmt)\n\n    if isinstance(spec, str):\n        instance = instantiate_from_spec(\n            spec,\n            spec_name=spec_name,\n            optional_defaults=optional_defaults,\n            dict_requires_type=dict_requires_type,\n            dict_default_cls=dict_default_cls,\n            registry=registry,\n        )\n        return _ensure_expected_type(instance, expected_type, spec_name, type_error_fmt)\n\n    if isinstance(spec, dict):\n        instance = instantiate_from_spec(\n            spec,  # type: ignore\n            spec_name=spec_name,\n            optional_defaults=optional_defaults,\n            dict_requires_type=dict_requires_type,\n            dict_default_cls=dict_default_cls,\n            registry=registry,\n        )\n        return _ensure_expected_type(instance, expected_type, spec_name, type_error_fmt)\n\n    if invalid_spec_error_fmt:\n        raise ValueError(invalid_spec_error_fmt.format(actual_type=type(spec), expected_type=expected_type.__name__))  # type: ignore\n\n    type_name = str(type(spec))  # type: ignore\n    raise ValueError(f\"Invalid {spec_name} type: {type_name}. Expected {expected_type.__name__}, str, dict, or None.\")\n</code></pre>"},{"location":"reference/trainer/#execution-strategy","title":"Execution Strategy","text":""},{"location":"reference/trainer/#agentlightning.ExecutionStrategy","title":"<code>agentlightning.ExecutionStrategy</code>","text":"<p>When trainer has created the executable of algorithm and runner in two bundles, the execution strategy defines how to run them together, and how many parallel runners to run.</p> <p>The store is the centric place for the two bundles to communicate.</p> <p>The algorithm and runner's behavior (whether runner should perform one step or run forever, whether the algo would send out the tasks or not) are defined inside the bundle, and does not belong to the execution strategy.</p> <p>The execute should support Ctrl+C to exit gracefully.</p> Source code in <code>agentlightning/execution/base.py</code> <pre><code>class ExecutionStrategy:\n    \"\"\"When trainer has created the executable of algorithm and runner in two bundles,\n    the execution strategy defines how to run them together, and how many parallel runners to run.\n\n    The store is the centric place for the two bundles to communicate.\n\n    The algorithm and runner's behavior (whether runner should perform one step or run forever,\n    whether the algo would send out the tasks or not) are defined inside the bundle,\n    and does not belong to the execution strategy.\n\n    The execute should support Ctrl+C to exit gracefully.\n    \"\"\"\n\n    def execute(self, algorithm: AlgorithmBundle, runner: RunnerBundle, store: LightningStore) -&gt; None:\n        raise NotImplementedError()\n</code></pre>"},{"location":"reference/trainer/#agentlightning.ClientServerExecutionStrategy","title":"<code>agentlightning.ClientServerExecutionStrategy</code>","text":"<p>               Bases: <code>ExecutionStrategy</code></p> <p>Run algorithm (server) and runners (clients) as separate processes over HTTP.</p> <p>Execution Roles:</p> <ul> <li>\"algorithm\": Start the HTTP server (<code>LightningStoreServer</code>) in-process and run the   algorithm bundle against it.</li> <li>\"runner\": Connect to an already running server via <code>LightningStoreClient</code> and   execute runner bundles (optionally in multiple processes).</li> <li>\"both\": Spawn the runner processes first, then launch the algorithm/server   bundle on the main process. This mode orchestrates the full loop locally.</li> </ul> <p>When role == \"both\", you may choose which side runs on the main process via <code>main_process</code> (debug helper). Running the runner bundle on the main process is only supported with <code>n_runners == 1</code>.</p> <p>Important: When <code>main_process == \"runner\"</code>, the algorithm runs in a subprocess with the LightningStore server. This means any state modifications made during execution remain in that subprocess and are NOT reflected in the original store object passed to <code>execute()</code>. The main process runner accesses the store only through the HTTP client interface.</p> <p>Abort / Stop Model (four-step escalation):</p> <ol> <li>Cooperative stop:    A shared :class:<code>~agentlightning.execution.events.MultiprocessingEvent</code>    (<code>stop_evt</code>) is passed to all bundles. Bundles should check it to exit.    Any crash (algorithm or runner) sets <code>stop_evt</code> so the other side can    stop cooperatively. Ctrl+C on the main process also flips the event.</li> <li>KeyboardInterrupt synth:    Remaining subprocesses receive <code>SIGINT</code> to trigger <code>KeyboardInterrupt</code>    handlers.</li> <li>Termination:    Stubborn subprocesses get <code>terminate()</code> (SIGTERM on POSIX).</li> <li>Kill:     As a last resort we call <code>kill()</code> (SIGKILL on POSIX).</li> </ol> Notes <p>This mirrors the semantics implemented in :mod:<code>shared_memory</code>, but adapted to multiple processes and the HTTP client/server boundary.</p> Source code in <code>agentlightning/execution/client_server.py</code> <pre><code>class ClientServerExecutionStrategy(ExecutionStrategy):\n    \"\"\"Run algorithm (server) and runners (clients) as separate processes over HTTP.\n\n    **Execution Roles:**\n\n    - \"algorithm\": Start the HTTP server (`LightningStoreServer`) in-process and run the\n      algorithm bundle against it.\n    - \"runner\": Connect to an already running server via `LightningStoreClient` and\n      execute runner bundles (optionally in multiple processes).\n    - \"both\": Spawn the runner processes first, then launch the algorithm/server\n      bundle on the main process. This mode orchestrates the full loop locally.\n\n    When role == \"both\", you may choose which side runs on the main process via\n    `main_process` (debug helper). Running the runner bundle on the main process\n    is only supported with `n_runners == 1`.\n\n    Important: When `main_process == \"runner\"`, the algorithm runs in a subprocess\n    with the LightningStore server. This means any state modifications made during\n    execution remain in that subprocess and are NOT reflected in the original store\n    object passed to `execute()`. The main process runner accesses the store only\n    through the HTTP client interface.\n\n    **Abort / Stop Model (four-step escalation):**\n\n    1. Cooperative stop:\n       A shared :class:`~agentlightning.execution.events.MultiprocessingEvent`\n       (`stop_evt`) is passed to *all* bundles. Bundles should check it to exit.\n       Any crash (algorithm or runner) sets `stop_evt` so the other side can\n       stop cooperatively. Ctrl+C on the main process also flips the event.\n    2. KeyboardInterrupt synth:\n       Remaining subprocesses receive `SIGINT` to trigger `KeyboardInterrupt`\n       handlers.\n    3. Termination:\n       Stubborn subprocesses get `terminate()` (SIGTERM on POSIX).\n    4. Kill:\n        As a last resort we call `kill()` (SIGKILL on POSIX).\n\n    Notes:\n        This mirrors the semantics implemented in :mod:`shared_memory`, but adapted\n        to multiple processes and the HTTP client/server boundary.\n    \"\"\"\n\n    alias: str = \"cs\"\n\n    def __init__(\n        self,\n        role: Literal[\"algorithm\", \"runner\", \"both\"] | None = None,\n        server_host: str | None = None,\n        server_port: int | None = None,\n        n_runners: int = 1,\n        graceful_timeout: float = 5.0,\n        terminate_timeout: float = 5.0,\n        main_process: Literal[\"algorithm\", \"runner\"] = \"algorithm\",\n        managed_store: bool | None = None,\n    ) -&gt; None:\n        \"\"\"Configure the strategy.\n\n        Args:\n            role: Which side(s) to run in this process. When omitted, the\n                :envvar:`AGL_CURRENT_ROLE` environment variable is used.\n            server_host: Interface the HTTP server binds to when running the\n                algorithm bundle locally. Defaults to :envvar:`AGL_SERVER_HOST`\n                or ``\"localhost\"`` if unset.\n            server_port: Port for the HTTP server in \"algorithm\"/\"both\" modes.\n                Defaults to :envvar:`AGL_SERVER_PORT` or ``4747`` if unset.\n            n_runners: Number of runner processes to spawn in \"runner\"/\"both\".\n            graceful_timeout: How long to wait (seconds) after setting the stop\n                event before escalating to signals.\n            terminate_timeout: How long to wait between escalation steps beyond\n                the cooperative phase (re-used for SIGINT, terminate, and kill).\n            main_process: Which bundle runs on the main process when\n                `role == \"both\"`. `\"runner\"` requires `n_runners == 1` and is\n                primarily intended for debugging.\n            managed_store: When ``True`` (default) the strategy constructs\n                LightningStore client/server wrappers automatically. When\n                ``False`` the provided ``store`` is passed directly to the\n                bundles, allowing callers to manage store wrappers manually.\n        \"\"\"\n        if role is None:\n            role_env = os.getenv(\"AGL_CURRENT_ROLE\")\n            if role_env is None:\n                # Use both if not specified via env var or argument\n                role = \"both\"\n            elif role_env not in (\"algorithm\", \"runner\", \"both\"):\n                raise ValueError(\"role must be one of 'algorithm', 'runner', or 'both'\")\n            else:\n                role = role_env\n\n        if server_host is None:\n            server_host = os.getenv(\"AGL_SERVER_HOST\", \"localhost\")\n\n        if server_port is None:\n            server_port_env = os.getenv(\"AGL_SERVER_PORT\")\n            if server_port_env is None:\n                server_port = 4747\n            else:\n                try:\n                    server_port = int(server_port_env)\n                except ValueError as exc:\n                    raise ValueError(\"AGL_SERVER_PORT must be an integer\") from exc\n\n        self.role = role\n        self.n_runners = n_runners\n        self.server_host = server_host\n        self.server_port = server_port\n        self.graceful_timeout = graceful_timeout\n        self.terminate_timeout = terminate_timeout\n        if main_process not in (\"algorithm\", \"runner\"):\n            raise ValueError(\"main_process must be 'algorithm' or 'runner'\")\n        if main_process == \"runner\":\n            if role != \"both\":\n                raise ValueError(\"main_process='runner' is only supported when role='both'\")\n            if n_runners != 1:\n                raise ValueError(\"main_process='runner' requires n_runners to be 1\")\n        self.main_process = main_process\n        self.managed_store = resolve_managed_store_flag(managed_store)\n\n    async def _execute_algorithm(\n        self, algorithm: AlgorithmBundle, store: LightningStore, stop_evt: ExecutionEvent\n    ) -&gt; None:\n        wrapper_store: LightningStore | None = None\n        if self.managed_store:\n            logger.info(\"Starting LightningStore server on %s:%s\", self.server_host, self.server_port)\n            wrapper_store = LightningStoreServer(store, host=self.server_host, port=self.server_port)\n            server_started = False\n        else:\n            wrapper_store = store\n            server_started = False\n\n        try:\n            if self.managed_store and isinstance(wrapper_store, LightningStoreServer):\n                await wrapper_store.start()\n                server_started = True\n                logger.debug(\"Algorithm bundle starting against endpoint %s\", wrapper_store.endpoint)\n            await algorithm(wrapper_store, stop_evt)\n            logger.debug(\"Algorithm bundle completed successfully\")\n        except KeyboardInterrupt:\n            logger.warning(\"Algorithm received KeyboardInterrupt; signaling stop event\")\n            stop_evt.set()\n            raise\n        except BaseException:\n            logger.exception(\"Algorithm bundle crashed; signaling stop event\")\n            stop_evt.set()\n            raise\n        finally:\n            if self.managed_store and isinstance(wrapper_store, LightningStoreServer) and server_started:\n                try:\n                    await wrapper_store.stop()\n                except Exception:\n                    logger.exception(\"Error stopping LightningStore server\")\n                else:\n                    logger.debug(\"LightningStore server shutdown completed\")\n\n    async def _execute_runner(\n        self,\n        runner: RunnerBundle,\n        worker_id: int,\n        store: LightningStore,\n        stop_evt: ExecutionEvent,\n    ) -&gt; None:\n        if self.managed_store:\n            # If managed, we actually do not use the provided store\n            client_store = LightningStoreClient(f\"http://{self.server_host}:{self.server_port}\")\n        else:\n            client_store = store\n        try:\n            if self.managed_store:\n                logger.debug(\"Runner %s connecting to server at %s:%s\", worker_id, self.server_host, self.server_port)\n            else:\n                logger.debug(\"Runner %s executing with provided store\", worker_id)\n            await runner(client_store, worker_id, stop_evt)\n            logger.debug(\"Runner %s completed successfully\", worker_id)\n        except KeyboardInterrupt:\n            logger.warning(\"Runner %s received KeyboardInterrupt; signaling stop event\", worker_id)\n            stop_evt.set()\n            raise\n        except BaseException:\n            logger.exception(\"Runner %s crashed; signaling stop event\", worker_id)\n            stop_evt.set()\n            raise\n        finally:\n            if self.managed_store and isinstance(client_store, LightningStoreClient):\n                try:\n                    await client_store.close()\n                except Exception:\n                    logger.exception(\"Error closing LightningStore client for runner %s\", worker_id)\n                else:\n                    logger.debug(\"Runner %s closed LightningStore client\", worker_id)\n\n    def _spawn_runners(\n        self,\n        runner: RunnerBundle,\n        store: LightningStore,\n        stop_evt: ExecutionEvent,\n        *,\n        ctx: BaseContext,\n    ) -&gt; list[multiprocessing.Process]:\n        \"\"\"Used when `role == \"runner\"` or `role == \"both\"` and `n_runners &gt; 1`.\"\"\"\n        processes: list[multiprocessing.Process] = []\n\n        def _runner_sync(runner: RunnerBundle, worker_id: int, store: LightningStore, stop_evt: ExecutionEvent) -&gt; None:\n            # Runners are executed in child processes; each process owns its own\n            # event loop to keep the asyncio scheduler isolated.\n            asyncio.run(self._execute_runner(runner, worker_id, store, stop_evt))\n\n        for i in range(self.n_runners):\n            process = cast(\n                multiprocessing.Process,\n                ctx.Process(target=_runner_sync, args=(runner, i, store, stop_evt), name=f\"runner-{i}\"),  # type: ignore\n            )\n            process.start()\n            logger.debug(\"Spawned runner process %s (pid=%s)\", process.name, process.pid)\n            processes.append(process)\n\n        return processes\n\n    def _spawn_algorithm_process(\n        self,\n        algorithm: AlgorithmBundle,\n        store: LightningStore,\n        stop_evt: ExecutionEvent,\n        *,\n        ctx: BaseContext,\n    ) -&gt; multiprocessing.Process:\n        \"\"\"Used when `main_process == \"runner\"`.\"\"\"\n\n        def _algorithm_sync(algorithm: AlgorithmBundle, store: LightningStore, stop_evt: ExecutionEvent) -&gt; None:\n            asyncio.run(self._execute_algorithm(algorithm, store, stop_evt))\n\n        process = cast(\n            multiprocessing.Process,\n            ctx.Process(target=_algorithm_sync, args=(algorithm, store, stop_evt), name=\"algorithm\"),  # type: ignore\n        )\n        process.start()\n        logger.debug(\"Spawned algorithm process %s (pid=%s)\", process.name, process.pid)\n        return process\n\n    def _join_until_deadline(\n        self,\n        processes: Iterable[multiprocessing.Process],\n        timeout: float,\n    ) -&gt; list[multiprocessing.Process]:\n        \"\"\"Join ``processes`` until ``timeout`` elapses, returning those still alive.\"\"\"\n        deadline = time.monotonic() + timeout\n        still_alive: list[multiprocessing.Process] = []\n        for process in processes:\n            remaining = deadline - time.monotonic()\n            if remaining &gt; 0:\n                process.join(remaining)\n            else:\n                process.join(0)\n            if process.is_alive():\n                still_alive.append(process)\n        return still_alive\n\n    def _signal_processes(\n        self,\n        processes: Iterable[multiprocessing.Process],\n        action: Callable[[multiprocessing.Process], None],\n    ) -&gt; None:\n        \"\"\"Invoke ``action`` on each process while suppressing individual failures.\"\"\"\n        for process in processes:\n            try:\n                action(process)\n            except Exception:\n                logger.exception(\"Error signaling process %s (pid=%s)\", process.name, process.pid)\n\n    def _shutdown_processes(\n        self,\n        processes: list[multiprocessing.Process],\n        stop_evt: ExecutionEvent,\n    ) -&gt; None:\n        \"\"\"4-step escalation shutdown of ``processes``.\"\"\"\n        if not processes:\n            logger.debug(\"No subprocesses to shutdown\")\n            return\n\n        if not stop_evt.is_set():\n            logger.debug(\"Sending cooperative stop signal to subprocesses\")\n            stop_evt.set()\n        else:\n            logger.debug(\"Stop event already set; waiting for subprocesses to exit\")\n\n        alive = self._join_until_deadline(processes, self.graceful_timeout)\n        if not alive:\n            return\n\n        logger.warning(\n            \"Subprocesses still alive after cooperative wait; sending SIGINT to %s\",\n            \", \".join(p.name or str(p.pid) for p in alive),\n        )\n        # SIGINT is not reliable on Windows, but we do not consider such case yet.\n        self._signal_processes(alive, lambda p: os.kill(cast(int, p.pid), signal.SIGINT))\n        alive = self._join_until_deadline(alive, self.terminate_timeout)\n        if not alive:\n            return\n\n        logger.warning(\n            \"Subprocesses still alive after SIGINT wait; sending terminate() to %s\",\n            \", \".join(p.name or str(p.pid) for p in alive),\n        )\n        self._signal_processes(alive, lambda p: p.terminate())\n\n        alive = self._join_until_deadline(alive, self.terminate_timeout)\n        if not alive:\n            return\n\n        logger.error(\n            \"Subprocesses still alive after terminate(); sending kill() to %s\",\n            \", \".join(p.name or str(p.pid) for p in alive),\n        )\n        self._signal_processes(alive, lambda p: p.kill())\n        alive = self._join_until_deadline(alive, self.terminate_timeout)\n\n        if alive:\n            logger.error(\n                \"Subprocesses failed to exit even after kill(): %s\", \", \".join(p.name or str(p.pid) for p in alive)\n            )\n\n    def _check_process_exitcodes(self, processes: Iterable[multiprocessing.Process]) -&gt; None:\n        \"\"\"Raise an error if any managed process exited with a non-zero status.\"\"\"\n        failed = [p for p in processes if p.exitcode not in (0, None)]\n        if failed:\n            formatted = \", \".join(f\"{p.name or p.pid} (exitcode={p.exitcode})\" for p in failed)\n            raise RuntimeError(f\"Subprocesses failed: {formatted}\")\n\n    def execute(self, algorithm: AlgorithmBundle, runner: RunnerBundle, store: LightningStore) -&gt; None:\n        logger.info(\n            \"Starting client-server execution with %d runner(s) [role=%s, main_process=%s]\",\n            self.n_runners,\n            self.role,\n            self.main_process,\n        )\n\n        # Re-use the active multiprocessing context so the event and processes\n        # agree on the start method (fork/spawn/forkserver).\n        ctx = multiprocessing.get_context()\n        stop_evt = MultiprocessingEvent(ctx=ctx)\n        # Track spawned processes so we can enforce termination ordering and\n        # surface non-zero exit codes back to the caller.\n        processes: list[multiprocessing.Process] = []\n\n        exception: BaseException | None = None\n        keyboard_interrupt = False\n\n        try:\n            if self.role == \"algorithm\":\n                logger.info(\"Running algorithm solely...\")\n                asyncio.run(self._execute_algorithm(algorithm, store, stop_evt))\n            elif self.role == \"runner\":\n                if self.n_runners == 1:\n                    logger.info(\"Running runner solely...\")\n                    asyncio.run(self._execute_runner(runner, 0, store, stop_evt))\n                else:\n                    logger.info(\"Spawning runner processes...\")\n                    processes = self._spawn_runners(runner, store, stop_evt, ctx=ctx)\n                    # Wait for the processes to finish naturally.\n                    for process in processes:\n                        process.join()\n                    self._check_process_exitcodes(processes)\n            elif self.role == \"both\":\n                if self.main_process == \"algorithm\":\n                    logger.info(\"Spawning runner processes...\")\n                    processes = self._spawn_runners(runner, store, stop_evt, ctx=ctx)\n                    try:\n                        logger.info(\"Running algorithm...\")\n                        asyncio.run(self._execute_algorithm(algorithm, store, stop_evt))\n                    finally:\n                        # Always request the runner side to unwind once the\n                        # algorithm/server portion finishes (successfully or not).\n                        stop_evt.set()\n                else:  # main_process == \"runner\"\n                    if self.n_runners &gt; 1:\n                        raise ValueError(\"main_process='runner' requires n_runners to be 1\")\n\n                    logger.info(\"Spawning algorithm process...\")\n                    algorithm_process = self._spawn_algorithm_process(algorithm, store, stop_evt, ctx=ctx)\n                    processes = [algorithm_process]\n\n                    # Run the lone runner cooperatively in-process so users can\n                    # attach a debugger. The algorithm + HTTP server live in\n                    # the background process spawned above (the provided\n                    # store must therefore be picklable when using spawn).\n                    logger.info(\"Running runner...\")\n                    asyncio.run(self._execute_runner(runner, 0, store, stop_evt))\n\n                    # Wait for the algorithm process to finish.\n                    algorithm_process.join()\n            else:\n                raise ValueError(f\"Unknown role: {self.role}\")\n        except KeyboardInterrupt:\n            logger.warning(\"KeyboardInterrupt received; initiating shutdown\")\n            stop_evt.set()\n            keyboard_interrupt = True\n        except BaseException as exc:\n            logger.exception(\"Unhandled exception in execute method\")\n            stop_evt.set()\n            # Preserve the original exception so we can avoid masking it during\n            # the cleanup phase.\n            exception = exc\n            raise\n        finally:\n            logger.info(\"Shutting down subprocesses\")\n            self._shutdown_processes(processes, stop_evt)\n            if processes:\n                try:\n                    self._check_process_exitcodes(processes)\n                except RuntimeError as err:\n                    if exception is not None or keyboard_interrupt:\n                        # We already propagate/handled a different failure, so\n                        # emit a warning instead of raising a secondary error.\n                        logger.warning(\"Subprocesses ended abnormally during shutdown: %s\", err)\n                    else:\n                        raise\n</code></pre>"},{"location":"reference/trainer/#agentlightning.ClientServerExecutionStrategy.__init__","title":"<code>__init__(role=None, server_host=None, server_port=None, n_runners=1, graceful_timeout=5.0, terminate_timeout=5.0, main_process='algorithm', managed_store=None)</code>","text":"<p>Configure the strategy.</p> <p>Parameters:</p> Name Type Description Default <code>role</code> <code>Literal['algorithm', 'runner', 'both'] | None</code> <p>Which side(s) to run in this process. When omitted, the :envvar:<code>AGL_CURRENT_ROLE</code> environment variable is used.</p> <code>None</code> <code>server_host</code> <code>str | None</code> <p>Interface the HTTP server binds to when running the algorithm bundle locally. Defaults to :envvar:<code>AGL_SERVER_HOST</code> or <code>\"localhost\"</code> if unset.</p> <code>None</code> <code>server_port</code> <code>int | None</code> <p>Port for the HTTP server in \"algorithm\"/\"both\" modes. Defaults to :envvar:<code>AGL_SERVER_PORT</code> or <code>4747</code> if unset.</p> <code>None</code> <code>n_runners</code> <code>int</code> <p>Number of runner processes to spawn in \"runner\"/\"both\".</p> <code>1</code> <code>graceful_timeout</code> <code>float</code> <p>How long to wait (seconds) after setting the stop event before escalating to signals.</p> <code>5.0</code> <code>terminate_timeout</code> <code>float</code> <p>How long to wait between escalation steps beyond the cooperative phase (re-used for SIGINT, terminate, and kill).</p> <code>5.0</code> <code>main_process</code> <code>Literal['algorithm', 'runner']</code> <p>Which bundle runs on the main process when <code>role == \"both\"</code>. <code>\"runner\"</code> requires <code>n_runners == 1</code> and is primarily intended for debugging.</p> <code>'algorithm'</code> <code>managed_store</code> <code>bool | None</code> <p>When <code>True</code> (default) the strategy constructs LightningStore client/server wrappers automatically. When <code>False</code> the provided <code>store</code> is passed directly to the bundles, allowing callers to manage store wrappers manually.</p> <code>None</code> Source code in <code>agentlightning/execution/client_server.py</code> <pre><code>def __init__(\n    self,\n    role: Literal[\"algorithm\", \"runner\", \"both\"] | None = None,\n    server_host: str | None = None,\n    server_port: int | None = None,\n    n_runners: int = 1,\n    graceful_timeout: float = 5.0,\n    terminate_timeout: float = 5.0,\n    main_process: Literal[\"algorithm\", \"runner\"] = \"algorithm\",\n    managed_store: bool | None = None,\n) -&gt; None:\n    \"\"\"Configure the strategy.\n\n    Args:\n        role: Which side(s) to run in this process. When omitted, the\n            :envvar:`AGL_CURRENT_ROLE` environment variable is used.\n        server_host: Interface the HTTP server binds to when running the\n            algorithm bundle locally. Defaults to :envvar:`AGL_SERVER_HOST`\n            or ``\"localhost\"`` if unset.\n        server_port: Port for the HTTP server in \"algorithm\"/\"both\" modes.\n            Defaults to :envvar:`AGL_SERVER_PORT` or ``4747`` if unset.\n        n_runners: Number of runner processes to spawn in \"runner\"/\"both\".\n        graceful_timeout: How long to wait (seconds) after setting the stop\n            event before escalating to signals.\n        terminate_timeout: How long to wait between escalation steps beyond\n            the cooperative phase (re-used for SIGINT, terminate, and kill).\n        main_process: Which bundle runs on the main process when\n            `role == \"both\"`. `\"runner\"` requires `n_runners == 1` and is\n            primarily intended for debugging.\n        managed_store: When ``True`` (default) the strategy constructs\n            LightningStore client/server wrappers automatically. When\n            ``False`` the provided ``store`` is passed directly to the\n            bundles, allowing callers to manage store wrappers manually.\n    \"\"\"\n    if role is None:\n        role_env = os.getenv(\"AGL_CURRENT_ROLE\")\n        if role_env is None:\n            # Use both if not specified via env var or argument\n            role = \"both\"\n        elif role_env not in (\"algorithm\", \"runner\", \"both\"):\n            raise ValueError(\"role must be one of 'algorithm', 'runner', or 'both'\")\n        else:\n            role = role_env\n\n    if server_host is None:\n        server_host = os.getenv(\"AGL_SERVER_HOST\", \"localhost\")\n\n    if server_port is None:\n        server_port_env = os.getenv(\"AGL_SERVER_PORT\")\n        if server_port_env is None:\n            server_port = 4747\n        else:\n            try:\n                server_port = int(server_port_env)\n            except ValueError as exc:\n                raise ValueError(\"AGL_SERVER_PORT must be an integer\") from exc\n\n    self.role = role\n    self.n_runners = n_runners\n    self.server_host = server_host\n    self.server_port = server_port\n    self.graceful_timeout = graceful_timeout\n    self.terminate_timeout = terminate_timeout\n    if main_process not in (\"algorithm\", \"runner\"):\n        raise ValueError(\"main_process must be 'algorithm' or 'runner'\")\n    if main_process == \"runner\":\n        if role != \"both\":\n            raise ValueError(\"main_process='runner' is only supported when role='both'\")\n        if n_runners != 1:\n            raise ValueError(\"main_process='runner' requires n_runners to be 1\")\n    self.main_process = main_process\n    self.managed_store = resolve_managed_store_flag(managed_store)\n</code></pre>"},{"location":"reference/trainer/#agentlightning.SharedMemoryExecutionStrategy","title":"<code>agentlightning.SharedMemoryExecutionStrategy</code>","text":"<p>               Bases: <code>ExecutionStrategy</code></p> <p>Run algorithm and runners in a single process with threads sharing memory.</p> <p>Termination &amp; abort model:</p> <ul> <li>One shared ThreadingEvent (<code>stop_evt</code>) is passed to all bundles.</li> <li>The main thread (only) receives KeyboardInterrupt on Ctrl+C; we set <code>stop_evt</code> there.</li> <li>If any bundle raises, we set <code>stop_evt</code> from that thread to stop the rest.</li> <li>After the main-thread bundle finishes normally:</li> <li>If main_thread is \"algorithm\", we also set <code>stop_evt</code> to stop the runners.</li> <li>If main_thread is \"runner\", we do not set <code>stop_evt</code> to stop the algorithm.     We instead wait for the algorithm to finish naturally.</li> <li>Background threads are daemons; we join briefly and log any stragglers.</li> </ul> <p>Notes: Signals other than SIGINT (e.g., SIGTERM) are not intercepted; we respect Python's default behavior for them.</p> Source code in <code>agentlightning/execution/shared_memory.py</code> <pre><code>class SharedMemoryExecutionStrategy(ExecutionStrategy):\n    \"\"\"Run algorithm and runners in a single process with threads sharing memory.\n\n    Termination &amp; abort model:\n\n    - One shared ThreadingEvent (`stop_evt`) is passed to *all* bundles.\n    - The main thread (only) receives KeyboardInterrupt on Ctrl+C; we set `stop_evt` there.\n    - If any bundle raises, we set `stop_evt` from that thread to stop the rest.\n    - After the main-thread bundle finishes normally:\n      - If main_thread is \"algorithm\", we also set `stop_evt` to stop the runners.\n      - If main_thread is \"runner\", we do not set `stop_evt` to stop the algorithm.\n        We instead wait for the algorithm to finish naturally.\n    - Background threads are daemons; we join briefly and log any stragglers.\n\n    Notes: Signals other than SIGINT (e.g., SIGTERM) are not intercepted; we respect\n    Python's default behavior for them.\n    \"\"\"\n\n    alias: str = \"shm\"\n\n    def __init__(\n        self,\n        n_runners: int = 1,\n        main_thread: Literal[\"algorithm\", \"runner\"] = \"runner\",\n        join_timeout: float = 15.0,\n        graceful_delay: float = 5.0,\n        poll_interval: float = 0.05,\n        managed_store: bool | None = None,\n    ) -&gt; None:\n        if main_thread not in (\"algorithm\", \"runner\"):\n            raise ValueError(\"main_thread must be 'algorithm' or 'runner'\")\n        if main_thread == \"runner\" and n_runners != 1:\n            raise ValueError(\"When main_thread is 'runner', n_runners must be 1\")\n        self.n_runners = n_runners\n        self.main_thread = main_thread\n        self.join_timeout = join_timeout\n        self.graceful_delay = graceful_delay\n        self.poll_interval = poll_interval\n        self.managed_store = resolve_managed_store_flag(managed_store)\n\n    async def _run_until_completed_or_canceled(self, coro: Awaitable[Any], stop_evt: ExecutionEvent) -&gt; Any:\n        \"\"\"Run `coro` until it finishes or a cooperative stop is requested.\n\n        Control flow:\n          1) Start the bundle coroutine as `task`.\n          2) Start a watcher task that waits for `stop_evt` *without blocking* the loop\n             by periodically polling the threading event.\n          3) When the stop event flips:\n               a) Give the bundle *graceful_delay* seconds to finish on its own,\n                  because well-behaved bundles will check the event and return.\n               b) If still running after the grace period, cancel the bundle task.\n          4) Ensure both tasks are awaited; swallow `CancelledError` where appropriate.\n\n        This is a *backup* mechanism for bundles that might not poll the event\n        frequently; cooperative shutdown (checking `stop_evt` yourself) is still preferred.\n        \"\"\"\n        task: asyncio.Task[Any] = asyncio.create_task(coro)  # type: ignore\n        task_exception: Optional[BaseException] = None\n\n        async def watcher() -&gt; None:\n            # Poll the threading event without blocking the event loop. Using a\n            # background thread via ``asyncio.to_thread`` makes cancellation\n            # difficult because ``ThreadingEvent.wait`` is not interruptible.\n            # Instead we cooperatively check the flag from the loop so the\n            # watcher task stays cancellable and tests don't hang when the\n            # bundle finishes naturally before the stop event is set.\n            while not stop_evt.is_set():\n                await asyncio.sleep(self.poll_interval)\n\n            # Grace period: let a cooperative bundle exit on its own.\n            try:\n                # At this point of waiting, the main task should already see the stop event.\n                await asyncio.wait_for(asyncio.shield(task), timeout=self.graceful_delay)  # type: ignore\n                logger.debug(\"Bundle finished by itself during grace period.\")\n                return  # bundle finished by itself during grace period\n            except asyncio.TimeoutError:\n                # Still running after the grace window.\n                pass\n            except asyncio.CancelledError:\n                # If someone else canceled the task already, we're done.\n                logger.debug(\"Bundle already canceled by someone else; exiting watcher.\")\n                return\n\n            # Still running after the grace window: cancel it.\n            if not task.done():\n                logger.debug(\"Graceful delay elapsed; canceling bundle task...\")\n                task.cancel()\n\n        watcher_task = asyncio.create_task(watcher())\n        result: Any = None\n\n        try:\n            # We don't wait on FIRST_COMPLETED here, because we want the watcher\n            # to be able to grant a grace window after stop_evt flips.\n            await asyncio.wait(\n                {task, watcher_task}, return_when=asyncio.FIRST_COMPLETED\n            )  # pyright: ignore[reportUnknownArgumentType]\n        finally:\n            # If the main task hasn't completed yet (e.g., watcher scheduled cancel),\n            # finish the cancellation handshake.\n            if not task.done():\n                try:\n                    await asyncio.wait_for(task, timeout=self.graceful_delay)  # second chance\n                except asyncio.TimeoutError:\n                    logger.error(\n                        \"Bundle task did not stop after cancellation; abandoning task.\"\n                        \"This thread could live until the process exits.\"\n                    )\n                    # We return without awaiting it. asyncio.run will still try to cancel\n                    # pending tasks on loop close; if the task ignores cancellation, this\n                    # thread may still stick. It's the best we can do in Python.\n                    # We don't raise an exception here, but the thread could be a zombie.\n                    return result\n            else:\n                # Task completed naturally; retrieve result.\n                try:\n                    result = await task  # type: ignore\n                except asyncio.CancelledError:\n                    pass\n                except BaseException as exc:\n                    task_exception = exc\n\n            watcher_task.cancel()\n            with suppress(asyncio.CancelledError):\n                await watcher_task\n\n        if task_exception is not None:\n            raise task_exception\n\n        return result  # type: ignore\n\n    def _run_algorithm(\n        self,\n        algorithm: AlgorithmBundle,\n        store: LightningStore,\n        stop_evt: ExecutionEvent,\n        thread_exceptions: Optional[SimpleQueue[BaseException]],\n    ) -&gt; None:\n        try:\n            asyncio.run(self._run_until_completed_or_canceled(algorithm(store, stop_evt), stop_evt))\n        except asyncio.CancelledError:\n            logger.info(\"Algorithm bundle canceled due to stop signal.\")\n        except BaseException as exc:\n            logger.exception(\"Algorithm bundle crashed; signaling stop to others.\")\n            if thread_exceptions is not None:\n                thread_exceptions.put(exc)\n            stop_evt.set()\n            raise\n\n    def _run_runner(\n        self,\n        runner: RunnerBundle,\n        store: LightningStore,\n        worker_id: int,\n        stop_evt: ExecutionEvent,\n        thread_exceptions: Optional[SimpleQueue[BaseException]],\n    ) -&gt; None:\n        try:\n            asyncio.run(self._run_until_completed_or_canceled(runner(store, worker_id, stop_evt), stop_evt))\n        except asyncio.CancelledError:\n            logger.info(\"Runner bundle (worker_id=%s) canceled due to stop signal.\", worker_id)\n        except BaseException as exc:\n            logger.exception(\"Runner bundle crashed (worker_id=%s); signaling stop to others.\", worker_id)\n            if thread_exceptions is not None:\n                thread_exceptions.put(exc)\n            stop_evt.set()\n            raise\n\n    def execute(self, algorithm: AlgorithmBundle, runner: RunnerBundle, store: LightningStore) -&gt; None:\n        logger.info(\n            \"Starting shm execution with %d runner(s); main thread runs '%s'\",\n            self.n_runners,\n            self.main_thread,\n        )\n\n        # Create stop event and thread-safe store.\n        stop_evt = ThreadingEvent()\n        if self.managed_store:\n            thread_safe_store = LightningStoreThreaded(store)\n        else:\n            thread_safe_store = store\n\n        thread_exceptions: SimpleQueue[BaseException] = SimpleQueue()\n        raised_from_thread: Optional[BaseException] = None\n\n        def make_thread(name: str, target: Callable[..., Any], args: Tuple[Any, ...]) -&gt; threading.Thread:\n            t = threading.Thread(name=name, target=target, args=args, daemon=True)\n            t.start()\n            return t\n\n        threads: List[threading.Thread] = []\n\n        try:\n            if self.main_thread == \"algorithm\":\n                # Start runner threads; algorithm runs on main thread.\n                for i in range(self.n_runners):\n                    thread = make_thread(\n                        name=f\"runner-{i}\",\n                        target=self._run_runner,\n                        args=(runner, thread_safe_store, i, stop_evt, thread_exceptions),\n                    )\n                    threads.append(thread)\n\n                # Ctrl+C here raises KeyboardInterrupt on this stack.\n                # Main thread doesn't need to collect exceptions.\n                self._run_algorithm(algorithm, thread_safe_store, stop_evt, None)\n\n                # If algo finishes naturally, request runners to stop.\n                stop_evt.set()\n\n            else:  # main_thread == \"runner\"\n                # Start algorithm in background; runner runs on main thread.\n                thread = make_thread(\n                    name=\"algorithm\",\n                    target=self._run_algorithm,\n                    args=(algorithm, thread_safe_store, stop_evt, thread_exceptions),\n                )\n                threads.append(thread)\n\n                # Ctrl+C here raises KeyboardInterrupt on this stack.\n                # Main thread doesn't need to collect exceptions.\n                self._run_runner(runner, thread_safe_store, 0, stop_evt, None)\n\n                # If runner finishes naturally, WAIT FOR ALGORITHM TO FINISH.\n                thread.join()\n\n            if not thread_exceptions.empty():\n                raised_from_thread = thread_exceptions.get()\n\n        except KeyboardInterrupt:\n            logger.warning(\"KeyboardInterrupt received on main thread; initiating cooperative shutdown...\")\n            stop_evt.set()\n        finally:\n            # Attempt a clean join; if some threads don't comply, log and move on.\n            for t in threads:\n                logger.debug(\"Joining thread %s...\", t.name)\n                t.join(timeout=self.join_timeout)\n\n            alive = [t.name for t in threads if t.is_alive()]\n            if alive:\n                logger.error(\n                    \"Threads still alive after %.1fs: %s. They are daemons; continuing shutdown.\",\n                    self.join_timeout,\n                    \", \".join(alive),\n                )\n\n            if raised_from_thread is None and not thread_exceptions.empty():\n                raised_from_thread = thread_exceptions.get()\n\n        if raised_from_thread is not None:\n            raise raised_from_thread\n</code></pre>"},{"location":"reference/trainer/#events","title":"Events","text":""},{"location":"reference/trainer/#agentlightning.ExecutionEvent","title":"<code>agentlightning.ExecutionEvent</code>","text":"<p>               Bases: <code>Protocol</code></p> <p>A minimal protocol similar to threading.Event.</p> <p>Methods:</p> Name Description <code>set</code> <p>Signal event like a cancellation (idempotent).</p> <code>clear</code> <p>Reset to the non-set state.</p> <code>is_set</code> <p>True if event has been signaled.</p> <code>wait</code> <p>Optional[float] = None) -&gt; bool: Block until event is set or timeout. Returns True if event has signaled.</p> Source code in <code>agentlightning/execution/events.py</code> <pre><code>class ExecutionEvent(Protocol):\n    \"\"\"\n    A minimal protocol similar to threading.Event.\n\n    Methods:\n        set(): Signal event like a cancellation (idempotent).\n        clear(): Reset to the non-set state.\n        is_set() -&gt; bool: True if event has been signaled.\n        wait(timeout: Optional[float] = None) -&gt; bool:\n            Block until event is set or timeout. Returns True if event has signaled.\n    \"\"\"\n\n    def set(self) -&gt; None: ...\n    def clear(self) -&gt; None: ...\n    def is_set(self) -&gt; bool: ...\n    def wait(self, timeout: Optional[float] = None) -&gt; bool: ...\n</code></pre>"},{"location":"reference/trainer/#agentlightning.ThreadingEvent","title":"<code>agentlightning.ThreadingEvent</code>","text":"<p>An Event implementation using threading.Event.</p> <p>Provides a thread-safe event object for signaling between threads.</p> Source code in <code>agentlightning/execution/events.py</code> <pre><code>class ThreadingEvent:\n    \"\"\"\n    An Event implementation using threading.Event.\n\n    Provides a thread-safe event object for signaling between threads.\n    \"\"\"\n\n    __slots__ = (\"_evt\",)\n\n    def __init__(self) -&gt; None:\n        self._evt = threading.Event()\n\n    def set(self) -&gt; None:\n        self._evt.set()\n\n    def clear(self) -&gt; None:\n        self._evt.clear()\n\n    def is_set(self) -&gt; bool:\n        return self._evt.is_set()\n\n    def wait(self, timeout: Optional[float] = None) -&gt; bool:\n        return self._evt.wait(timeout)\n</code></pre>"},{"location":"reference/trainer/#agentlightning.MultiprocessingEvent","title":"<code>agentlightning.MultiprocessingEvent</code>","text":"<p>An Event implementation using multiprocessing.Event.</p> <p>Provides a process-safe event object for signaling between processes. Optionally accepts a multiprocessing context for custom process start methods.</p> Source code in <code>agentlightning/execution/events.py</code> <pre><code>class MultiprocessingEvent:\n    \"\"\"\n    An Event implementation using multiprocessing.Event.\n\n    Provides a process-safe event object for signaling between processes.\n    Optionally accepts a multiprocessing context for custom process start methods.\n    \"\"\"\n\n    __slots__ = (\"_evt\",)\n\n    def __init__(self, *, ctx: Optional[BaseContext] = None) -&gt; None:\n        self._evt = (ctx or mp).Event()\n\n    def set(self) -&gt; None:\n        self._evt.set()\n\n    def clear(self) -&gt; None:\n        self._evt.clear()\n\n    def is_set(self) -&gt; bool:\n        return self._evt.is_set()\n\n    def wait(self, timeout: Optional[float] = None) -&gt; bool:\n        return self._evt.wait(timeout)\n</code></pre>"},{"location":"reference/trainer/#cli-builder","title":"CLI Builder","text":""},{"location":"reference/trainer/#agentlightning.lightning_cli","title":"<code>agentlightning.lightning_cli(*classes)</code>","text":"<pre><code>lightning_cli(cls1: Type[_C1]) -&gt; _C1\n</code></pre><pre><code>lightning_cli(\n    cls1: Type[_C1], cls2: Type[_C2]\n) -&gt; Tuple[_C1, _C2]\n</code></pre><pre><code>lightning_cli(\n    cls1: Type[_C1], cls2: Type[_C2], cls3: Type[_C3]\n) -&gt; Tuple[_C1, _C2, _C3]\n</code></pre><pre><code>lightning_cli(\n    cls1: Type[_C1],\n    cls2: Type[_C2],\n    cls3: Type[_C3],\n    cls4: Type[_C4],\n) -&gt; Tuple[_C1, _C2, _C3, _C4]\n</code></pre><pre><code>lightning_cli(\n    *classes: Type[CliConfigurable],\n) -&gt; Tuple[CliConfigurable, ...]\n</code></pre> <p>Parses command-line arguments to configure and instantiate provided CliConfigurable classes.</p> <p>Parameters:</p> Name Type Description Default <code>*classes</code> <code>Type[CliConfigurable]</code> <p>One or more classes that inherit from CliConfigurable. Each class's       init parameters will be exposed as command-line arguments.</p> <code>()</code> <p>Returns:</p> Type Description <code>CliConfigurable | Tuple[CliConfigurable, ...]</code> <p>A tuple of instantiated objects, corresponding to the input classes in order.</p> Source code in <code>agentlightning/config.py</code> <pre><code>def lightning_cli(*classes: Type[CliConfigurable]) -&gt; CliConfigurable | Tuple[CliConfigurable, ...]:  # type: ignore\n    \"\"\"\n    Parses command-line arguments to configure and instantiate provided CliConfigurable classes.\n\n    Args:\n        *classes: One or more classes that inherit from CliConfigurable. Each class's\n                  __init__ parameters will be exposed as command-line arguments.\n\n    Returns:\n        A tuple of instantiated objects, corresponding to the input classes in order.\n    \"\"\"\n    if not classes:\n        return tuple()  # Return an empty tuple if no classes are provided\n\n    parser = _create_argument_parser()\n\n    # This map will store {cls: {init_param_name: argparse_dest_name}}\n    class_arg_configs_maps: Dict[Type[CliConfigurable], Dict[str, str]] = {}\n\n    for cls in classes:\n        _add_arguments_for_class(parser, cls, class_arg_configs_maps)\n\n    parsed_args = parser.parse_args()  # Uses sys.argv[1:] by default\n\n    # Correctly handle single class case for return type matching overloads\n    instances = _instantiate_classes(parsed_args, classes, class_arg_configs_maps)\n    if len(classes) == 1:\n        return instances[0]\n    return instances\n</code></pre>"},{"location":"reference/types/","title":"Type References","text":""},{"location":"reference/types/#core-types","title":"Core Types","text":""},{"location":"reference/types/#agentlightning.Triplet","title":"<code>agentlightning.Triplet</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>A standard structure for a single turn in a RL trajectory.</p> Source code in <code>agentlightning/types/core.py</code> <pre><code>class Triplet(BaseModel):\n    \"\"\"A standard structure for a single turn in a RL trajectory.\"\"\"\n\n    prompt: Any\n    response: Any\n    reward: Optional[float] = None\n    metadata: Dict[str, Any] = Field(default_factory=dict)\n</code></pre>"},{"location":"reference/types/#agentlightning.TaskInput","title":"<code>agentlightning.TaskInput = Any</code>  <code>module-attribute</code>","text":"<p>Task input type. Can be any type.</p>"},{"location":"reference/types/#agentlightning.RolloutRawResult","title":"<code>agentlightning.RolloutRawResult = Union[None, float, List[ReadableSpan], List[Span]]</code>  <code>module-attribute</code>","text":""},{"location":"reference/types/#agentlightning.RolloutMode","title":"<code>agentlightning.RolloutMode = Literal['train', 'val', 'test']</code>  <code>module-attribute</code>","text":""},{"location":"reference/types/#agentlightning.GenericResponse","title":"<code>agentlightning.GenericResponse</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>A generic response message that can be used for various purposes.</p> Source code in <code>agentlightning/types/core.py</code> <pre><code>class GenericResponse(BaseModel):\n    \"\"\"\n    A generic response message that can be used for various purposes.\n    \"\"\"\n\n    status: str = \"success\"\n    message: Optional[str] = None\n    data: Optional[Dict[str, Any]] = None\n</code></pre>"},{"location":"reference/types/#agentlightning.ParallelWorkerBase","title":"<code>agentlightning.ParallelWorkerBase</code>","text":"<p>Base class for objects that can be parallelized across multiple worker processes.</p> <p>This class defines the standard lifecycle for parallel processing:</p> Main Process <ol> <li>init() - Initialize the object in the main process</li> <li>spawn workers and call init_worker() in each worker</li> <li>run() - Execute the main workload in parallel across workers</li> <li>teardown_worker() - Clean up resources in each worker</li> <li>teardown() - Final cleanup in the main process</li> </ol> <p>Subclasses should implement the run() method and optionally override the lifecycle methods for custom initialization and cleanup behavior.</p> Source code in <code>agentlightning/types/core.py</code> <pre><code>class ParallelWorkerBase:\n    \"\"\"Base class for objects that can be parallelized across multiple worker processes.\n\n    This class defines the standard lifecycle for parallel processing:\n\n    Main Process:\n        1. init() - Initialize the object in the main process\n        2. spawn workers and call init_worker() in each worker\n        3. run() - Execute the main workload in parallel across workers\n        4. teardown_worker() - Clean up resources in each worker\n        5. teardown() - Final cleanup in the main process\n\n    Subclasses should implement the run() method and optionally override\n    the lifecycle methods for custom initialization and cleanup behavior.\n    \"\"\"\n\n    def __init__(self) -&gt; None:\n        \"\"\"Initialize the base class. This method can be overridden by subclasses.\"\"\"\n        self.worker_id: Optional[int] = None\n\n    def init(self, *args: Any, **kwargs: Any) -&gt; None:\n        pass\n\n    def init_worker(self, worker_id: int, *args: Any, **kwargs: Any) -&gt; None:\n        self.worker_id = worker_id\n\n    def run(self, *args: Any, **kwargs: Any) -&gt; Any:\n        pass\n\n    def teardown_worker(self, worker_id: int, *args: Any, **kwargs: Any) -&gt; None:\n        pass\n\n    def teardown(self, *args: Any, **kwargs: Any) -&gt; None:\n        pass\n</code></pre>"},{"location":"reference/types/#agentlightning.ParallelWorkerBase.__init__","title":"<code>__init__()</code>","text":"<p>Initialize the base class. This method can be overridden by subclasses.</p> Source code in <code>agentlightning/types/core.py</code> <pre><code>def __init__(self) -&gt; None:\n    \"\"\"Initialize the base class. This method can be overridden by subclasses.\"\"\"\n    self.worker_id: Optional[int] = None\n</code></pre>"},{"location":"reference/types/#agentlightning.Dataset","title":"<code>agentlightning.Dataset</code>","text":"<p>               Bases: <code>Protocol</code>, <code>Generic[T_co]</code></p> <p>The general interface for a dataset.</p> <p>It's currently implemented as a protocol, having a similar interface to torch.utils.data.Dataset. You don't have to inherit from this class; you can use a simple list if you want to.</p> Source code in <code>agentlightning/types/core.py</code> <pre><code>class Dataset(Protocol, Generic[T_co]):\n    \"\"\"The general interface for a dataset.\n\n    It's currently implemented as a protocol, having a similar interface to torch.utils.data.Dataset.\n    You don't have to inherit from this class; you can use a simple list if you want to.\n    \"\"\"\n\n    def __getitem__(self, index: SupportsIndex, /) -&gt; T_co: ...\n\n    def __len__(self) -&gt; int: ...\n</code></pre>"},{"location":"reference/types/#agentlightning.AttemptStatus","title":"<code>agentlightning.AttemptStatus = Literal['preparing', 'running', 'failed', 'succeeded', 'unresponsive', 'timeout']</code>  <code>module-attribute</code>","text":""},{"location":"reference/types/#agentlightning.RolloutStatus","title":"<code>agentlightning.RolloutStatus = Literal['queuing', 'preparing', 'running', 'failed', 'succeeded', 'cancelled', 'requeuing']</code>  <code>module-attribute</code>","text":""},{"location":"reference/types/#agentlightning.RolloutConfig","title":"<code>agentlightning.RolloutConfig</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Configurations for rollout execution.</p> Source code in <code>agentlightning/types/core.py</code> <pre><code>class RolloutConfig(BaseModel):\n    \"\"\"Configurations for rollout execution.\"\"\"\n\n    timeout_seconds: Optional[float] = None\n    \"\"\"The timeout for the rollout, in seconds. None indicates no timeout.\"\"\"\n    unresponsive_seconds: Optional[float] = None\n    \"\"\"The unresponsive timeout for the rollout, in seconds. None indicates no unresponsive timeout.\"\"\"\n    max_attempts: int = Field(default=1, ge=1)\n    \"\"\"The maximum number of attempts for the rollout, including the first attempt.\"\"\"\n    retry_condition: List[AttemptStatus] = Field(default_factory=cast(Callable[[], List[AttemptStatus]], list))\n    \"\"\"The list of statuses that should trigger a retry.\"\"\"\n</code></pre>"},{"location":"reference/types/#agentlightning.RolloutConfig.max_attempts","title":"<code>max_attempts = Field(default=1, ge=1)</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The maximum number of attempts for the rollout, including the first attempt.</p>"},{"location":"reference/types/#agentlightning.RolloutConfig.retry_condition","title":"<code>retry_condition = Field(default_factory=(cast(Callable[[], List[AttemptStatus]], list)))</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The list of statuses that should trigger a retry.</p>"},{"location":"reference/types/#agentlightning.RolloutConfig.timeout_seconds","title":"<code>timeout_seconds = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The timeout for the rollout, in seconds. None indicates no timeout.</p>"},{"location":"reference/types/#agentlightning.RolloutConfig.unresponsive_seconds","title":"<code>unresponsive_seconds = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The unresponsive timeout for the rollout, in seconds. None indicates no unresponsive timeout.</p>"},{"location":"reference/types/#agentlightning.Rollout","title":"<code>agentlightning.Rollout</code>","text":"<p>               Bases: <code>BaseModel</code></p> Source code in <code>agentlightning/types/core.py</code> <pre><code>class Rollout(BaseModel):\n    rollout_id: str\n    \"\"\"The universal id for the rollout.\"\"\"\n\n    input: TaskInput\n    \"\"\"The input of the rollout, also known as a task.\"\"\"\n\n    # Time to track the lifecycle of the rollout\n    start_time: float\n    \"\"\"The time when the rollout has started.\"\"\"\n    end_time: Optional[float] = None\n    \"\"\"The time when the rollout has ended.\"\"\"\n\n    mode: Optional[RolloutMode] = None\n    \"\"\"The mode of the rollout (e.g., train, val, test).\"\"\"\n    resources_id: Optional[str] = None\n    \"\"\"The id of the resources used by the rollout.\"\"\"\n\n    status: RolloutStatus = \"queuing\"\n    \"\"\"The status of the rollout.\"\"\"\n\n    config: RolloutConfig = Field(default_factory=RolloutConfig)\n    \"\"\"The configuration of the rollout, e.g., retry policy.\"\"\"\n\n    metadata: Optional[Dict[str, Any]] = None\n    \"\"\"A bucket for any other relevant information.\"\"\"\n</code></pre>"},{"location":"reference/types/#agentlightning.Rollout.config","title":"<code>config = Field(default_factory=RolloutConfig)</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The configuration of the rollout, e.g., retry policy.</p>"},{"location":"reference/types/#agentlightning.Rollout.end_time","title":"<code>end_time = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The time when the rollout has ended.</p>"},{"location":"reference/types/#agentlightning.Rollout.input","title":"<code>input</code>  <code>instance-attribute</code>","text":"<p>The input of the rollout, also known as a task.</p>"},{"location":"reference/types/#agentlightning.Rollout.metadata","title":"<code>metadata = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>A bucket for any other relevant information.</p>"},{"location":"reference/types/#agentlightning.Rollout.mode","title":"<code>mode = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The mode of the rollout (e.g., train, val, test).</p>"},{"location":"reference/types/#agentlightning.Rollout.resources_id","title":"<code>resources_id = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The id of the resources used by the rollout.</p>"},{"location":"reference/types/#agentlightning.Rollout.rollout_id","title":"<code>rollout_id</code>  <code>instance-attribute</code>","text":"<p>The universal id for the rollout.</p>"},{"location":"reference/types/#agentlightning.Rollout.start_time","title":"<code>start_time</code>  <code>instance-attribute</code>","text":"<p>The time when the rollout has started.</p>"},{"location":"reference/types/#agentlightning.Rollout.status","title":"<code>status = 'queuing'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The status of the rollout.</p>"},{"location":"reference/types/#agentlightning.Attempt","title":"<code>agentlightning.Attempt</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>An attempt to execute a rollout. A rollout can have multiple attempts if retries are needed.</p> Source code in <code>agentlightning/types/core.py</code> <pre><code>class Attempt(BaseModel):\n    \"\"\"An attempt to execute a rollout. A rollout can have multiple attempts if retries are needed.\"\"\"\n\n    rollout_id: str\n    \"\"\"The rollout which this attempt belongs to.\"\"\"\n    attempt_id: str\n    \"\"\"The universal id for current attempt.\"\"\"\n    sequence_id: int\n    \"\"\"The sequence number of the attempt, starting from 1.\"\"\"\n    start_time: float\n    \"\"\"The time when the attempt has started.\"\"\"\n    end_time: Optional[float] = None\n    \"\"\"The time when the attempt has ended.\"\"\"\n    status: AttemptStatus = \"preparing\"\n    \"\"\"The status of the attempt.\"\"\"\n    worker_id: Optional[str] = None\n    \"\"\"The rollout worker which is executing this attempt.\"\"\"\n\n    last_heartbeat_time: Optional[float] = None\n    \"\"\"The last time when the worker has reported progress (i.e., a span).\"\"\"\n\n    metadata: Optional[Dict[str, Any]] = None\n    \"\"\"A bucket for any other relevant information.\"\"\"\n</code></pre>"},{"location":"reference/types/#agentlightning.Attempt.attempt_id","title":"<code>attempt_id</code>  <code>instance-attribute</code>","text":"<p>The universal id for current attempt.</p>"},{"location":"reference/types/#agentlightning.Attempt.end_time","title":"<code>end_time = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The time when the attempt has ended.</p>"},{"location":"reference/types/#agentlightning.Attempt.last_heartbeat_time","title":"<code>last_heartbeat_time = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The last time when the worker has reported progress (i.e., a span).</p>"},{"location":"reference/types/#agentlightning.Attempt.metadata","title":"<code>metadata = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>A bucket for any other relevant information.</p>"},{"location":"reference/types/#agentlightning.Attempt.rollout_id","title":"<code>rollout_id</code>  <code>instance-attribute</code>","text":"<p>The rollout which this attempt belongs to.</p>"},{"location":"reference/types/#agentlightning.Attempt.sequence_id","title":"<code>sequence_id</code>  <code>instance-attribute</code>","text":"<p>The sequence number of the attempt, starting from 1.</p>"},{"location":"reference/types/#agentlightning.Attempt.start_time","title":"<code>start_time</code>  <code>instance-attribute</code>","text":"<p>The time when the attempt has started.</p>"},{"location":"reference/types/#agentlightning.Attempt.status","title":"<code>status = 'preparing'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The status of the attempt.</p>"},{"location":"reference/types/#agentlightning.Attempt.worker_id","title":"<code>worker_id = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The rollout worker which is executing this attempt.</p>"},{"location":"reference/types/#agentlightning.AttemptedRollout","title":"<code>agentlightning.AttemptedRollout</code>","text":"<p>               Bases: <code>Rollout</code></p> <p>A rollout along with its active attempt.</p> Source code in <code>agentlightning/types/core.py</code> <pre><code>class AttemptedRollout(Rollout):\n    \"\"\"A rollout along with its active attempt.\"\"\"\n\n    attempt: Attempt\n\n    @model_validator(mode=\"after\")\n    def check_consistency(self) -&gt; AttemptedRollout:\n        if self.attempt.rollout_id != self.rollout_id:\n            raise ValueError(\"Inconsistent rollout_id between Rollout and Attempt\")\n        return self\n</code></pre>"},{"location":"reference/types/#agentlightning.Hook","title":"<code>agentlightning.Hook</code>","text":"<p>               Bases: <code>ParallelWorkerBase</code></p> <p>Base class for defining hooks in the agent runner's lifecycle.</p> Source code in <code>agentlightning/types/core.py</code> <pre><code>class Hook(ParallelWorkerBase):\n    \"\"\"Base class for defining hooks in the agent runner's lifecycle.\"\"\"\n\n    async def on_trace_start(\n        self, *, agent: LitAgent[Any], runner: Runner[Any], tracer: Tracer, rollout: Rollout\n    ) -&gt; None:\n        \"\"\"Hook called immediately after the tracer enters the trace context but before the rollout begins.\n\n        Args:\n            agent: The :class:`LitAgent` instance associated with the runner.\n            runner: The :class:`Runner` managing the rollout.\n            tracer: The :class:`Tracer` instance associated with the runner.\n            rollout: The :class:`Rollout` object that will be processed.\n\n        Subclasses can override this method to implement custom logic such as logging,\n        metric collection, or resource setup. By default, this is a no-op.\n        \"\"\"\n\n    async def on_trace_end(\n        self, *, agent: LitAgent[Any], runner: Runner[Any], tracer: Tracer, rollout: Rollout\n    ) -&gt; None:\n        \"\"\"Hook called immediately after the rollout completes but before the tracer exits the trace context.\n\n        Args:\n            agent: The :class:`LitAgent` instance associated with the runner.\n            runner: The :class:`Runner` managing the rollout.\n            tracer: The :class:`Tracer` instance associated with the runner.\n            rollout: The :class:`Rollout` object that has been processed.\n\n        Subclasses can override this method to implement custom logic such as logging,\n        metric collection, or resource cleanup. By default, this is a no-op.\n        \"\"\"\n\n    async def on_rollout_start(self, *, agent: LitAgent[Any], runner: Runner[Any], rollout: Rollout) -&gt; None:\n        \"\"\"Hook called immediately before a rollout *attempt* begins.\n\n        Args:\n            agent: The :class:`LitAgent` instance associated with the runner.\n            runner: The :class:`Runner` managing the rollout.\n            rollout: The :class:`Rollout` object that will be processed.\n\n        Subclasses can override this method to implement custom logic such as\n        logging, metric collection, or resource setup. By default, this is a\n        no-op.\n        \"\"\"\n\n    async def on_rollout_end(\n        self,\n        *,\n        agent: LitAgent[Any],\n        runner: Runner[Any],\n        rollout: Rollout,\n        spans: Union[List[ReadableSpan], List[Span]],\n    ) -&gt; None:\n        \"\"\"Hook called after a rollout *attempt* completes.\n\n        Args:\n            agent: The :class:`LitAgent` instance associated with the runner.\n            runner: The :class:`Runner` managing the rollout.\n            rollout: The :class:`Rollout` object that has been processed.\n            spans: The spans that have been added to the store.\n\n        Subclasses can override this method for cleanup or additional\n        logging. By default, this is a no-op.\n        \"\"\"\n</code></pre>"},{"location":"reference/types/#agentlightning.Hook.on_rollout_end","title":"<code>on_rollout_end(*, agent, runner, rollout, spans)</code>  <code>async</code>","text":"<p>Hook called after a rollout attempt completes.</p> <p>Parameters:</p> Name Type Description Default <code>agent</code> <code>LitAgent[Any]</code> <p>The :class:<code>LitAgent</code> instance associated with the runner.</p> required <code>runner</code> <code>Runner[Any]</code> <p>The :class:<code>Runner</code> managing the rollout.</p> required <code>rollout</code> <code>Rollout</code> <p>The :class:<code>Rollout</code> object that has been processed.</p> required <code>spans</code> <code>Union[List[ReadableSpan], List[Span]]</code> <p>The spans that have been added to the store.</p> required <p>Subclasses can override this method for cleanup or additional logging. By default, this is a no-op.</p> Source code in <code>agentlightning/types/core.py</code> <pre><code>async def on_rollout_end(\n    self,\n    *,\n    agent: LitAgent[Any],\n    runner: Runner[Any],\n    rollout: Rollout,\n    spans: Union[List[ReadableSpan], List[Span]],\n) -&gt; None:\n    \"\"\"Hook called after a rollout *attempt* completes.\n\n    Args:\n        agent: The :class:`LitAgent` instance associated with the runner.\n        runner: The :class:`Runner` managing the rollout.\n        rollout: The :class:`Rollout` object that has been processed.\n        spans: The spans that have been added to the store.\n\n    Subclasses can override this method for cleanup or additional\n    logging. By default, this is a no-op.\n    \"\"\"\n</code></pre>"},{"location":"reference/types/#agentlightning.Hook.on_rollout_start","title":"<code>on_rollout_start(*, agent, runner, rollout)</code>  <code>async</code>","text":"<p>Hook called immediately before a rollout attempt begins.</p> <p>Parameters:</p> Name Type Description Default <code>agent</code> <code>LitAgent[Any]</code> <p>The :class:<code>LitAgent</code> instance associated with the runner.</p> required <code>runner</code> <code>Runner[Any]</code> <p>The :class:<code>Runner</code> managing the rollout.</p> required <code>rollout</code> <code>Rollout</code> <p>The :class:<code>Rollout</code> object that will be processed.</p> required <p>Subclasses can override this method to implement custom logic such as logging, metric collection, or resource setup. By default, this is a no-op.</p> Source code in <code>agentlightning/types/core.py</code> <pre><code>async def on_rollout_start(self, *, agent: LitAgent[Any], runner: Runner[Any], rollout: Rollout) -&gt; None:\n    \"\"\"Hook called immediately before a rollout *attempt* begins.\n\n    Args:\n        agent: The :class:`LitAgent` instance associated with the runner.\n        runner: The :class:`Runner` managing the rollout.\n        rollout: The :class:`Rollout` object that will be processed.\n\n    Subclasses can override this method to implement custom logic such as\n    logging, metric collection, or resource setup. By default, this is a\n    no-op.\n    \"\"\"\n</code></pre>"},{"location":"reference/types/#agentlightning.Hook.on_trace_end","title":"<code>on_trace_end(*, agent, runner, tracer, rollout)</code>  <code>async</code>","text":"<p>Hook called immediately after the rollout completes but before the tracer exits the trace context.</p> <p>Parameters:</p> Name Type Description Default <code>agent</code> <code>LitAgent[Any]</code> <p>The :class:<code>LitAgent</code> instance associated with the runner.</p> required <code>runner</code> <code>Runner[Any]</code> <p>The :class:<code>Runner</code> managing the rollout.</p> required <code>tracer</code> <code>Tracer</code> <p>The :class:<code>Tracer</code> instance associated with the runner.</p> required <code>rollout</code> <code>Rollout</code> <p>The :class:<code>Rollout</code> object that has been processed.</p> required <p>Subclasses can override this method to implement custom logic such as logging, metric collection, or resource cleanup. By default, this is a no-op.</p> Source code in <code>agentlightning/types/core.py</code> <pre><code>async def on_trace_end(\n    self, *, agent: LitAgent[Any], runner: Runner[Any], tracer: Tracer, rollout: Rollout\n) -&gt; None:\n    \"\"\"Hook called immediately after the rollout completes but before the tracer exits the trace context.\n\n    Args:\n        agent: The :class:`LitAgent` instance associated with the runner.\n        runner: The :class:`Runner` managing the rollout.\n        tracer: The :class:`Tracer` instance associated with the runner.\n        rollout: The :class:`Rollout` object that has been processed.\n\n    Subclasses can override this method to implement custom logic such as logging,\n    metric collection, or resource cleanup. By default, this is a no-op.\n    \"\"\"\n</code></pre>"},{"location":"reference/types/#agentlightning.Hook.on_trace_start","title":"<code>on_trace_start(*, agent, runner, tracer, rollout)</code>  <code>async</code>","text":"<p>Hook called immediately after the tracer enters the trace context but before the rollout begins.</p> <p>Parameters:</p> Name Type Description Default <code>agent</code> <code>LitAgent[Any]</code> <p>The :class:<code>LitAgent</code> instance associated with the runner.</p> required <code>runner</code> <code>Runner[Any]</code> <p>The :class:<code>Runner</code> managing the rollout.</p> required <code>tracer</code> <code>Tracer</code> <p>The :class:<code>Tracer</code> instance associated with the runner.</p> required <code>rollout</code> <code>Rollout</code> <p>The :class:<code>Rollout</code> object that will be processed.</p> required <p>Subclasses can override this method to implement custom logic such as logging, metric collection, or resource setup. By default, this is a no-op.</p> Source code in <code>agentlightning/types/core.py</code> <pre><code>async def on_trace_start(\n    self, *, agent: LitAgent[Any], runner: Runner[Any], tracer: Tracer, rollout: Rollout\n) -&gt; None:\n    \"\"\"Hook called immediately after the tracer enters the trace context but before the rollout begins.\n\n    Args:\n        agent: The :class:`LitAgent` instance associated with the runner.\n        runner: The :class:`Runner` managing the rollout.\n        tracer: The :class:`Tracer` instance associated with the runner.\n        rollout: The :class:`Rollout` object that will be processed.\n\n    Subclasses can override this method to implement custom logic such as logging,\n    metric collection, or resource setup. By default, this is a no-op.\n    \"\"\"\n</code></pre>"},{"location":"reference/types/#resources","title":"Resources","text":""},{"location":"reference/types/#agentlightning.Resource","title":"<code>agentlightning.Resource</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Corresponding to opentelemetry.sdk.resources.Resource</p> Source code in <code>agentlightning/types/tracer.py</code> <pre><code>class Resource(BaseModel):\n    \"\"\"Corresponding to opentelemetry.sdk.resources.Resource\"\"\"\n\n    attributes: Attributes\n    schema_url: str\n\n    @classmethod\n    def from_opentelemetry(cls, src: OtelResource) -&gt; \"Resource\":\n        return cls(\n            attributes=dict(src.attributes) if src.attributes else {},\n            schema_url=src.schema_url if src.schema_url else \"\",\n            **extract_extra_fields(src, [\"attributes\", \"schema_url\"]),\n        )\n</code></pre>"},{"location":"reference/types/#agentlightning.LLM","title":"<code>agentlightning.LLM</code>","text":"<p>               Bases: <code>Resource</code></p> <p>Provide an LLM endpoint and model name as a resource.</p> <p>Attributes:</p> Name Type Description <code>endpoint</code> <code>str</code> <p>The URL of the LLM API endpoint.</p> <code>model</code> <code>str</code> <p>The identifier for the model to be used (e.g., 'gpt-4o').</p> <code>sampling_parameters</code> <code>SamplingParameters</code> <p>A dictionary of hyperparameters for model inference, such as temperature, top_p, etc.</p> Source code in <code>agentlightning/types/resources.py</code> <pre><code>class LLM(Resource):\n    \"\"\"\n    Provide an LLM endpoint and model name as a resource.\n\n    Attributes:\n        endpoint (str): The URL of the LLM API endpoint.\n        model (str): The identifier for the model to be used (e.g., 'gpt-4o').\n        sampling_parameters (SamplingParameters): A dictionary of hyperparameters\n            for model inference, such as temperature, top_p, etc.\n    \"\"\"\n\n    resource_type: Literal[\"llm\"] = \"llm\"\n    endpoint: str\n    \"\"\"The URL of the LLM API endpoint.\"\"\"\n    model: str\n    \"\"\"The identifier for the model to be used (e.g., 'gpt-4o').\"\"\"\n    api_key: Optional[str] = None\n    \"\"\"The API key for the LLM API.\"\"\"\n    sampling_parameters: Dict[str, Any] = Field(default_factory=dict)\n    \"\"\"A dictionary of hyperparameters for model inference, such as temperature, top_p, etc.\"\"\"\n\n    def get_base_url(self, *args: Any, **kwargs: Any) -&gt; str:\n        \"\"\"The base_url to put into openai.OpenAI.\n\n        Users are encouraged to use `base_url` to get the LLM endpoint instead of accessing `endpoint` directly.\n        \"\"\"\n        return self.endpoint\n</code></pre>"},{"location":"reference/types/#agentlightning.LLM.api_key","title":"<code>api_key = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The API key for the LLM API.</p>"},{"location":"reference/types/#agentlightning.LLM.endpoint","title":"<code>endpoint</code>  <code>instance-attribute</code>","text":"<p>The URL of the LLM API endpoint.</p>"},{"location":"reference/types/#agentlightning.LLM.model","title":"<code>model</code>  <code>instance-attribute</code>","text":"<p>The identifier for the model to be used (e.g., 'gpt-4o').</p>"},{"location":"reference/types/#agentlightning.LLM.sampling_parameters","title":"<code>sampling_parameters = Field(default_factory=dict)</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>A dictionary of hyperparameters for model inference, such as temperature, top_p, etc.</p>"},{"location":"reference/types/#agentlightning.LLM.get_base_url","title":"<code>get_base_url(*args, **kwargs)</code>","text":"<p>The base_url to put into openai.OpenAI.</p> <p>Users are encouraged to use <code>base_url</code> to get the LLM endpoint instead of accessing <code>endpoint</code> directly.</p> Source code in <code>agentlightning/types/resources.py</code> <pre><code>def get_base_url(self, *args: Any, **kwargs: Any) -&gt; str:\n    \"\"\"The base_url to put into openai.OpenAI.\n\n    Users are encouraged to use `base_url` to get the LLM endpoint instead of accessing `endpoint` directly.\n    \"\"\"\n    return self.endpoint\n</code></pre>"},{"location":"reference/types/#agentlightning.ProxyLLM","title":"<code>agentlightning.ProxyLLM</code>","text":"<p>               Bases: <code>LLM</code></p> <p>Proxy LLM resource that is tailored by <code>llm_proxy.LLMProxy</code>.</p> Source code in <code>agentlightning/types/resources.py</code> <pre><code>class ProxyLLM(LLM):\n    \"\"\"Proxy LLM resource that is tailored by `llm_proxy.LLMProxy`.\"\"\"\n\n    resource_type: Literal[\"proxy_llm\"] = \"proxy_llm\"  # type: ignore\n    _initialized: bool = False\n\n    def model_post_init(self, __context: Any) -&gt; None:\n        \"\"\"Mark initialization as complete after Pydantic finishes setup.\"\"\"\n        super().model_post_init(__context)\n        object.__setattr__(self, \"_initialized\", True)\n\n    def __getattribute__(self, name: str) -&gt; Any:\n        \"\"\"Override to emit a warning when endpoint is accessed directly.\"\"\"\n        # Check if we're accessing endpoint after initialization and not from base_url\n        if name == \"endpoint\":\n            try:\n                initialized = object.__getattribute__(self, \"_initialized\")\n            except AttributeError:\n                initialized = False\n\n            if initialized:\n                # Check the call stack to see if we're being called from base_url\n                frame = inspect.currentframe()\n                if frame and frame.f_back:\n                    caller_name = frame.f_back.f_code.co_name\n                    if caller_name != \"get_base_url\":\n                        logger.warning(\n                            \"Accessing 'endpoint' directly on ProxyLLM is discouraged. \"\n                            \"Use 'get_base_url(rollout_id, attempt_id)' instead to get the properly formatted endpoint.\"\n                        )\n        return super().__getattribute__(name)\n\n    def with_attempted_rollout(self, rollout: AttemptedRollout) -&gt; LLM:\n        \"\"\"Bake the rollout and attempt id into the endpoint.\"\"\"\n        return LLM(\n            endpoint=self.get_base_url(rollout.rollout_id, rollout.attempt.attempt_id),\n            model=self.model,\n            sampling_parameters=self.sampling_parameters,\n            api_key=self.api_key,\n        )\n\n    def get_base_url(self, rollout_id: Optional[str], attempt_id: Optional[str]) -&gt; str:\n        \"\"\"Get the base URL for the LLM endpoint.\n        Embed the rollout and attempt id into the endpoint.\n\n        Args:\n            rollout_id: The rollout ID.\n            attempt_id: The attempt ID.\n\n        Returns:\n            The base URL for the LLM endpoint.\n        \"\"\"\n        if rollout_id is None and attempt_id is None:\n            return self.endpoint\n\n        if not (isinstance(rollout_id, str) and isinstance(attempt_id, str)):\n            raise ValueError(\"rollout_id and attempt_id must be strings or all be empty\")\n\n        prefix = self.endpoint\n        if prefix.endswith(\"/\"):\n            prefix = prefix[:-1]\n        if prefix.endswith(\"/v1\"):\n            prefix = prefix[:-3]\n            has_v1 = True\n        else:\n            has_v1 = False\n        # Now the prefix should look like \"http://localhost:11434\"\n\n        # Append the rollout and attempt id to the prefix\n        prefix = prefix + f\"/rollout/{rollout_id}/attempt/{attempt_id}\"\n        if has_v1:\n            prefix = prefix + \"/v1\"\n        return prefix\n</code></pre>"},{"location":"reference/types/#agentlightning.ProxyLLM.__getattribute__","title":"<code>__getattribute__(name)</code>","text":"<p>Override to emit a warning when endpoint is accessed directly.</p> Source code in <code>agentlightning/types/resources.py</code> <pre><code>def __getattribute__(self, name: str) -&gt; Any:\n    \"\"\"Override to emit a warning when endpoint is accessed directly.\"\"\"\n    # Check if we're accessing endpoint after initialization and not from base_url\n    if name == \"endpoint\":\n        try:\n            initialized = object.__getattribute__(self, \"_initialized\")\n        except AttributeError:\n            initialized = False\n\n        if initialized:\n            # Check the call stack to see if we're being called from base_url\n            frame = inspect.currentframe()\n            if frame and frame.f_back:\n                caller_name = frame.f_back.f_code.co_name\n                if caller_name != \"get_base_url\":\n                    logger.warning(\n                        \"Accessing 'endpoint' directly on ProxyLLM is discouraged. \"\n                        \"Use 'get_base_url(rollout_id, attempt_id)' instead to get the properly formatted endpoint.\"\n                    )\n    return super().__getattribute__(name)\n</code></pre>"},{"location":"reference/types/#agentlightning.ProxyLLM.get_base_url","title":"<code>get_base_url(rollout_id, attempt_id)</code>","text":"<p>Get the base URL for the LLM endpoint. Embed the rollout and attempt id into the endpoint.</p> <p>Parameters:</p> Name Type Description Default <code>rollout_id</code> <code>Optional[str]</code> <p>The rollout ID.</p> required <code>attempt_id</code> <code>Optional[str]</code> <p>The attempt ID.</p> required <p>Returns:</p> Type Description <code>str</code> <p>The base URL for the LLM endpoint.</p> Source code in <code>agentlightning/types/resources.py</code> <pre><code>def get_base_url(self, rollout_id: Optional[str], attempt_id: Optional[str]) -&gt; str:\n    \"\"\"Get the base URL for the LLM endpoint.\n    Embed the rollout and attempt id into the endpoint.\n\n    Args:\n        rollout_id: The rollout ID.\n        attempt_id: The attempt ID.\n\n    Returns:\n        The base URL for the LLM endpoint.\n    \"\"\"\n    if rollout_id is None and attempt_id is None:\n        return self.endpoint\n\n    if not (isinstance(rollout_id, str) and isinstance(attempt_id, str)):\n        raise ValueError(\"rollout_id and attempt_id must be strings or all be empty\")\n\n    prefix = self.endpoint\n    if prefix.endswith(\"/\"):\n        prefix = prefix[:-1]\n    if prefix.endswith(\"/v1\"):\n        prefix = prefix[:-3]\n        has_v1 = True\n    else:\n        has_v1 = False\n    # Now the prefix should look like \"http://localhost:11434\"\n\n    # Append the rollout and attempt id to the prefix\n    prefix = prefix + f\"/rollout/{rollout_id}/attempt/{attempt_id}\"\n    if has_v1:\n        prefix = prefix + \"/v1\"\n    return prefix\n</code></pre>"},{"location":"reference/types/#agentlightning.ProxyLLM.model_post_init","title":"<code>model_post_init(__context)</code>","text":"<p>Mark initialization as complete after Pydantic finishes setup.</p> Source code in <code>agentlightning/types/resources.py</code> <pre><code>def model_post_init(self, __context: Any) -&gt; None:\n    \"\"\"Mark initialization as complete after Pydantic finishes setup.\"\"\"\n    super().model_post_init(__context)\n    object.__setattr__(self, \"_initialized\", True)\n</code></pre>"},{"location":"reference/types/#agentlightning.ProxyLLM.with_attempted_rollout","title":"<code>with_attempted_rollout(rollout)</code>","text":"<p>Bake the rollout and attempt id into the endpoint.</p> Source code in <code>agentlightning/types/resources.py</code> <pre><code>def with_attempted_rollout(self, rollout: AttemptedRollout) -&gt; LLM:\n    \"\"\"Bake the rollout and attempt id into the endpoint.\"\"\"\n    return LLM(\n        endpoint=self.get_base_url(rollout.rollout_id, rollout.attempt.attempt_id),\n        model=self.model,\n        sampling_parameters=self.sampling_parameters,\n        api_key=self.api_key,\n    )\n</code></pre>"},{"location":"reference/types/#agentlightning.PromptTemplate","title":"<code>agentlightning.PromptTemplate</code>","text":"<p>               Bases: <code>Resource</code></p> <p>A prompt template as a resource.</p> <p>Attributes:</p> Name Type Description <code>template</code> <code>str</code> <p>The template string. The format depends on the engine.</p> <code>engine</code> <code>Literal['jinja', 'f-string', 'poml']</code> <p>The templating engine to use for rendering the prompt. I imagine users can use their own customized engines, but algos can only well operate on a subset of them.</p> Source code in <code>agentlightning/types/resources.py</code> <pre><code>class PromptTemplate(Resource):\n    \"\"\"\n    A prompt template as a resource.\n\n    Attributes:\n        template (str): The template string. The format depends on the engine.\n        engine (Literal['jinja', 'f-string', 'poml']): The templating engine\n            to use for rendering the prompt. I imagine users can use their own\n            customized engines, but algos can only well operate on a subset of them.\n    \"\"\"\n\n    resource_type: Literal[\"prompt_template\"] = \"prompt_template\"\n    template: str\n    engine: Literal[\"jinja\", \"f-string\", \"poml\"]\n\n    def format(self, **kwargs: Any) -&gt; str:\n        \"\"\"Format the prompt template with the given kwargs.\"\"\"\n        if self.engine == \"f-string\":\n            return self.template.format(**kwargs)\n        else:\n            raise NotImplementedError(\n                \"Formatting prompt templates for non-f-string engines with format() helper is not supported yet.\"\n            )\n</code></pre>"},{"location":"reference/types/#agentlightning.PromptTemplate.format","title":"<code>format(**kwargs)</code>","text":"<p>Format the prompt template with the given kwargs.</p> Source code in <code>agentlightning/types/resources.py</code> <pre><code>def format(self, **kwargs: Any) -&gt; str:\n    \"\"\"Format the prompt template with the given kwargs.\"\"\"\n    if self.engine == \"f-string\":\n        return self.template.format(**kwargs)\n    else:\n        raise NotImplementedError(\n            \"Formatting prompt templates for non-f-string engines with format() helper is not supported yet.\"\n        )\n</code></pre>"},{"location":"reference/types/#agentlightning.ResourceUnion","title":"<code>agentlightning.ResourceUnion = Annotated[Union[LLM, ProxyLLM, PromptTemplate], Field(discriminator='resource_type')]</code>  <code>module-attribute</code>","text":""},{"location":"reference/types/#agentlightning.NamedResources","title":"<code>agentlightning.NamedResources = Dict[str, ResourceUnion]</code>  <code>module-attribute</code>","text":"<p>A dictionary-like class to hold named resources.</p> Example <p>resources: NamedResources = {     'main_llm': LLM(         endpoint=\"http://localhost:8080\",         model=\"llama3\",         sampling_parameters={'temperature': 0.7, 'max_tokens': 100}     ),     'system_prompt': PromptTemplate(         template=\"You are a helpful assistant.\",         engine='f-string'     ) }</p>"},{"location":"reference/types/#agentlightning.ResourcesUpdate","title":"<code>agentlightning.ResourcesUpdate</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>A resource update message to be sent from the server to clients.</p> <p>This message contains a dictionary of resources that clients should use for subsequent tasks. It is used to update the resources available to clients dynamically.</p> Source code in <code>agentlightning/types/resources.py</code> <pre><code>class ResourcesUpdate(BaseModel):\n    \"\"\"\n    A resource update message to be sent from the server to clients.\n\n    This message contains a dictionary of resources that clients should use\n    for subsequent tasks. It is used to update the resources available to\n    clients dynamically.\n    \"\"\"\n\n    resources_id: str\n    resources: NamedResources\n</code></pre>"},{"location":"reference/types/#traces","title":"Traces","text":""},{"location":"reference/types/#agentlightning.AttributeValue","title":"<code>agentlightning.AttributeValue = Union[str, bool, int, float, Sequence[str], Sequence[bool], Sequence[int], Sequence[float]]</code>  <code>module-attribute</code>","text":""},{"location":"reference/types/#agentlightning.Attributes","title":"<code>agentlightning.Attributes = Dict[str, AttributeValue]</code>  <code>module-attribute</code>","text":""},{"location":"reference/types/#agentlightning.TraceState","title":"<code>agentlightning.TraceState = Dict[str, str]</code>  <code>module-attribute</code>","text":""},{"location":"reference/types/#agentlightning.SpanContext","title":"<code>agentlightning.SpanContext</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Corresponding to opentelemetry.trace.SpanContext</p> Source code in <code>agentlightning/types/tracer.py</code> <pre><code>class SpanContext(BaseModel):\n    \"\"\"Corresponding to opentelemetry.trace.SpanContext\"\"\"\n\n    trace_id: str\n    span_id: str\n    is_remote: bool\n    trace_state: TraceState\n\n    class Config:\n        allow_extra = True\n\n    @classmethod\n    def from_opentelemetry(cls, src: trace_api.SpanContext) -&gt; \"SpanContext\":\n        return cls(\n            trace_id=trace_api.format_trace_id(src.trace_id),\n            span_id=trace_api.format_span_id(src.span_id),\n            is_remote=src.is_remote,\n            trace_state={k: v for k, v in src.trace_state.items()} if src.trace_state else {},\n            **extract_extra_fields(src, [\"trace_id\", \"span_id\", \"is_remote\", \"trace_state\"]),\n        )\n</code></pre>"},{"location":"reference/types/#agentlightning.TraceStatus","title":"<code>agentlightning.TraceStatus</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Corresponding to opentelemetry.trace.Status</p> Source code in <code>agentlightning/types/tracer.py</code> <pre><code>class TraceStatus(BaseModel):\n    \"\"\"Corresponding to opentelemetry.trace.Status\"\"\"\n\n    status_code: str\n    description: Optional[str] = None\n\n    class Config:\n        allow_extra = True\n\n    @classmethod\n    def from_opentelemetry(cls, src: OtelStatus) -&gt; \"TraceStatus\":\n        return cls(\n            status_code=src.status_code.name,\n            description=src.description,\n            **extract_extra_fields(src, [\"status_code\", \"description\"]),\n        )\n</code></pre>"},{"location":"reference/types/#agentlightning.Event","title":"<code>agentlightning.Event</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Corresponding to opentelemetry.trace.Event</p> Source code in <code>agentlightning/types/tracer.py</code> <pre><code>class Event(BaseModel):\n    \"\"\"Corresponding to opentelemetry.trace.Event\"\"\"\n\n    name: str\n    attributes: Attributes\n    timestamp: Optional[float] = None\n\n    class Config:\n        allow_extra = True\n\n    @classmethod\n    def from_opentelemetry(cls, src: OtelEvent) -&gt; \"Event\":\n        return cls(\n            name=src.name,\n            attributes=dict(src.attributes) if src.attributes else {},\n            timestamp=convert_timestamp(src.timestamp),\n            **extract_extra_fields(src, [\"name\", \"attributes\", \"timestamp\"]),\n        )\n</code></pre>"},{"location":"reference/types/#agentlightning.Link","title":"<code>agentlightning.Link</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Corresponding to opentelemetry.trace.Link</p> Source code in <code>agentlightning/types/tracer.py</code> <pre><code>class Link(BaseModel):\n    \"\"\"Corresponding to opentelemetry.trace.Link\"\"\"\n\n    context: SpanContext\n    attributes: Optional[Attributes] = None\n\n    class Config:\n        allow_extra = True\n\n    @classmethod\n    def from_opentelemetry(cls, src: trace_api.Link) -&gt; \"Link\":\n        return cls(\n            context=SpanContext.from_opentelemetry(src.context),\n            attributes=dict(src.attributes) if src.attributes else None,\n            **extract_extra_fields(src, [\"context\", \"attributes\"]),\n        )\n</code></pre>"},{"location":"reference/types/#agentlightning.Resource","title":"<code>agentlightning.Resource</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Corresponding to opentelemetry.sdk.resources.Resource</p> Source code in <code>agentlightning/types/tracer.py</code> <pre><code>class Resource(BaseModel):\n    \"\"\"Corresponding to opentelemetry.sdk.resources.Resource\"\"\"\n\n    attributes: Attributes\n    schema_url: str\n\n    @classmethod\n    def from_opentelemetry(cls, src: OtelResource) -&gt; \"Resource\":\n        return cls(\n            attributes=dict(src.attributes) if src.attributes else {},\n            schema_url=src.schema_url if src.schema_url else \"\",\n            **extract_extra_fields(src, [\"attributes\", \"schema_url\"]),\n        )\n</code></pre>"},{"location":"reference/types/#agentlightning.Span","title":"<code>agentlightning.Span</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Agent-Lightning's core span data type.</p> <p>Corresponding to <code>opentelemetry.sdk.trace.ReadableSpan</code>. However, only parts of the fields are preserved officially. The other fields are preserved as extra fields.</p> Source code in <code>agentlightning/types/tracer.py</code> <pre><code>class Span(BaseModel):\n    \"\"\"Agent-Lightning's core span data type.\n\n    Corresponding to `opentelemetry.sdk.trace.ReadableSpan`.\n    However, only parts of the fields are preserved officially.\n    The other fields are preserved as extra fields.\n    \"\"\"\n\n    class Config:\n        allow_extra = True  # allow extra fields if needed\n\n    rollout_id: str\n    \"\"\"The rollout which this span belongs to.\"\"\"\n    attempt_id: str\n    \"\"\"The attempt which this span belongs to.\"\"\"\n    sequence_id: int\n    \"\"\"The ID to make spans ordered within a single attempt.\"\"\"\n\n    # Current ID (in hex, formatted via trace_api.format_*)\n    trace_id: str  # one rollout can have traces coming from multiple places\n    \"\"\"The trace ID of the span. One rollout/attempt can have multiple traces.\n    This ID comes from the OpenTelemetry trace ID generator.\n    \"\"\"\n    span_id: str\n    \"\"\"The span ID of the span. This ID comes from the OpenTelemetry span ID generator.\"\"\"\n    parent_id: Optional[str]\n    \"\"\"The parent span ID of the span.\"\"\"\n\n    # Core ReadableSpan fields\n    name: str\n    \"\"\"The name of the span. See https://opentelemetry.io/docs/concepts/signals/traces/\"\"\"\n    status: TraceStatus\n    \"\"\"The status of the span. See https://opentelemetry.io/docs/concepts/signals/traces/\"\"\"\n    attributes: Attributes\n    \"\"\"The attributes of the span. See https://opentelemetry.io/docs/concepts/signals/traces/\"\"\"\n    events: List[Event]\n    \"\"\"The events of the span. See https://opentelemetry.io/docs/concepts/signals/traces/\"\"\"\n    links: List[Link]\n    \"\"\"The links of the span. See https://opentelemetry.io/docs/concepts/signals/traces/\"\"\"\n\n    # Timestamps\n    start_time: Optional[float]\n    \"\"\"The start time of the span. See https://opentelemetry.io/docs/concepts/signals/traces/\"\"\"\n    end_time: Optional[float]\n    \"\"\"The end time of the span. See https://opentelemetry.io/docs/concepts/signals/traces/\"\"\"\n\n    # Other parsable fields\n    context: Optional[SpanContext]\n    \"\"\"The context of the span. See https://opentelemetry.io/docs/concepts/signals/traces/\"\"\"\n    parent: Optional[SpanContext]\n    \"\"\"The parent context of the span. See https://opentelemetry.io/docs/concepts/signals/traces/\"\"\"\n    resource: Resource\n    \"\"\"The resource of the span. See https://opentelemetry.io/docs/concepts/signals/traces/\"\"\"\n\n    # Preserve other fields in the readable span as extra fields\n    # Make sure that are json serializable (so no bytes, complex objects, ...)\n\n    @classmethod\n    def from_opentelemetry(\n        cls,\n        src: ReadableSpan,\n        rollout_id: str,\n        attempt_id: str,\n        sequence_id: int,\n    ) -&gt; \"Span\":\n        \"\"\"Convert an [OpenTelemetry ReadableSpan](https://opentelemetry.io/docs/concepts/signals/traces/)\n        to an Agent-Lightning Span.\n\n        Args:\n            src: The OpenTelemetry ReadableSpan to convert.\n            rollout_id: The rollout ID.\n            attempt_id: The attempt ID.\n            sequence_id: The sequence ID.\n        \"\"\"\n        context = src.get_span_context()\n        if context is None:\n            trace_id = span_id = 0\n        else:\n            trace_id = context.trace_id\n            span_id = context.span_id\n        return cls(\n            rollout_id=rollout_id,\n            attempt_id=attempt_id,\n            sequence_id=sequence_id,\n            trace_id=trace_api.format_trace_id(trace_id),\n            span_id=trace_api.format_span_id(span_id),\n            parent_id=(trace_api.format_span_id(src.parent.span_id) if src.parent else None),\n            name=src.name,\n            status=TraceStatus.from_opentelemetry(src.status),\n            attributes=dict(src.attributes) if src.attributes else {},\n            events=[Event.from_opentelemetry(event) for event in src.events] if src.events else [],\n            links=[Link.from_opentelemetry(link) for link in src.links] if src.links else [],\n            start_time=convert_timestamp(src.start_time),\n            end_time=convert_timestamp(src.end_time),\n            context=SpanContext.from_opentelemetry(context) if context else None,\n            parent=(SpanContext.from_opentelemetry(src.parent) if src.parent else None),\n            resource=Resource.from_opentelemetry(src.resource),\n            **extract_extra_fields(\n                src,\n                [\n                    \"name\",\n                    \"context\",\n                    \"parent\",\n                    \"resource\",\n                    \"attributes\",\n                    \"events\",\n                    \"links\",\n                    \"start_time\",\n                    \"end_time\",\n                    \"status\",\n                    \"span_processor\",\n                    \"rollout_id\",\n                    \"attempt_id\",\n                    \"trace_id\",\n                    \"span_id\",\n                    \"parent_id\",\n                ],\n            ),\n        )\n\n    @classmethod\n    def from_attributes(\n        cls,\n        *,\n        attributes: Attributes,\n        rollout_id: Optional[str] = None,\n        attempt_id: Optional[str] = None,\n        sequence_id: Optional[int] = None,\n        name: Optional[str] = None,\n        trace_id: Optional[str] = None,\n        span_id: Optional[str] = None,\n        parent_id: Optional[str] = None,\n        start_time: Optional[float] = None,\n        end_time: Optional[float] = None,\n        resource: Optional[Resource] = None,\n    ) -&gt; \"Span\":\n\n        id_generator = RandomIdGenerator()\n        trace_id = trace_id or trace_api.format_trace_id(id_generator.generate_trace_id())\n        span_id = span_id or trace_api.format_span_id(id_generator.generate_span_id())\n\n        return cls(\n            rollout_id=rollout_id or \"\",\n            attempt_id=attempt_id or \"\",\n            sequence_id=sequence_id or 0,\n            trace_id=trace_id,\n            span_id=span_id,\n            parent_id=parent_id,\n            start_time=start_time,\n            end_time=end_time,\n            context=SpanContext(\n                trace_id=trace_id,\n                span_id=span_id,\n                is_remote=False,\n                trace_state={},\n            ),\n            name=name or SpanNames.VIRTUAL.value,\n            resource=resource or Resource(attributes={}, schema_url=\"\"),\n            attributes=attributes,\n            status=TraceStatus(status_code=\"OK\"),\n            events=[],\n            links=[],\n            parent=(\n                SpanContext(\n                    trace_id=trace_id,\n                    span_id=parent_id,\n                    is_remote=False,\n                    trace_state={},\n                )\n                if parent_id\n                else None\n            ),\n        )\n</code></pre>"},{"location":"reference/types/#agentlightning.Span.attempt_id","title":"<code>attempt_id</code>  <code>instance-attribute</code>","text":"<p>The attempt which this span belongs to.</p>"},{"location":"reference/types/#agentlightning.Span.attributes","title":"<code>attributes</code>  <code>instance-attribute</code>","text":"<p>The attributes of the span. See https://opentelemetry.io/docs/concepts/signals/traces/</p>"},{"location":"reference/types/#agentlightning.Span.context","title":"<code>context</code>  <code>instance-attribute</code>","text":"<p>The context of the span. See https://opentelemetry.io/docs/concepts/signals/traces/</p>"},{"location":"reference/types/#agentlightning.Span.end_time","title":"<code>end_time</code>  <code>instance-attribute</code>","text":"<p>The end time of the span. See https://opentelemetry.io/docs/concepts/signals/traces/</p>"},{"location":"reference/types/#agentlightning.Span.events","title":"<code>events</code>  <code>instance-attribute</code>","text":"<p>The events of the span. See https://opentelemetry.io/docs/concepts/signals/traces/</p>"},{"location":"reference/types/#agentlightning.Span.links","title":"<code>links</code>  <code>instance-attribute</code>","text":"<p>The links of the span. See https://opentelemetry.io/docs/concepts/signals/traces/</p>"},{"location":"reference/types/#agentlightning.Span.name","title":"<code>name</code>  <code>instance-attribute</code>","text":"<p>The name of the span. See https://opentelemetry.io/docs/concepts/signals/traces/</p>"},{"location":"reference/types/#agentlightning.Span.parent","title":"<code>parent</code>  <code>instance-attribute</code>","text":"<p>The parent context of the span. See https://opentelemetry.io/docs/concepts/signals/traces/</p>"},{"location":"reference/types/#agentlightning.Span.parent_id","title":"<code>parent_id</code>  <code>instance-attribute</code>","text":"<p>The parent span ID of the span.</p>"},{"location":"reference/types/#agentlightning.Span.resource","title":"<code>resource</code>  <code>instance-attribute</code>","text":"<p>The resource of the span. See https://opentelemetry.io/docs/concepts/signals/traces/</p>"},{"location":"reference/types/#agentlightning.Span.rollout_id","title":"<code>rollout_id</code>  <code>instance-attribute</code>","text":"<p>The rollout which this span belongs to.</p>"},{"location":"reference/types/#agentlightning.Span.sequence_id","title":"<code>sequence_id</code>  <code>instance-attribute</code>","text":"<p>The ID to make spans ordered within a single attempt.</p>"},{"location":"reference/types/#agentlightning.Span.span_id","title":"<code>span_id</code>  <code>instance-attribute</code>","text":"<p>The span ID of the span. This ID comes from the OpenTelemetry span ID generator.</p>"},{"location":"reference/types/#agentlightning.Span.start_time","title":"<code>start_time</code>  <code>instance-attribute</code>","text":"<p>The start time of the span. See https://opentelemetry.io/docs/concepts/signals/traces/</p>"},{"location":"reference/types/#agentlightning.Span.status","title":"<code>status</code>  <code>instance-attribute</code>","text":"<p>The status of the span. See https://opentelemetry.io/docs/concepts/signals/traces/</p>"},{"location":"reference/types/#agentlightning.Span.trace_id","title":"<code>trace_id</code>  <code>instance-attribute</code>","text":"<p>The trace ID of the span. One rollout/attempt can have multiple traces. This ID comes from the OpenTelemetry trace ID generator.</p>"},{"location":"reference/types/#agentlightning.Span.from_opentelemetry","title":"<code>from_opentelemetry(src, rollout_id, attempt_id, sequence_id)</code>  <code>classmethod</code>","text":"<p>Convert an OpenTelemetry ReadableSpan to an Agent-Lightning Span.</p> <p>Parameters:</p> Name Type Description Default <code>src</code> <code>ReadableSpan</code> <p>The OpenTelemetry ReadableSpan to convert.</p> required <code>rollout_id</code> <code>str</code> <p>The rollout ID.</p> required <code>attempt_id</code> <code>str</code> <p>The attempt ID.</p> required <code>sequence_id</code> <code>int</code> <p>The sequence ID.</p> required Source code in <code>agentlightning/types/tracer.py</code> <pre><code>@classmethod\ndef from_opentelemetry(\n    cls,\n    src: ReadableSpan,\n    rollout_id: str,\n    attempt_id: str,\n    sequence_id: int,\n) -&gt; \"Span\":\n    \"\"\"Convert an [OpenTelemetry ReadableSpan](https://opentelemetry.io/docs/concepts/signals/traces/)\n    to an Agent-Lightning Span.\n\n    Args:\n        src: The OpenTelemetry ReadableSpan to convert.\n        rollout_id: The rollout ID.\n        attempt_id: The attempt ID.\n        sequence_id: The sequence ID.\n    \"\"\"\n    context = src.get_span_context()\n    if context is None:\n        trace_id = span_id = 0\n    else:\n        trace_id = context.trace_id\n        span_id = context.span_id\n    return cls(\n        rollout_id=rollout_id,\n        attempt_id=attempt_id,\n        sequence_id=sequence_id,\n        trace_id=trace_api.format_trace_id(trace_id),\n        span_id=trace_api.format_span_id(span_id),\n        parent_id=(trace_api.format_span_id(src.parent.span_id) if src.parent else None),\n        name=src.name,\n        status=TraceStatus.from_opentelemetry(src.status),\n        attributes=dict(src.attributes) if src.attributes else {},\n        events=[Event.from_opentelemetry(event) for event in src.events] if src.events else [],\n        links=[Link.from_opentelemetry(link) for link in src.links] if src.links else [],\n        start_time=convert_timestamp(src.start_time),\n        end_time=convert_timestamp(src.end_time),\n        context=SpanContext.from_opentelemetry(context) if context else None,\n        parent=(SpanContext.from_opentelemetry(src.parent) if src.parent else None),\n        resource=Resource.from_opentelemetry(src.resource),\n        **extract_extra_fields(\n            src,\n            [\n                \"name\",\n                \"context\",\n                \"parent\",\n                \"resource\",\n                \"attributes\",\n                \"events\",\n                \"links\",\n                \"start_time\",\n                \"end_time\",\n                \"status\",\n                \"span_processor\",\n                \"rollout_id\",\n                \"attempt_id\",\n                \"trace_id\",\n                \"span_id\",\n                \"parent_id\",\n            ],\n        ),\n    )\n</code></pre>"},{"location":"reference/types/#agentlightning.SpanNames","title":"<code>agentlightning.SpanNames</code>","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p> <p>Standard span name values for AgentLightning.</p> <p>Currently reward, message, object and exception spans are supported. We will add more spans related to error handling in the future.</p> Source code in <code>agentlightning/types/tracer.py</code> <pre><code>class SpanNames(str, Enum):\n    \"\"\"Standard span name values for AgentLightning.\n\n    Currently reward, message, object and exception spans are supported.\n    We will add more spans related to error handling in the future.\n    \"\"\"\n\n    REWARD = \"agentlightning.reward\"\n    \"\"\"The name of the reward span.\"\"\"\n    MESSAGE = \"agentlightning.message\"\n    \"\"\"The name of the message span.\"\"\"\n    OBJECT = \"agentlightning.object\"\n    \"\"\"The name of the object span.\"\"\"\n    EXCEPTION = \"agentlightning.exception\"\n    \"\"\"The name of the exception span.\"\"\"\n    VIRTUAL = \"agentlightning.virtual\"\n    \"\"\"The name of the virtual span. It's used to represent a span\n    that is not associated with any real operations.\"\"\"\n</code></pre>"},{"location":"reference/types/#agentlightning.SpanNames.EXCEPTION","title":"<code>EXCEPTION = 'agentlightning.exception'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The name of the exception span.</p>"},{"location":"reference/types/#agentlightning.SpanNames.MESSAGE","title":"<code>MESSAGE = 'agentlightning.message'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The name of the message span.</p>"},{"location":"reference/types/#agentlightning.SpanNames.OBJECT","title":"<code>OBJECT = 'agentlightning.object'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The name of the object span.</p>"},{"location":"reference/types/#agentlightning.SpanNames.REWARD","title":"<code>REWARD = 'agentlightning.reward'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The name of the reward span.</p>"},{"location":"reference/types/#agentlightning.SpanNames.VIRTUAL","title":"<code>VIRTUAL = 'agentlightning.virtual'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The name of the virtual span. It's used to represent a span that is not associated with any real operations.</p>"},{"location":"reference/types/#agentlightning.SpanAttributeNames","title":"<code>agentlightning.SpanAttributeNames</code>","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p> <p>Standard attribute names for AgentLightning spans.</p> Source code in <code>agentlightning/types/tracer.py</code> <pre><code>class SpanAttributeNames(str, Enum):\n    \"\"\"Standard attribute names for AgentLightning spans.\"\"\"\n\n    MESSAGE = \"message\"\n    \"\"\"The name of the message attribute.\"\"\"\n    OBJECT = \"object\"\n    \"\"\"The name of the object attribute.\"\"\"\n</code></pre>"},{"location":"reference/types/#agentlightning.SpanAttributeNames.MESSAGE","title":"<code>MESSAGE = 'message'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The name of the message attribute.</p>"},{"location":"reference/types/#agentlightning.SpanAttributeNames.OBJECT","title":"<code>OBJECT = 'object'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The name of the object attribute.</p>"},{"location":"reference/types/#agentlightning.SpanLike","title":"<code>agentlightning.SpanLike = Union[ReadableSpan, Span]</code>  <code>module-attribute</code>","text":""},{"location":"tutorials/debug/","title":"Debugging and Troubleshooting","text":"<p>When you train your own agent with Agent-lightning, most failures surface because the agent logic is brittle or simply incorrect. Debugging becomes easier when you peel back the stack: start by driving the rollout logic on its own, dry-run the trainer loop, and only then bring the full algorithm and runner topology online. The <code>examples/apo/apo_debug.py</code> script demonstrates these techniques; this guide expands on each approach and helps you decide when to reach for them.</p>"},{"location":"tutorials/debug/#using-runner-in-isolation","title":"Using <code>Runner</code> in Isolation","text":"<p><code>Runner</code> is a long-lived worker that wraps your <code>LitAgent</code>, coordinates tracing, and talks to the <code>LightningStore</code>. In typical training flows the trainer manages runners for you, but being able to spin one up manually is invaluable while debugging.</p> <p>If you define rollout logic with <code>@rollout</code> or implement a <code>LitAgent</code> directly, you will get a <code>LitAgent</code> instance and you should be able to execute it with <code>LitAgentRunner</code>, which is a subclass of <code>Runner</code>. The runner needs but does not instantiate a <code>Tracer</code>, so supply one yourself. See Working with Traces for a walkthrough of tracer options.</p> <p><code>Runner.run_context</code> prepares the runner to execute a particular agent. Besides the agent and tracer you must provide a store that will collect spans and rollouts. <code>InMemoryLightningStore</code> keeps everything in-process, which is perfect for debugging sessions.</p> <pre><code>import agentlightning as agl\n\ntracer = agl.OtelTracer()\nrunner = agl.LitAgentRunner(tracer)\nstore = agl.InMemoryLightningStore()\n\nwith runner.run_context(agent=apo_rollout, store=store):\n    ...\n</code></pre> <p>Inside the <code>run_context</code> block you can call <code>runner.step(...)</code> to execute a single rollout. The payload includes the task input and any <code>NamedResources</code> the agent expects. Read introduction to Resources and NamedResources for more details. For example, if your agent references a <code>PromptTemplate</code>, pass it through the <code>resources</code> argument:</p> <pre><code>with runner.run_context(agent=apo_rollout, store=store):\n    resource = agl.PromptTemplate(template=\"You are a helpful assistant. {any_question}\", engine=\"f-string\")\n    rollout = await runner.step(\n        \"Explain why the sky appears blue using principles of light scattering in 100 words.\",\n        resources={\"main_prompt\": resource},\n    )\n</code></pre> <p>You can do as many things as you want within the <code>Runner.run_context</code> block. After the rollout finishes you can query the store to inspect what happened:</p> <pre><code>print(await store.query_rollouts())\nprint(await store.query_spans(rollout.rollout_id))\n</code></pre> <p>Example output (with a reward span captured):</p> <pre><code>[Rollout(rollout_id='ro-519769241af8', input='Explain why the sky appears blue using principles of light scattering in 100 words.', start_time=1760706315.6996238, ..., status='succeeded')]\n[Span(rollout_id='ro-519769241af8', attempt_id='at-a6b62caf', sequence_id=1, ..., name='agentlightning.reward', attributes={'reward': 0.95}, ...)]\n</code></pre> <p>Swap in an <code>AgentOpsTracer</code> instead of <code>OtelTracer</code> to see the underlying LLM spans alongside reward information:</p> <pre><code>[\n    Span(rollout_id='ro-519769241af8', attempt_id='at-a6b62caf', sequence_id=1, ..., name='openai.chat.completion', attributes={..., 'gen_ai.prompt.0.role': 'user', 'gen_ai.prompt.0.content': 'You are a helpful assistant. Explain why the sky appears blue using principles of light scattering in 100 words.', ...}),\n    Span(rollout_id='ro-519769241af8', attempt_id='at-a6b62caf', sequence_id=2, ..., name='openai.chat.completion', attributes={..., 'gen_ai.prompt.0.role': 'user', 'gen_ai.prompt.0.content': 'Evaluate how well the output fulfills the task...', ...}),\n    Span(rollout_id='ro-519769241af8', attempt_id='at-a6b62caf', sequence_id=3, ..., name='agentlightning.reward', attributes={'reward': 0.95}, ...)\n]\n</code></pre> <p>Tip</p> <p>Spans too difficult to read? Try using <code>Adapter</code> to convert them into a more readable format.</p> <p><code>Runner.step</code> executes a full rollout even though it is named \"step\". The companion method <code>Runner.iter</code> executes multiple \"steps\" by continuously pulling new rollout inputs from the store until a stop event is set. Use <code>iter</code> once you are confident the single-step path works and you have another worker <code>enqueue_rollout</code> to the store.</p> <p>Tip</p> <p>You can also call <code>Runner.step</code> to inject ad-hoc rollouts into a running store being used by another algorithm, so that the rollouts can be consumed by the algorithms. This is very recently known as the paradigm of \"online RL\". At the moment, no algorithm in the algorithm zoo consumes externally generated rollouts, but the data flow is available there if you need it.</p>"},{"location":"tutorials/debug/#hook-into-runners-lifecycle","title":"Hook into Runner's Lifecycle","text":"<p><code>Runner.run_context</code> accepts a <code>hooks</code> argument so you can observe or augment lifecycle events without editing your agent. Hooks subclass <code>Hook</code> and can respond to four asynchronous callbacks: <code>on_trace_start</code>, <code>on_rollout_start</code>, <code>on_rollout_end</code>, and <code>on_trace_end</code>. This is useful for:</p> <ul> <li>Capturing raw OpenTelemetry spans before they hit the store and before the <code>LitAgentRunner</code> do postprocessing on the rollout</li> <li>Inspecting the tracer instance after they are activated</li> <li>Logging rollout inputs before they are processed by the agent</li> </ul> <p>The <code>hook</code> mode in <code>examples/apo/apo_debug.py</code> prints every span collected during a rollout:</p> <pre><code>import agentlightning as agl\n\n# ... Same as previous example\n\nclass DebugHook(agl.Hook):\n    async def on_trace_end(self, *, agent, runner, tracer, rollout):\n        trace = tracer.get_last_trace()\n        print(\"Trace spans collected during the rollout:\")\n        for span in trace:\n            print(f\"- {span.name} (status: {span.status}):\\n  {span.attributes}\")\n\nwith runner.run_context(\n    agent=apo_rollout,\n    store=store,\n    hooks=[DebugHook()],\n):\n    await runner.step(\n        \"Explain why the sky appears blue using principles of light scattering in 100 words.\",\n        resources={\"main_prompt\": resource},\n    )\n</code></pre> <p>Because hooks run inside the runner process you can also attach debuggers or breakpoints directly in the callback implementations.</p>"},{"location":"tutorials/debug/#dry-run-the-trainer-loop","title":"Dry-Run the Trainer Loop","text":"<p>Once single rollouts behave, switch to the trainer\u2019s dry-run mode. <code>Trainer.dev</code> spins up a lightweight fast algorithm \u2014 <code>agentlightning.Baseline</code> by default \u2014 so you can exercise the same infrastructure as <code>Trainer.fit</code> without standing up complex stacks like RL or SFT.</p> <p>Warning</p> <p>When you enable multiple runners via <code>n_runners</code>, the trainer may execute them in separate worker processes. Attaching a debugger such as <code>pdb</code> is only practical when <code>n_runners=1</code>, and even then the runner might not live in the main process.</p> <pre><code>import agentlightning as agl\n\ndataset: agl.Dataset[str] = [\n    \"Explain why the sky appears blue using principles of light scattering in 100 words.\",\n    \"What's the capital of France?\",\n]\nresource = agl.PromptTemplate(template=\"You are a helpful assistant. {any_question}\", engine=\"f-string\")\n\ntrainer = agl.Trainer(\n    n_runners=1,\n    initial_resources={\"main_prompt\": resource},\n)\ntrainer.dev(apo_rollout, dataset)\n</code></pre> <p>Just like <code>Runner.run_context</code>, <code>Trainer.dev</code> requires the <code>NamedResources</code> your agent expects. The key difference is that resources are attached to the trainer rather than the runner.</p> <p><code>Trainer.dev</code> uses an almost switchable interface from <code>Trainer.fit</code>. It also needs a dataset to iterate over, similar to <code>fit</code>. Under the hood <code>dev</code> uses the same implementation as <code>fit</code>, which means you can spin up multiple runners, observe scheduler behavior, and validate how algorithms adapt rollouts. The default <code>Baseline</code> logs detailed traces so you can see each rollout as the algorithm perceives it:</p> <pre><code>21:20:30 Initial resources set: {'main_prompt': PromptTemplate(resource_type='prompt_template', template='You are a helpful assistant. {any_question}', engine='f-string')}\n21:20:30 Proceeding epoch 1/1.\n21:20:30 Enqueued rollout ro-302fb202bd85 in train mode with sample: Explain why the sky appears blue using principles of light scattering in 100 words.\n21:20:30 Enqueued rollout ro-e65a3ffaa540 in train mode with sample: What's the capital of France?\n21:20:30 Waiting for 2 harvest tasks to complete...\n21:20:30 [Rollout ro-302fb202bd85] Status is initialized to queuing.\n21:20:30 [Rollout ro-e65a3ffaa540] Status is initialized to queuing.\n21:20:35 [Rollout ro-302fb202bd85] Finished with status succeeded in 3.80 seconds.\n21:20:35 [Rollout ro-302fb202bd85 | Attempt 1] ID: at-f84ad21c. Status: succeeded. Worker: Worker-0\n21:20:35 [Rollout ro-302fb202bd85 | Attempt at-f84ad21c | Span 3a286a856af6bea8] #1 (openai.chat.completion) ... 1.95 seconds. Attribute keys: ['gen_ai.request.type', 'gen_ai.system', ...]\n21:20:35 [Rollout ro-302fb202bd85 | Attempt at-f84ad21c | Span e2f44b775e058dd6] #2 (openai.chat.completion) ... 1.24 seconds. Attribute keys: ['gen_ai.request.type', 'gen_ai.system', ...]\n21:20:35 [Rollout ro-302fb202bd85 | Attempt at-f84ad21c | Span 45ee3c94fa1070ec] #3 (agentlightning.reward) ... 0.00 seconds. Attribute keys: ['reward']\n21:20:35 [Rollout ro-302fb202bd85] Adapted data: [Triplet(prompt={'token_ids': []}, response={'token_ids': []}, reward=None, metadata={'response_id': '...', 'agent_name': ''}), Triplet(prompt={'token_ids': []}, response={'token_ids': []}, reward=0.95, metadata={'response_id': '...', 'agent_name': ''})]\n21:20:35 Finished 1 rollouts.\n21:20:35 [Rollout ro-e65a3ffaa540] Status changed to preparing.\n21:20:40 [Rollout ro-e65a3ffaa540] Finished with status succeeded in 6.39 seconds.\n21:20:40 [Rollout ro-e65a3ffaa540 | Attempt 1] ID: at-eaefa5d4. Status: succeeded. Worker: Worker-0\n21:20:40 [Rollout ro-e65a3ffaa540 | Attempt at-eaefa5d4 | Span 901dd6acc0f50147] #1 (openai.chat.completion) ... 1.30 seconds. Attribute keys: ['gen_ai.request.type', 'gen_ai.system', ...]\n21:20:40 [Rollout ro-e65a3ffaa540 | Attempt at-eaefa5d4 | Span 52e0aa63e02be611] #2 (openai.chat.completion) ... 1.26 seconds. Attribute keys: ['gen_ai.request.type', 'gen_ai.system', ...]\n21:20:40 [Rollout ro-e65a3ffaa540 | Attempt at-eaefa5d4 | Span 6c452de193fbffd3] #3 (agentlightning.reward) ... 0.00 seconds. Attribute keys: ['reward']\n21:20:40 [Rollout ro-e65a3ffaa540] Adapted data: [Triplet(prompt={'token_ids': []}, response={'token_ids': []}, reward=None, metadata={'response_id': '...', 'agent_name': ''}), Triplet(prompt={'token_ids': []}, response={'token_ids': []}, reward=1.0, metadata={'response_id': '...', 'agent_name': ''})]\n21:20:40 Finished 2 rollouts.\n</code></pre> <p>The only limitation is that resources remain static and components like <code>LLMProxy</code> are not wired in. For richer dry runs you can subclass <code>FastAlgorithm</code> and override the pieces you care about.</p>"},{"location":"tutorials/debug/#debug-the-algorithm-runner-boundary","title":"Debug the Algorithm-Runner Boundary","text":"<p>Debugging algorithms in Agent-Lightning is often more challenging than debugging agents. Algorithms are typically stateful and depend on several moving parts \u2014 runners, stores, and trainers \u2014 which makes it difficult to isolate and inspect their behavior. Even mocking an agent to cooperate with an algorithm can be costly and error-prone. To simplify this, Agent-Lightning provides a way to run algorithms in isolation so you can attach a debugger and inspect internal state without interference from other components.</p> <p>By default, <code>Trainer.fit</code> runs the algorithm in the main process and thread, but its logs are interleaved with those from the store and runners, making it hard to follow what\u2019s happening inside the algorithm itself. In Write Your First Algorithm, we covered how to stand up a store, algorithm, and runner in isolation for your own implementations. This section extends that approach to cover two common questions:</p> <ol> <li>How can I run built-in or class-based algorithms (inheriting from <code>Algorithm</code>) in isolation?</li> <li>How can I still use <code>Trainer</code> features like <code>n_runners</code>, <code>adapter</code>, or <code>llm_proxy</code> while debugging?</li> </ol> <p>The solution is to keep using a <code>Trainer</code> instance but manage the store yourself, running the algorithm and runner roles separately. This approach mirrors the internal process orchestration of <code>Trainer.fit</code>, but with more visibility and control. Below, we show a step-by-step guide to achieve this with the <code>calc_agent</code> example.</p> <p>1. Launch the store manually. In a separate terminal, start the store:</p> <pre><code>agl store --port 4747\n</code></pre> <p>Then, in your training script, create a <code>LightningStoreClient</code> and pass it to the trainer:</p> <pre><code>client = agl.LightningStoreClient(\"http://localhost:4747\")\ntrainer = agl.Trainer(store=client, ...)\n</code></pre> <p>Set the environment variable <code>AGL_MANAGED_STORE=0</code> so the trainer doesn't attempt to manage the store automatically.</p> <p>2. Start the runner and algorithm processes separately. Each process should run the same training script, but with different environment variables specifying the current role. This setup faithfully mirrors how <code>Trainer.fit</code> orchestrates these components behind the scenes.</p> <pre><code># Terminal 2 \u2013 Runner process\nAGL_MANAGED_STORE=0 AGL_CURRENT_ROLE=runner \\\n    python train_calc_agent.py --external-store-address http://localhost:4747 --val-file data/test_mini.parquet\n\n# Terminal 3 \u2013 Algorithm process\nAGL_MANAGED_STORE=0 AGL_CURRENT_ROLE=algorithm \\\n    python train_calc_agent.py --external-store-address http://localhost:4747 --val-file data/test_mini.parquet\n</code></pre> <p>3. Reuse your existing trainer configuration. You can continue using the same datasets, adapters, and proxies as usual. Because the store is now external, you can:</p> <ul> <li>Attach debuggers to either the algorithm or runner process</li> <li>Add fine-grained logging or tracing</li> <li>Simulate partial failures or latency in individual components</li> </ul> <p>This setup provides a faithful reproduction of the algorithm\u2013runner interaction while keeping the store visible for inspection. Once you\u2019ve resolved the issue, simply set <code>AGL_MANAGED_STORE=1</code> (or omit it) to return to the standard managed training workflow.</p>"},{"location":"tutorials/installation/","title":"Installation","text":""},{"location":"tutorials/installation/#install-from-pypi","title":"Install from PyPI","text":""},{"location":"tutorials/installation/#set-up-your-environment","title":"Set Up Your Environment","text":"<p>We strongly recommend creating a new virtual environment to avoid conflicts with other packages. You can use either <code>conda</code> or <code>venv</code>. Python 3.10 or later is recommended.</p>"},{"location":"tutorials/installation/#install-core-training-dependencies-optional","title":"Install Core Training Dependencies (Optional)","text":"<p>If you are running RL with Agent-Lightning, the next step is to install the essential packages: <code>PyTorch</code>, <code>FlashAttention</code>, <code>vLLM</code> and <code>VERL</code>. The following versions and installation order have been tested and are confirmed to work.</p> <pre><code>pip install torch==2.7.0 torchvision==0.22.0 torchaudio==2.7.0 --index-url https://download.pytorch.org/whl/cu128\npip install flash-attn --no-build-isolation\npip install vllm==0.9.2\npip install verl==0.5.0\n</code></pre> <p>See this script for a full installation script.</p>"},{"location":"tutorials/installation/#install-agent-lightning","title":"Install Agent Lightning","text":"<p>Now, you're ready to install Agent Lightning itself.</p> <pre><code>pip install agentlightning\n</code></pre>"},{"location":"tutorials/installation/#install-agent-frameworks-optional","title":"Install Agent Frameworks (Optional)","text":"<p>If you plan to use other agent frameworks, you can install them with the following commands. If you don't need these, feel free to skip this step. We recommend doing this as the final step to avoid dependency versions being overwritten by mistake.</p> <pre><code># AutoGen (Recommended to install first)\npip install \"autogen-agentchat\" \"autogen-ext[openai]\"\n\n# LiteLLM\npip install \"litellm[proxy]\"\n\n# MCP\npip install mcp\n\n# UV\npip install uv\n\n# OpenAI Agents\npip install openai-agents\n\n# LangChain\npip install langgraph \"langchain[openai]\" langchain-community langchain-text-splitters\n\n# SQL-related dependencies\npip install sqlparse nltk\n</code></pre>"},{"location":"tutorials/installation/#shortcuts-for-installing-extra-dependencies","title":"Shortcuts for installing Extra Dependencies","text":"<p>For development: <pre><code>pip install agentlightning[dev]\n</code></pre></p> <p>For agent support: <pre><code>pip install agentlightning[agent]\n</code></pre></p>"},{"location":"tutorials/installation/#install-from-source","title":"Install from Source","text":"<pre><code>git clone https://github.com/microsoft/agent-lightning\ncd agent-lightning\npip install -e .[dev]\n</code></pre> <p>Please run pre-commit hooks before checking in code:</p> <pre><code>pre-commit install\npre-commit run --all-files --show-diff-on-failure --color=always\n</code></pre>"},{"location":"tutorials/parallelize/","title":"Scaling out Algorithms and Rollouts","text":""},{"location":"tutorials/parallelize/#parallelizing-rollouts-with-trainer","title":"Parallelizing Rollouts with Trainer","text":""},{"location":"tutorials/parallelize/#client-server-architecture","title":"Client-server Architecture","text":""},{"location":"tutorials/parallelize/#execution-strategy","title":"Execution Strategy","text":""},{"location":"tutorials/parallelize/#parallelizing-algorithms","title":"Parallelizing Algorithms","text":""},{"location":"tutorials/traces/","title":"Working with Traces","text":"<p>Tracing is the secret capability that lets Agent-lightning train almost any agent without rewriting its core logic. The idea was born in observability tooling inside LLMOps workflows and, in Agent-lightning, evolved into a first-class primitive inside the learning loop. Beyond helping you understand what happened inside a rollout, traces provide reward spans and other learning signals that power reinforcement learning and fine-tuning algorithms.</p> <p></p> <p>Agent-lightning stores every recorded operation as a <code>Span</code> inside a <code>LightningStore</code>. The naming comes from the OpenTelemetry spans, shown in the screenshot above. A span can represent an LLM call, a tool invocation, a graph edge, an explicit reward emission, or an arbitrary Python code block. Spans form a tree where parent spans describe higher-level steps and children record the detailed work. The sections below walk through how spans are produced and how to interpret them once they reach the store.</p>"},{"location":"tutorials/traces/#writing-spans","title":"Writing Spans","text":"<p>Most <code>Runner</code> implementations wire a <code>Tracer</code> into the agent\u2019s lifecycle. The tracer is responsible for installing instrumentation, buffering OpenTelemetry spans, and committing them to the <code>LightningStore</code>. When a runner executes a rollout it allocates a store-backed tracing context:</p> <pre><code>async with tracer.trace_context(\n    name=\"my-rollout\",\n    store=store,\n    rollout_id=rollout.rollout_id,\n    attempt_id=attempt.attempt_id,\n):\n    await run_agent_logic()\n</code></pre> <p>The context manager then requests sequence numbers from the store, converts OpenTelemetry spans into <code>Span</code> objects, and persists them in the middle or at the end of the attempt, depending on the tracer implementation. Agent-lightning ships two tracers out of the box; both rely on OpenTelemetry Traces and ignore metrics or logs.</p> <p>What's instrumentation?</p> <p>In simple terms, instrumentation means adding \"patches\" or hooks inside your code so you can observe what it\u2019s doing while it runs. Think of it like putting flight recorders in an airplane \u2014 instrumentation records key actions, inputs, outputs, and timings without changing how the code behaves. In Agent-lightning tracers, this instrumentation automatically creates spans (small, structured records of work) that show what each part of an agent did, how long it took, and how different steps connect together.</p>"},{"location":"tutorials/traces/#agentops-tracer","title":"AgentOps Tracer","text":"<p><code>AgentOpsTracer</code> will be the default tracer when <code>Trainer</code> is used but no tracer is explicitly specified. It bootstraps the AgentOps SDK locally, installs the supplied instrumentation hooks (LangChain, LangGraph, LiteLLM, FastAPI, and others) provided by AgentOps Python SDK, and forwards everything through a local OpenTelemetry <code>TracerProvider</code>. <code>AgentOpsTracer</code> never calls the hosted AgentOps service; instead it attaches a <code>LightningSpanProcessor</code> that is implemented by the Agent-lightning team, so spans are captured and shipped straight into the store.</p> <p>Because it shares the AgentOps instrumentation surface, any framework supported by AgentOps automatically gains tracing in Agent-lightning. We layer additional hooks on top of AgentOps to capture features that the SDK misses today:</p> <ol> <li>Certain providers emit extra metadata \u2014 for example token IDs returned by vLLM \u2014 that are not recorded by the stock SDK. We augment those spans with the missing payloads.</li> <li>AgentOps constructs parent-child relationships best-effort, but mixed instrumentation (for example, OpenAI Agent SDK alongside direct OpenAI Chat Completion calls) can leave segments disconnected. Our implementation (actually implemented in the <code>TracerTraceToTriplet</code> adapter) repairs those relationships when the hierarchy can be inferred from rollout context.</li> <li>Some versions of downstream frameworks simply do not emit spans for critical events (LangGraph node entrances are a common example). The tracer installs lightweight shims so those spans appear consistently.</li> </ol> <p>If a vendor integration behaves unexpectedly, users are encouraged to combine the tracer with Hooks to inspect the raw spans or diagnosis, and/or implement a specialized tracer for the framework in question.</p>"},{"location":"tutorials/traces/#opentelemetry-tracer","title":"OpenTelemetry Tracer","text":"<p><code>OtelTracer</code> is a minimal implementation that initializes a vanilla <code>TracerProvider</code> and gives you direct control over span creation through the standard <code>opentelemetry.trace</code> API. Use it when you already have explicit instrumentation in your agent, when the AgentOps SDK does not support your framework, or when you want to emit custom spans from business logic.</p> <p>Note</p> <p>Microsoft Agent Framework is a typical example with built-in OpenTelemetry support. Once you had <code>OBSERVABILITY_SETTINGS.enable_otel = True</code>, the framework will automatically emit OpenTelemetry spans and <code>OtelTracer</code> will be able to capture them. No extra instrumentation is needed.</p> <p>Inside your agent you can call <code>opentelemetry.trace.get_trace_provider().get_tracer(\"my-agent\")</code> and use that tracer to create spans exactly as you would in any OpenTelemetry application. The Lightning span processor attached by <code>OtelTracer</code> guarantees that every span is sequenced, converted, and written to the store. Same for emitted rewards (<code>emit_reward</code>) and other emitter signals, which are just a special case of manually-created spans.</p>"},{"location":"tutorials/traces/#llm-proxy","title":"LLM Proxy","text":"<p>Sometimes the runner can\u2019t observe the agent directly\u2014because it\u2019s in another language or running remotely. <code>LLMProxy</code> bridges that gap by instrumenting the server side of LLM calls. It wraps LiteLLM and adds middleware that accepts prefixed routes like <code>/rollout/{rid}/attempt/{aid}/v1/chat/completions</code>. Before forwarding, the middleware rewrites the path to <code>/v1/chat/completions</code>, fetches a monotonic <code>sequence_id</code> from the <code>LightningStore</code>, injects <code>x-rollout-id</code>, <code>x-attempt-id</code>, and <code>x-sequence-id</code> into the request headers, and then forwards to the backend LLM endpoint.</p> <p>LiteLLM produces OpenTelemetry spans for the request/response. A custom <code>LightningSpanExporter</code> reads the rollout/attempt/sequence identifiers from the recorded request headers and persists each span to the store. Because the <code>sequence_id</code> is allocated at the start of the request, traces stay in strict order even across machines with skewed clocks or when responses complete asynchronously.</p> <pre><code>sequenceDiagram\n    participant Agent\n    participant Proxy as LLM Proxy\n    participant Backend as LLM Backend\n    participant Store as LightningStore\n\n    Agent-&gt;&gt;Proxy: POST /rollout/{rid}/attempt/{aid}/v1/chat/completions\n    Proxy-&gt;&gt;Store: get_next_span_sequence_id(rid, aid)\n    Store--&gt;&gt;Proxy: sequence_id\n    Proxy-&gt;&gt;Backend: Forward /v1/chat/completions&lt;br&gt;(headers: rid, aid, sid)\n    Backend--&gt;&gt;Proxy: Response (tokens, usage, token_ids)\n    Proxy-&gt;&gt;Store: Export OTEL spans (rid, aid, sequence_id)\n    Proxy--&gt;&gt;Agent: OpenAI-compatible response</code></pre> <p><code>LLMProxy</code> actually provides more functionalities than just the middleware for tracing. Read Serving LLM for more details.</p> <p>Distributed Tracing</p> <p>Agent-lightning enforces deterministic span ordering by assigning a monotonic <code>sequence_id</code> to every span within an attempt. Before calling <code>LightningStore.add_span</code> or <code>LightningStore.add_otel_span</code>, tracers are expected to call <code>LightningStore.get_next_span_sequence_id</code> to get the next sequence id. This removes clock skew and merges spans produced on different machines or threads. If you implement a custom tracer or exporter, make sure you do this (or respect the one provided in headers by components such as <code>LLMProxy</code>); otherwise adapters will struggle to reconstruct the execution tree.</p>"},{"location":"tutorials/traces/#custom-tracer","title":"Custom Tracer","text":"<p>If none of the built-in tracers fit your environment, the first option to consider is to return the spans directly from your agent implementation. If that's not possible, or you want to support multiple agents in a unified effort, you can implement your own tracer by subclassing <code>Tracer</code>.</p> <p>Custom tracers must implement at least <code>trace_context</code>. The <code>trace_context</code> coroutine should install or activate whatever instrumentation you need, then yield a span processor that ultimately adds spans to the store. You can reuse the <code>LightningSpanProcessor</code> if you produce OpenTelemetry <code>ReadableSpan</code> objects, or call <code>LightningStore.add_span</code> directly if you generate <code>Span</code> instances yourself.</p> <p>Advanced tracers often run auxiliary services (for example, starting a telemetry daemon or attaching to a container runtime) inside <code>init_worker</code> and tear them down in <code>teardown_worker</code>. The <code>ParallelWorkerBase</code> lifecycle that <code>Tracer</code> inherits from ensures those hooks are executed in every runner subprocess.</p>"},{"location":"tutorials/traces/#reading-traces","title":"Reading Traces","text":"<p>Generally, there are two approaches to reading traces. When you only need a quick look, <code>Tracer.get_last_trace</code> returns the raw OpenTelemetry spans captured most recently. For historical analysis, use the <code>LightningStore.query_spans</code> API, which yields normalized <code>Span</code> objects keyed by rollout ID and attempt ID. Combine those queries with <code>LightningStore.query_rollouts</code> to align spans with rollout status, retries, and timing information.</p> <p>Spans arrive asynchronously, originate from different processes, and form hierarchies rather than simple lists. The attributes of each span are tedious and unfriendly to human readers. This combination makes raw traces time-consuming to inspect, especially when you only care about specific signals such as rewards, LLM prompts, responses, or tool outputs. Understanding how the store exposes traces and how adapters reshape them will save hours when debugging or training.</p> <p>Why traces can be difficult to read?</p> <p>The trace tree for a single rollout typically mixes multiple abstraction layers: a planner span may contain several LLM spans, each of which contains tool execution spans that can themselves trigger nested agent invocations. There are also instrumentations at different levels. For example, when a request delegates to another library (e.g., from LangChain to OpenAI), two libraries might emit spans for the same request. At the top level, there could be concurrently running agents that may flush spans slightly out of order. Sorting by <code>sequence_id</code> restores the chronological view, but interpreting the tree requires additional context about parent-child relationships and rollout metadata.</p>"},{"location":"tutorials/traces/#adapter","title":"Adapter","text":"<p>Adapters transform lists of spans into higher-level data structures that training algorithms can consume directly. Agent-lightning provides several adapters out of the box:</p> <ul> <li><code>TracerTraceToTriplet</code> converts spans into <code>(prompt, response, reward)</code> triplets, which power reinforcement-learning algorithms such as VERL and connect trace data to gradient updates.</li> <li><code>TraceToMessages</code> rewrites spans into OpenAI chat message JSON suitable for supervised fine-tuning or evaluation harnesses.</li> <li><code>LlmProxyTraceToTriplet</code> mirrors <code>TracerTraceToTriplet</code> but understands spans emitted by LLMProxy. It is experimental and might be merged with <code>TracerTraceToTriplet</code> in the future.</li> </ul> <p>Adapters are regular Python callable instances, so you can plug them into <code>Trainer</code> via the <code>adapter</code> argument, or call them manually during exploration. When used in <code>Trainer</code>, adapters are bundled into the <code>Algorithm</code> before the algorithm runs, through the <code>Algorithm.set_adapter</code> method.</p> <p>You can also customize an <code>Adapter</code> by extending the implementations above or subclassing the base class. If you need a bespoke format, subclass <code>TraceAdapter</code> (for store spans) or <code>OtelTraceAdapter</code> (for raw OpenTelemetry spans) and implement <code>adapt</code> (these two classes can usually share the same implementation).</p>"},{"location":"tutorials/traces/#reading-rewards","title":"Reading Rewards","text":"<p>Rewards are recorded as dedicated spans named <code>agentlightning.reward</code>. Emitting a reward through <code>emit_reward</code> or the <code>@reward</code> decorator ensures the value is stored in the span\u2019s <code>attributes[\"reward\"]</code>. To audit rewards, fetch spans from the store and use the helper utilities in <code>agentlightning.emitter</code>:</p> <pre><code>from agentlightning.emitter import find_final_reward\n\nspans = await store.query_spans(rollout_id)\nreward = find_final_reward(spans)\nprint(f\"Final reward: {reward}\")\n</code></pre> <p><code>find_reward_spans</code> returns every reward span so you can visualize intermediate shaping signals, while <code>find_final_reward</code> extracts the last non-null reward per attempt. While these helpers are convenient, they don\u2019t necessarily help you understand the chronological or hierarchical relationships between reward spans and other spans. Using an <code>Adapter</code> \u2014 especially the same one used in the algorithm you\u2019re working with \u2014 remains the recommended way to inspect your generated spans.</p>"},{"location":"tutorials/write-agents/","title":"Writing Agents","text":"<p>This tutorial will focus on the heart of the system: the agent itself, guiding you through the different ways to define an agent's logic in Agent-lightning.</p> <p>The basic requirements for any agent are:</p> <ol> <li>It must accept a single task as input.</li> <li>It must accept a set of tunable resources (like a PromptTemplate or LLM).</li> <li>It must emit trace span data so that algorithms can understand its behavior and learn from it. The simplest way to do this is by returning a final reward.</li> </ol> <p>In practice, please also bear in mind that tasks, resources, and spans have extra requirements, in order to make it trainable within Agent-lightning:</p> <ol> <li>You will need a training dataset containing a set of tasks, of the same type that your agent expects as input.</li> <li>The tunable resources are related to the algorithm. For example, the APO algorithm we've seen tunes a PromptTemplate. Other algorithms might tune model weights or other configurations.</li> <li>The type of spans an algorithm can use varies. Almost all algorithms support a single, final reward span at the end of a rollout. However, not all algorithms support rewards emitted mid-rollout, let alone other kinds of spans like exceptions or log messages.</li> </ol> <p>This tutorial will show you how to write an agent that can handle various tasks and resources and emit all kinds of spans. However, you should understand that agents and algorithms are often co-designed. Supporting new types of resources or spans in an algorithm is often much more complex than just adding them to an agent.</p>"},{"location":"tutorials/write-agents/#rollout-decorator","title":"<code>@rollout</code> Decorator","text":"<p>The simplest way to create an agent is by writing a standard Python function and marking it with the @rollout decorator. This approach is perfect for agents with straightforward logic that doesn't require complex state management.</p> <p>Agent-lightning automatically inspects your function's signature and injects the required resources. For example, if your function has a parameter named <code>prompt_template</code>, Agent-lightning will find the PromptTemplate resource for the current rollout and pass it in.</p> <p>Let's revisit the <code>room_selector</code> agent from the first tutorial:</p> <pre><code>from typing import TypedDict\nfrom agentlightning import PromptTemplate, rollout\n\n# Define a data structure for the task input\nclass RoomSelectionTask(TypedDict):\n    # ... fields for the task ...\n    pass\n\n@rollout\ndef room_selector(task: RoomSelectionTask, prompt_template: PromptTemplate) -&gt; float:\n    # 1. Use the injected prompt_template to format the input for the LLM\n    prompt = prompt_template.format(**task)\n\n    # 2. Execute the agent's logic (e.g., call an LLM, use tools)\n    # ...\n\n    # 3. Grade the final choice to get a reward\n    reward = room_selection_grader(final_message, task[\"expected_choice\"])\n\n    # 4. Return the final reward as a float\n    return reward\n</code></pre> <p>When you train this agent, the dataset is expected to be a list of <code>RoomSelectionTask</code> objects:</p> <pre><code>from agentlightning import Dataset, Trainer\n\ndataset: Dataset[RoomSelectionTask] = [\n    RoomSelectionTask(date=\"2025-10-15\", time=\"10:00\", duration_min=60, attendees=10),\n    RoomSelectionTask(date=\"2025-10-16\", time=\"10:00\", duration_min=60, attendees=10),\n]\n\nTrainer().fit(agent=room_selector, train_dataset=dataset)\n</code></pre> <p>Behind the scenes, the <code>@rollout</code> decorator wraps your function in a <code>FunctionalLitAgent</code> object, which is a subclass of LitAgent introduced below, making it compatible with the Trainer and Runner. It supports parameters like <code>task</code>, <code>prompt_template</code>, <code>llm</code>, and <code>rollout</code>, giving you flexible access to the execution context.</p> <p>Here is another example with more advanced usage with <code>llm</code> and <code>rollout</code> as parameters. The <code>llm</code> parameter gives you an OpenAI-compatible LLM endpoint to interact with, which can be tuned under the hood by algorithms. The <code>rollout</code> parameter gives you the full Rollout object, which contains the rollout ID, rollout mode (training or validation), etc.</p> <pre><code>from openai import OpenAI\nfrom agentlightning import LLM, Rollout\n\nclass FlightBookingTask(TypedDict):\n    request: str\n    expected_booking: dict\n\n@rollout\ndef flight_assistant(task: FlightBookingTask, llm: LLM, rollout: Rollout) -&gt; float:\n    print(f\"Rollout ID: {rollout.rollout_id}\")\n    print(f\"Rollout Mode: {rollout.mode}\")\n\n    # Use the tuned LLM resource to create an OpenAI client\n    client = OpenAI(\n        # This endpoint could be a proxy to a proxy to a proxy ...\n        # It could be different every time `flight_assistant` is called\n        # But it should be OpenAI-API compatible\n        base_url=llm.endpoint,\n\n        # Use a dummy key if not provided\n        # Usually this does not matter because the training LLM is often not guarded by an API key\n        # But you can use `or os.environ[\"OPENAI_API_KEY\"]` to make the function compatible with 3rd-party LLMs\n        api_key=llm.api_key or \"dummy-key\",\n    )\n\n    # Make an API call with the specified model\n    response = client.chat.completions.create(\n        model=llm.model,\n        messages=[{\"role\": \"user\", \"content\": task[\"request\"]}],\n    )\n    # Whether the API supports features like streaming, tool calls, etc. depends on\n    # the endpoint that algorithms are serving to you.\n    final_message = response.choices[0].message.content\n\n    # Grade the result and return a reward\n    reward = grade_flight_booking(final_message, task[\"expected_booking\"])\n    return reward\n</code></pre>"},{"location":"tutorials/write-agents/#return-values-from-agents","title":"Return Values from Agents","text":"<p>The value your agent function returns (i.e., the return value of the function decorated by <code>@rollout</code>) is crucial, as it's the primary way to report the outcome of a rollout. Agent-lightning supports several return types to accommodate different scenarios, from simple rewards to detailed, custom traces.</p> <ul> <li> <p><code>float</code>: This is the simplest and most common return type. The <code>float</code> is treated as the final reward for the entire rollout. Agent-lightning automatically creates a final reward span based on this value.</p> </li> <li> <p><code>None</code>: Returning <code>None</code> tells the runner that trace collection is being handled entirely by the Tracer through auto-instrumentation (e.g., via AgentOps). In this case, the runner will simply retrieve the spans that the tracer has already captured.</p> </li> </ul> <p>Emitting the Final Reward</p> <p>When returning <code>None</code>, you must still ensure a final reward is logged. You can do this by using the <code>emit_reward</code> function (covered in the Emitter section below) or by wrapping your reward calculation function with the <code>@reward</code> decorator.</p> <ul> <li><code>list[ReadableSpan]</code> or <code>list[Span]</code>: For advanced use cases, you can manually construct and return a complete list of all spans for the rollout. This gives you full control over the trace data. You can return either a list of OpenTelemetry <code>ReadableSpan</code> objects or Agent-lightning's native <code>Span</code> objects.</li> </ul> <p>For most users, returning a <code>float</code> for simple agents or returning <code>None</code> and using the emitter for more complex ones are the recommended approaches.</p>"},{"location":"tutorials/write-agents/#class-based-agents","title":"Class-based Agents","text":"<p>For more complex agents that require state, helper methods, or distinct logic for training versus validation, you can create a class that inherits from <code>LitAgent</code>. This object-oriented approach provides more structure and control over the agent's lifecycle.</p> <p>To create a class-based agent, you subclass agentlightning.LitAgent and implement its <code>rollout</code> method.</p> <p></p> <p>Here's how the <code>room_selector</code> could be implemented as a class. The rollout method has a slightly different signature than the function-based agent, mainly in how it handles the resources. Putting it simply, algorithms do not just send a PromptTemplate to the agents, they instead send NamedResources, which is a mapping from resource key to Resource. This design is to allow for more advanced features like multi-resource tuning.</p> <p>With <code>@rollout</code> decorator, the resource with correctly matched type will be automatically injected into the rollout method. However, when you use a class-based agent, you need to manually access the resource from the <code>resources</code> dictionary. Built-in algorithms listed their resource key naming conventions here.</p> <pre><code>import agentlightning as agl\n\nclass RoomSelectorAgent(agl.LitAgent[RoomSelectionTask]):\n    def rollout(self, task: RoomSelectionTask, resources: agl.NamedResources, rollout: agl.Rollout) -&gt; float:\n        # 1. Access the prompt_template from the resources dictionary\n        prompt_template = resources[\"prompt_template\"]\n\n        # 2. Execute the agent's logic\n        prompt = prompt_template.format(**task)\n        # ...\n\n        # 3. Grade the final choice\n        reward = room_selection_grader(final_message, task[\"expected_choice\"])\n\n        # 4. Return the final reward\n        return reward\n\n# To use it with the trainer:\n# agent = RoomSelectorAgent()\n# trainer.fit(agent=agent, ...)\n</code></pre> <p>The <code>LitAgent</code> class provides several methods you can override for more fine-grained control:</p> <ul> <li><code>rollout()</code>: The primary method for the agent's logic. It's called for both training and validation by default.</li> <li><code>training_rollout()</code> / <code>validation_rollout()</code>: Implement these if you need different behavior during training (e.g., with exploration) and validation (e.g., with deterministic choices).</li> <li><code>rollout_async()</code> / <code>training_rollout_async()</code> / <code>validation_rollout_async()</code>: Implement the asynchronous versions of these methods if your agent uses <code>asyncio</code>.</li> </ul> <p>Note</p> <p>Rollout is always executed in an asynchronous context no matter whether the agent is asynchronous or synchronous. If your synchronous agent contains some <code>asyncio.run()</code> calls, it might raise an error that there is already an event loop running. To avoid blocking the event loop, it's recommended to offload the inner async operations to a separate thread. Here is a sample code:</p> <pre><code>import asyncio\nimport queue\nimport threading\n\ndef run_sync_ephemeral(coro) -&gt; Any:\n    \"\"\"\n    Run an async coroutine from sync code.\n    - If no loop in this thread: use asyncio.run() directly.\n    - If already in an event loop: spawn a worker thread that calls asyncio.run()\n    (which creates and closes a brand-new event loop per call).\n    \"\"\"\n    try:\n        asyncio.get_running_loop()\n    except RuntimeError:\n        # No running loop in this thread; safe to use asyncio.run\n        return asyncio.run(coro)\n\n    # Already in a running loop -&gt; execute in a worker thread\n    q = queue.Queue[Any]()\n\n    def worker():\n        try:\n            result = asyncio.run(coro)  # creates &amp; closes its own loop\n            q.put((True, result))\n        except BaseException as e:\n            q.put((False, e))\n\n    t = threading.Thread(target=worker, daemon=True)\n    t.start()\n    ok, payload = q.get()\n    t.join()\n    if ok:\n        return payload\n    raise payload\n</code></pre>"},{"location":"tutorials/write-agents/#using-the-emitter","title":"Using the Emitter","text":"<p>While returning a single float for the final reward is sufficient for many algorithms, some advanced scenarios require richer feedback. For instance, an algorithm might learn more effectively if it receives intermediate rewards throughout a multi-step task.</p> <p>Agent-lightning provides an emitter module that allows you to record custom spans from within your agent's logic. Remember, the Tracer automatically instruments many common operations (like LLM calls), but the emitter is for your own, domain-specific events.</p> <p>You can find the emitter functions from agentlightning.emitter.</p>"},{"location":"tutorials/write-agents/#emitting-rewards-messages-and-more","title":"Emitting Rewards, Messages, and More","text":"<p>Here are the primary emitter functions:</p> <ul> <li><code>emit_reward(value: float)</code>: Records an intermediate reward.</li> <li><code>emit_message(message: str)</code>: Records a simple log message as a span.</li> <li><code>emit_exception(exception: BaseException)</code>: Records a Python exception, including its type, message, and stack trace.</li> <li><code>emit_object(obj: Any)</code>: Records any JSON-serializable object, perfect for structured data.</li> </ul> <p>Let's see an example of an agent using these emitters to provide detailed feedback.</p> <pre><code>import agentlightning as agl\n\n@agl.rollout\ndef multi_step_agent(task: dict, prompt_template: PromptTemplate) -&gt; float:\n    try:\n        # Step 1: Initial planning\n        agl.emit_message(\"Starting planning phase.\")\n        plan = generate_plan(task, prompt_template)\n        agl.emit_object({\"plan_steps\": len(plan), \"first_step\": plan[0]})\n\n        # Award a small reward for a valid plan\n        plan_reward = grade_plan(plan)\n        agl.emit_reward(plan_reward)\n\n        # Step 2: Execute the plan\n        agl.emit_message(f\"Executing {len(plan)}-step plan.\")\n        execution_result = execute_plan(plan)\n\n        # Step 3: Final evaluation\n        final_reward = custom_grade_final_result(execution_result, task[\"expected_output\"])\n\n        # The return value is treated as the final reward for the rollout\n        return final_reward\n\n    except ValueError as e:\n        # Record the specific error and return a failure reward\n        agl.emit_exception(e)\n        return 0.0\n</code></pre> <p>By using the emitter, you create a rich, detailed trace of your agent's execution. This data can be invaluable for debugging and is essential for advanced algorithms that can learn from more than just a single final score.</p>"}]}